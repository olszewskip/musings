{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import bs4 as bs\n",
    "import time\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv metadata harvester\n",
    "arXiv is an online repository of scientific pre-prints, see https://arxiv.org/help/general\n",
    "## Grab records from the requested timespan, from all or from one selected category\n",
    "\n",
    "## Write to tab-delimited local csv:\n",
    "## columns: *id, primary_category, sub_categories, title, abstract*\n",
    "(Dealing with funny characters in the names of authors was beyond me. One could also get a date associated with each record but it's supposed not to necessarily correspond to the date of posting by the authors.)\n",
    "### There are two functions; both will talk to You using prints:\n",
    "* *harvest_slice* needs You to explicitly choose the category (possibly 'all') and the filename as arguments\n",
    "    * just appends lines to the file, it's up to You not to make a mess\n",
    "    \n",
    "* *harvest_data* divides the timespan into slices of given length (367 days by default) and harvests those using *harvest_slice*:\n",
    "    * can make up the name of the file on its own\n",
    "    * adds the header to the csv\n",
    "    * default behavior when the file already exists is to quit\n",
    "    * default category is 'all'\n",
    "\n",
    "### It is slow.    \n",
    "### Examples:\n",
    "*  1 min,  2 MB >>> harvest_slice(\"2018-10-01\", \"2018-10-10\", \"math\", \"test.csv\")\n",
    "*  4 min, 11 MB >>> harvest_slice(\"2018-10-01\", \"2018-10-10\", \"all\", \"test.csv\")\n",
    "* 8 min, 16 MB >>> harvest_data(\"2018-08-01\", \"2018-11-01\", category=\"math\", file_name = \"test.csv\", overwrite=True)\n",
    "* 30 min, 68 MB >>> harvest_data(\"2018-08-01\", \"2018-11-01\")\n",
    "\n",
    "### Example of a basic query used in the code:\n",
    "* http://export.arxiv.org/oai2?verb=ListRecords&from=2012-01-01&until=2018-02-01&set=physics:hep-th&metadataPrefix=arXiv\n",
    "* \"http://export.arxiv.org/oai2?verb=ListSets\"\n",
    "\n",
    "See https://arxiv.org/help/bulk_data for more info "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each paper on arXive has assigned to it a single primary category, e.g. *cs* (Computer Science), *econ* (Economics), etc. We can retrieve the list of existing categories from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs': 'Computer Science',\n",
       " 'econ': 'Economics',\n",
       " 'eess': 'Electrical Engineering and Systems Science',\n",
       " 'math': 'Mathematics',\n",
       " 'physics': 'Physics',\n",
       " 'physics:astro-ph': 'Astrophysics',\n",
       " 'physics:cond-mat': 'Condensed Matter',\n",
       " 'physics:gr-qc': 'General Relativity and Quantum Cosmology',\n",
       " 'physics:hep-ex': 'High Energy Physics - Experiment',\n",
       " 'physics:hep-lat': 'High Energy Physics - Lattice',\n",
       " 'physics:hep-ph': 'High Energy Physics - Phenomenology',\n",
       " 'physics:hep-th': 'High Energy Physics - Theory',\n",
       " 'physics:math-ph': 'Mathematical Physics',\n",
       " 'physics:nlin': 'Nonlinear Sciences',\n",
       " 'physics:nucl-ex': 'Nuclear Experiment',\n",
       " 'physics:nucl-th': 'Nuclear Theory',\n",
       " 'physics:physics': 'Physics (Other)',\n",
       " 'physics:quant-ph': 'Quantum Physics',\n",
       " 'q-bio': 'Quantitative Biology',\n",
       " 'q-fin': 'Quantitative Finance',\n",
       " 'stat': 'Statistics'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The query retrieves short xml meta-metadata containing info\n",
    "# about the accesible arXiv categories of topics called 'sets', e.g.\n",
    "# <set>\n",
    "# <setspec>cs</setspec>\n",
    "# <setname>Computer Science</setname>\n",
    "# </set>\n",
    "\n",
    "\n",
    "if not Path(\"categories.txt\").is_file() :\n",
    "    \n",
    "    xml_query = \"http://export.arxiv.org/oai2?verb=ListSets\"\n",
    "    sauce = urllib.request.urlopen(xml_query).read()\n",
    "    soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "    sets = soup.find_all(\"set\")\n",
    "\n",
    "    categories = {}\n",
    "\n",
    "    for set_ in sets:\n",
    "        categories[set_.setspec.string] = set_.setname.string\n",
    "\n",
    "    with open(\"categories.txt\", \"w\") as file:\n",
    "        for category, description in categories.items():\n",
    "            file.write(\"\".join([category,\"\\t\" , description, \"\\n\"]))\n",
    "            \n",
    "\n",
    "categories = {}\n",
    "with open(\"categories.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        category, description = line.rstrip('\\n').split('\\t')\n",
    "        categories[category] = description\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The matter of categories is actually more messy, I think. The primary and secondary categorizations chosen by an author may be finer, e.g. *cs.ai* (Computer Science: Artificial Intelligence) instead of just *cs*, etc.\n",
    "\n",
    "### What You see above are just names of *sets* that can be used in the API queries. Apparently physics enthusiasts get more options. Also *Economics* and *Electrical Engineering* start only in 2017 (I've checked).\n",
    "\n",
    "### Lets treat *physics* as a single category for consistency, and let's exclude *econ* and *eess*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs': 'Computer Science',\n",
       " 'math': 'Mathematics',\n",
       " 'physics': 'Physics',\n",
       " 'q-bio': 'Quantitative Biology',\n",
       " 'q-fin': 'Quantitative Finance',\n",
       " 'stat': 'Statistics'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = {cat: cat_name for (cat, cat_name) in categories.items() if cat not in  ['econ' ,'eess'] and not re.match(r'physics:.+', cat)}\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvest_slice(date_from, date_until, category, file) -> int:\n",
    "    # returns -1 if unsuccesful\n",
    "    # returns number of downloaded records if succesful\n",
    "    \n",
    "    base_query = \"http://export.arxiv.org/oai2?verb=ListRecords\"\n",
    "    \n",
    "    if category == \"all\":\n",
    "        query = base_query + f\"&from={date_from}&until={date_until}&metadataPrefix=arXiv\"\n",
    "    else:\n",
    "        query = base_query + f\"&from={date_from}&until={date_until}&set={category}&metadataPrefix=arXiv\"\n",
    "    \n",
    "    retrieved = 0\n",
    "    \n",
    "    while query:\n",
    "        \n",
    "        time_0 = time.time()\n",
    "        \n",
    "        # try to download\n",
    "        try:            \n",
    "            sauce = urllib.request.urlopen(query).read()\n",
    "\n",
    "        except:\n",
    "            print(f\"Failed at: {category} from {date_from} until {date_until} requesting {query}\\n\")\n",
    "            return -1\n",
    "        \n",
    "        # parse the xml looking for <record>'s\n",
    "        soup = bs.BeautifulSoup(sauce, 'lxml')\n",
    "        records = soup.find_all('record')\n",
    "\n",
    "        retrieved = retrieved + len(records)\n",
    "\n",
    "        with open(file, \"a\") as dump:\n",
    "\n",
    "            writer = csv.writer(dump, delimiter='\\t')\n",
    "            for record in records:                \n",
    "                record_string = [record.id.string,\n",
    "                                 record.setspec.string,\n",
    "                                 record.categories.string,\n",
    "                                 record.title.string,\n",
    "                                 record.abstract.string\n",
    "                                ]\n",
    "                writer.writerow(record_string)\n",
    "        \n",
    "        if len(records) == 0:\n",
    "            print(\"\".join([category,\" from \", f\"{date_from}\",\" until \", f\"{date_until}\",\" empty\"]))\n",
    "            break\n",
    "        \n",
    "        # info at the end of 'soup' about where to resume if the data stream was cut at 1000 records\n",
    "        # None if the stream wasn't cut\n",
    "        res_token = soup.find(\"resumptiontoken\")\n",
    "        \n",
    "        if res_token:\n",
    "\n",
    "            # data in the current loop started at this record in the 'query'\n",
    "            started_at = int(res_token['cursor']) + 1\n",
    "            \n",
    "            # total number of records in the 'query', should be the same in each loop\n",
    "            all_to_retrieve = int(res_token['completelistsize'])\n",
    "            \n",
    "            if res_token.string:\n",
    "                # the identifier that allows to resume the query\n",
    "                # None if the slice was completed\n",
    "\n",
    "                query = base_query + f\"&resumptionToken={res_token.string}\"\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                query = None\n",
    "            \n",
    "        else:\n",
    "            started_at = 1 \n",
    "            all_to_retrieve = len(records)\n",
    "            query = None\n",
    "        \n",
    "        time_1 = time.time()\n",
    "        \n",
    "        print(\"\".join([category,\n",
    "                       \" from \", f\"{date_from}\", \" until \", f\"{date_until}\",\n",
    "                       f\" ({started_at:>5}-{started_at+len(records)-1:>5})/{all_to_retrieve:>5}\",\n",
    "                      \" in \", f\"{(time_1 - time_0):3.2f}\", \"s\"]) )\n",
    "    \n",
    "    # end of while loop\n",
    "     \n",
    "    return retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math from 2018-10-01 until 2018-10-10 (    1- 1000)/ 2363 in 29.96s\n",
      "math from 2018-10-01 until 2018-10-10 ( 1001- 2000)/ 2363 in 27.36s\n",
      "math from 2018-10-01 until 2018-10-10 ( 2001- 2363)/ 2363 in 6.40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvest_slice(\"2018-10-01\", \"2018-10-10\", \"math\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all from 2018-10-01 until 2018-10-10 (    1- 1000)/ 7663 in 32.15s\n",
      "all from 2018-10-01 until 2018-10-10 ( 1001- 2000)/ 7663 in 25.72s\n",
      "all from 2018-10-01 until 2018-10-10 ( 2001- 3000)/ 7663 in 26.29s\n",
      "all from 2018-10-01 until 2018-10-10 ( 3001- 4000)/ 7663 in 25.64s\n",
      "all from 2018-10-01 until 2018-10-10 ( 4001- 5000)/ 7663 in 24.63s\n",
      "all from 2018-10-01 until 2018-10-10 ( 5001- 6000)/ 7663 in 24.01s\n",
      "all from 2018-10-01 until 2018-10-10 ( 6001- 7000)/ 7663 in 25.05s\n",
      "all from 2018-10-01 until 2018-10-10 ( 7001- 7663)/ 7663 in 10.29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7663"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvest_slice(\"2018-10-01\", \"2018-10-10\", \"all\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper around harvest_slice\n",
    "# handles file-names\n",
    "# slices the time period of papers to avoid maxing-out the response from server\n",
    "def harvest_data(isoday_0, isoday_1, category='all', days_in_slice = 367, file_name=None, overwrite=False) -> int:\n",
    "\n",
    "    date_0 = dateutil.parser.parse(isoday_0).date()\n",
    "    date_1 = dateutil.parser.parse(isoday_1).date()\n",
    "\n",
    "    if not file_name:\n",
    "        # create a file with an overly descriptive name\n",
    "        file = f\"arXivMeta_{category.replace(':','--')}_from_{date_0}_to_{date_1}.csv\"\n",
    "    else:\n",
    "        file = file_name\n",
    "    \n",
    "    # check if file already exists\n",
    "    if Path(file).is_file():\n",
    "        if overwrite :\n",
    "\n",
    "            # try to backup the old file\n",
    "            file_info = re.match(r\"(\\w.+)\\.(\\w\\w+)\", file)\n",
    "            if file_info:\n",
    "                new_file = \"\".join([ file_info.group(1), \"_bak.\", file_info.group(2) ])\n",
    "                if not Path(new_file).is_file():\n",
    "                    os.rename(file, new_file)\n",
    "                    print(f\"Old file backed up as {new_file}\")\n",
    "\n",
    "            # clear the file\n",
    "            print(f\"Overwriting {file}\\n\")\n",
    "            with open(file, \"w\") as dump:\n",
    "                dump.truncate(0)\n",
    "            \n",
    "        else:\n",
    "            print(f\"The file {file} already exists\")\n",
    "            return -1\n",
    "    \n",
    "    else:\n",
    "        print(f\"Writing to {file}\\n\")\n",
    "    \n",
    "    with open(file, \"a\") as dump:\n",
    "            writer = csv.writer(dump, delimiter='\\t')\n",
    "            header = ['id', 'prim_cat', 'sec_cats', 'title', 'abstract']\n",
    "            writer.writerow(header)\n",
    "    \n",
    "    # Star the clock\n",
    "    time_0 = time.time()\n",
    "    \n",
    "    # Let's count all downloaded records\n",
    "    retrieved = 0\n",
    "    \n",
    "    # We'll go from 'date_0' until 'date_1' in slices of 'days_in_slice' days\n",
    "    # The server's response presumably maxes out at some number of records,\n",
    "    # so we hope to have slices with less records than that.\n",
    "\n",
    "    date_from = date_0\n",
    "\n",
    "    while date_from <= date_1:\n",
    "        \n",
    "        date_until = min(date_1, date_from + datetime.timedelta(days_in_slice-1))\n",
    "\n",
    "        # try to download the slice\n",
    "        newly_retrieved = harvest_slice(date_from, date_until, category, file)\n",
    "        \n",
    "        if newly_retrieved == -1:\n",
    "            break\n",
    "        \n",
    "        retrieved = retrieved + newly_retrieved\n",
    "\n",
    "        # move on to the next slice\n",
    "        date_from = date_until + datetime.timedelta(days=1)\n",
    "        time.sleep(10)\n",
    "\n",
    "    time_1 = time.time()\n",
    "    \n",
    "    print(\"\".join([category,\n",
    "                   \" from \", str(date_0), \" until \", str(date_1),\n",
    "                   \" retrieved \", str(retrieved), \" records\"\n",
    "                   ,\" in \", f\"{(time_1 - time_0)/60:.0f}\", \" min\"])\n",
    "         )\n",
    "    \n",
    "    return retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to test.csv\n",
      "\n",
      "math from 2018-08-01 until 2018-11-01 (    1- 1000)/18739 in 26.22s\n",
      "math from 2018-08-01 until 2018-11-01 ( 1001- 2000)/18739 in 26.94s\n",
      "math from 2018-08-01 until 2018-11-01 ( 2001- 3000)/18739 in 27.15s\n",
      "math from 2018-08-01 until 2018-11-01 ( 3001- 4000)/18739 in 24.76s\n",
      "math from 2018-08-01 until 2018-11-01 ( 4001- 5000)/18739 in 26.61s\n",
      "math from 2018-08-01 until 2018-11-01 ( 5001- 6000)/18739 in 24.70s\n",
      "math from 2018-08-01 until 2018-11-01 ( 6001- 7000)/18739 in 24.08s\n",
      "math from 2018-08-01 until 2018-11-01 ( 7001- 8000)/18739 in 26.17s\n",
      "math from 2018-08-01 until 2018-11-01 ( 8001- 9000)/18739 in 23.18s\n",
      "math from 2018-08-01 until 2018-11-01 ( 9001-10000)/18739 in 24.53s\n",
      "math from 2018-08-01 until 2018-11-01 (10001-11000)/18739 in 24.96s\n",
      "math from 2018-08-01 until 2018-11-01 (11001-12000)/18739 in 23.93s\n",
      "math from 2018-08-01 until 2018-11-01 (12001-13000)/18739 in 23.57s\n",
      "math from 2018-08-01 until 2018-11-01 (13001-14000)/18739 in 22.86s\n",
      "math from 2018-08-01 until 2018-11-01 (14001-15000)/18739 in 23.51s\n",
      "math from 2018-08-01 until 2018-11-01 (15001-16000)/18739 in 22.78s\n",
      "math from 2018-08-01 until 2018-11-01 (16001-17000)/18739 in 23.27s\n",
      "math from 2018-08-01 until 2018-11-01 (17001-18000)/18739 in 22.73s\n",
      "math from 2018-08-01 until 2018-11-01 (18001-18739)/18739 in 10.13s\n",
      "math from 2018-08-01 until 2018-11-01 retrieved 18739 records in   8min\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18739"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvest_data(\"2018-08-01\", \"2018-11-01\", category=\"math\", file_name = \"test.csv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_all_from_2018-08-01_to_2018-11-01.csv\n",
      "\n",
      "all from 2018-08-01 until 2018-11-01 (    1- 1000)/61276 in 26.90s\n",
      "all from 2018-08-01 until 2018-11-01 ( 1001- 2000)/61276 in 27.15s\n",
      "all from 2018-08-01 until 2018-11-01 ( 2001- 3000)/61276 in 27.79s\n",
      "all from 2018-08-01 until 2018-11-01 ( 3001- 4000)/61276 in 28.60s\n",
      "all from 2018-08-01 until 2018-11-01 ( 4001- 5000)/61276 in 41.76s\n",
      "all from 2018-08-01 until 2018-11-01 ( 5001- 6000)/61276 in 28.32s\n",
      "all from 2018-08-01 until 2018-11-01 ( 6001- 7000)/61276 in 26.41s\n",
      "all from 2018-08-01 until 2018-11-01 ( 7001- 8000)/61276 in 27.18s\n",
      "all from 2018-08-01 until 2018-11-01 ( 8001- 9000)/61276 in 30.19s\n",
      "all from 2018-08-01 until 2018-11-01 ( 9001-10000)/61276 in 29.14s\n",
      "all from 2018-08-01 until 2018-11-01 (10001-11000)/61276 in 30.14s\n",
      "all from 2018-08-01 until 2018-11-01 (11001-12000)/61276 in 27.50s\n",
      "all from 2018-08-01 until 2018-11-01 (12001-13000)/61276 in 26.80s\n",
      "all from 2018-08-01 until 2018-11-01 (13001-14000)/61276 in 72.56s\n",
      "all from 2018-08-01 until 2018-11-01 (14001-15000)/61276 in 27.83s\n",
      "all from 2018-08-01 until 2018-11-01 (15001-16000)/61276 in 28.64s\n",
      "all from 2018-08-01 until 2018-11-01 (16001-17000)/61276 in 27.29s\n",
      "all from 2018-08-01 until 2018-11-01 (17001-18000)/61276 in 28.67s\n",
      "all from 2018-08-01 until 2018-11-01 (18001-19000)/61276 in 30.01s\n",
      "all from 2018-08-01 until 2018-11-01 (19001-20000)/61276 in 27.59s\n",
      "all from 2018-08-01 until 2018-11-01 (20001-21000)/61276 in 30.23s\n",
      "all from 2018-08-01 until 2018-11-01 (21001-22000)/61276 in 31.88s\n",
      "all from 2018-08-01 until 2018-11-01 (22001-23000)/61276 in 26.92s\n",
      "all from 2018-08-01 until 2018-11-01 (23001-24000)/61276 in 29.73s\n",
      "all from 2018-08-01 until 2018-11-01 (24001-25000)/61276 in 28.47s\n",
      "all from 2018-08-01 until 2018-11-01 (25001-26000)/61276 in 28.55s\n",
      "all from 2018-08-01 until 2018-11-01 (26001-27000)/61276 in 28.14s\n",
      "all from 2018-08-01 until 2018-11-01 (27001-28000)/61276 in 26.14s\n",
      "all from 2018-08-01 until 2018-11-01 (28001-29000)/61276 in 27.20s\n",
      "all from 2018-08-01 until 2018-11-01 (29001-30000)/61276 in 25.48s\n",
      "all from 2018-08-01 until 2018-11-01 (30001-31000)/61276 in 25.42s\n",
      "all from 2018-08-01 until 2018-11-01 (31001-32000)/61276 in 25.41s\n",
      "all from 2018-08-01 until 2018-11-01 (32001-33000)/61276 in 25.96s\n",
      "all from 2018-08-01 until 2018-11-01 (33001-34000)/61276 in 25.73s\n",
      "all from 2018-08-01 until 2018-11-01 (34001-35000)/61276 in 25.34s\n",
      "all from 2018-08-01 until 2018-11-01 (35001-36000)/61276 in 25.65s\n",
      "all from 2018-08-01 until 2018-11-01 (36001-37000)/61276 in 33.56s\n",
      "all from 2018-08-01 until 2018-11-01 (37001-38000)/61276 in 25.57s\n",
      "all from 2018-08-01 until 2018-11-01 (38001-39000)/61276 in 24.94s\n",
      "all from 2018-08-01 until 2018-11-01 (39001-40000)/61276 in 23.84s\n",
      "all from 2018-08-01 until 2018-11-01 (40001-41000)/61276 in 24.87s\n",
      "all from 2018-08-01 until 2018-11-01 (41001-42000)/61276 in 24.44s\n",
      "all from 2018-08-01 until 2018-11-01 (42001-43000)/61276 in 24.66s\n",
      "all from 2018-08-01 until 2018-11-01 (43001-44000)/61276 in 25.41s\n",
      "all from 2018-08-01 until 2018-11-01 (44001-45000)/61276 in 24.67s\n",
      "all from 2018-08-01 until 2018-11-01 (45001-46000)/61276 in 23.98s\n",
      "all from 2018-08-01 until 2018-11-01 (46001-47000)/61276 in 25.46s\n",
      "all from 2018-08-01 until 2018-11-01 (47001-48000)/61276 in 25.48s\n",
      "all from 2018-08-01 until 2018-11-01 (48001-49000)/61276 in 24.75s\n",
      "all from 2018-08-01 until 2018-11-01 (49001-50000)/61276 in 25.54s\n",
      "all from 2018-08-01 until 2018-11-01 (50001-51000)/61276 in 25.93s\n",
      "all from 2018-08-01 until 2018-11-01 (51001-52000)/61276 in 24.73s\n",
      "all from 2018-08-01 until 2018-11-01 (52001-53000)/61276 in 24.43s\n",
      "all from 2018-08-01 until 2018-11-01 (53001-54000)/61276 in 23.98s\n",
      "all from 2018-08-01 until 2018-11-01 (54001-55000)/61276 in 23.98s\n",
      "all from 2018-08-01 until 2018-11-01 (55001-56000)/61276 in 24.45s\n",
      "all from 2018-08-01 until 2018-11-01 (56001-57000)/61276 in 23.88s\n",
      "all from 2018-08-01 until 2018-11-01 (57001-58000)/61276 in 23.92s\n",
      "all from 2018-08-01 until 2018-11-01 (58001-59000)/61276 in 24.99s\n",
      "all from 2018-08-01 until 2018-11-01 (59001-60000)/61276 in 34.16s\n",
      "all from 2018-08-01 until 2018-11-01 (60001-61000)/61276 in 23.68s\n",
      "all from 2018-08-01 until 2018-11-01 (61001-61276)/61276 in 15.13s\n",
      "all from 2018-08-01 until 2018-11-01 retrieved 61276 records in 29min\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61276"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harvest_data(\"2018-08-01\", \"2018-11-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cs': 'Computer Science',\n",
       " 'math': 'Mathematics',\n",
       " 'physics': 'Physics',\n",
       " 'q-bio': 'Quantitative Biology',\n",
       " 'q-fin': 'Quantitative Finance',\n",
       " 'stat': 'Statistics'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_stat_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "stat from 2015-01-01 until 2015-12-31 (    1- 1000)/ 4847 in 27.61s\n",
      "stat from 2015-01-01 until 2015-12-31 ( 1001- 2000)/ 4847 in 27.32s\n",
      "stat from 2015-01-01 until 2015-12-31 ( 2001- 3000)/ 4847 in 25.01s\n",
      "stat from 2015-01-01 until 2015-12-31 ( 3001- 4000)/ 4847 in 25.59s\n",
      "stat from 2015-01-01 until 2015-12-31 ( 4001- 4847)/ 4847 in 13.94s\n",
      "stat from 2015-01-01 until 2015-12-31 retrieved 4847 records in 2 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4847"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'stat'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old file backed up as arXivMeta_stat_from_2012-01-01_to_2014-12-31_bak.csv\n",
      "Overwriting arXivMeta_stat_from_2012-01-01_to_2014-12-31.csv\n",
      "\n",
      "Failed at: stat from 2012-01-01 until 2012-12-31 requesting http://export.arxiv.org/oai2?verb=ListRecords&from=2012-01-01&until=2012-12-31&set=stat&metadataPrefix=arXiv\n",
      "\n",
      "stat from 2012-01-01 until 2014-12-31 retrieved 0 records in 0 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year0 = 2012\n",
    "year1 = 2014\n",
    "cat = 'stat'\n",
    "harvest_data(f\"{year0}-01-01\", f\"{year1}-12-31\", category=cat, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_q-fin_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "q-fin from 2015-01-01 until 2015-12-31 (    1- 1000)/ 1118 in 24.65s\n",
      "q-fin from 2015-01-01 until 2015-12-31 ( 1001- 1118)/ 1118 in 3.77s\n",
      "q-fin from 2015-01-01 until 2015-12-31 retrieved 1118 records in 1 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1118"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'q-fin'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old file backed up as arXivMeta_q-fin_from_2012-01-01_to_2014-12-31_bak.csv\n",
      "Overwriting arXivMeta_q-fin_from_2012-01-01_to_2014-12-31.csv\n",
      "\n",
      "Failed at: q-fin from 2012-01-01 until 2012-12-31 requesting http://export.arxiv.org/oai2?verb=ListRecords&from=2012-01-01&until=2012-12-31&set=q-fin&metadataPrefix=arXiv\n",
      "\n",
      "q-fin from 2012-01-01 until 2014-12-31 retrieved 0 records in 0 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year0 = 2012\n",
    "year1 = 2014\n",
    "cat = 'q-fin'\n",
    "harvest_data(f\"{year0}-01-01\", f\"{year1}-12-31\", category=cat, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_q-bio_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "q-bio from 2015-01-01 until 2015-12-31 (    1- 1000)/ 3633 in 27.92s\n",
      "q-bio from 2015-01-01 until 2015-12-31 ( 1001- 2000)/ 3633 in 27.71s\n",
      "q-bio from 2015-01-01 until 2015-12-31 ( 2001- 3000)/ 3633 in 25.48s\n",
      "q-bio from 2015-01-01 until 2015-12-31 ( 3001- 3633)/ 3633 in 11.02s\n",
      "q-bio from 2015-01-01 until 2015-12-31 retrieved 3633 records in 2 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3633"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'q-bio'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_q-bio_from_2012-01-01_to_2014-12-31.csv\n",
      "\n",
      "Failed at: q-bio from 2012-01-01 until 2012-12-31 requesting http://export.arxiv.org/oai2?verb=ListRecords&from=2012-01-01&until=2012-12-31&set=q-bio&metadataPrefix=arXiv\n",
      "\n",
      "q-bio from 2012-01-01 until 2014-12-31 retrieved 0 records in 0 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year0 = 2012\n",
    "year1 = 2014\n",
    "cat = 'q-bio'\n",
    "harvest_data(f\"{year0}-01-01\", f\"{year1}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_cs_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "cs from 2015-01-01 until 2015-12-31 (    1- 1000)/20442 in 28.37s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 1001- 2000)/20442 in 27.26s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 2001- 3000)/20442 in 26.66s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 3001- 4000)/20442 in 33.14s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 4001- 5000)/20442 in 27.91s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 5001- 6000)/20442 in 25.80s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 6001- 7000)/20442 in 26.08s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 7001- 8000)/20442 in 24.76s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 8001- 9000)/20442 in 25.76s\n",
      "cs from 2015-01-01 until 2015-12-31 ( 9001-10000)/20442 in 26.13s\n",
      "cs from 2015-01-01 until 2015-12-31 (10001-11000)/20442 in 25.30s\n",
      "cs from 2015-01-01 until 2015-12-31 (11001-12000)/20442 in 25.18s\n",
      "cs from 2015-01-01 until 2015-12-31 (12001-13000)/20442 in 24.68s\n",
      "cs from 2015-01-01 until 2015-12-31 (13001-14000)/20442 in 24.82s\n",
      "cs from 2015-01-01 until 2015-12-31 (14001-15000)/20442 in 24.69s\n",
      "cs from 2015-01-01 until 2015-12-31 (15001-16000)/20442 in 24.95s\n",
      "cs from 2015-01-01 until 2015-12-31 (16001-17000)/20442 in 27.05s\n",
      "cs from 2015-01-01 until 2015-12-31 (17001-18000)/20442 in 24.20s\n",
      "cs from 2015-01-01 until 2015-12-31 (18001-19000)/20442 in 24.43s\n",
      "cs from 2015-01-01 until 2015-12-31 (19001-20000)/20442 in 24.02s\n",
      "cs from 2015-01-01 until 2015-12-31 (20001-20442)/20442 in 7.77s\n",
      "cs from 2015-01-01 until 2015-12-31 retrieved 20442 records in 9 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20442"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'cs'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_math_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "math from 2015-01-01 until 2015-12-31 (    1- 1000)/45052 in 27.74s\n",
      "math from 2015-01-01 until 2015-12-31 ( 1001- 2000)/45052 in 25.26s\n",
      "math from 2015-01-01 until 2015-12-31 ( 2001- 3000)/45052 in 23.18s\n",
      "math from 2015-01-01 until 2015-12-31 ( 3001- 4000)/45052 in 24.57s\n",
      "math from 2015-01-01 until 2015-12-31 ( 4001- 5000)/45052 in 25.77s\n",
      "math from 2015-01-01 until 2015-12-31 ( 5001- 6000)/45052 in 26.72s\n",
      "math from 2015-01-01 until 2015-12-31 ( 6001- 7000)/45052 in 24.42s\n",
      "math from 2015-01-01 until 2015-12-31 ( 7001- 8000)/45052 in 25.21s\n",
      "math from 2015-01-01 until 2015-12-31 ( 8001- 9000)/45052 in 24.86s\n",
      "math from 2015-01-01 until 2015-12-31 ( 9001-10000)/45052 in 26.47s\n",
      "math from 2015-01-01 until 2015-12-31 (10001-11000)/45052 in 26.96s\n",
      "math from 2015-01-01 until 2015-12-31 (11001-12000)/45052 in 26.23s\n",
      "math from 2015-01-01 until 2015-12-31 (12001-13000)/45052 in 29.02s\n",
      "math from 2015-01-01 until 2015-12-31 (13001-14000)/45052 in 27.12s\n",
      "math from 2015-01-01 until 2015-12-31 (14001-15000)/45052 in 27.91s\n",
      "math from 2015-01-01 until 2015-12-31 (15001-16000)/45052 in 27.96s\n",
      "math from 2015-01-01 until 2015-12-31 (16001-17000)/45052 in 27.22s\n",
      "math from 2015-01-01 until 2015-12-31 (17001-18000)/45052 in 29.39s\n",
      "math from 2015-01-01 until 2015-12-31 (18001-19000)/45052 in 25.92s\n",
      "math from 2015-01-01 until 2015-12-31 (19001-20000)/45052 in 26.26s\n",
      "math from 2015-01-01 until 2015-12-31 (20001-21000)/45052 in 24.82s\n",
      "math from 2015-01-01 until 2015-12-31 (21001-22000)/45052 in 23.89s\n",
      "math from 2015-01-01 until 2015-12-31 (22001-23000)/45052 in 24.46s\n",
      "math from 2015-01-01 until 2015-12-31 (23001-24000)/45052 in 23.04s\n",
      "math from 2015-01-01 until 2015-12-31 (24001-25000)/45052 in 22.05s\n",
      "math from 2015-01-01 until 2015-12-31 (25001-26000)/45052 in 23.11s\n",
      "math from 2015-01-01 until 2015-12-31 (26001-27000)/45052 in 23.19s\n",
      "math from 2015-01-01 until 2015-12-31 (27001-28000)/45052 in 22.74s\n",
      "math from 2015-01-01 until 2015-12-31 (28001-29000)/45052 in 23.88s\n",
      "math from 2015-01-01 until 2015-12-31 (29001-30000)/45052 in 26.46s\n",
      "math from 2015-01-01 until 2015-12-31 (30001-31000)/45052 in 23.46s\n",
      "math from 2015-01-01 until 2015-12-31 (31001-32000)/45052 in 23.36s\n",
      "math from 2015-01-01 until 2015-12-31 (32001-33000)/45052 in 22.48s\n",
      "math from 2015-01-01 until 2015-12-31 (33001-34000)/45052 in 22.81s\n",
      "math from 2015-01-01 until 2015-12-31 (34001-35000)/45052 in 23.47s\n",
      "math from 2015-01-01 until 2015-12-31 (35001-36000)/45052 in 24.09s\n",
      "math from 2015-01-01 until 2015-12-31 (36001-37000)/45052 in 23.47s\n",
      "math from 2015-01-01 until 2015-12-31 (37001-38000)/45052 in 23.54s\n",
      "math from 2015-01-01 until 2015-12-31 (38001-39000)/45052 in 23.30s\n",
      "math from 2015-01-01 until 2015-12-31 (39001-40000)/45052 in 22.99s\n",
      "math from 2015-01-01 until 2015-12-31 (40001-41000)/45052 in 23.56s\n",
      "math from 2015-01-01 until 2015-12-31 (41001-42000)/45052 in 24.50s\n",
      "math from 2015-01-01 until 2015-12-31 (42001-43000)/45052 in 23.58s\n",
      "math from 2015-01-01 until 2015-12-31 (43001-44000)/45052 in 26.20s\n",
      "math from 2015-01-01 until 2015-12-31 (44001-45000)/45052 in 26.22s\n",
      "math from 2015-01-01 until 2015-12-31 (45001-45052)/45052 in 3.33s\n",
      "math from 2015-01-01 until 2015-12-31 retrieved 45052 records in 19 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45052"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'math'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-12-31\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to arXivMeta_physics_from_2015-01-01_to_2015-12-31.csv\n",
      "\n",
      "physics from 2015-01-01 until 2015-12-31 (    1- 1000)/170251 in 28.50s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 1001- 2000)/170251 in 27.58s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 2001- 3000)/170251 in 26.90s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 3001- 4000)/170251 in 27.16s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 4001- 5000)/170251 in 25.46s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 5001- 6000)/170251 in 26.21s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 6001- 7000)/170251 in 26.06s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 7001- 8000)/170251 in 26.87s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 8001- 9000)/170251 in 27.72s\n",
      "physics from 2015-01-01 until 2015-12-31 ( 9001-10000)/170251 in 28.31s\n",
      "physics from 2015-01-01 until 2015-12-31 (10001-11000)/170251 in 28.09s\n",
      "physics from 2015-01-01 until 2015-12-31 (11001-12000)/170251 in 26.01s\n",
      "physics from 2015-01-01 until 2015-12-31 (12001-13000)/170251 in 25.33s\n",
      "physics from 2015-01-01 until 2015-12-31 (13001-14000)/170251 in 25.96s\n",
      "physics from 2015-01-01 until 2015-12-31 (14001-15000)/170251 in 26.46s\n",
      "physics from 2015-01-01 until 2015-12-31 (15001-16000)/170251 in 26.62s\n",
      "physics from 2015-01-01 until 2015-12-31 (16001-17000)/170251 in 26.65s\n",
      "physics from 2015-01-01 until 2015-12-31 (17001-18000)/170251 in 28.16s\n",
      "physics from 2015-01-01 until 2015-12-31 (18001-19000)/170251 in 28.77s\n",
      "physics from 2015-01-01 until 2015-12-31 (19001-20000)/170251 in 26.13s\n",
      "physics from 2015-01-01 until 2015-12-31 (20001-21000)/170251 in 30.86s\n",
      "physics from 2015-01-01 until 2015-12-31 (21001-22000)/170251 in 28.32s\n",
      "physics from 2015-01-01 until 2015-12-31 (22001-23000)/170251 in 26.95s\n",
      "physics from 2015-01-01 until 2015-12-31 (23001-24000)/170251 in 27.09s\n",
      "physics from 2015-01-01 until 2015-12-31 (24001-25000)/170251 in 25.93s\n",
      "physics from 2015-01-01 until 2015-12-31 (25001-26000)/170251 in 28.33s\n",
      "physics from 2015-01-01 until 2015-12-31 (26001-27000)/170251 in 26.79s\n",
      "physics from 2015-01-01 until 2015-12-31 (27001-28000)/170251 in 26.36s\n",
      "physics from 2015-01-01 until 2015-12-31 (28001-29000)/170251 in 26.62s\n",
      "physics from 2015-01-01 until 2015-12-31 (29001-30000)/170251 in 33.12s\n",
      "physics from 2015-01-01 until 2015-12-31 (30001-31000)/170251 in 28.99s\n",
      "physics from 2015-01-01 until 2015-12-31 (31001-32000)/170251 in 44.52s\n",
      "physics from 2015-01-01 until 2015-12-31 (32001-33000)/170251 in 28.87s\n",
      "physics from 2015-01-01 until 2015-12-31 (33001-34000)/170251 in 29.75s\n",
      "physics from 2015-01-01 until 2015-12-31 (34001-35000)/170251 in 28.88s\n",
      "physics from 2015-01-01 until 2015-12-31 (35001-36000)/170251 in 29.22s\n",
      "physics from 2015-01-01 until 2015-12-31 (36001-37000)/170251 in 28.44s\n",
      "physics from 2015-01-01 until 2015-12-31 (37001-38000)/170251 in 28.65s\n",
      "physics from 2015-01-01 until 2015-12-31 (38001-39000)/170251 in 27.96s\n",
      "physics from 2015-01-01 until 2015-12-31 (39001-40000)/170251 in 30.77s\n",
      "physics from 2015-01-01 until 2015-12-31 (40001-41000)/170251 in 31.36s\n",
      "physics from 2015-01-01 until 2015-12-31 (41001-42000)/170251 in 35.01s\n",
      "physics from 2015-01-01 until 2015-12-31 (42001-43000)/170251 in 29.21s\n",
      "physics from 2015-01-01 until 2015-12-31 (43001-44000)/170251 in 29.66s\n",
      "physics from 2015-01-01 until 2015-12-31 (44001-45000)/170251 in 27.94s\n",
      "physics from 2015-01-01 until 2015-12-31 (45001-46000)/170251 in 29.81s\n",
      "physics from 2015-01-01 until 2015-12-31 (46001-47000)/170251 in 28.97s\n",
      "physics from 2015-01-01 until 2015-12-31 (47001-48000)/170251 in 28.68s\n",
      "physics from 2015-01-01 until 2015-12-31 (48001-49000)/170251 in 27.14s\n",
      "physics from 2015-01-01 until 2015-12-31 (49001-50000)/170251 in 27.79s\n",
      "physics from 2015-01-01 until 2015-12-31 (50001-51000)/170251 in 26.86s\n",
      "physics from 2015-01-01 until 2015-12-31 (51001-52000)/170251 in 28.55s\n",
      "physics from 2015-01-01 until 2015-12-31 (52001-53000)/170251 in 26.05s\n",
      "physics from 2015-01-01 until 2015-12-31 (53001-54000)/170251 in 30.10s\n",
      "physics from 2015-01-01 until 2015-12-31 (54001-55000)/170251 in 26.95s\n",
      "physics from 2015-01-01 until 2015-12-31 (55001-56000)/170251 in 26.99s\n",
      "physics from 2015-01-01 until 2015-12-31 (56001-57000)/170251 in 27.97s\n",
      "physics from 2015-01-01 until 2015-12-31 (57001-58000)/170251 in 27.37s\n",
      "physics from 2015-01-01 until 2015-12-31 (58001-59000)/170251 in 26.55s\n",
      "physics from 2015-01-01 until 2015-12-31 (59001-60000)/170251 in 27.91s\n",
      "physics from 2015-01-01 until 2015-12-31 (60001-61000)/170251 in 28.15s\n",
      "physics from 2015-01-01 until 2015-12-31 (61001-62000)/170251 in 27.18s\n",
      "physics from 2015-01-01 until 2015-12-31 (62001-63000)/170251 in 28.33s\n",
      "physics from 2015-01-01 until 2015-12-31 (63001-64000)/170251 in 27.68s\n",
      "physics from 2015-01-01 until 2015-12-31 (64001-65000)/170251 in 27.28s\n",
      "physics from 2015-01-01 until 2015-12-31 (65001-66000)/170251 in 28.94s\n",
      "physics from 2015-01-01 until 2015-12-31 (66001-67000)/170251 in 28.95s\n",
      "physics from 2015-01-01 until 2015-12-31 (67001-68000)/170251 in 26.82s\n",
      "physics from 2015-01-01 until 2015-12-31 (68001-69000)/170251 in 27.51s\n",
      "physics from 2015-01-01 until 2015-12-31 (69001-70000)/170251 in 27.07s\n",
      "physics from 2015-01-01 until 2015-12-31 (70001-71000)/170251 in 26.33s\n",
      "physics from 2015-01-01 until 2015-12-31 (71001-72000)/170251 in 27.33s\n",
      "physics from 2015-01-01 until 2015-12-31 (72001-73000)/170251 in 28.47s\n",
      "physics from 2015-01-01 until 2015-12-31 (73001-74000)/170251 in 27.43s\n",
      "physics from 2015-01-01 until 2015-12-31 (74001-75000)/170251 in 26.87s\n",
      "physics from 2015-01-01 until 2015-12-31 (75001-76000)/170251 in 27.12s\n",
      "physics from 2015-01-01 until 2015-12-31 (76001-77000)/170251 in 26.91s\n",
      "physics from 2015-01-01 until 2015-12-31 (77001-78000)/170251 in 29.40s\n",
      "physics from 2015-01-01 until 2015-12-31 (78001-79000)/170251 in 26.11s\n",
      "physics from 2015-01-01 until 2015-12-31 (79001-80000)/170251 in 27.27s\n",
      "physics from 2015-01-01 until 2015-12-31 (80001-81000)/170251 in 26.29s\n",
      "physics from 2015-01-01 until 2015-12-31 (81001-82000)/170251 in 26.53s\n",
      "physics from 2015-01-01 until 2015-12-31 (82001-83000)/170251 in 26.85s\n",
      "physics from 2015-01-01 until 2015-12-31 (83001-84000)/170251 in 28.32s\n",
      "physics from 2015-01-01 until 2015-12-31 (84001-85000)/170251 in 33.16s\n",
      "physics from 2015-01-01 until 2015-12-31 (85001-86000)/170251 in 26.01s\n",
      "physics from 2015-01-01 until 2015-12-31 (86001-87000)/170251 in 26.51s\n",
      "physics from 2015-01-01 until 2015-12-31 (87001-88000)/170251 in 27.82s\n",
      "physics from 2015-01-01 until 2015-12-31 (88001-89000)/170251 in 28.05s\n",
      "physics from 2015-01-01 until 2015-12-31 (89001-90000)/170251 in 26.94s\n",
      "physics from 2015-01-01 until 2015-12-31 (90001-91000)/170251 in 28.06s\n",
      "physics from 2015-01-01 until 2015-12-31 (91001-92000)/170251 in 26.64s\n",
      "physics from 2015-01-01 until 2015-12-31 (92001-93000)/170251 in 26.64s\n",
      "physics from 2015-01-01 until 2015-12-31 (93001-94000)/170251 in 27.38s\n",
      "physics from 2015-01-01 until 2015-12-31 (94001-95000)/170251 in 27.72s\n",
      "physics from 2015-01-01 until 2015-12-31 (95001-96000)/170251 in 28.62s\n",
      "physics from 2015-01-01 until 2015-12-31 (96001-97000)/170251 in 26.89s\n",
      "physics from 2015-01-01 until 2015-12-31 (97001-98000)/170251 in 27.03s\n",
      "physics from 2015-01-01 until 2015-12-31 (98001-99000)/170251 in 27.15s\n",
      "physics from 2015-01-01 until 2015-12-31 (99001-100000)/170251 in 27.64s\n",
      "physics from 2015-01-01 until 2015-12-31 (100001-101000)/170251 in 27.45s\n",
      "physics from 2015-01-01 until 2015-12-31 (101001-102000)/170251 in 28.74s\n",
      "physics from 2015-01-01 until 2015-12-31 (102001-103000)/170251 in 28.24s\n",
      "physics from 2015-01-01 until 2015-12-31 (103001-104000)/170251 in 29.26s\n",
      "physics from 2015-01-01 until 2015-12-31 (104001-105000)/170251 in 29.72s\n",
      "physics from 2015-01-01 until 2015-12-31 (105001-106000)/170251 in 29.06s\n",
      "physics from 2015-01-01 until 2015-12-31 (106001-107000)/170251 in 28.64s\n",
      "physics from 2015-01-01 until 2015-12-31 (107001-108000)/170251 in 28.84s\n",
      "Failed at: physics from 2015-01-01 until 2015-12-31 requesting http://export.arxiv.org/oai2?verb=ListRecords&resumptionToken=3132355|108001\n",
      "\n",
      "physics from 2015-01-01 until 2015-12-31 retrieved 0 records in 51 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "cat = 'physics'\n",
    "harvest_data(f\"{year}-01-01\", f\"{year}-06-01\", category=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
