id	prim_cat	sec_cats	title	abstract
0704.0394	q-fin	q-fin.RM math.PR	Average optimality for risk-sensitive control with general state space	"  This paper deals with discrete-time Markov control processes on a general
state space. A long-run risk-sensitive average cost criterion is used as a
performance measure. The one-step cost function is nonnegative and possibly
unbounded. Using the vanishing discount factor approach, the optimality
inequality and an optimal stationary strategy for the decision maker are
established.
"
0707.1897	q-fin	q-fin.GN physics.soc-ph	"Maximum Entropy, the Collective Welfare Principle and the Globalization
  Process"	"  Although both systems analyzed are described through two theories apparently
different (quantum mechanics and game theory) it is shown that both are
analogous and thus exactly equivalents. The quantum analogue of the replicator
dynamics is the von Neumann equation. Quantum mechanics could be used to
explain more correctly biological and economical processes. It could even
encloses theories like games and evolutionary dynamics. We can take some
concepts and definitions from quantum mechanics and physics for the best
understanding of the behavior of economics and biology. Also, we could maybe
understand nature like a game in where its players compete for a common welfare
and the equilibrium of the system that they are members. All the members of our
system will play a game in which its maximum payoff is the equilibrium of the
system. They act as a whole besides individuals like they obey a rule in where
they prefer to work for the welfare of the collective besides the individual
welfare. A system where its members are in Nash Equilibrium (or ESS) is exactly
equivalent to a system in a maximum entropy state. A system is stable only if
it maximizes the welfare of the collective above the welfare of the individual.
If it is maximized the welfare of the individual above the welfare of the
collective the system gets unstable an eventually collapses. The results of
this work shows that the ""globalization"" process has a behavior exactly
equivalent to a system that is tending to a maximum entropy state and predicts
the apparition of big common markets and strong common currencies that will
find its ""equilibrium"" by decreasing its number until they get a state
characterized by only one common currency and only one common market around the
world.
"
0710.1307	q-fin	q-fin.GN physics.soc-ph	Common Markets, Strong Currencies & the Collective Welfare	"  The so called ""globalization"" process (i.e. the inexorable integration of
markets, currencies, nation-states, technologies and the intensification of
consciousness of the world as a whole) has a behavior exactly equivalent to a
system that is tending to a maximum entropy state. This globalization process
obeys a collective welfare principle in where the maximum payoff is given by
the equilibrium of the system and its stability by the maximization of the
welfare of the collective besides the individual welfare. This let us predict
the apparition of big common markets and strong common currencies. They will
reach the ""equilibrium"" by decreasing its number until they reach a state
characterized by only one common currency and only one big common community
around the world.
"
0809.2270	q-fin	q-fin.CP math.PR	On incompleteness of bond markets with infinite number of random factors	"  The completeness of a bond market model with infinite number of sources of
randomness on a finite time interval in the Heath-Jarrow-Morton framework is
studied. It is proved that the market is not complete. A construction of a
bounded contingent claim, which can not be replicated, is provided.
"
0901.0401	q-fin	q-fin.ST cs.IT math.IT physics.data-an physics.pop-ph stat.CO stat.ME	"From Physics to Economics: An Econometric Example Using Maximum Relative
  Entropy"	"  Econophysics, is based on the premise that some ideas and methods from
physics can be applied to economic situations. We intend to show in this paper
how a physics concept such as entropy can be applied to an economic problem. In
so doing, we demonstrate how information in the form of observable data and
moment constraints are introduced into the method of Maximum relative Entropy
(MrE). A general example of updating with data and moments is shown. Two
specific econometric examples are solved in detail which can then be used as
templates for real world problems. A numerical example is compared to a large
deviation solution which illustrates some of the advantages of the MrE method.
"
0901.3812	q-fin	q-fin.TR	The Minimal Model of Financial Complexity	"  A representative investor generates realistic and complex security price
paths by following this trading strategy: if, a few ticks ago, the market asset
had two consecutive upticks or two consecutive downticks, then sell, and
otherwise buy. This simple, unique, and robust model is the smallest possible
deterministic model of financial complexity, and its generalization leads to
complex variety. Compared to a random walk, the minimal model generates time
series with fatter tails and more frequent crashes, thus more closely matching
the real world. It does all this without any parameter fitting.
"
0901.4604	q-fin	q-fin.CP math.AP math.NA	Laplace transformation method for the Black-Scholes equation	"  In this paper we apply the innovative Laplace transformation method
introduced by Sheen, Sloan, and Thom\'ee (IMA J. Numer. Anal., 2003) to solve
the Black-Scholes equation. The algorithm is of arbitrary high convergence rate
and naturally parallelizable. It is shown that the method is very efficient for
calculating various options. Existence and uniqueness properties of the Laplace
transformed Black-Scholes equation are analyzed. Also a transparent boundary
condition associated with the Laplace transformation method is proposed.
Several numerical results for various options under various situations confirm
the efficiency, convergence and parallelization property of the proposed
scheme.
"
0906.0658	q-fin	q-fin.PR	"Asymptotic Implied Volatility at the Second Order with Application to
  the SABR Model"	"  We provide a general method to compute a Taylor expansion in time of implied
volatility for stochastic volatility models, using a heat kernel expansion.
Beyond the order 0 implied volatility which is already known, we compute the
first order correction exactly at all strikes from the scalar coefficient of
the heat kernel expansion. Furthermore, the first correction in the heat kernel
expansion gives the second order correction for implied volatility, which we
also give exactly at all strikes. As an application, we compute this asymptotic
expansion at order 2 for the SABR model.
"
0910.0087	q-fin	q-fin.ST nlin.CD	Wavelet Based Volatility Clustering Estimation of Foreign Exchange Rates	"  We have presented a novel technique of detecting intermittencies in a
financial time series of the foreign exchange rate data of U.S.- Euro
dollar(US/EUR) using a combination of both statistical and spectral techniques.
This has been possible due to Continuous Wavelet Transform (CWT) analysis which
has been popularly applied to fluctuating data in various fields science and
engineering and is also being tried out in finance and economics. We have been
able to qualitatively identify the presence of nonlinearity and chaos in the
time series of the foreign exchange rates for US/EURO (United States dollar to
Euro Dollar) and US/UK (United States dollar to United Kingdom Pound)
currencies. Interestingly we find that for the US-INDIA(United States dollar to
Indian Rupee) foreign exchange rates, no such chaotic dynamics is observed.
This could be a result of the government control over the foreign exchange
rates, instead of the market controlling them.
"
0911.0562	q-fin	q-fin.PR	"A remark on Gatheral's 'most-likely path approximation' of implied
  volatility"	"  We give a new proof of the representation of implied volatility as a
time-average of weighted expectations of local or stochastic volatility. With
this proof we clarify the question of existence of 'forward implied variance'
in the original derivation of Gatheral, who introduced this representation in
his book 'The Volatility Surface'.
"
0911.5048	q-fin	q-fin.ST q-fin.CP	Resilience of Volatility	"  The problem of non-stationarity in financial markets is discussed and related
to the dynamic nature of price volatility. A new measure is proposed for
estimation of the current asset volatility. A simple and illustrative
explanation is suggested of the emergence of significant serial
autocorrelations in volatility and squared returns. It is shown that when
non-stationarity is eliminated, the autocorrelations substantially reduce and
become statistically insignificant. The causes of non-Gaussian nature of the
probability of returns distribution are considered. For both stock and currency
markets data samples, it is shown that removing the non-stationary component
substantially reduces the kurtosis of distribution, bringing it closer to the
Gaussian one. A statistical criterion is proposed for controlling the degree of
smoothing of the empirical values of volatility. The hypothesis of smooth,
non-stochastic nature of volatility is put forward, and possible causes of
volatility shifts are discussed.
"
1001.4031	q-fin	q-fin.CP math.PR q-fin.PR	"Is the minimum value of an option on variance generated by local
  volatility?"	"  We discuss the possibility of obtaining model-free bounds on volatility
derivatives, given present market data in the form of a calibrated local
volatility model. A counter-example to a wide-spread conjecture is given.
"
1002.2281	q-fin	q-fin.GN	Regulation Simulation	"  A deterministic trading strategy by a representative investor on a single
market asset, which generates complex and realistic returns with its first four
moments similar to the empirical values of European stock indices, is used to
simulate the effects of financial regulation that either pricks bubbles, props
up crashes, or both. The results suggest that regulation makes the market
process appear more Gaussian and less complex, with the difference more
pronounced for more frequent intervention, though particular periods can be
worse than the non-regulated version, and that pricking bubbles and propping up
crashes are not symmetrical.
"
1002.2282	q-fin	q-fin.GN q-fin.PM q-fin.RM	The Hazards of Propping Up: Bubbles and Chaos	"  In the current environment of financial distress, many governments are likely
to soon become major holders of financial assets, but the policy debate focuses
only on the likelihood and extent of short-term market stabilization. This
paper shows that government intervention and propping up are likely to lead to
long-term bubbles and even wildly chaotic behavior. The discontinuities occur
when the committed capital reaches a critical amount that depends on just two
parameters: the market impact of trading and the target exposure percentage.
"
1002.2604	q-fin	q-fin.RM	"The two defaults scenario for stressing credit portfolio loss
  distributions"	"  The impact of a stress scenario of default events on the loss distribution of
a credit portfolio can be assessed by determining the loss distribution
conditional on these events. While it is conceptually easy to estimate loss
distributions conditional on default events by means of Monte Carlo simulation,
it becomes impractical for two or more simultaneous defaults as then the
conditioning event is extremely rare. We provide an analytical approach to the
calculation of the conditional loss distribution for the CreditRisk+ portfolio
model with independent random loss given default distributions. The analytical
solution for this case can be used to check the accuracy of an approximation to
the conditional loss distribution whereby the unconditional model is run with
stressed input probabilities of default (PDs). It turns out that this
approximation is unbiased. Numerical examples, however, suggest that the
approximation may be seriously inaccurate but that the inaccuracy leads to
overestimation of tail losses and hence the approach errs on the conservative
side.
"
1003.0793	q-fin	q-fin.GN nlin.CG	"Boolean delay equations on networks: An application to economic damage
  propagation"	"  We introduce economic models based on Boolean Delay Equations: this formalism
makes easier to take into account the complexity of the interactions between
firms and is particularly appropriate for studying the propagation of an
initial damage due to a catastrophe. Here we concentrate on simple cases, which
allow to understand the effects of multiple concurrent production paths as well
as the presence of stochasticity in the path time lengths or in the network
structure.
  In absence of flexibility, the shortening of production of a single firm in
an isolated network with multiple connections usually ends up by attaining a
finite fraction of the firms or the whole economy, whereas the interactions
with the outside allow a partial recovering of the activity, giving rise to
periodic solutions with waves of damage which propagate across the structure.
The damage propagation speed is strongly dependent upon the topology. The
existence of multiple concurrent production paths does not necessarily imply a
slowing down of the propagation, which can be as fast as the shortest path.
"
1005.0279	q-fin	q-fin.GN math.PR	Rough paths in idealized financial markets	"  This paper considers possible price paths of a financial security in an
idealized market. Its main result is that the variation index of typical price
paths is at most 2, in this sense, typical price paths are not rougher than
typical paths of Brownian motion. We do not make any stochastic assumptions and
only assume that the price path is positive and right-continuous. The
qualification ""typical"" means that there is a trading strategy (constructed
explicitly in the proof) that risks only one monetary unit but brings infinite
capital when the variation index of the realized price path exceeds 2. The
paper also reviews some known results for continuous price paths and lists
several open problems.
"
1005.3518	q-fin	q-fin.GN	"Inequality reversal: effects of the savings propensity and correlated
  returns"	"  In the last decade, a large body of literature has been developed to explain
the universal features of inequality in terms of income and wealth. By now, it
is established that the distributions of income and wealth in various economies
show a number of statistical regularities. There are several models to explain
such static features of inequality in an unifying framework and the kinetic
exchange models, in particular, provide one such framework. Here we focus on
the dynamic features of inequality. In the process of development and growth,
inequality in an economy in terms of income and wealth follows a particular
pattern of rising in the initial stage followed by an eventual fall. This
inverted U-shaped curve is known as the Kuznets Curve. We examine the
possibilities of such behavior of an economy in the context of a generalized
kinetic exchange model. It is shown that under some specific conditions, our
model economy indeed shows inequality reversal.
"
1008.3746	q-fin	q-fin.PM cond-mat.stat-mech cs.LG math.OC q-fin.RM	Belief Propagation Algorithm for Portfolio Optimization Problems	"  The typical behavior of optimal solutions to portfolio optimization problems
with absolute deviation and expected shortfall models using replica analysis
was pioneeringly estimated by S. Ciliberti and M. M\'ezard [Eur. Phys. B. 57,
175 (2007)]; however, they have not yet developed an approximate derivation
method for finding the optimal portfolio with respect to a given return set. In
this study, an approximation algorithm based on belief propagation for the
portfolio optimization problem is presented using the Bethe free energy
formalism, and the consistency of the numerical experimental results of the
proposed algorithm with those of replica analysis is confirmed. Furthermore,
the conjecture of H. Konno and H. Yamazaki, that the optimal solutions with the
absolute deviation model and with the mean-variance model have the same typical
behavior, is verified using replica analysis and the belief propagation
algorithm.
"
1009.3247	q-fin	math.OC math.PR q-fin.RM	Optimal control of risk process in a regime-switching environment	"  This paper is concerned with cost optimization of an insurance company. The
surplus of the insurance company is modeled by a controlled regime switching
diffusion, where the regime switching mechanism provides the fluctuations of
the random environment. The goal is to find an optimal control that minimizes
the total cost up to a stochastic exit time. A weaker sufficient condition than
that of (Fleming and Soner 2006, Section V.2) for the continuity of the value
function is obtained. Further, the value function is shown to be a viscosity
solution of a Hamilton-Jacobian-Bellman equation.
"
1010.5810	q-fin	q-fin.RM	Quantile hedging for basket derivatives	"  The problem of quantile hedging for basket derivatives in the Black-Scholes
model with correlation is considered. Explicit formulas for the probability
maximizing function and the cost reduction function are derived. Applicability
of the results for the widely traded derivatives as digital, quantos,
outperformance and spread options is shown.
"
1102.3928	q-fin	math.OC q-fin.RM	Integral representations of risk functions for basket derivatives	"  The risk minimizing problem
$\mathbf{E}[l((H-X_T^{x,\pi})^{+})]\overset{\pi}{\longrightarrow}\min$ in the
multidimensional Black-Scholes framework is studied. Specific formulas for the
minimal risk function and the cost reduction function for basket derivatives
are shown. Explicit integral representations for the risk functions for
$l(x)=x$ and $l(x)=x^p$, with $p>1$ for digital, quantos, outperformance and
spread options are derived.
"
1104.5326	q-fin	math.ST q-fin.CP q-fin.ST stat.TH	Density Approximations for Multivariate Affine Jump-Diffusion Processes	"  We introduce closed-form transition density expansions for multivariate
affine jump-diffusion processes. The expansions rely on a general approximation
theory which we develop in weighted Hilbert spaces for random variables which
possess all polynomial moments. We establish parametric conditions which
guarantee existence and differentiability of transition densities of affine
models and show how they naturally fit into the approximation framework.
Empirical applications in credit risk, likelihood inference, and option pricing
highlight the usefulness of our expansions. The approximations are extremely
fast to evaluate, and they perform very accurately and numerically stable.
"
1106.1774	q-fin	math.DG q-fin.CP	Fibrations of financial events	"  In this paper we shall prove that the plane of financial events, introduced
and applied to financial problems by the author himself (see [2], [3] and [4])
can be considered as a fibration in two different ways. The first one, the
natural one, reveals itself to be isomorphic to the tangent- bundle of the real
line, when the last one is considered as a differentiable manifold in the
natural way; the second one is a fibration induced by the status of compound
interest capitalization at a given rate i in the interval ] - 1, \rightarrow [.
Moreover, in the paper we define on the first fibration an affine connection,
also in this case induced by the status of compound interest at a given rate i.
The final goal of this paper is the awareness that all the effects determined
by the status of compound interest are nothing but the consequences of the fact
that the space of financial events is a fibration endowed with a particular
affine connection, so they are consequences of purely geometric properties, at
last, depending upon the curvature determined by the connection upon the
fibration. A natural preorder upon the set of fibers of the second fibration is
considered. Some remarks about the applicability to economics and finance of
the theories presented in the paper and about the possible developments are
made in the directions followed in papers [1], [5], [6], [7], [8] of the
author.
"
1106.2781	q-fin	math.OC cs.SY math.PR q-fin.RM	"Optimal Dividend Payments for the Piecewise-Deterministic Poisson Risk
  Model"	"  This paper considers the optimal dividend payment problem in
piecewise-deterministic compound Poisson risk models. The objective is to
maximize the expected discounted dividend payout up to the time of ruin. We
provide a comparative study in this general framework of both restricted and
unrestricted payment schemes, which were only previously treated separately in
certain special cases of risk models in the literature. In the case of
restricted payment scheme, the value function is shown to be a classical
solution of the corresponding HJB equation, which in turn leads to an optimal
restricted payment policy known as the threshold strategy. In the case of
unrestricted payment scheme, by solving the associated integro-differential
quasi-variational inequality, we obtain the value function as well as an
optimal unrestricted dividend payment scheme known as the barrier strategy.
When claim sizes are exponentially distributed, we provide easily verifiable
conditions under which the threshold and barrier strategies are optimal
restricted and unrestricted dividend payment policies, respectively. The main
results are illustrated with several examples, including a new example
concerning regressive growth rates.
"
1107.4632	q-fin	q-fin.RM math.PR q-fin.GN	From Smile Asymptotics to Market Risk Measures	"  The left tail of the implied volatility skew, coming from quotes on
out-of-the-money put options, can be thought to reflect the market's assessment
of the risk of a huge drop in stock prices. We analyze how this market
information can be integrated into the theoretical framework of convex monetary
measures of risk. In particular, we make use of indifference pricing by dynamic
convex risk measures, which are given as solutions of backward stochastic
differential equations (BSDEs), to establish a link between these two
approaches to risk measurement. We derive a characterization of the implied
volatility in terms of the solution of a nonlinear PDE and provide a small
time-to-maturity expansion and numerical solutions. This procedure allows to
choose convex risk measures in a conveniently parametrized class, distorted
entropic dynamic risk measures, which we introduce here, such that the
asymptotic volatility skew under indifference pricing can be matched with the
market skew. We demonstrate this in a calibration exercise to market implied
volatility data.
"
1109.2557	q-fin	q-fin.CP math.NA math.PR q-fin.PR	Numerical integration of Heath-Jarrow-Morton model of interest rates	"  We propose and analyze numerical methods for the Heath-Jarrow-Morton (HJM)
model. To construct the methods, we first discretize the infinite dimensional
HJM equation in maturity time variable using quadrature rules for approximating
the arbitrage-free drift. This results in a finite dimensional system of
stochastic differential equations (SDEs) which we approximate in the weak and
mean-square sense using the general theory of numerical integration of SDEs.
The proposed numerical algorithms are computationally highly efficient due to
the use of high-order quadrature rules which allow us to take relatively large
discretization steps in the maturity time without affecting overall accuracy of
the algorithms. Convergence theorems for the methods are proved. Results of
some numerical experiments with European-type interest rate derivatives are
presented.
"
1109.3908	q-fin	q-fin.PM q-fin.PR	Forward Exponential Performances: Pricing and Optimal Risk Sharing	"  In a Markovian stochastic volatility model, we consider financial agents
whose investment criteria are modelled by forward exponential performance
processes. The problem of contingent claim indifference valuation is first
addressed and a number of properties are proved and discussed. Special
attention is given to the comparison between the forward exponential and the
backward exponential utility indifference valuation. In addition, we construct
the problem of optimal risk sharing in this forward setting and solve it when
the agents' forward performance criteria are exponential.
"
1109.6909	q-fin	q-fin.GN physics.soc-ph	Pricing stocks with yardsticks and sentiments	"  Human decision making by professionals trading daily in the stock market can
be a daunting task. It includes decisions on whether to keep on investing or to
exit a market subject to huge price swings, and how to price in news or rumors
attributed to a specific stock. The question then arises how professional
traders, who specialize in daily buying and selling large amounts of a given
stock, know how to properly price a given stock on a given day? Here we
introduce the idea that people use heuristics, or ""rules of thumb"", in terms of
""yard sticks"" from the performance of the other stocks in a stock index. The
under- /over-performance with respect to such a yard stick then signifies a
general negative/positive sentiment of the market participants towards a given
stock. Using empirical data of the Dow Jones Industrial Average, stocks are
shown to have daily performances with a clear tendency to cluster around the
measures introduced by the yard sticks. We illustrate how sentiments, most
likely due to insider information, can influence the performance of a given
stock over period of months, and in one case years.
"
1110.5144	q-fin	q-fin.CP math.OC	Computing Economic Equilibria by a Homotopy Method	"  In this paper the possibility of computing equilibrium in pure exchange and
production economies by a homotopy method is investigated. The performance of
the algorithm is tested on examples with known equilibria taken from the
literature on general equilibrium models and numerical results are presented.
In computing equilibria, economy will be specified by excess demand function.
"
1110.5594	q-fin	math.AP math.PR q-fin.CP q-fin.PR	"Boundary-degenerate elliptic operators and Holder continuity for
  solutions to variational equations and inequalities"	"  The Heston stochastic volatility process, which is widely used as an asset
price model in mathematical finance, is a paradigm for a degenerate diffusion
process where the degeneracy in the diffusion coefficient is proportional to
the square root of the distance to the boundary of the half-plane. The
generator of this process with killing, called the elliptic Heston operator, is
a second-order, degenerate-elliptic partial differential operator whose
coefficients have linear growth in the spatial variables and where the
degeneracy in the operator symbol is proportional to the distance to the
boundary of the half-plane. With the aid of weighted Sobolev spaces, we prove
supremum bounds, a Harnack inequality, and H\""older continuity near the
boundary for solutions to variational equations defined by the elliptic Heston
operator, as well as H\""older continuity up to the boundary for solutions to
variational inequalities defined by the elliptic Heston operator. In
mathematical finance, solutions to obstacle problems for the elliptic Heston
operator correspond to value functions for perpetual American-style options on
the underlying asset.
"
1112.1652	q-fin	q-fin.PR	"Asymptotic Expansions of the Lognormal Implied Volatility : A Model Free
  Approach"	"  We invert the Black-Scholes formula. We consider the cases low strike, large
strike, short maturity and large maturity. We give explicitly the first 5 terms
of the expansions. A method to compute all the terms by induction is also
given. At the money, we have a closed form formula for implied lognormal
volatility in terms of a power series in call price.
"
1112.3217	q-fin	q-fin.GN	Pseudo Hermitian formulation of Black-Scholes equation	"  We show that the non Hermitian Black-Scholes Hamiltonian and its various
generalizations are eta-pseudo Hermitian. The metric operator eta is explicitly
constructed for this class of Hamitonians. It is also shown that the effective
Black-Scholes Hamiltonian and its partner form a pseudo supersymmetric system.
"
1112.4824	q-fin	math.AP math.PR q-fin.CP q-fin.PR	"A Schauder approach to degenerate-parabolic partial differential
  equations with unbounded coefficients"	"  Motivated by applications to probability and mathematical finance, we
consider a parabolic partial differential equation on a half-space whose
coefficients are suitably Holder continuous and allowed to grow linearly in the
spatial variable and which become degenerate along the boundary of the
half-space. We establish existence and uniqueness of solutions in weighted
Holder spaces which incorporate both the degeneracy at the boundary and the
unboundedness of the coefficients. In our companion article [arXiv:1211.4636],
we apply the main result of this article to show that the martingale problem
associated with a degenerate-elliptic partial differential operator is
well-posed in the sense of Stroock and Varadhan.
"
1201.3432	q-fin	physics.soc-ph physics.data-an q-fin.GN	The leading digit distribution of the worldwide Illicit Financial Flows	"  Benford's law states that in data sets from different phenomena leading
digits tend to be distributed logarithmically such that the numbers beginning
with smaller digits occur more often than those with larger ones. Particularly,
the law is known to hold for different types of financial data. The Illicit
Financial Flows (IFFs) exiting the developing countries are frequently
discussed as hidden resources which could have been otherwise properly utilized
for their development. We investigate here the distribution of the leading
digits in the recent data on estimates of IFFs to look for the existence of a
pattern as predicted by Benford's law and establish that the frequency of
occurrence of the leading digits in these estimates does closely follow the
law.
"
1202.0100	q-fin	q-fin.ST	"The Evolution of Stock Market Efficiency in the US: A Non-Bayesian
  Time-Varying Model Approach"	"  A non-Bayesian time-varying model is developed by introducing the concept of
the degree of market efficiency that varies over time. This model may be seen
as a reflection of the idea that continuous technological progress alters the
trading environment over time. With new methodologies and a new measure of the
degree of market efficiency, we examine whether the US stock market evolves
over time. In particular, a time-varying autoregressive (TV-AR) model is
employed. Our main findings are: (i) the US stock market has evolved over time
and the degree of market efficiency has cyclical fluctuations with a
considerably long periodicity, from 30 to 40 years; and (ii) the US stock
market has been efficient with the exception of four times in our sample
period: during the long-recession of 1873-1879; the recession of 1902-1904; the
New Deal era; and the recession of 1957-1958 and soon after it. It is then
shown that our results are partly consistent with the view of behavioral
finance.
"
1202.6632	q-fin	q-fin.GN	Coherent Price Systems and Uncertainty-Neutral Valuation	"  We consider fundamental questions of arbitrage pricing arising when the
uncertainty model is given by a set of possible mutually singular probability
measures. With a single probability model, essential equivalence between the
absence of arbitrage and the existence of an equivalent martingale measure is a
folk theorem, see Harrison and Kreps (1979). We establish a microeconomic
foundation of sublinear price systems and present an extension result. In this
context we introduce a prior dependent notion of marketed spaces and viable
price systems. We associate this extension with a canonically altered concept
of equivalent symmetric martingale measure sets, in a dynamic trading framework
under absence of prior depending arbitrage. We prove the existence of such sets
when volatility uncertainty is modeled by a stochastic differential equation,
driven by Peng's G-Brownian motions.
"
1203.6877	q-fin	math.PR q-fin.CP	The maximum maximum of a martingale with given $n$ marginals	"  We obtain bounds on the distribution of the maximum of a martingale with
fixed marginals at finitely many intermediate times. The bounds are sharp and
attained by a solution to $n$-marginal Skorokhod embedding problem in
Ob{\l}\'oj and Spoida [An iterated Az\'ema-Yor type embedding for finitely many
marginals (2013) Preprint]. It follows that their embedding maximizes the
maximum among all other embeddings. Our motivating problem is superhedging
lookback options under volatility uncertainty for an investor allowed to
dynamically trade the underlying asset and statically trade European call
options for all possible strikes and finitely-many maturities. We derive a
pathwise inequality which induces the cheapest superhedging value, which
extends the two-marginals pathwise inequality of Brown, Hobson and Rogers
[Probab. Theory Related Fields 119 (2001) 558-578]. This inequality, proved by
elementary arguments, is derived by following the stochastic control approach
of Galichon, Henry-Labord\`ere and Touzi [Ann. Appl. Probab. 24 (2014)
312-336].
"
1204.2065	q-fin	q-fin.GN math.OC	Toehold Purchase Problem: A comparative analysis of two strategies	"  Toehold purchase, defined here as purchase of one share in a firm by an
investor preparing a tender offer to acquire majority of shares in it, reduces
by one the number of shares this investor needs for majority. In the paper we
construct mathematical models for the toehold and no-toehold strategies and
compare the expected profits of the investor and the probabilities of takeover
the firm in both strategies. It turns out that the expected profits of the
investor in both strategies coincide. On the other hand, the probability of
takeover the firm using the toehold strategy is considerably higher comparing
to the no-toehold strategy. In the analysis of the models we apply the
apparatus of incomplete Beta functions and some refined bounds for central
binomial coefficients.
"
1204.6613	q-fin	math.AP math.PR q-fin.PR	"Maximum principles for boundary-degenerate second-order linear elliptic
  differential operators"	"  We prove weak and strong maximum principles, including a Hopf lemma, for
smooth subsolutions to equations defined by linear, second-order, partial
differential operators whose principal symbols vanish along a portion of the
domain boundary. The boundary regularity property of the smooth subsolutions
along this boundary vanishing locus ensures that these maximum principles hold
irrespective of the sign of the Fichera function. Boundary conditions need only
be prescribed on the complement in the domain boundary of the principal symbol
vanishing locus. We obtain uniqueness and a priori maximum principle estimates
for smooth solutions to boundary value and obstacle problems defined by these
boundary-degenerate elliptic operators for partial Dirichlet or Neumann
boundary conditions along the complement of the boundary vanishing locus. We
also prove weak maximum principles and uniqueness for solutions to the
corresponding variational equations and inequalities defined with the aide of
weighted Sobolev spaces. The domain is allowed to be unbounded when the
operator coefficients and solutions obey certain growth conditions.
"
1205.3555	q-fin	q-fin.CP math.PR	Approximating stochastic volatility by recombinant trees	"  A general method to construct recombinant tree approximations for stochastic
volatility models is developed and applied to the Heston model for stock price
dynamics. In this application, the resulting approximation is a four tuple
Markov process. The first two components are related to the stock and
volatility processes and take values in a two-dimensional binomial tree. The
other two components of the Markov process are the increments of random walks
with simple values in $\{-1,+1\}$. The resulting efficient option pricing
equations are numerically implemented for general American and European options
including the standard put and calls, barrier, lookback and Asian-type
pay-offs. The weak and extended weak convergences are also proved.
"
1206.0384	q-fin	q-fin.GN	The Effect of Market Power on Risk-Sharing	"  The paper studies an oligopolistic equilibrium model of financial agents who
aim to share their random endowments. The risk-sharing securities and their
prices are endogenously determined as the outcome of a strategic game played
among all the participating agents. In the complete-market setting, each
agent's set of strategic choices consists of the security payoffs and the
pricing kernel that are consistent with the optimal-sharing rules; while in the
incomplete setting, agents respond via demand functions on a vector of given
tradeable securities. It is shown that at the (Nash) risk-sharing equilibrium,
the sharing securities are suboptimal, since agents submit for sharing
different risk exposures than their true endowments. On the other hand, the
Nash equilibrium prices stay unaffected by the game only in the special case of
agents with the same risk aversion. In addition, agents with sufficiently lower
risk aversion act as predatory traders, since they absorb utility surplus from
the high risk averse agents and reduce the efficiency of sharing. The main
results of the paper also hold under the generalized models that allow the
presence of noise traders and heterogeneity in agents' beliefs.
"
1206.0831	q-fin	math.AP math.PR q-fin.CP q-fin.PR	C^{1,1} regularity for degenerate elliptic obstacle problems	"  The Heston stochastic volatility process is a degenerate diffusion process
where the degeneracy in the diffusion coefficient is proportional to the square
root of the distance to the boundary of the half-plane. The generator of this
process with killing, called the elliptic Heston operator, is a second-order,
degenerate-elliptic partial differential operator, where the degeneracy in the
operator symbol is proportional to the distance to the boundary of the
half-plane. In mathematical finance, solutions to the obstacle problem for the
elliptic Heston operator correspond to value functions for perpetual
American-style options on the underlying asset. With the aid of weighted
Sobolev spaces and weighted Holder spaces, we establish the optimal $C^{1,1}$
regularity (up to the boundary of the half-plane) for solutions to obstacle
problems for the elliptic Heston operator when the obstacle functions are
sufficiently smooth.
"
1207.1842	q-fin	q-fin.ST	"A Test of the Adaptive Market Hypothesis using a Time-Varying AR Model
  in Japan"	"  This study examines the adaptive market hypothesis (AMH) in Japanese stock
markets (TOPIX and TSE2). In particular, we measure the degree of market
efficiency by using a time-varying model approach. The empirical results show
that (1) the degree of market efficiency changes over time in the two markets,
(2) the level of market efficiency of the TSE2 is lower than that of the TOPIX
in most periods, and (3) the market efficiency of the TOPIX has evolved, but
that of the TSE2 has not. We conclude that the results support the AMH for the
more qualified stock market in Japan.
"
1208.3083	q-fin	q-fin.TR math-ph math.MP math.PR	"Investor's sentiment in multi-agent model of the continuous double
  auction"	"  We introduce and treat rigorously a new multi-agent model of the continuous
double auction or in other words the order book (OB). It is designed to explain
collective behaviour of the market when new information affecting the market
arrives. The novel feature of the model is two additional slow changing
parameters, the so-called sentiment functions. These sentiment functions
measure the conception of the fair price of two groups of investors, namely,
bulls and bears. Our model specifies differential equations for the time
evolution of sentiment functions and constitutes a nonlinear Markov process
which exhibits long term correlations. We explain the intuition behind
equations for sentiment functions and present numerical simulations which show
that the behaviour of our model is similar to the behaviour of the real market.
We also obtain a diffusion limit of the model, the Ornstein-Uhlenbeck type
process with variable volatility. The volatility is proportional to the
difference of opinions of bulls and bears about the fair price of a security.
The paper is complimentary to our previous work where mathematical proofs are
presented.
"
1209.1544	q-fin	q-fin.ST math.ST stat.ME stat.TH	On Geometric Ergodicity of Skewed - SVCHARME models	"  Markov Chain Monte Carlo is repeatedly used to analyze the properties of
intractable distributions in a convenient way. In this paper we derive
conditions for geometric ergodicity of a general class of nonparametric
stochastic volatility models with skewness driven by hidden Markov Chain with
switching.
"
1209.4849	q-fin	q-fin.GN physics.soc-ph	Iterated Function Systems with Economic Applications	"  This work's purpose is to understand the dynamics of some social systems
whose properties can be captured by certain iterated function systems. To
achieve this intension, we start from the theory of iterated function systems,
and then we study two specific economic models on random utility function and
optimal stochastic growth.
"
1210.6727	q-fin	math.AP math.PR q-fin.CP q-fin.PR	"Schauder a priori estimates and regularity of solutions to
  boundary-degenerate elliptic linear second-order partial differential
  equations"	"  We establish Schauder a priori estimates and regularity for solutions to a
class of boundary-degenerate elliptic linear second-order partial differential
equations. Furthermore, given a smooth source function, we prove regularity of
solutions up to the portion of the boundary where the operator is degenerate.
Degenerate-elliptic operators of the kind described in our article appear in a
diverse range of applications, including as generators of affine diffusion
processes employed in stochastic volatility models in mathematical finance,
generators of diffusion processes arising in mathematical biology, and the
study of porous media.
"
1211.4636	q-fin	math.PR math.AP q-fin.CP q-fin.PR	"On the martingale problem for degenerate-parabolic partial differential
  operators with unbounded coefficients and a mimicking theorem for Ito
  processes"	"  Using results from our companion article [arXiv:1112.4824v2] on a Schauder
approach to existence of solutions to a degenerate-parabolic partial
differential equation, we solve three intertwined problems, motivated by
probability theory and mathematical finance, concerning degenerate diffusion
processes. We show that the martingale problem associated with a
degenerate-elliptic differential operator with unbounded, locally Holder
continuous coefficients on a half-space is well-posed in the sense of Stroock
and Varadhan. Second, we prove existence, uniqueness, and the strong Markov
property for weak solutions to a stochastic differential equation with
degenerate diffusion and unbounded coefficients with suitable H\""older
continuity properties. Third, for an Ito process with degenerate diffusion and
unbounded but appropriately regular coefficients, we prove existence of a
strong Markov process, unique in the sense of probability law, whose
one-dimensional marginal probability distributions match those of the given Ito
process.
"
1211.5235	q-fin	q-fin.RM	Optimal portfolio for a robust financial system	"  This study presents an ANWSER model (asset network systemic risk model) to
quantify the risk of financial contagion which manifests itself in a financial
crisis. The transmission of financial distress is governed by a heterogeneous
bank credit network and an investment portfolio of banks. Bankruptcy
reproductive ratio of a financial system is computed as a function of the
diversity and risk exposure of an investment portfolio of banks, and the
denseness and concentration of a heterogeneous bank credit network. An analytic
solution of the bankruptcy reproductive ratio for a small financial system is
derived and a numerical solution for a large financial system is obtained. For
a large financial system, Large diversity among banks in the investment
portfolio makes financial contagion more damaging on the average. But large
diversity is essentially effective in eliminating the risk of financial
contagion in the worst case of financial crisis scenarios. A bank-unique
specialization portfolio is more suitable than a uniform diversification
portfolio and a system-wide specialization portfolio in strengthening the
robustness of a financial system.
"
1212.6732	q-fin	q-fin.RM math.PR q-fin.CP	"A Fourier Approach to the Computation of CV@R and Optimized Certainty
  Equivalents"	"  We consider the class of risk measures associated with optimized certainty
equivalents. This class includes several popular examples, such as CV@R and
monotone mean-variance. Numerical schemes are developed for the computation of
these risk measures using Fourier transform methods. This leads, in particular,
to a very competitive method for the calculation of CV@R which is comparable in
computational time to the calculation of V@R. We also develop methods for the
efficient computation of risk contributions.
"
1301.0091	q-fin	math.PR cs.SY math.OC q-fin.PR	On the Robust Optimal Stopping Problem	"  We study a robust optimal stopping problem with respect to a set $\cP$ of
mutually singular probabilities. This can be interpreted as a zero-sum
controller-stopper game in which the stopper is trying to maximize its pay-off
while an adverse player wants to minimize this payoff by choosing an evaluation
criteria from $\cP$. We show that the \emph{upper Snell envelope $\ol{Z}$} of
the reward process $Y$ is a supermartingale with respect to an appropriately
defined nonlinear expectation $\ul{\sE}$, and $\ol{Z}$ is further an
$\ul{\sE}-$martingale up to the first time $\t^*$ when $\ol{Z}$ meets $Y$.
Consequently, $\t^*$ is the optimal stopping time for the robust optimal
stopping problem and the corresponding zero-sum game has a value. Although the
result seems similar to the one obtained in the classical optimal stopping
theory, the mutual singularity of probabilities and the game aspect of the
problem give rise to major technical hurdles, which we circumvent using some
new methods.
"
1301.1496	q-fin	q-fin.RM math.PR	Multivariate risk measures: a constructive approach based on selections	"  Since risky positions in multivariate portfolios can be offset by various
choices of capital requirements that depend on the exchange rules and related
transaction costs, it is natural to assume that the risk measures of random
vectors are set-valued. Furthermore, it is reasonable to include the exchange
rules in the argument of the risk measure and so consider risk measures of
set-valued portfolios. This situation includes the classical Kabanov's
transaction costs model, where the set-valued portfolio is given by the sum of
a random vector and an exchange cone, but also a number of further cases of
additional liquidity constraints.
  We suggest a definition of the risk measure based on calling a set-valued
portfolio acceptable if it possesses a selection with all individually
acceptable marginals. The obtained selection risk measure is coherent (or
convex), law invariant and has values being upper convex closed sets. We
describe the dual representation of the selection risk measure and suggest
efficient ways of approximating it from below and from above. In case of
Kabanov's exchange cone model, it is shown how the selection risk measure
relates to the set-valued risk measures considered by Kulikov (2008), Hamel and
Heyde (2010), and Hamel, Heyde and Rudloff (2013).
"
1301.6252	q-fin	q-fin.PR math.AP	"Option pricing with linear market impact and non-linear Black and
  Scholes equations"	"  We consider a model of linear market impact, and address the problem of
replicating a contingent claim in this framework. We derive a non-linear
Black-Scholes Equation that provides an exact replication strategy.
  This equation is fully non-linear and singular, but we show that it is well
posed, and we prove existence of smooth solutions for a large class of final
payoffs, both for constant and local volatility. To obtain regularity of the
solutions, we develop an original method based on Legendre transforms.
  The close connections with the problem of hedging with it gamma constraints
studied by Cheridito, Soner and Touzi and with the problem of hedging under it
liquidity costs are discussed.
  We also derive a modified Black-Scholes formula valid for asymptotically
small impact parameter, and finally provide numerical simulations as an
illustration.
"
1302.2534	q-fin	math.PR q-fin.CP	Stationarity and ergodicity for an affine two factor model	"  We study the existence of a unique stationary distribution and ergodicity for
a 2-dimensional affine process. The first coordinate is supposed to be a
so-called alpha-root process with \alpha\in(1,2]. The existence of a unique
stationary distribution for the affine process is proved in case of
\alpha\in(1,2]; further, in case of \alpha=2, the ergodicity is also shown.
"
1303.2044	q-fin	q-fin.TR physics.soc-ph	Bubbles, Jumps, and Scaling from Properly Anticipated Prices	"  Prices in financial markets exhibit extreme jumps far more often than can be
accounted for by external news. Further, magnitudes of price changes are
correlated over long times. These so called stylized facts are quantified by
scaling laws similar to, for example, turbulent fluids. They are believed to
reflect the complex interactions of heterogenous agents which give rise to
irrational herding. Therefore, the stylized facts have been argued to provide
evidence against the efficient market hypothesis which states that prices
rapidly reflect available information and therefore are described by a
martingale. Here we show, that in very simple bidding processes efficiency is
not opposed to, but causative to scaling properties observed in real markets.
Thereby, we link the stylized facts not only to price efficiency, but also to
the economic theory of rational bubbles. We then demonstrate effects predicted
from our normative model in the dynamics of groups of real human subjects
playing a modified minority game. An extended version of the latter can be
played online at seesaw.neuro.uni-bremen.de.
"
1303.2513	q-fin	q-fin.PM	"Portfolio Optimization under Partial Information with Expert Opinions: a
  Dynamic Programming Approach"	"  This paper investigates optimal portfolio strategies in a market where the
drift is driven by an unobserved Markov chain. Information on the state of this
chain is obtained from stock prices and expert opinions in the form of signals
at random discrete time points. As in Frey et al. (2012), Int. J. Theor. Appl.
Finance, 15, No. 1, we use stochastic filtering to transform the original
problem into an optimization problem under full information where the state
variable is the filter for the Markov chain. The dynamic programming equation
for this problem is studied with viscosity-solution techniques and with
regularization arguments.
"
1304.3824	q-fin	q-fin.GN	Pricing and Valuation under the Real-World Measure	"  In general it is not clear which kind of information is supposed to be used
for calculating the fair value of a contingent claim. Even if the information
is specified, it is not guaranteed that the fair value is uniquely determined
by the given information. A further problem is that asset prices are typically
expressed in terms of a risk-neutral measure. This makes it difficult to
transfer the fundamental results of financial mathematics to econometrics. I
show that the aforementioned problems evaporate if the financial market is
complete and sensitive. In this case, after an appropriate choice of the
numeraire, the discounted price processes turn out to be uniformly integrable
martingales under the real-world measure. This leads to a Law of One Price and
a simple real-world valuation formula in a model-independent framework where
the number of assets as well as the lifetime of the market can be finite or
infinite.
"
1304.7535	q-fin	q-fin.GN	Elasticity theory of structuring	"  Financial derivatives have often been criticized as casino-style betting
instruments. It turns out that many naive ways of making them are indeed
equivalent to gambling. Fortunately, this inadvertent effect can be understood
and prevented. We present a theory of product design which achieves that.
"
1305.0479	q-fin	q-fin.CP	"A robust tree method for pricing American options with CIR stochastic
  interest rate"	"  We propose a robust and stable lattice method which permits to obtain very
accurate American option prices in presence of CIR stochastic interest rate
without any numerical restriction on its parameters. Numerical results show the
reliability and the accuracy of the proposed method.
"
1305.6023	q-fin	math.FA math.OC math.PR q-fin.CP	A Robust Version of Convex Integral Functionals	"  We study the pointwise supremum of convex integral functionals
$\mathcal{I}_{f,\gamma}(\xi)= \sup_{Q} \left( \int_\Omega
f(\omega,\xi(\omega))Q(d\omega)-\gamma(Q)\right)$ on
$L^\infty(\Omega,\mathcal{F},\mathbb{P})$ where
$f:\Omega\times\mathbb{R}\rightarrow\overline{\mathbb{R}}$ is a proper normal
convex integrand, $\gamma$ is a proper convex function on the set of
probability measures absolutely continuous w.r.t. $\mathbb{P}$, and the
supremum is taken over all such measures. We give a pair of upper and lower
bounds for the conjugate of $\mathcal{I}_{f,\gamma}$ as direct sums of a common
regular part and respective singular parts; they coincide when
$\mathrm{dom}(\gamma)=\{\mathbb{P}\}$ as Rockafellar's result, while both
inequalities can generally be strict. We then investigate when the conjugate
eliminates the singular measures, which a fortiori yields the equality in
bounds, and its relation to other finer regularity properties of the original
functional and of the conjugate.
"
1305.6797	q-fin	physics.data-an q-fin.ST q-fin.TR	"Continuous-Time Random Walk with multi-step memory: An application to
  market dynamics"	"  A novel version of the Continuous-Time Random Walk (CTRW) model with memory
is developed. This memory means the dependence between arbitrary number of
successive jumps of the process, while waiting times between jumps are
considered as i.i.d. random variables. The dependence was found by analysis of
empirical histograms for the stochastic process of a single share price on a
market within the high frequency time scale, and justified theoretically by
considering bid-ask bounce mechanism containing some delay characteristic for
any double-auction market. Our model turns out to be exactly analytically
solvable, which enables a direct comparison of its predictions with their
empirical counterparts, for instance, with empirical velocity autocorrelation
function. Thus this paper significantly extends the capabilities of the CTRW
formalism.
"
1306.2508	q-fin	q-fin.ST q-fin.PM	Phase Transition in the S&P Stock Market	"  We analyze the stock prices of the S&P market from 1987 until 2012 with the
covariance matrix of the firm returns determined in time windows of several
years. The eigenvector belonging to the leading eigenvalue (market) exhibits in
its long term time dependence a phase transition with an order parameter which
can be interpreted within an agent-based model. From 1995 to 2005 the market is
in an ordered state and after 2005 in a disordered state.
"
1306.2793	q-fin	math.PR q-fin.PR	On the probability density function of baskets	"  The state price density of a basket, even under uncorrelated Black-Scholes
dynamics, does not allow for a closed from density. (This may be rephrased as
statement on the sum of lognormals and is especially annoying for such are used
most frequently in Financial and Actuarial Mathematics.) In this note we
discuss short time and small volatility expansions, respectively. The method
works for general multi-factor models with correlations and leads to the
analysis of a system of ordinary (Hamiltonian) differential equations.
Surprisingly perhaps, even in two asset Black-Scholes situation (with its flat
geometry), the expansion can degenerate at a critical (basket) strike level; a
phenomena which seems to have gone unnoticed in the literature to date.
Explicit computations relate this to a phase transition from a unique to more
than one ""most-likely"" paths (along which the diffusion, if suitably
conditioned, concentrates in the afore-mentioned regimes). This also provides a
(quantifiable) understanding of how precisely a presently out-of-money basket
option may still end up in-the-money.
"
1306.4994	q-fin	q-fin.ST	"Additive versus multiplicative parameters - applications in economics
  and finance"	"  In this paper, we pay our attention to geometric parameters and their
applications in economics and finance. We discuss the multiplicative models in
which a geometric mean and a geometric standard deviation are more natural than
arithmetic ones. We give two examples from Warsaw Stock Exchange in 1995--2009
and from a bid of 52-week treasury bills in 1992--2009 in Poland as an
illustrative example. For distributions having applications in finance and
insurance we give their multiplicative parameters as well as their estimations.
We consider, among others, heavy-tailed distributions such as lognormal and
Pareto distribution, applied to modelling of large losses.
"
1307.0444	q-fin	q-fin.GN	Revisiting the Merit-Order Effect of Renewable Energy Sources	"  An on-going debate in the energy economics and power market community has
raised the question if energy-only power markets are increasingly failing due
to growing feed-in shares from subsidized renewable energy sources (RES). The
short answer to this is: No, they are not failing. Energy-based power markets
are, however, facing several market distortions, namely from the gap between
the electricity volume traded at day-ahead markets versus the overall
electricity consumption as well as the (wrong) regulatory assumption that
variable RES generation, i.e., wind and photovoltaic (PV), truly have zero
marginal operation costs. In this paper we show that both effects over-amplify
the well-known merit-order effect of RES power feed-in beyond a level that is
explainable by underlying physical realities, i.e., thermal power plants being
willing to accept negative electricity prices to be able to stay online due to
considerations of wear & tear and start-stop constraints. We analyze the
impacts of wind and PV power feed-in on the day-ahead market for a region that
is already today experiencing significant feed-in tariff (FIT)-subsidized RES
power feed-in, the EPEX German-Austrian market zone ($\approx\,$20% FIT share).
Our analysis shows that, if the necessary regulatory adaptations are taken,
i.e., increasing the day-ahead market's share of overall load demand and using
the true marginal costs of RES units in the merit-order, energy-based power
markets can remain functional despite high RES power feed-in.
"
1307.0817	q-fin	q-fin.GN cond-mat.stat-mech	"A Statistical Test of Walrasian Equilibrium by Means of Complex Networks
  Theory"	"  We represent an exchange economy in terms of statistical ensembles for
complex networks by introducing the concept of market configuration. This is
defined as a sequence of nonnegative discrete random variables $\{w_{ij}\}$
describing the flow of a given commodity from agent $i$ to agent $j$. This
sequence can be arranged in a nonnegative matrix $W$ which we can regard as the
representation of a weighted and directed network or digraph $G$. Our main
result consists in showing that general equilibrium theory imposes highly
restrictive conditions upon market configurations, which are in most cases not
fulfilled by real markets. An explicit example with reference to the e-MID
interbank credit market is provided.
"
1307.2824	q-fin	q-fin.PM q-fin.GN	"Optimal Retirement Tontines for the 21st Century: With Reference to
  Mortality Derivatives in 1693"	"  Historical tontines promised enormous rewards to the last survivors at the
expense of those who died early. While this design appealed to the gambling
instinct, it is a suboptimal way to manage longevity risk during retirement.
This is why fair life annuities making constant payments -- where the insurance
company is exposed to the longevity risk -- induces greater lifetime utility.
However, tontines do not have to be designed using a winner-take-all approach
and insurance companies do not actually sell fair life annuities, partially due
to aggregate longevity risk.
  In this paper we derive the tontine structure that maximizes lifetime
utility, but doesn't expose the sponsor to any longevity risk. We examine its
sensitivity to the size of the tontine pool; individual longevity risk
aversion; and subjective health status. The optimal tontine varies with the
individual's longevity risk aversion $\gamma$ and the number of participants
$n$, which is problematic for product design. That said, we introduce a
structure called a natural tontine whose payout declines in exact proportion to
the (expected) survival probabilities, which is near-optimal for all $\gamma$
and $n$. We compare the utility of optimal tontines to the utility of loaded
life annuities under reasonable demographic and economic conditions and find
that the life annuity's advantage over tontines, is minimal.
  We also review and analyze the first-ever mortality-derivative issued by the
British government, known as King Williams's tontine of 1693. We shed light on
the preferences and beliefs of those who invested in the tontines vs. the
annuities and argue that tontines should be re-introduced and allowed to
co-exist with life annuities. Individuals would likely select a portfolio of
tontines and annuities that suit their personal preferences for consumption and
longevity risk, as they did over 320 years ago.
"
1308.5376	q-fin	q-fin.PM math.PR	Energy, entropy, and arbitrage	"  We introduce a pathwise approach to analyze the relative performance of an
equity portfolio with respect to a benchmark market portfolio. In this
energy-entropy framework, the relative performance is decomposed into three
components: a volatility term, a relative entropy term measuring the distance
between the portfolio weights and the market capital distribution, and another
entropy term that can be controlled by the investor by adopting a suitable
rebalancing strategy. This framework leads to a class of portfolio strategies
that allows one to outperform, in the long run, a market that is diverse and
sufficiently volatile in the sense of stochastic portfolio theory. The
framework is illustrated with several empirical examples.
"
1309.0260	q-fin	q-fin.ST	"Learning from the past, predicting the statistics for the future,
  learning an evolving system"	"  We bring the theory of rough paths to the study of non-parametric statistics
on streamed data. We discuss the problem of regression where the input variable
is a stream of information, and the dependent response is also (potentially) a
stream.
  A certain graded feature set of a stream, known in the rough path literature
as the signature, has a universality that allows formally, linear regression to
be used to characterise the functional relationship between independent
explanatory variables and the conditional distribution of the dependent
response.
  This approach, via linear regression on the signature of the stream, is
almost totally general, and yet it still allows explicit computation. The
grading allows truncation of the feature set and so leads to an efficient local
description for streams (rough paths). In the statistical context this method
offers potentially significant, even transformational dimension reduction.
  By way of illustration, our approach is applied to stationary time series
including the familiar AR model and ARCH model. In the numerical examples we
examined, our predictions achieve similar accuracy to the Gaussian Process (GP)
approach with much lower computational cost especially when the sample size is
large.
"
1309.3057	q-fin	math.PR q-fin.RM	Tail behavior of sums and differences of log-normal random variables	"  We present sharp tail asymptotics for the density and the distribution
function of linear combinations of correlated log-normal random variables, that
is, exponentials of components of a correlated Gaussian vector. The asymptotic
behavior turns out to depend on the correlation between the components, and the
explicit solution is found by solving a tractable quadratic optimization
problem. These results can be used either to approximate the probability of
tail events directly, or to construct variance reduction procedures to estimate
these probabilities by Monte Carlo methods. In particular, we propose an
efficient importance sampling estimator for the left tail of the distribution
function of the sum of log-normal variables. As a corollary of the tail
asymptotics, we compute the asymptotics of the conditional law of a Gaussian
random vector given a linear combination of exponentials of its components. In
risk management applications, this finding can be used for the systematic
construction of stress tests, which the financial institutions are required to
conduct by the regulators. We also characterize the asymptotic behavior of the
Value at Risk for log-normal portfolios in the case where the confidence level
tends to one.
"
1309.6141	q-fin	math.PR q-fin.GN	Change of measure up to a random time: Details	"  This paper extends results of Mortimer and Williams (1991) about changes of
probability measure up to a random time under the assumptions that all
martingales are continuous and that the random time avoids stopping times. We
consider locally absolutely continuous measure changes up to a random time,
changes of probability measure up to and after an honest time, and changes of
probability measure up to a pseudo-stopping time. Moreover, we apply our
results to construct a change of probability measure that is equivalent to the
enlargement formula and to build for a certain class of pseudo-stopping times a
class of measure changes that preserve the pseudo-stopping time property.
Furthermore, we study for a price process modeled by a continuous
semimartingale the stability of the No Free Lunch with Vanishing Risk (NFLVR)
property up to a random time, that avoids stopping times, in the progressively
enlarged filtration and provide sufficient conditions for this stability in
terms of the Az\'ema supermartingale.
"
1309.6505	q-fin	q-fin.PR math.AP	"General Properties of Solutions to Inhomogeneous Black-Scholes Equations
  with Discontinuous Maturity Payoffs and Application"	"  We provide representations of solutions to terminal value problems of
inhomogeneous Black-Scholes equations and studied such general properties as
min-max estimates, gradient estimates, monotonicity and convexity of the
solutions with respect to the stock price variable, which are important for
financial security pricing. In particular, we focus on finding representation
of the gradient (with respect to the stock price variable) of solutions to the
terminal value problems with discontinuous terminal payoffs or inhomogeneous
terms. Such terminal value problems are often encountered in pricing problems
of compound-like options such as Bermudan options or defaultable bonds with
discrete default barrier, default intensity and endogenous default recovery.
Our results are applied in pricing defaultable discrete coupon bonds.
"
1310.0099	q-fin	q-fin.PR	"Convergence of the discrete variance swap in time-homogeneous diffusion
  models"	"  In stochastic volatility models based on time-homogeneous diffusions, we
provide a simple necessary and sufficient condition for the discretely sampled
fair strike of a variance swap to converge to the continuously sampled fair
strike. It extends Theorem 3.8 of Jarrow, Kchia, Larsson and Protter (2013) and
gives an affirmative answer to a problem posed in this paper in the case of 3/2
stochastic volatility model. We also give precise conditions (not based on
asymptotics) when the discrete fair strike of the variance swap is higher than
the continuous one and discuss the convex order conjecture proposed by
Keller-Ressel and Griessler (2012) in this context.
"
1310.1634	q-fin	q-fin.ST physics.soc-ph q-fin.GN	Cascades in real interbank markets	"  We analyze cascades of defaults in an interbank loan market. The novel
feature of this study is that the network structure and the size distribution
of banks are derived from empirical data. We find that the ability of a
defaulted institution to start a cascade depends on an interplay of shock size
and connectivity. Further results indicate that the ability to limit default
risk by spreading the lending to many counterparts decreased with the financial
crisis. To evaluate the influence of the network structure on market stability,
we compare the simulated cascades from the empirical network with results from
different randomized network models. The results show that the empirical
network has non-random features, which cannot be captured by rewired networks.
The analysis also reveals that simulations assuming homogeneity for size of
banks and loan contracts dramatically overestimates the fragility of the
interbank market.
"
1310.3061	q-fin	q-fin.PR	"Small-maturity asymptotics for the at-the-money implied volatility slope
  in L\'evy models"	"  We consider the at-the-money strike derivative of implied volatility as the
maturity tends to zero. Our main results quantify the behavior of the slope for
infinite activity exponential L\'evy models including a Brownian component. As
auxiliary results, we obtain asymptotic expansions of short maturity
at-the-money digital call options, using Mellin transform asymptotics. Finally,
we discuss when the at-the-money slope is consistent with the steepness of the
smile wings, as given by Lee's moment formula.
"
1310.3860	q-fin	q-fin.PR	Stochastic Modeling and Fair Valuation of Drawdown Insurance	"  This paper studies the stochastic modeling of market drawdown events and the
fair valuation of insurance contracts based on drawdowns. We model the asset
drawdown process as the current relative distance from the historical maximum
of the asset value. We first consider a vanilla insurance contract whereby the
protection buyer pays a constant premium over time to insure against a drawdown
of a pre-specified level. This leads to the analysis of the conditional Laplace
transform of the drawdown time, which will serve as the building block for
drawdown insurance with early cancellation or drawup contingency. For the
cancellable drawdown insurance, we derive the investor's optimal cancellation
timing in terms of a two-sided first passage time of the underlying drawdown
process. Our model can also be applied to insure against a drawdown by a
defaultable stock. We provide analytic formulas for the fair premium and
illustrate the impact of default risk.
"
1310.4067	q-fin	q-fin.PR q-fin.GN	On pricing kernels, information and risk	"  We discuss the finding that cross-sectional characteristic based models have
yielded portfolios with higher excess monthly returns but lower risk than their
arbitrage pricing theory counterparts in an analysis of equity returns of
stocks listed on the JSE. Under the assumption of general no-arbitrage
conditions, we argue that evidence in favour of characteristic based pricing
implies that information is more likely assimilated by means of nonlinear
pricing kernels for the markets considered.
"
1310.4538	q-fin	q-fin.GN	The Origin of Fat Tails	"  We propose a random walk model of asset returns where the parameters depend
on market stress. Stress is measured by, e.g., the value of an implied
volatility index. We show that model parameters including standard deviations
and correlations can be estimated robustly and that all distributions are
approximately normal. Fat tails in observed distributions occur because time
series sample different stress levels and therefore different normal
distributions. This provides a quantitative description of the observed
distribution including the fat tails. We discuss simple applications in risk
management and portfolio construction.
"
1310.4783	q-fin	math.ST q-fin.ST stat.TH	"Asymptotic properties of maximum likelihood estimators for Heston models
  based on continuous time observations"	"  We study asymptotic properties of maximum likelihood estimators for Heston
models based on continuous time observations of the log-price process. We
distinguish three cases: subcritical (also called ergodic), critical and
supercritical. In the subcritical case, asymptotic normality is proved for all
the parameters, while in the critical and supercritical cases, non-standard
asymptotic behavior is described.
"
1310.5114	q-fin	cond-mat.dis-nn cs.LG physics.soc-ph q-fin.GN	Explore or exploit? A generic model and an exactly solvable case	"  Finding a good compromise between the exploitation of known resources and the
exploration of unknown, but potentially more profitable choices, is a general
problem, which arises in many different scientific disciplines. We propose a
stylized model for these exploration-exploitation situations, including
population or economic growth, portfolio optimisation, evolutionary dynamics,
or the problem of optimal pinning of vortices or dislocations in disordered
materials. We find the exact growth rate of this model for tree-like geometries
and prove the existence of an optimal migration rate in this case. Numerical
simulations in the one-dimensional case confirm the generic existence of an
optimum.
"
1310.6873	q-fin	q-fin.GN math.PR	Double Cascade Model of Financial Crises	"  The scope of financial systemic risk research encompasses a wide range of
interbank channels and effects, including asset correlation shocks, default
contagion, illiquidity contagion, and asset fire sales. This paper introduces a
financial network model that combines the default and liquidity stress
mechanisms into a ""double cascade mapping"". The progress and eventual result of
the crisis is obtained by iterating this mapping to its fixed point. Unlike
simpler models, this model can therefore quantify how illiquidity or default of
one bank influences the overall level of liquidity stress and default in the
system. Large-network asymptotic cascade mapping formulas are derived that can
be used for efficient network computations of the double cascade. Numerical
experiments then demonstrate that these asymptotic formulas agree qualitatively
with Monte Carlo results for large finite networks, and quantitatively except
when the initial system is placed in an exceptional ""knife-edge"" configuration.
The experiments clearly support the main conclusion that when banks respond to
liquidity stress by hoarding liquidity, then in the absence of asset fire
sales, the level of defaults in a financial network is negatively related to
the strength of bank liquidity hoarding and the eventual level of stress in the
network.
"
1311.1545	q-fin	q-fin.PR math.PR q-fin.CP	Varadhan's formula, conditioned diffusions, and local volatilities	"  Motivated by marginals-mimicking results for It\^o processes via SDEs and by
their applications to volatility modeling in finance, we discuss the weak
convergence of the law of a hypoelliptic diffusions conditioned to belong to a
target affine subspace at final time, namely $\mathcal{L}(Z_t|Y_t = y)$ if
$X_{\cdot}=(Y_\cdot,Z_{\cdot})$. To do so, we revisit Varadhan-type estimates
in a small-noise regime (as opposed to small-time), studying the density of the
lower-dimensional component $Y$. The application to stochastic volatility
models include the small-time and, for certain models, the large-strike
asymptotics of the Gyongy-Dupire's local volatility function. The final product
are asymptotic formulae that can (i) motivate parameterizations of the local
volatility surface and (ii) be used to extrapolate local volatilities in a
given model.
"
1311.6187	q-fin	math.PR q-fin.GN	Pathwise stochastic integrals for model free finance	"  We present two different approaches to stochastic integration in frictionless
model free financial mathematics. The first one is in the spirit of It\^o's
integral and based on a certain topology which is induced by the outer measure
corresponding to the minimal superhedging price. The second one is based on the
controlled rough path integral. We prove that every ""typical price path"" has a
naturally associated It\^o rough path, and justify the application of the
controlled rough path integral in finance by showing that it is the limit of
non-anticipating Riemann sums, a new result in itself. Compared to the first
approach, rough paths have the disadvantage of severely restricting the space
of integrands, but the advantage of being a Banach space theory. Both
approaches are based entirely on financial arguments and do not require any
probabilistic structure.
"
1312.6841	q-fin	q-fin.PM q-fin.GN q-fin.RM	"Hedging Against the Interest-rate Risk by Measuring the Yield-curve
  Movement"	"  By adopting the polynomial interpolation method, we propose an approach to
hedge against the interest-rate risk of the default-free bonds by measuring the
nonparallel movement of the yield-curve, such as the translation, the rotation
and the twist. The empirical analysis shows that our hedging strategies are
comparable to traditional duration-convexity strategy, or even better when we
have more suitable hedging instruments on hand. The article shows that this
strategy is flexible and robust to cope with the interest-rate risk and can
help fine-tune a position as time changes.
"
1401.1888	q-fin	q-fin.TR cs.CE q-fin.ST	"Dynamical Models of Stock Prices Based on Technical Trading Rules Part
  I: The Models"	"  In this paper we use fuzzy systems theory to convert the technical trading
rules commonly used by stock practitioners into excess demand functions which
are then used to drive the price dynamics. The technical trading rules are
recorded in natural languages where fuzzy words and vague expressions abound.
In Part I of this paper, we will show the details of how to transform the
technical trading heuristics into nonlinear dynamic equations. First, we define
fuzzy sets to represent the fuzzy terms in the technical trading rules; second,
we translate each technical trading heuristic into a group of fuzzy IF-THEN
rules; third, we combine the fuzzy IF-THEN rules in a group into a fuzzy
system; and finally, the linear combination of these fuzzy systems is used as
the excess demand function in the price dynamic equation. We transform a wide
variety of technical trading rules into fuzzy systems, including moving average
rules, support and resistance rules, trend line rules, big buyer, big seller
and manipulator rules, band and stop rules, and volume and relative strength
rules. Simulation results show that the price dynamics driven by these
technical trading rules are complex and chaotic, and some common phenomena in
real stock prices such as jumps, trending and self-fulfilling appear naturally.
"
1401.1891	q-fin	q-fin.TR cs.CE q-fin.ST	"Dynamical Models of Stock Prices Based on Technical Trading Rules Part
  II: Analysis of the Models"	"  In Part II of this paper, we concentrate our analysis on the price dynamical
model with the moving average rules developed in Part I of this paper. By
decomposing the excessive demand function, we reveal that it is the interplay
between trend-following and contrarian actions that generates the price chaos,
and give parameter ranges for the price series to change from divergence to
chaos and to oscillation. We prove that the price dynamical model has an
infinite number of equilibrium points but all these equilibrium points are
unstable. We demonstrate the short-term predictability of the return volatility
and derive the detailed formula of the Lyapunov exponent as function of the
model parameters. We show that although the price is chaotic, the volatility
converges to some constant very quickly at the rate of the Lyapunov exponent.
We extract the formula relating the converged volatility to the model
parameters based on Monte-Carlo simulations. We explore the circumstances under
which the returns show independency and illustrate in details how the
independency index changes with the model parameters. Finally, we plot the
strange attractor and return distribution of the chaotic price model to
illustrate the complex structure and fat-tailed distribution of the returns.
"
1401.1892	q-fin	q-fin.TR cs.CE q-fin.ST	"Dynamical Models of Stock Prices Based on Technical Trading Rules Part
  III: Application to Hong Kong Stocks"	"  In Part III of this study, we apply the price dynamical model with big buyers
and big sellers developed in Part I of this paper to the daily closing prices
of the top 20 banking and real estate stocks listed in the Hong Kong Stock
Exchange. The basic idea is to estimate the strength parameters of the big
buyers and the big sellers in the model and make buy/sell decisions based on
these parameter estimates. We propose two trading strategies: (i)
Follow-the-Big-Buyer which buys when big buyer begins to appear and there is no
sign of big sellers, holds the stock as long as the big buyer is still there,
and sells the stock once the big buyer disappears; and (ii) Ride-the-Mood which
buys as soon as the big buyer strength begins to surpass the big seller
strength, and sells the stock once the opposite happens. Based on the testing
over 245 two-year intervals uniformly distributed across the seven years from
03-July-2007 to 02-July-2014 which includes a variety of scenarios, the net
profits would increase 67% or 120% on average if an investor switched from the
benchmark Buy-and-Hold strategy to the Follow-the-Big-Buyer or Ride-the-Mood
strategies during this period, respectively.
"
1401.3911	q-fin	stat.AP q-fin.ST	"Inference on Self-Exciting Jumps in Prices and Volatility using High
  Frequency Measures"	"  Dynamic jumps in the price and volatility of an asset are modelled using a
joint Hawkes process in conjunction with a bivariate jump diffusion. A state
space representation is used to link observed returns, plus nonparametric
measures of integrated volatility and price jumps, to the specified model
components; with Bayesian inference conducted using a Markov chain Monte Carlo
algorithm. An evaluation of marginal likelihoods for the proposed model
relative to a large number of alternative models, including some that have
featured in the literature, is provided. An extensive empirical investigation
is undertaken using data on the S&P500 market index over the 1996 to 2014
period, with substantial support for dynamic jump intensities - including in
terms of predictive accuracy - documented.
"
1401.8026	q-fin	q-fin.RM	"Elimination of systemic risk in financial networks by means of a
  systemic risk transaction tax"	"  Financial markets are exposed to systemic risk (SR), the risk that a major
fraction of the system ceases to function, and collapses. It has recently
become possible to quantify SR in terms of underlying financial networks where
nodes represent financial institutions, and links capture the size and maturity
of assets (loans), liabilities, and other obligations, such as derivatives. We
demonstrate that it is possible to quantify the share of SR that individual
liabilities within a financial network contribute to the overall SR. We use
empirical data of nationwide interbank liabilities to show that the marginal
contribution to overall SR of liabilities for a given size varies by a factor
of a thousand. We propose a tax on individual transactions that is proportional
to their marginal contribution to overall SR. If a transaction does not
increase SR it is tax-free. With an agent-based model (CRISIS macro-financial
model) we demonstrate that the proposed ""Systemic Risk Tax"" (SRT) leads to a
self-organised restructuring of financial networks that are practically free of
SR. The SRT can be seen as an insurance for the public against costs arising
from cascading failure. ABM predictions are shown to be in remarkable agreement
with the empirical data and can be used to understand the relation of credit
risk and SR.
"
1402.4683	q-fin	math.PR q-fin.RM	Tails of weakly dependent random vectors	"  We introduce a new functional measure of tail dependence for weakly dependent
(asymptotically independent) random vectors, termed weak tail dependence
function. The new measure is defined at the level of copulas and we compute it
for several copula families such as the Gaussian copula, copulas of a class of
Gaussian mixture models, certain Archimedean copulas and extreme value copulas.
The new measure allows to quantify the tail behavior of certain functionals of
weakly dependent random vectors at the log scale.
"
1402.6313	q-fin	q-fin.PM	"Expert Opinions and Logarithmic Utility Maximization in a Market with
  Gaussian Drift"	"  This paper investigates optimal portfolio strategies in a financial market
where the drift of the stock returns is driven by an unobserved Gaussian mean
reverting process. Information on this process is obtained from observing stock
returns and expert opinions. The latter provide at discrete time points an
unbiased estimate of the current state of the drift. Nevertheless, the drift
can only be observed partially and the best estimate is given by the
conditional expectation given the available information, i.e., by the filter.
We provide the filter equations in the model with expert opinion and derive in
detail properties of the conditional variance. For an investor who maximizes
expected logarithmic utility of his portfolio, we derive the optimal strategy
explicitly in different settings for the available information. The optimal
expected utility, the value function of the control problem, depends on the
conditional variance. The bounds and asymptotic results for the conditional
variances are used to derive bounds and asymptotic properties for the value
functions. The results are illustrated with numerical examples.
"
1403.0527	q-fin	math.ST math.PR q-fin.ST stat.TH	"Parameter estimation for the subcritical Heston model based on discrete
  time observations"	"  We study asymptotic properties of some (essentially conditional least
squares) parameter estimators for the subcritical Heston model based on
discrete time observations derived from conditional least squares estimators of
some modified parameters.
"
1403.1183	q-fin	q-fin.PR math.PR	On the Frequency of Drawdowns for Brownian Motion Processes	"  Drawdowns measuring the decline in value from the historical running maxima
over a given period of time, are considered as extremal events from the
standpoint of risk management. To date, research on the topic has mainly focus
on the side of severity by studying the first drawdown over certain
pre-specified size. In this paper, we extend the discussion by investigating
the frequency of drawdowns, and some of their inherent characteristics. We
consider two types of drawdown time sequences depending on whether a historical
running maximum {is reset or not}. For each type, we study the frequency rate
of drawdowns, the Laplace transform of the $n$-th drawdown time, the
distribution of the running maximum and the value process at the $n$-th
drawdown time, as well as some other quantities of interest. Interesting
relationships between these two drawdown time sequences are also established.
Finally, insurance policies protecting against the risk of frequent drawdowns
are also proposed and priced.
"
1403.1548	q-fin	q-fin.GN	To bail-out or to bail-in? Answers from an agent-based model	"  Since beginning of the 2008 financial crisis almost half a trillion euros
have been spent to financially assist EU member states in taxpayer-funded
bail-outs. These crisis resolutions are often accompanied by austerity programs
causing political and social friction on both domestic and international
levels. The question of how to resolve failing financial institutions under
which economic preconditions is therefore a pressing and controversial issue of
vast political importance. In this work we employ an agent-based model to study
the economic and financial ramifications of three highly relevant crisis
resolution mechanisms. To establish the validity of the model we show that it
reproduces a series of key stylized facts if the financial and real economy.
The distressed institution can either be closed via a purchase & assumption
transaction, it can be bailed-out using taxpayer money, or it may be bailed-in
in a debt-to-equity conversion. We find that for an economy characterized by
low unemployment and high productivity the optimal crisis resolution with
respect to financial stability and economic productivity is to close the
distressed institution. For economies in recession with high unemployment the
bail-in tool provides the most efficient crisis resolution mechanism. Under no
circumstances do taxpayer-funded bail-out schemes outperform bail-ins with
private sector involvement.
"
1403.2229	q-fin	q-fin.TR	"A reinforcement learning extension to the Almgren-Chriss model for
  optimal trade execution"	"  Reinforcement learning is explored as a candidate machine learning technique
to enhance existing analytical solutions for optimal trade execution with
elements from the market microstructure. Given a volume-to-trade, fixed time
horizon and discrete trading periods, the aim is to adapt a given volume
trajectory such that it is dynamic with respect to favourable/unfavourable
conditions during realtime execution, thereby improving overall cost of
trading. We consider the standard Almgren-Chriss model with linear price impact
as a candidate base model. This model is popular amongst sell-side institutions
as a basis for arrival price benchmark execution algorithms. By training a
learning agent to modify a volume trajectory based on the market's prevailing
spread and volume dynamics, we are able to improve post-trade implementation
shortfall by up to 10.3% on average compared to the base model, based on a
sample of stocks and trade sizes in the South African equity market.
"
1403.4099	q-fin	q-fin.CP cs.DC cs.NE	"High-speed detection of emergent market clustering via an unsupervised
  parallel genetic algorithm"	"  We implement a master-slave parallel genetic algorithm (PGA) with a bespoke
log-likelihood fitness function to identify emergent clusters within price
evolutions. We use graphics processing units (GPUs) to implement a PGA and
visualise the results using disjoint minimal spanning trees (MSTs). We
demonstrate that our GPU PGA, implemented on a commercially available general
purpose GPU, is able to recover stock clusters in sub-second speed, based on a
subset of stocks in the South African market. This represents a pragmatic
choice for low-cost, scalable parallel computing and is significantly faster
than a prototype serial implementation in an optimised C-based
fourth-generation programming language, although the results are not directly
comparable due to compiler differences. Combined with fast online intraday
correlation matrix estimation from high frequency data for cluster
identification, the proposed implementation offers cost-effective,
near-real-time risk assessment for financial practitioners.
"
1403.4460	q-fin	q-fin.GN physics.data-an	"Stationarity, non-stationarity and early warning signals in economic
  networks"	"  Economic integration, globalization and financial crises represent examples
of processes whose understanding requires the analysis of the underlying
network structure. Of particular interest is establishing whether a real
economic network is in a state of (quasi)stationary equilibrium, i.e.
characterized by smooth structural changes rather than abrupt transitions.
While in the former case the behaviour of the system can be reasonably
controlled and predicted, in the latter case this is generally impossible.
Here, we propose a method to assess whether a real economic network is in a
quasi-stationary state by checking the consistency of its structural evolution
with appropriate quasi-equilibrium maximum-entropy ensembles of graphs. As
illustrative examples, we consider the International Trade Network (ITN) and
the Dutch Interbank Network (DIN). We find that the ITN is an almost perfect
example of quasi-equilibrium network, while the DIN is clearly
out-of-equilibrium. In the latter, the entity of the deviation from
quasi-stationarity contains precious information that allows us to identify
remarkable early warning signals of the interbank crisis of 2008. These early
warning signals involve certain dyadic and triadic topological properties,
including dangerous 'debt loops' with different levels of interbank
reciprocity.
"
1404.0410	q-fin	q-fin.PR math.PR	Non-Arbitrage under a Class of Honest Times	"  This paper quantifies the interplay between the non-arbitrage notion of
No-Unbounded-Profit-with-Bounded-Risk (NUPBR hereafter) and additional
information generated by a random time. This study complements the one of
Aksamit/Choulli/Deng/Jeanblanc [1] in which the authors studied similar topics
for the case of stopping at the random time instead, while herein we are
concerned with the part after the occurrence of the random time. Given that all
the literature -up to our knowledge- proves that the NUPBR notion is always
violated after honest times that avoid stopping times in a continuous
filtration, herein we propose a new class of honest times for which the NUPBR
notion can be preserved for some models. For this family of honest times, we
elaborate two principal results. The first main result characterizes the pairs
of initial market and honest time for which the resulting model preserves the
NUPBR property, while the second main result characterizes the honest times
that preserve the NUPBR property for any quasi-left continuous model.
Furthermore, we construct explicitly ""the-after-tau"" local martingale deflators
for a large class of initial models (i.e. models in the small filtration) that
are already risk-neutralized.
"
1404.1351	q-fin	q-fin.PR q-fin.RM q-fin.ST	"Model-Free Discretisation-Invariant Swaps and S&P 500 Higher-Moment Risk
  Premia"	"  We derive a general multivariate theory for realised characteristics of
`model-free discretisation-invariant swaps', so-called because the standard
no-arbitrage assumption of martingale forward prices is sufficient to derive
fair-value swap rates for such characteristics which have no jump or
discretisation errors. This theory underpins specific examples for swaps based
on higher moments of a single log return distribution where exact replication
is possible via option-implied `fundamental contracts' like the log contact.
The common factors determining the S&P 500 risk premia associated with these
higher-moment characteristics are investigated empirically at the daily, weekly
and monthly frequencies.
"
1404.4275	q-fin	cs.CE cs.CR q-fin.GN	"A Bitcoin system with no mining and no history transactions: Build a
  compact Bitcoin system"	"  We give an explicit definition of decentralization and show you that
decentralization is almost impossible for the current stage and Bitcoin is the
first truly noncentralized currency in the currency history. We propose a new
framework of noncentralized cryptocurrency system with an assumption of the
existence of a weak adversary for a bank alliance. It abandons the mining
process and blockchain, and removes history transactions from data
synchronization. We propose a consensus algorithm named Converged Consensus for
a noncentralized cryptocurrency system.
"
1404.5222	q-fin	q-fin.PM math.OC	"Self-Averaging Property of Minimal Investment Risk of Mean-Variance
  Model"	"  In portfolio optimization problems, the minimum expected investment risk is
not always smaller than the expected minimal investment risk. That is, using a
well-known approach from operations research, it is possible to derive a
strategy that minimizes the expected investment risk, but this strategy does
not always result in the best rate of return on assets. Prior to making
investment decisions, it is important to an investor to know the potential
minimal investment risk (or the expected minimal investment risk) and to
determine the strategy that will maximize the return on assets. We use the
self-averaging property to analyze the potential minimal investment risk and
the concentrated investment level for the strategy that gives the best rate of
return. We compare the results from our method with the results obtained by the
operations research approach and with those obtained by a numerical simulation
using the optimal portfolio. The results of our method and the numerical
simulation are in agreement, but they differ from that of the operations
research approach.
"
1404.6190	q-fin	q-fin.PR math.PR	Polynomial Term Structure Models	"  This article discuss a class of tractable model in the form of polynomial
type.
"
1404.7493	q-fin	q-fin.PM q-fin.MF q-fin.ST	Drawdown: From Practice to Theory and Back Again	"  Maximum drawdown, the largest cumulative loss from peak to trough, is one of
the most widely used indicators of risk in the fund management industry, but
one of the least developed in the context of measures of risk. We formalize
drawdown risk as Conditional Expected Drawdown (CED), which is the tail mean of
maximum drawdown distributions. We show that CED is a degree one positive
homogenous risk measure, so that it can be linearly attributed to factors; and
convex, so that it can be used in quantitative optimization. We empirically
explore the differences in risk attributions based on CED, Expected Shortfall
(ES) and volatility. An important feature of CED is its sensitivity to serial
correlation. In an empirical study that fits AR(1) models to US Equity and US
Bonds, we find substantially higher correlation between the autoregressive
parameter and CED than with ES or with volatility.
"
1404.7632	q-fin	q-fin.ST math.PR	"A multivariate model for financial indices and an algorithm for
  detection of jumps in the volatility"	"  We consider a mean-reverting stochastic volatility model which satisfies some
relevant stylized facts of financial markets. We introduce an algorithm for the
detection of peaks in the volatility profile, that we apply to the time series
of Dow Jones Industrial Average and Financial Times Stock Exchange 100 in the
period 1984-2013. Based on empirical results, we propose a bivariate version of
the model, for which we find an explicit expression for the decay over time of
cross-asset correlations between absolute returns. We compare our theoretical
predictions with empirical estimates on the same financial time series, finding
an excellent agreement.
"
1405.0585	q-fin	q-fin.EC cond-mat.stat-mech q-fin.GN	Evaluating gambles using dynamics	"  Gambles are random variables that model possible changes in monetary wealth.
Classic decision theory transforms money into utility through a utility
function and defines the value of a gamble as the expectation value of utility
changes. Utility functions aim to capture individual psychological
characteristics, but their generality limits predictive power. Expectation
value maximizers are defined as rational in economics, but expectation values
are only meaningful in the presence of ensembles or in systems with ergodic
properties, whereas decision-makers have no access to ensembles and the
variables representing wealth in the usual growth models do not have the
relevant ergodic properties. Simultaneously addressing the shortcomings of
utility and those of expectations, we propose to evaluate gambles by averaging
wealth growth over time. No utility function is needed, but a dynamic must be
specified to compute time averages. Linear and logarithmic ""utility functions""
appear as transformations that generate ergodic observables for purely additive
and purely multiplicative dynamics, respectively. We highlight inconsistencies
throughout the development of decision theory, whose correction clarifies that
our perspective is legitimate. These invalidate a commonly cited argument for
bounded utility functions.
"
1405.1212	q-fin	q-fin.RM q-fin.PR	"Market risk modelling in Solvency II regime and hedging options not
  using underlying"	"  In the paper we develop mathematical tools of quantile hedging in incomplete
market. Those could be used for two significant applications:
  o calculating the \textbf{optimal capital requirement imposed by Solvency II}
(Directive 2009/138/EC of the European Parliament and of the Council) when the
market and non-market risk is present in insurance company. We show hot to find
the minimal capital $V_0$ to provide with the one-year hedging strategy for
insurance company satisfying $E\left[{\mathbf 1}_{\{V_1 \geq
D\}}\right]=0.995$, where $V_1$ denotes the value of insurance company in one
year time and $D$ is the payoff of the contract.
  o finding a hedging strategy for derivative not using underlying but an asset
with dynamics correlated or in some other way dependent (no deterministically)
on underlying. The work is a generalisation of the work of Klusik and Palmowski
\cite{KluPal}.
  Keywords: quantile hedging, solvency II, capital modelling, hedging options
on nontradable asset.
"
1405.1326	q-fin	math.PR math.ST q-fin.RM q-fin.ST stat.ME stat.TH	Paths and indices of maximal tail dependence	"  We demonstrate both analytically and numerically that the existing methods
for measuring tail dependence in copulas may sometimes underestimate the extent
of extreme co-movements of dependent risks and, therefore, may not always
comply with the new paradigm of prudent risk management. This phenomenon holds
in the context of both symmetric and asymmetric copulas with and without
singularities. As a remedy, we introduce a notion of paths of maximal (tail)
dependence and utilize it to propose several new indices of tail dependence.
The suggested new indices are conservative, conform with the basic concepts of
modern quantitative risk management, and are able to distinguish between
distinct risky positions in situations when the existing indices fail to do so.
"
1405.1791	q-fin	stat.AP q-fin.RM q-fin.ST	On the Super-Additivity and Estimation Biases of Quantile Contributions	"  Sample measures of top centile contributions to the total (concentration) are
downward biased, unstable estimators, extremely sensitive to sample size and
concave in accounting for large deviations. It makes them particularly unfit in
domains with power law tails, especially for low values of the exponent. These
estimators can vary over time and increase with the population size, as shown
in this article, thus providing the illusion of structural changes in
concentration. They are also inconsistent under aggregation and mixing
distributions, as the weighted average of concentration measures for A and B
will tend to be lower than that from A U B. In addition, it can be shown that
under such fat tails, increases in the total sum need to be accompanied by
increased sample size of the concentration measurement. We examine the
estimation superadditivity and bias under homogeneous and mixed distributions.
"
1405.2023	q-fin	q-fin.MF q-fin.TR	Simultaneous Trading in 'Lit' and Dark Pools	"  We consider an optimal trading problem over a finite period of time during
which an investor has access to both a standard exchange and a dark pool. We
take the exchange to be an order-driven market and propose a continuous-time
setup for the best bid price and the market spread, both modelled by L\'evy
processes. Effects on the best bid price arising from the arrival of limit buy
orders at more favourable prices, the incoming market sell orders potentially
walking the book, and deriving from the cancellations of limit sell orders at
the best ask price are incorporated in the proposed price dynamics. A permanent
impact that occurs when 'lit' pool trades cannot be avoided is built in, and an
instantaneous impact that models the slippage, to which all 'lit' exchange
trades are subject, is also considered. We assume that the trading price in the
dark pool is the mid-price and that no fees are due for posting orders. We
allow for partial trade executions in the dark pool, and we find the optimal
trading strategy in both venues. Since the mid-price is taken from the
exchange, the dynamics of the limit order book also affects the optimal
allocation of shares in the dark pool. We propose a general objective function
and we show that, subject to suitable technical conditions, the value function
can be characterised by the unique continuous viscosity solution to the
associated partial integro differential equation. We present two explicit
examples of the price and the spread models, and derive the associated optimal
trading strategy numerically. We discuss the various degrees of the agent's
risk aversion and further show that roundtrips, i.e. posting the remaining
inventory in the dark pool at every point in time, are not necessarily
beneficial.
"
1405.2609	q-fin	q-fin.MF q-fin.PR	"Risk Neutral Option Pricing With Neither Dynamic Hedging nor Complete
  Markets"	"  Proof that under simple assumptions, such as constraints of Put-Call Parity,
the probability measure for the valuation of a European option has the mean
derived from the forward price which can, but does not have to be the
risk-neutral one, under any general probability distribution, bypassing the
Black-Scholes-Merton dynamic hedging argument, and without the requirement of
complete markets and other strong assumptions. We confirm that the heuristics
used by traders for centuries are both more robust, more consistent, and more
rigorous than held in the economics literature. We also show that options can
be priced using infinite variance (finite mean) distributions.
"
1405.3202	q-fin	physics.soc-ph physics.data-an q-fin.GN	The systematic structure and predictability of urban business diversity	"  Understanding cities is central to addressing major global challenges from
climate and health to economic resilience. Although increasingly perceived as
fundamental socio-economic units, the detailed fabric of urban economic
activities is only now accessible to comprehensive analyses with the
availability of large datasets. Here, we study abundances of business
categories across U.S. metropolitan statistical areas to investigate how
diversity of economic activities depends on city size. A universal structure
common to all cities is revealed, manifesting self-similarity in internal
economic structure as well as aggregated metrics (GDP, patents, crime). A
derivation is presented that explains universality and the observed empirical
distribution. The model incorporates a generalized preferential attachment
process with ceaseless introduction of new business types. Combined with
scaling analyses for individual categories, the theory quantitatively predicts
how individual business types systematically change rank with city size,
thereby providing a quantitative means for estimating their expected abundances
as a function of city size. These results shed light on processes of economic
differentiation with scale, suggesting a general structure for the growth of
national economies as integrated urban systems.
"
1405.3512	q-fin	q-fin.GN physics.soc-ph	Quantum Brownian motion model for the stock market	"  It is believed by the majority today that the efficient market hypothesis is
imperfect because of market irrationality. Using the physical concepts and
mathematical structures of quantum mechanics, we construct an econophysics
framework for the stock market, based on which we analogously map massive
numbers of single stocks into a reservoir consisting of many quantum harmonic
oscillators and their stock index into a typical quantum open system--a quantum
Brownian particle. In particular, the irrationality of stock transactions is
quantitatively considered as the Planck constant within Heisenberg's
uncertainty relationship of quantum mechanics in an analogous manner. We
analyze real stock data of Shanghai Stock Exchange of China and investigate
fat-tail phenomena and non-Markovian behaviors of the stock index with the
assistance of the quantum Brownian motion model, thereby interpreting and
studying the limitations of the classical Brownian motion model for the
efficient market hypothesis from a new perspective of quantum open system
dynamics.
"
1405.3561	q-fin	q-fin.CP math.NA	"An explicit Euler scheme with strong rate of convergence for financial
  SDEs with non-Lipschitz coefficients"	"  We consider the approximation of stochastic differential equations (SDEs)
with non-Lipschitz drift or diffusion coefficients. We present a modified
explicit Euler-Maruyama discretisation scheme that allows us to prove strong
convergence, with a rate. Under some regularity and integrability conditions,
we obtain the optimal strong error rate. We apply this scheme to SDEs widely
used in the mathematical finance literature, including the
Cox-Ingersoll-Ross~(CIR), the 3/2 and the Ait-Sahalia models, as well as a
family of mean-reverting processes with locally smooth coefficients. We
numerically illustrate the strong convergence of the scheme and demonstrate its
efficiency in a multilevel Monte Carlo setting.
"
1405.4474	q-fin	q-fin.PR math.PR	"Local martingale deflators for asset processes stopped at a default time
  $S^\tau$ or right before $S^{\tau-}$"	"  Let $\mathbb{F}\subset \mathbb{G}$ be two filtrations and $S$ be a
$\mathbb{F}$ semimartingale possessing a $\mathbb{F}$ local martingale
deflator. Consider $\tau$ a $\mathbb{G}$ stopping time. We study the problem
whether $S^{\tau-}$ or $S^{\tau}$ can have $\mathbb{G}$ local martingale
deflators. A suitable theoretical framework is set up in this paper, within
which necessary/sufficient conditions for the problem to be solved have been
proved. Under these conditions, we will construct $\mathbb{G}$ local martingale
deflators for $S^{\tau-}$ or for $S^{\tau}$. Among others, it is proved that
$\mathbb{G}$ local martingale deflators are multiples of $\mathbb{F}$ local
martingale deflators, with a multiplicator coming from the multiplicative
decomposition of the Az\'ema supermartingale of $\tau$. The proofs of the
necessary/sufficient conditions require various results to be established about
Az\'ema supermartingale, about local martingale deflator, about filtration
enlargement, which are interesting in themselves.
  Our study is based on a filtration enlargement setting. For applications, it
is important to have a method to infer the existence of such setting from the
knowledge of the market information. This question is discussed at the end of
the paper.
"
1405.4490	q-fin	q-fin.GN physics.soc-ph	"Quantum spatial-periodic harmonic model for daily price-limited stock
  markets"	"  We investigate the behavior of stocks in daily price-limited stock markets by
purposing a quantum spatial-periodic harmonic model. The stock price is
presumed to oscillate and damp in a quantum spatial-periodic harmonic
oscillator potential well. Complicated non-linear relations including
inter-band positive correlation and intra-band negative correlation between the
volatility and the trading volume of stocks are derived by considering the
energy band structure of the model. The validity of price limitation is then
examined and abnormal phenomena of a price-limited stock market (Shanghai Stock
Exchange) of China are studied by applying our quantum model.
"
1405.5000	q-fin	q-fin.ST physics.soc-ph	"Correlation structure and principal components in global crude oil
  market"	"  This article investigates the correlation structure of the global crude oil
market using the daily returns of 71 oil price time series across the world
from 1992 to 2012. We identify from the correlation matrix six clusters of time
series exhibiting evident geographical traits, which supports Weiner's (1991)
regionalization hypothesis of the global oil market. We find that intra-cluster
pairs of time series are highly correlated while inter-cluster pairs have
relatively low correlations. Principal component analysis shows that most
eigenvalues of the correlation matrix locate outside the prediction of the
random matrix theory and these deviating eigenvalues and their corresponding
eigenvectors contain rich economic information. Specifically, the largest
eigenvalue reflects a collective effect of the global market, other four
largest eigenvalues possess a partitioning function to distinguish the six
clusters, and the smallest eigenvalues highlight the pairs of time series with
the largest correlation coefficients. We construct an index of the global oil
market based on the eigenfortfolio of the largest eigenvalue, which evolves
similarly as the average price time series and has better performance than the
benchmark $1/N$ portfolio under the buy-and-hold strategy.
"
1405.5230	q-fin	q-fin.MF q-fin.TR	"A Functional Limit Theorem for Limit Order Books with State Dependent
  Price Dynamics"	"  We consider a stochastic model for the dynamics of the two-sided limit order
book (LOB). Our model is flexible enough to allow for a dependence of the price
dynamics on volumes. For the joint dynamics of best bid and ask prices and the
standing buy and sell volume densities, we derive a functional limit theorem,
which states that our LOB model converges in distribution to a fully coupled
SDE-SPDE system when the order arrival rates tend to infinity and the impact of
an individual order arrival on the book as well as the tick size tends to zero.
The SDE describes the bid/ask price dynamics while the SPDE describes the
volume dynamics.
"
1405.6400	q-fin	physics.soc-ph cs.SI q-fin.GN	Networks of Military Alliances, Wars, and International Trade	"  We investigate the role of networks of alliances in preventing (multilateral)
interstate wars. We first show that, in the absence of international trade, no
network of alliances is peaceful and stable. We then show that international
trade induces peaceful and stable networks: trade increases the density of
alliances so that countries are less vulnerable to attack and also reduces
countries' incentives to attack an ally. We present historical data on wars and
trade, noting that the dramatic drop in interstate wars since 1950, and
accompanying densification and stabilization of alliances, are consistent with
the model but not other prominent theories.
"
1405.6677	q-fin	math.ST q-fin.RM stat.TH	Bregman superquantiles. Estimation methods and applications	"  In this work, we extend some quantities introduced in ""Optimization of
conditional value-at-risk"" of R.T Rockafellar and S. Uryasev to the case where
the proximity between real numbers is measured by using a Bregman divergence.
This leads to the definition of the Bregman superquantile. Axioms of a coherent
measure of risk discussed in ""Coherent approches to risk in optimization under
uncertainty"" of R.T Rockafellar are studied in the case of Bregman
superquantile. Furthermore, we deal with asymptotic properties of a Monte Carlo
estimator of the Bregman superquantile.
"
1405.6905	q-fin	q-fin.MF math.ST stat.TH	On the stationarity of Dynamic Conditional Correlation models	"  We provide conditions for the existence and the unicity of strictly
stationary solutions of the usual Dynamic Conditional Correlation GARCH models
(DCC-GARCH). The proof is based on Tweedie's (1988) criteria, after having
rewritten DCC-GARCH models as nonlinear Markov chains. Moreover, we study the
existence of their finite moments.
"
1405.7801	q-fin	q-fin.EC math.PR	Gambling in contests with random initial law	"  This paper studies a variant of the contest model introduced in Seel and
Strack [J. Econom. Theory 148 (2013) 2033-2048]. In the Seel-Strack contest,
each agent or contestant privately observes a Brownian motion, absorbed at
zero, and chooses when to stop it. The winner of the contest is the agent who
stops at the highest value. The model assumes that all the processes start from
a common value $x_0>0$ and the symmetric Nash equilibrium is for each agent to
utilise a stopping rule which yields a randomised value for the stopped
process. In the two-player contest, this randomised value has a uniform
distribution on $[0,2x_0]$. In this paper, we consider a variant of the problem
whereby the starting values of the Brownian motions are independent,
nonnegative random variables that have a common law $\mu$. We consider a
two-player contest and prove the existence and uniqueness of a symmetric Nash
equilibrium for the problem. The solution is that each agent should aim for the
target law $\nu$, where $\nu$ is greater than or equal to $\mu$ in convex
order; $\nu$ has an atom at zero of the same size as any atom of $\mu$ at zero,
and otherwise is atom free; on $(0,\infty)$ $\nu$ has a decreasing density; and
the density of $\nu$ only decreases at points where the convex order constraint
is binding.
"
1406.0412	q-fin	q-fin.MF	Option Pricing in an Imperfect World	"  In a model with no given probability measure, we consider asset pricing in
the presence of frictions and other imperfections and characterize the property
of coherent pricing, a notion related to (but much weaker than) the no
arbitrage property. We show that prices are coherent if and only if the set of
pricing measures is non empty, i.e. if pricing by expectation is possible. We
then obtain a decomposition of coherent prices highlighting the role of
bubbles. eventually we show that under very weak conditions the coherent
pricing of options allows for a very clear representation from which it is
possible, as in the original work of Breeden and Litzenberger, to extract the
implied probability. Eventually we test this conclusion empirically via a new
non parametric approach.
"
1406.1149	q-fin	q-fin.PR math.NA	"Numerical analysis for Spread option pricing model in illiquid
  underlying asset market: full feedback model"	"  This paper performs the numerical analysis and the computation of a Spread
option in a market with imperfect liquidity. The number of shares traded in the
stock market has a direct impact on the stock's price. Thus, we consider a
full-feedback model in which price impact is fully incorporated into the model.
The price of a Spread option is characterize by a nonlinear partial
differential equation. This is reduced to linear equations by asymptotic
expansions. The Peaceman-Rachford scheme as an alternating direction implicit
method is employed to solve the linear equations numerically. We discuss the
stability and the convergence of the numerical scheme. Illustrative examples
are included to demonstrate the validity and applicability of the presented
method. Finally we provide a numerical analysis of the illiquidity effect in
replicating an European Spread option; compared to the Black-Scholes case, a
trader generally buys more stock to replicate this option.
"
1406.1936	q-fin	q-fin.MF math.PR	Stochastic Analysis Seminar on Filtering Theory	"  These notes were originally written for the Stochastic Analysis Seminar in
the Department of Operations Research and Financial Engineering at Princeton
University, in February of 2011. The seminar was attended and supported by
members of the Research Training Group, with the author being partially
supported by NSF grant DMS-0739195.
"
1406.2133	q-fin	q-fin.PR	"Historical Backtesting of Local Volatility Model using AUD/USD Vanilla
  Options"	"  The Local Volatility model is a well-known extension of the Black-Scholes
constant volatility model whereby the volatility is dependent on both time and
the underlying asset. This model can be calibrated to provide a perfect fit to
a wide range of implied volatility surfaces. The model is easy to calibrate and
still very popular in FX option trading. In this paper we address a question of
validation of the Local Volatility model. Different stochastic models for the
underlying can be calibrated to provide a good fit to the current market data
but should be recalibrated every trading date. A good fit to the current market
data does not imply that the model is appropriate and historical backtesting
should be performed for validation purposes. We study delta hedging errors
under the Local Volatility model using historical data from 2005 to 2011 for
the AUD/USD implied volatility. We performed backtests for a range of option
maturities and strikes using sticky delta and theoretically correct delta
hedging. The results show that delta hedging errors under the standard
Black-Scholes model are no worse than that of the Local Volatility model.
Moreover, for the case of in and at the money options, the hedging error for
the Back-Scholes model is significantly better.
"
1406.4301	q-fin	q-fin.MF math.PR	A general HJM framework for multiple yield curve modeling	"  We propose a general framework for modeling multiple yield curves which have
emerged after the last financial crisis. In a general semimartingale setting,
we provide an HJM approach to model the term structure of multiplicative
spreads between FRA rates and simply compounded OIS risk-free forward rates. We
derive an HJM drift and consistency condition ensuring absence of arbitrage
and, in addition, we show how to construct models such that multiplicative
spreads are greater than one and ordered with respect to the tenor's length.
When the driving semimartingale is specified as an affine process, we obtain a
flexible Markovian structure. Finally, we show that the proposed framework
allows to unify and extend several recent approaches to multiple yield curve
modeling.
"
1406.5817	q-fin	q-fin.RM physics.soc-ph q-fin.GN q-fin.TR	Reduction of systemic risk by means of Pigouvian taxation	"  We analyze the possibility of reduction of systemic risk in financial markets
through Pigouvian taxation of financial institutions which is used to support
the rescue fund. We introduce the concept of the cascade risk with a clear
operational definition as a subclass and a network related measure of the
systemic risk. Using financial networks constructed from real Italian money
market data and using realistic parameters, we show that the cascade risk can
be substantially reduced by a small rate of taxation and by means of a simple
strategy of the money transfer from the rescue fund to interbanking market
subjects. Furthermore, we show that while negative effects on the return on
investment ($ROI$) are direct and certain, an overall positive effect on risk
adjusted return on investments ($ROI^{RA}$) is visible. Please note that
\emph{the taxation} is introduced as a monetary/regulatory, not as a fiscal
measure, as the term could suggest. \emph{The rescue fund} is implemented in a
form of a common reserve fund.
"
1406.6441	q-fin	physics.soc-ph cond-mat.stat-mech q-fin.EC	"Thermodynamics of inequalities: from precariousness to economic
  stratification"	"  Growing economic inequalities are observed in several countries throughout
the world. Following Pareto, the power-law structure of these inequalities has
been the subject of much theoretical and empirical work. But their
nonequilibrium dynamics, e.g. after a policy change, remains incompletely
understood. Here we introduce a thermodynamical theory of inequalities based on
the analogy between economic stratification and statistical entropy. Within
this framework we identify the combination of upward mobility with
precariousness as a fundamental driver of inequality. We formalize this
statement by a ""second-law"" inequality displaying upward mobility and
precariousness as thermodynamic conjugate variables. We estimate the time scale
for the ""relaxation"" of the wealth distribution after a sudden change of the
after-tax return on capital. Our method can be generalized to gain insight into
the dynamics of inequalities in any Markovian model of socioeconomic
interactions.
"
1406.6951	q-fin	math.PR q-fin.MF	Change of numeraire in the two-marginals martingale transport problem	"  In this paper we apply change of numeraire techniques to the optimal
transport approach for computing model-free prices of derivatives in a two
periods model. In particular, we consider the optimal transport plan
constructed in \cite{HobsonKlimmek2013} as well as the one introduced in
\cite{BeiglJuil} and further studied in \cite{BrenierMartingale}. We show that,
in the case of positive martingales, a suitable change of numeraire applied to
\cite{HobsonKlimmek2013} exchanges forward start straddles of type I and type
II, so that the optimal transport plan in the subhedging problems is the same
for both types of options. Moreover, for \cite{BrenierMartingale}'s
construction, the right monotone transference plan can be viewed as a mirror
coupling of its left counterpart under the change of numeraire. An application
to stochastic volatility models is also provided.
"
1407.2420	q-fin	math.PR q-fin.PR	"Markovian Nash equilibrium in financial markets with asymmetric
  information and related forward-backward systems"	"  This paper develops a new methodology for studying continuous-time Nash
equilibrium in a financial market with asymmetrically informed agents. This
approach allows us to lift the restriction of risk neutrality imposed on market
makers by the current literature. It turns out that, when the market makers are
risk averse, the optimal strategies of the agents are solutions of a
forward-backward system of partial and stochastic differential equations. In
particular, the price set by the market makers solves a nonstandard ""quadratic""
backward stochastic differential equation. The main result of the paper is the
existence of a Markovian solution to this forward-backward system on an
arbitrary time interval, which is obtained via a fixed-point argument on the
space of absolutely continuous distribution functions. Moreover, the
equilibrium obtained in this paper is able to explain several stylized facts
which are not captured by the current asymmetric information models.
"
1407.3749	q-fin	q-fin.EC	"Microscopic Models for Welfare Measures Addressing a Reduction of
  Economic Inequality"	"  We formulate a flexible micro-to-macro kinetic model which is able to explain
the emergence of income profiles out of a whole of individual economic
interactions. The model is expressed by a system of several nonlinear
differential equations which involve parameters defined by probabilities.
Society is described as an ensemble of individuals divided into income classes;
the individuals exchange money through binary and ternary interactions, leaving
the total wealth unchanged. The ternary interactions represent taxation and
redistribution effects. Dynamics is investigated through computational
simulations, the focus being on the effects that different fiscal policies and
differently weighted welfare policies have on the long-run income
distributions. The model provides a tool which may contribute to the
identification of the most effective actions towards a reduction of economic
inequality. We find for instance that, under certain hypotheses, the Gini index
is more affected by a policy of reduction of the welfare and subsidies for the
rich classes than by an increase of the upper tax rate. Such a policy also has
the effect of slightly increasing the total tax revenue.
"
1407.5278	q-fin	q-fin.PM	Risk-sensitive investment in a finite-factor model	"  A new jump diffusion regime-switching model is introduced, which allows for
linking jumps in asset prices with regime changes. We prove the existence and
uniqueness of the solution to the risk-sensitive asset management criterion
maximisation problem in this setting. We provide an ODE for the optimal value
function, which may be efficiently solved numerically. Relevant probability
measure changes are discussed in the appendix. The approach of Klebaner and
Lipster (2014) is used to prove the martingale property of the relevant density
processes.
"
1407.5684	q-fin	q-fin.TR	One-level limit order book models with memory and variable spread	"  We propose a new model for the level I of a Limit Order Book (LOB), which
incorporates the information about the standing orders at the opposite side of
the book after each price change and the arrivals of new orders within the
spread. Our main result gives a diffusion approximation for the mid-price
process. To illustrate the applicability of the considered framework, we also
propose a feasible method to compute several quantities of interest}, such as
the distribution of the time span between price changes and the probability of
consecutive price increments conditioned on the current state of the book. The
proposed method is used to develop an efficient simulation scheme for the price
dynamics, which is then applied to assess numerically the accuracy of the
diffusion approximation.
"
1407.7725	q-fin	q-fin.MF	"Utility indifference pricing and hedging for structured contracts in
  energy markets"	"  In this paper we study the pricing and hedging of structured products in
energy markets, such as swing and virtual gas storage, using the exponential
utility indifference pricing approach in a general incomplete multivariate
market model driven by finitely many stochastic factors. The buyer of such
contracts is allowed to trade in the forward market in order to hedge the risk
of his position. We fully characterize the buyer's utility indifference price
of a given product in terms of continuous viscosity solutions of suitable
nonlinear PDEs. This gives a way to identify reasonable candidates for the
optimal exercise strategy for the structured product as well as for the
corresponding hedging strategy. Moreover, in a model with two correlated
assets, one traded and one nontraded, we obtain a representation of the price
as the value function of an auxiliary simpler optimization problem under a risk
neutral probability, that can be viewed as a perturbation of the minimal
entropy martingale measure. Finally, numerical results are provided.
"
1408.0916	q-fin	q-fin.MF math.PR q-fin.PM	A system of quadratic BSDEs arising in a price impact model	"  We consider a financial model where the prices of risky assets are quoted by
a representative market maker who takes into account an exogenous demand. We
characterize these prices in terms of a system of BSDEs with quadratic growth.
We show that this system admits a unique solution for every bounded demand if
and only if the market maker's risk-aversion is sufficiently small. The
uniqueness is established in the natural class of solutions, without any
additional norm restrictions. To the best of our knowledge, this is the first
study that proves such (global) uniqueness result for a system of fully coupled
quadratic BSDEs.
"
1408.1382	q-fin	q-fin.PM math.PR	"Optimal Consumption under Habit Formation In Markets with Transaction
  Costs and Random Endowments"	"  This paper studies the optimal consumption under the addictive habit
formation preference in markets with transaction costs and unbounded random
endowments. To model the proportional transaction costs, we adopt the Kabanov's
multi-asset framework with a cash account. At the terminal time T, the investor
can receive unbounded random endowments for which we propose a new definition
of acceptable portfolios based on the strictly consistent price system (SCPS).
We prove a type of super-hedging theorem using the acceptable portfolios which
enables us to obtain the consumption budget constraint condition under market
frictions. Applying the path dependence reduction and the embedding approach,
we obtain the existence and uniqueness of the optimal consumption using some
auxiliary processes and the duality analysis. As an application of the duality
theory, the market isomorphism with special discounting factors is also
discussed in the sense that the original optimal consumption with habit
formation is equivalent to the standard optimal consumption problem without the
habits impact, however, in a modified isomorphic market model.
"
1408.2217	q-fin	q-fin.PM	Mean-Reversion and Optimization	"  The purpose of these notes is to provide a systematic quantitative framework
- in what is intended to be a ""pedagogical"" fashion - for discussing
mean-reversion and optimization. We start with pair trading and add complexity
by following the sequence ""mean-reversion via demeaning -> regression ->
weighted regression -> (constrained) optimization -> factor models"". We discuss
in detail how to do mean-reversion based on this approach, including common
pitfalls encountered in practical applications, such as the difference between
maximizing the Sharpe ratio and minimizing an objective function when trading
costs are included. We also discuss explicit algorithms for optimization with
linear costs, constraints and bounds.
"
1408.5951	q-fin	cs.GT q-fin.EC	Fragility of the Commons under Prospect-Theoretic Risk Attitudes	"  We study a common-pool resource game where the resource experiences failure
with a probability that grows with the aggregate investment in the resource. To
capture decision making under such uncertainty, we model each player's risk
preference according to the value function from prospect theory. We show the
existence and uniqueness of a pure Nash equilibrium when the players have
heterogeneous risk preferences and under certain assumptions on the rate of
return and failure probability of the resource. Greater competition, vis-a-vis
the number of players, increases the failure probability at the Nash
equilibrium; we quantify this effect by obtaining bounds on the ratio of the
failure probability at the Nash equilibrium to the failure probability under
investment by a single user. We further show that heterogeneity in attitudes
towards loss aversion leads to higher failure probability of the resource at
the equilibrium.
"
1408.6799	q-fin	math.PR math.OC q-fin.MF	Stochastic Perron for stochastic target games	"  We extend the stochastic Perron method to analyze the framework of stochastic
target games, in which one player tries to find a strategy such that the state
process almost surely reaches a given target no matter which action is chosen
by the other player. Within this framework, our method produces a viscosity
sub-solution (super-solution) of a Hamilton-Jacobi-Bellman (HJB) equation. We
then characterize the value function as a viscosity solution to the HJB
equation using a comparison result and a byproduct to obtain the dynamic
programming principle.
"
1409.0118	q-fin	q-fin.CP	Analysis of Spin Financial Market by GARCH Model	"  A spin model is used for simulations of financial markets. To determine
return volatility in the spin financial market we use the GARCH model often
used for volatility estimation in empirical finance. We apply the Bayesian
inference performed by the Markov Chain Monte Carlo method to the parameter
estimation of the GARCH model. It is found that volatility determined by the
GARCH model exhibits ""volatility clustering"" also observed in the real
financial markets. Using volatility determined by the GARCH model we examine
the mixture-of-distribution hypothesis (MDH) suggested for the asset return
dynamics. We find that the returns standardized by volatility are approximately
standard normal random variables. Moreover we find that the absolute
standardized returns show no significant autocorrelation. These findings are
consistent with the view of the MDH for the return dynamics.
"
1409.0407	q-fin	q-fin.PM math.OC	"Optimal dividend problems for a jump-diffusion model with capital
  injections and proportional transaction costs"	"  In this paper, we study the optimal control problem for a company whose
surplus process evolves as an upward jump diffusion with random return on
investment. Three types of practical optimization problems faced by a company
that can control its liquid reserves by paying dividends and injecting capital.
In the first problem, we consider the classical dividend problem without
capital injections. The second problem aims at maximizing the expected
discounted dividend payments minus the expected discounted costs of capital
injections over strategies with positive surplus at all times. The third
problem has the same objective as the second one, but without the constraints
on capital injections. Under the assumption of proportional transaction costs,
we identify the value function and the optimal strategies for any distribution
of gains.
"
1409.1071	q-fin	q-fin.RM physics.soc-ph	Default contagion risks in Russian interbank market	"  Systemic risks of default contagion in the Russian interbank market are
investigated. The analysis is based on considering the bow-tie structure of the
weighted oriented graph describing the structure of the interbank loans. A
probabilistic model of interbank contagion explicitly taking into account the
empirical bow-tie structure reflecting functionality of the corresponding nodes
(borrowers, lenders, borrowers and lenders simultaneously), degree
distributions and disassortativity of the interbank network under consideration
based on empirical data is developed. The characteristics of contagion-related
systemic risk calculated with this model are shown to be in agreement with
those of explicit stress tests.
"
1409.1393	q-fin	q-fin.MF	On Correlated Defaults and Incomplete Information	"  In this paper, we study a continuous time structural asset value model for
two correlated firms using a two-dimensional Brownian motion. We consider the
situation of incomplete information, where the information set available to the
market participants includes the default time of each firm and the periodic
asset value reports. In this situation, the default time of each firm becomes a
totally inaccessible stopping time to the market participants. The original
structural model is first transformed to a reduced-form model. Then the
conditional distribution of the default time together with the asset value of
each name are derived. We prove the existence of the intensity processes of
default times and also give the explicit form of the intensity processes.
Numerical studies on the intensities of the two correlated names are conducted
for some special cases. We also indicate the possible future research extension
into three names case by considering a special correlation structure.
"
1409.1748	q-fin	physics.soc-ph q-fin.GN	A spring-block analogy for the dynamics of stock indexes	"  A spring-block chain placed on a running conveyor belt is considered for
modeling stylized facts observed in the dynamics of stock indexes. Individual
stocks are modeled by the blocks, while the stock-stock correlations are
introduced via simple elastic forces acting in the springs. The dragging effect
of the moving belt corresponds to the expected economic growth. The
spring-block system produces collective behavior and avalanche like phenomena,
similar to the ones observed in stock markets. An artificial index is defined
for the spring-block chain, and its dynamics is compared with the one measured
for the Dow Jones Industrial Average. For certain parameter regions the model
reproduces qualitatively well the dynamics of the logarithmic index, the
logarithmic returns, the distribution of the logarithmic returns, the
avalanche-size distribution and the distribution of the investment horizons. A
noticeable success of the model is that it is able to account for the gain-loss
asymmetry observed in the inverse statistics. Our approach has mainly a
pedagogical value, bridging between a complex socio-economic phenomena and a
basic (mechanical) model in physics.
"
1409.1858	q-fin	math.PR math.AP q-fin.MF	Affine Processes	"  We put forward a complete theory on moment explosion for fairly general
state-spaces. This includes a characterization of the validity of the affine
transform formula in terms of minimal solutions of a system of generalized
Riccati differential equations.
  Also, we characterize the class of positive semidefinite processes, and
provide existence of weak and strong solutions for Wishart SDEs. As an
application, we answer a conjecture of M.L. Eaton on the maximal parameter
domain of non-central Wishart distributions.
  The last chapter of this thesis comprises three individual works on affine
models, such as a characterization of the martingale property of exponentially
affine processes, an investigation of the jump-behaviour of processes on
positive semidefinite cones, and an existence result for transition densities
of multivariate affine jump-diffusions and their approximation theory in
weighted Hilbert spaces.
"
1409.7960	q-fin	math.PR q-fin.MF	An $\alpha$-stable limit theorem under sublinear expectation	"  For $\alpha\in (1,2)$, we present a generalized central limit theorem for
$\alpha$-stable random variables under sublinear expectation. The foundation of
our proof is an interior regularity estimate for partial integro-differential
equations (PIDEs). A classical generalized central limit theorem is recovered
as a special case, provided a mild but natural additional condition holds. Our
approach contrasts with previous arguments for the result in the linear setting
which have typically relied upon tools that are non-existent in the sublinear
framework, for example, characteristic functions.
"
1409.8030	q-fin	physics.soc-ph cond-mat.stat-mech physics.data-an q-fin.GN	Socio-economic inequalities: a statistical physics perspective	"  Socio-economic inequalities are manifested in different aspects of our social
life. We discuss various aspects, beginning with the evolutionary and
historical origins, and discussing the major issues from the social and
economic point of view. The subject has attracted scholars from across various
disciplines, including physicists, who bring in a unique perspective to the
field. The major attempts to analyze the results, address the causes, and
understand the origins using statistical tools and statistical physics concepts
are discussed.
"
1409.8150	q-fin	math.ST q-fin.ST stat.TH	Near-optimal estimation of jump activity in semimartingales	"  In quantitative finance, we often model asset prices as semimartingales, with
drift, diffusion and jump components. The jump activity index measures the
strength of the jumps at high frequencies, and is of interest both in model
selection and fitting, and in volatility estimation. In this paper, we give a
novel estimate of the jump activity, together with corresponding confidence
intervals. Our estimate improves upon previous work, achieving near-optimal
rates of convergence, and good finite-sample performance in Monte-Carlo
experiments.
"
1410.0384	q-fin	math.PR q-fin.MF	Indifference pricing for Contingent Claims: Large Deviations Effects	"  We study utility indifference prices and optimal purchasing quantities for a
non-traded contingent claim in an incomplete semi-martingale market with
vanishing hedging errors. We make connections with the theory of large
deviations. We concentrate on sequences of semi-complete markets where in the
$n^{th}$ market, the claim $B_n$ admits the decomposition $B_n = D_n+Y_n$.
Here, $D_n$ is replicable by trading in the underlying assets $S_n$, but $Y_n$
is independent of $S_n$. Under broad conditions, we may assume that $Y_n$
vanishes in accordance with a large deviations principle as $n$ grows. In this
setting, for an exponential investor, we identify the limit of the average
indifference price $p_n(q_n)$, for $q_n$ units of $B_n$, as $n\rightarrow
\infty$. We show that if $|q_n|\rightarrow\infty$, the limiting price typically
differs from the price obtained by assuming bounded positions
$\sup_n|q_n|<\infty$, and the difference is explicitly identifiable using large
deviations theory. Furthermore, we show that optimal purchase quantities occur
at the large deviations scaling, and hence large positions arise endogenously
in this setting.
"
1410.0946	q-fin	q-fin.PM	An expansion in the model space in the context of utility maximization	"  In the framework of an incomplete financial market where the stock price
dynamics are modeled by a continuous semimartingale (not necessarily Markovian)
an explicit second-order expansion formula for the power investor's value
function - seen as a function of the underlying market price of risk process -
is provided. This allows us to provide first-order approximations of the
optimal primal and dual controls. Two specific calibrated numerical examples
illustrating the accuracy of the method are also given.
"
1410.1481	q-fin	q-fin.TR	Optimal execution of ASR contracts with fixed notional	"  Be it for taking advantage of stock undervaluation or in order to distribute
part of their profits to shareholders, firms may buy back their own shares. One
of the way they proceed is by including Accelerated Share Repurchases (ASR) as
part of their repurchase programs. In this article, we study the pricing and
optimal execution strategy of an ASR contract with fixed notional. In such a
contract the firm pays a fixed notional $F$ to the bank and receives, in
exchange, a number of shares corresponding to the ratio between $F$ and the
average stock price over the purchase period, the duration of this period being
decided upon by the bank. From a mathematical point of view, the problem is
related to both optimal execution and exotic option pricing.
"
1410.1611	q-fin	q-fin.MF hep-th q-fin.PR	Path Integral and Asset Pricing	"  We give a pragmatic/pedagogical discussion of using Euclidean path integral
in asset pricing. We then illustrate the path integral approach on short-rate
models. By understanding the change of path integral measure in the
Vasicek/Hull-White model, we can apply the same techniques to ""less-tractable""
models such as the Black-Karasinski model. We give explicit formulas for
computing the bond pricing function in such models in the analog of quantum
mechanical ""semiclassical"" approximation. We also outline how to apply
perturbative quantum mechanical techniques beyond the ""semiclassical""
approximation, which are facilitated by Feynman diagrams.
"
1410.3128	q-fin	q-fin.GN physics.soc-ph	"A study of Methods from Statistical Mechanics applied to income
  distribution"	"  We applied Dirac distribution, Bose-Einstein distribution, and occasionally
Boltzmann-Gibbs distribution in order to determine which is optimal for income
distribution on a large pool of countries. The best fit to the data was
observed in the case of Fermi-Dirac distribution, for which the coefficient of
determination showed the best goodness of fit to the data. Using this
distribution for data (spun throughout more years), we obtained the underlying
critical parameters of annual income distribution such as chemical potential
and temperature. The next step was to explore the evolution of income using
economic analogues to chemical potential and temperature. Using as background
the analogy made by Yakovenko between temperature from thermodynamic systems
and nominal income from Economics, we found other analogies that would allow
further analysis and explanation of income.
"
1410.3811	q-fin	physics.soc-ph q-fin.GN	"Applications of statistical physics distributions to several types of
  income"	"  This paper explores several types of income which have not been explored so
far by authors who tackled income and wealth distribution using Statistical
Physics. The main types of income we plan to analyze are income before
redistribution (or gross income), income of retired people (or pensions), and
income of active people (mostly wages). The distributions used to analyze
income distributions are Fermi-Dirac distribution and polynomial distribution
(as this is present in describing the behavior of dynamic systems in certain
aspects). The data we utilize for our analysis are from France and the UK. We
find that both distributions are robust in describing these varieties of
income. The main finding we consider to be the applicability of these
distributions to pensions, which are not regulated entirely by market
mechanisms.
"
1410.3851	q-fin	q-fin.GN physics.soc-ph	"An Econophysical dynamical approach of expenditure and income
  distribution in the UK"	"  We extend the exploration regarding dynamical approach of macroeconomic
variables by tackling systematically expenditure using Statistical Physics
models (for the first time to the best of our knowledge). Also, using
polynomial distribution which characterizes the behavior of dynamical systems
in certain situations, we extend also our analysis to mean income data from the
UK that span for a time interval of 35 years. We find that most of the values
for coefficient of determination obtained from fitting the data from
consecutive years analysis to be above 80%. We used for our analysis first
degree polynomial, but higher degree polynomials and longer time intervals
between the years considered can dramatically increase goodness of the fit. As
this methodology was applied successfully to income and wealth, we can conclude
that macroeconomic systems can be treated similarly to dynamic systems from
Physics. Subsequently, the analysis could be extended to other macroeconomic
indicators.
"
1410.3860	q-fin	q-fin.GN physics.soc-ph	"An econophysical approach of polynomial distribution applied to income
  and expenditure"	"  Polynomial distribution can be applied to dynamical systems in certain
situations. Macroeconomic systems characterized by economic variables such as
income and wealth can be modelled similarly using polynomials. We extend our
previous work to data regarding income from a more diversified pool of
countries, which contains developed countries with high income, developed
countries with middle income, developing and underdeveloped countries. Also,
for the first time we look at the applicability of polynomial distribution to
expenditure (consumption). Using cumulative distribution function, we found
that polynomials are applicable with a high degree of success to the
distribution of income to all countries considered without significant
differences. Moreover, expenditure data can be fitted very well by this
polynomial distribution. We considered a distribution to be robust if the
values for coefficient of determination are higher than 90%. Using this
criterion, we decided the degree for the polynomials used in our analysis by
trying to minimize the number of coefficients, respectively first or second
degree. Lastly, we look at possible correlation between the values from
coefficient of determination and Gini coefficient for disposable income.
"
1410.3865	q-fin	q-fin.GN physics.soc-ph	A statistical physics analysis of expenditure in the UK	"  Most papers which explored so far macroeconomic variables took into account
income and wealth. Equally important as the previous macroeconomic variables is
the expenditure or consumption, which shows the amount of goods and services
that a person or a household purchased. Using statistical distributions from
Physics, such as Fermi-Dirac and polynomial distributions, we try to fit the
data regarding the expenditure distribution divided in deciles of population
according to their income (gross and disposable expenditure are taken into
account). Using coefficient of determination as theoretical tool in order to
assess the degree of success for these distributions, we find that both
distributions are really robust in describing the expenditure distribution,
regardless the data set or the methodology used to calculate the expenditure
values for the deciles of income. This is the first paper to our knowledge
which tackles expenditure, especially using a method to describe expenditure
such as lower limit on expenditure. This is also relevant since it allows the
approach of macroeconomic systems using more variables characterizing their
activity, can help in the investigation of living standards and inequality, and
points to more theoretical explorations which can be very useful for the
Economics and business practice.
"
1410.4807	q-fin	q-fin.MF	Banach geometry of arbitrage free markets	"  The article presents a description of geometry of Banach structures forming
mathematical base of markets arbitrage absence type phenomena. In this
connection the role of reflexive subspaces (replacing classically considered
finite-dimensional subspaces) and plasterable cones is uncovered.
"
1410.4866	q-fin	q-fin.GN physics.soc-ph	A polynomial distribution applied to income and wealth distribution	"  Income and wealth distribution affect stability of a society to a large
extent and high inequality affects it negatively. Moreover, in the case of
developed countries, recently has been proven that inequality is closely
related to all negative phenomena affecting society. So far, Econophysics
papers tried to analyse income and wealth distribution by employing
distributions such as Fermi-Dirac, Bose-Einstein, Maxwell-Boltzmann, lognormal
(Gibrat), and exponential. Generally, distributions describe mostly income and
less wealth distribution for low and middle income segment of population, which
accounts about 90% of the population. Our approach is based on a totally new
distribution, not used so far in the literature regarding income and wealth
distribution. Using cumulative distribution method, we find that polynomial
functions, regardless of their degree (first, second, or higher), can describe
with very high accuracy both income and wealth distribution. Moreover, we find
that polynomial functions describe income and wealth distribution for entire
population including upper income segment for which traditionally Pareto
distribution is used.
"
1410.5466	q-fin	q-fin.EC	Conditional Preference Orders and their Numerical Representations	"  We provide an axiomatic system modeling conditional preference orders which
is based on conditional set theory. Conditional numerical representations are
introduced, and a conditional version of the theorems of Debreu on the
existence of numerical representations is proved. The conditionally continuous
representations follow from a conditional version of Debreu's Gap Lemma the
proof of which relies on a conditional version of the axiom of choice, free of
any measurable selection argument. We give a conditional version of the von
Neumann and Morgenstern representation as well as automatic conditional
continuity results, and illustrate them by examples.
"
1410.6144	q-fin	q-fin.MF math.PR q-fin.PM q-fin.TR	"Stability and analytic expansions of local solutions of systems of
  quadratic BSDEs with applications to a price impact model"	"  We obtain stability estimates and derive analytic expansions for local
solutions of multi-dimensional quadratic BSDEs. We apply these results to a
financial model where the prices of risky assets are quoted by a representative
dealer in such a way that it is optimal to meet an exogenous demand. We show
that the prices are stable under the demand process and derive their analytic
expansions for small risk aversion coefficients of the dealer.
"
1410.6408	q-fin	q-fin.MF q-fin.PR	Asset Pricing in an Imperfect World	"  In a model with no given probability measure, we consider asset pricing in
the presence of frictions and other imperfections and characterize the property
of coherent pricing, a notion related to (but much weaker than) the no
arbitrage property. We show that prices are coherent if and only if the set of
pricing measures is non empty, i.e. if pricing by expectation is possible. We
then obtain a decomposition of coherent prices highlighting the role of
bubbles. Eventually we show that under very weak conditions the coherent
pricing of options allows for a very clear representation which allows, as in
Breeden and Litzenberger, to extract the implied probability.
"
1410.6898	q-fin	q-fin.ST q-fin.RM stat.AP	Are news important to predict large losses?	"  In this paper we investigate the impact of news to predict extreme financial
returns using high frequency data. We consider several model specifications
differing for the dynamic property of the underlying stochastic process as well
as for the innovation process. Since news are essentially qualitative measures,
they are firstly transformed into quantitative measures which are subsequently
introduced as exogenous regressors into the conditional volatility dynamics.
Three basic sentiment indexes are constructed starting from three list of words
defined by historical market news response and by a discriminant analysis.
Models are evaluated in terms of their predictive accuracy to forecast
out-of-sample Value-at-Risk of the STOXX Europe 600 sectors at different
confidence levels using several statistic tests and the Model Confidence Set
procedure of Hansen et al. (2011). Since the Hansen's procedure usually
delivers a set of models having the same VaR predictive ability, we propose a
new forecasting combination technique that dynamically weights the VaR
predictions obtained by the models belonging to the optimal final set. Our
results confirms that the inclusion of exogenous information as well as the
right specification of the returns' conditional distribution significantly
decrease the number of actual versus expected VaR violations towards one, as
this is especially true for higher confidence levels.
"
1410.7453	q-fin	q-fin.PR q-fin.CP	"GMWB Riders in a Binomial Framework - Pricing, Hedging, and
  Diversification of Mortality Risk"	"  We construct a binomial model for a guaranteed minimum withdrawal benefit
(GMWB) rider to a variable annuity (VA) under optimal policyholder behaviour.
The binomial model results in explicitly formulated perfect hedging strategies
funded using only periodic fee income. We consider the separate perspectives of
the insurer and policyholder and introduce a unifying relationship.
Decompositions of the VA and GMWB contract into term-certain payments and
options representing the guarantee and early surrender features are extended to
the binomial framework. We incorporate an approximation algorithm for Asian
options that significantly improves efficiency of the binomial model while
retaining accuracy. Several numerical examples are provided which illustrate
both the accuracy and the tractability of the binomial model. We extend the
binomial model to include policy holder mortality and death benefits. Pricing,
hedging, and the decompositions of the contract are extended to incorporate
mortality risk. We prove limiting results for the hedging strategies and
demonstrate mortality risk diversification. Numerical examples are provided
which illustrate the effectiveness of hedging and the diversification of
mortality risk under capacity constraints with finite pools.
"
1410.7845	q-fin	q-fin.RM math.ST stat.TH	A new multivariate dependence measure based on comonotonicity	"  In this paper we introduce a new multivariate dependence measure based on
comonotonicity by means of product moment which motivated by the recent papers
of Koch and Schepper (ASTIN Bulletin 41 (2011) 191-213) and Dhaene et al.
(Journal of Computational and Applied Mathematics 263 (2014) 78-87). Some
differences and relations between the new dependence measure and other
multivariate measures are an- alyzed. We also give several characteristics of
this measure and estimations based on the definitions and its property are
presented.
"
1410.8160	q-fin	q-fin.MF q-fin.PR	Pricing and Hedging Long-Term Options	"  In this article, we investigate the behavior of long-term options. In many
cases, option prices follow an exponential decay (or growth) rate for further
maturity dates. We determine under what conditions option prices are
characterized by this property. To see this, we use the martingale extraction
method through which a pricing operator is transformed into a semigroup
operator, which is easier to address.
  We also explore notions of hedging long-term options. Hedging is an attempt
to reduce market risks, and we investigate the price sensitivities (Greeks)
with respect to such risks, which are typically repre- sented by variations in
the underlying process of an option. We combine the Malliavin calculus with the
martingale extraction method to analyze Greeks. We see that the ratios between
Greeks and the option price are expressed in a simple form in the long term.
"
1410.8595	q-fin	q-fin.CP math.PR	"A Fourier interpolation method for numerical solution of FBSDEs: Global
  convergence, stability, and higher order discretizations"	"  The implementation of the convolution method for the numerical solution of
backward stochastic differential equations (BSDEs) introduced in [19] uses a
uniform space grid. Locally, this approach produces a truncation error, a space
discretization error, and an additional extrapolation error. Even if the
extrapolation error is convergent in time, the resulting absolute error may be
high at the boundaries of the uniform space grid. In order to solve this
problem, we propose a tree-like grid for the space discretization which
suppresses the extrapolation error leading to a globally convergent numerical
solution for the (F)BSDE. On this alternative grid the conditional expectations
involved in the BSDE time discretization are computed using Fourier analysis
and the fast Fourier transform (FFT) algorithm as in the initial
implementation. The method is then extended to higher-order time
discretizations of FBSDEs. Numerical results demonstrating convergence are also
presented.
"
1411.1152	q-fin	q-fin.EC cs.GT	"Berk-Nash Equilibrium: A Framework for Modeling Agents with Misspecified
  Models"	"  We develop an equilibrium framework that relaxes the standard assumption that
people have a correctly-specified view of their environment. Each player is
characterized by a (possibly misspecified) subjective model, which describes
the set of feasible beliefs over payoff-relevant consequences as a function of
actions. We introduce the notion of a Berk-Nash equilibrium: Each player
follows a strategy that is optimal given her belief, and her belief is
restricted to be the best fit among the set of beliefs she considers possible.
The notion of best fit is formalized in terms of minimizing the
Kullback-Leibler divergence, which is endogenous and depends on the equilibrium
strategy profile. Standard solution concepts such as Nash equilibrium and
self-confirming equilibrium constitute special cases where players have
correctly-specified models. We provide a learning foundation for Berk-Nash
equilibrium by extending and combining results from the statistics literature
on misspecified learning and the economics literature on learning in games.
"
1411.1356	q-fin	q-fin.RM cs.SI	Impact of credit default swaps on financial contagion	"  It had been believed in the conventional practice that the risk of a bank
going bankrupt is lessened in a straightforward manner by transferring the risk
of loan defaults. But the failure of American International Group in 2008 posed
a more complex aspect of financial contagion. This study presents an extension
of the asset network systemic risk model (ANWSER) to investigate whether credit
default swaps mitigate or intensify the severity of financial contagion. A
protection buyer bank transfers the risk of every possible debtor bank default
to protection seller banks. The empirical distribution of the number of bank
bankruptcies is obtained with the extended model. Systemic capital buffer ratio
is calculated from the distribution. The ratio quantifies the effective loss
absorbency capability of the entire financial system to force back financial
contagion. The key finding is that the leverage ratio is a good estimate of a
systemic capital buffer ratio as the backstop of a financial system. The risk
transfer from small and medium banks to big banks in an interbank network does
not mitigate the severity of financial contagion.
"
1411.1624	q-fin	q-fin.PR math.PR	General smile asymptotics with bounded maturity	"  We provide explicit conditions on the distribution of risk-neutral
log-returns which yield sharp asymptotic estimates on the implied volatility
smile. We allow for a variety of asymptotic regimes, including both small
maturity (with arbitrary strike) and extreme strike (with arbitrary bounded
maturity), extending previous work of Benaim and Friz [Math. Finance 19 (2009),
1-12]. We present applications to popular models, including Carr-Wu finite
moment logstable model, Merton's jump diffusion model and Heston's model.
"
1411.2167	q-fin	q-fin.EC	"Comeback kids: an evolutionary approach of the long-run innovation
  process"	"  We provide a theoretical framework to understand when firms may benefit from
exploiting previously abandoned technologies and brands. We model for the long
run process of innovation, allowing for sustainable diversity and comebacks of
old brands and technologies. We present two extensions to the logistic and
Lotka-Volterra equations, which describe the diffusion of an innovation. First,
we extend the short-term competition to a long-term process characterized by a
sequence of innovations and substitutions. Second, by allowing the
substitutions to be incomplete, we extend the one-dimensional process to a
tree-form multidimensional one featuring diversification throughout the
long-term development.
"
1411.2525	q-fin	q-fin.PM	"Optimising Credit Portfolio Using a Quadratic Nonlinear Projection
  Method"	"  A novel optimisation framework through quadratic nonlinear projection is
introduced for credit portfolio when the portfolio risk is measured by
Conditional Value-at-Risk (CVaR). The whole optimisation procedure to search
toward the optimal portfolio state is conducted by a series of single-step
optimisations under the local constraints described in the multi-dimensional
constraint parameter space as functions of the total amount of portfolio
adjustment. Each single-step optimisation is approximated by the first-order
variation of the weight increments with respect to the total amount of
portfolio adjustment and is solved in the form of locally exact formula
formulated in the general Lagrange multiplier method. Our method can deal with
optimisation for general nonlinear objective functions, such as the
return-to-risk ratio maximisation or the diversification index, as well as the
risk minimisation or the return maximisation.
"
1411.2675	q-fin	math.OC q-fin.PM	"Process-Based Risk Measures and Risk-Averse Control of Discrete-Time
  Systems"	"  For controlled discrete-time stochastic processes we introduce a new class of
dynamic risk measures, which we call process-based. Their main features are
that they measure risk of processes that are functions of the history of a base
process. We introduce a new concept of conditional stochastic time consistency
and we derive the structure of process-based risk measures enjoying this
property. We show that they can be equivalently represented by a collection of
static law-invariant risk measures on the space of functions of the state of
the base process. We apply this result to controlled Markov processes and we
derive dynamic programming equations.
"
1411.2950	q-fin	math-ph math.MP math.PR q-fin.PR	"Algebraic Form of Malliavin Calculus: Creation-Annihilation Operators,
  Conserved Currents and All That"	"  The extremely useful method of Malliavin calculus has not yet gained adequate
popularity because of the complicated analytic apparatus of this method. The
author attempts here to propose a simplified algebraic formalism similar to
Malliavin calculus, but based on the notion of creation-annihilation operators
instead of Malliavin derivative to replace analytic theorems with algebraic
computations. Three test problems: the valuation of portfolio with stochastic
payoff function, the expression of the terminal payoff through stochastic
integral and the approximate equation for the high-frequency market measure are
discussed in Appendices.
"
1411.3078	q-fin	q-fin.EC	Long Term Risk: A Martingale Approach	"  This paper extends the long-term factorization of the stochastic discount
factor introduced and studied by Alvarez and Jermann (2005) in discretetime
ergodic environments and by Hansen and Scheinkman (2009) and Hansen (2012) in
Markovian environments to general semimartingale environments. The transitory
component discounts at the stochastic rate of return on the long bond and is
factorized into discounting at the long-term yield and a positive
semimartingale that extends the principal eigenfunction of Hansen and
Scheinkman (2009) to the semimartingale setting. The permanent component is a
martingale that accomplishes a change of probabilities to the long forward
measure, the limit of T-forward measures. The change of probabilities from the
data generating to the long forward measure absorbs the long-term risk-return
trade-off and interprets the latter as the long-term risk-neutral measure.
"
1411.3618	q-fin	q-fin.MF math.PR	"A Forward Equation for Barrier Options under the Brunick&Shreve
  Markovian Projection"	"  We derive a forward equation for arbitrage-free barrier option prices, in
terms of Markovian projections of the stochastic volatility process, in
continuous semi-martingale models. This provides a Dupire-type formula for the
coefficient derived by Brunick and Shreve for their mimicking diffusion and can
be interpreted as the canonical extension of local volatility for barrier
options. Alternatively, a forward partial-integro differential equation (PIDE)
is introduced which provides up-and-out call prices, under a Brunick-Shreve
model, for the complete set of strikes, barriers and maturities in one solution
step. Similar to the vanilla forward PDE, the above-named forward PIDE can
serve as a building block for an efficient calibration routine including
barrier option quotes. We provide a discretisation scheme for the PIDE as well
as a numerical validation.
"
1411.7502	q-fin	q-fin.TR	Hydrodynamic limit of order book dynamics	"  In this paper, we establish a fluid limit for a two--sided Markov order book
model. Our main result states that in a certain asymptotic regime, a pair of
measure-valued processes representing the ""sell-side shape"" and ""buy-side
shape"" of an order book converges to a pair of deterministic measure-valued
processes in a certain sense. We also test our fluid approximation on data. The
empirical results suggest that the approximation is reasonably good for
liquidly--traded stocks in certain time periods.
"
1411.7991	q-fin	q-fin.MF	"Existence and Uniqueness of a Steady State for an OTC Market with
  Several Assets"	"  We introduce and study a class of over-the-counter market models specified by
systems of Ordinary Differential Equations (ODE's), in the spirit of Duffie-
G^arleanu-Pedersen [6]. The key innovation is allowing for multiple assets. We
show the existence and uniqueness of a steady state for these ODE's.
"
1412.0064	q-fin	q-fin.RM	"Assessing the Basel II Internal Ratings-Based Approach: Empirical
  Evidence from Australia"	"  The Basel II internal ratings-based (IRB) approach to capital adequacy for
credit risk implements an asymptotic single risk factor (ASRF) model.
Measurements from the ASRF model of the prevailing state of Australia's economy
and the level of capitalisation of its banking sector find general agreement
with macroeconomic indicators, financial statistics and external credit
ratings. However, given the range of economic conditions, from mild contraction
to moderate expansion, experienced in Australia since the implementation of
Basel II, we cannot attest to the validity of the model specification of the
IRB approach for its intended purpose of solvency assessment. With the
implementation of Basel II preceding the time when the effect of the financial
crisis of 2007-09 was most acutely felt, our empirical findings offer a
fundamental assessment of the impact of the crisis on the Australian banking
sector. Access to internal bank data collected by the prudential regulator
distinguishes our research from other empirical studies on the IRB approach and
recent crisis.
"
1412.1183	q-fin	q-fin.RM	Regulatory Capital Modelling for Credit Risk	"  The Basel II internal ratings-based (IRB) approach to capital adequacy for
credit risk plays an important role in protecting the Australian banking sector
against insolvency. We outline the mathematical foundations of regulatory
capital for credit risk, and extend the model specification of the IRB approach
to a more general setting than the usual Gaussian case. It rests on the
proposition that quantiles of the distribution of conditional expectation of
portfolio percentage loss may be substituted for quantiles of the portfolio
loss distribution. We present a more economical proof of this proposition under
weaker assumptions. Then, constructing a portfolio that is representative of
credit exposures of the Australian banking sector, we measure the rate of
convergence, in terms of number of obligors, of empirical loss distributions to
the asymptotic (infinitely fine-grained) portfolio loss distribution. Moreover,
we evaluate the sensitivity of credit risk capital to dependence structure as
modelled by asset correlations and elliptical copulas. Access to internal bank
data collected by the prudential regulator distinguishes our research from
other empirical studies on the IRB approach.
"
1412.2262	q-fin	q-fin.PM	Purchasing Term Life Insurance to Reach a Bequest Goal while Consuming	"  We determine the optimal strategies for purchasing term life insurance and
for investing in a risky financial market in order to maximize the probability
of reaching a bequest goal while consuming from an investment account. We
extend Bayraktar and Young (2015) by allowing the individual to purchase term
life insurance to reach her bequest goal. The premium rate for life insurance,
$h$, serves as a parameter to connect two seemingly unrelated problems. As the
premium rate approaches $0$, covering the bequest goal becomes costless, so the
individual simply wants to avoid ruin that might result from her consumption.
Thus, as $h$ approaches $0$, the problem in this paper becomes equivalent to
minimizing the probability of lifetime ruin, which is solved in Young (2004).
On the other hand, as the premium rate becomes arbitrarily large, the
individual will not buy life insurance to reach her bequest goal. Thus, as $h$
approaches infinity, the problem in this paper becomes equivalent to maximizing
the probability of reaching the bequest goal when life insurance is not
available in the market, which is solved in Bayraktar and Young (2015).
"
1412.4208	q-fin	q-fin.RM math.PR	Equilibrium in risk-sharing games	"  The large majority of risk-sharing transactions involve few agents, each of
whom can heavily influence the structure and the prices of securities. This
paper proposes a game where agents' strategic sets consist of all possible
sharing securities and pricing kernels that are consistent with Arrow-Debreu
sharing rules. First, it is shown that agents' best response problems have
unique solutions. The risk-sharing Nash equilibrium admits a finite-dimensional
characterisation and it is proved to exist for arbitrary number of agents and
be unique in the two-agent game. In equilibrium, agents declare beliefs on
future random outcomes different than their actual probability assessments, and
the risk-sharing securities are endogenously bounded, implying (among other
things) loss of efficiency. In addition, an analysis regarding extremely risk
tolerant agents indicates that they profit more from the Nash risk-sharing
equilibrium as compared to the Arrow-Debreu one.
"
1412.4698	q-fin	q-fin.MF q-fin.PM	Conditional Analysis and a Principal-Agent problem	"  We analyze conditional optimization problems arising in discrete time
Principal-Agent problems of delegated portfolio optimization with linear
contracts. Applying tools from Conditional Analysis we show that some results
known in the literature for very specific instances of the problem carry over
to translation invariant and time-consistent utility functions in very general
probabilistic settings. However, we find that optimal contracts must in general
make use of derivatives for compensation.
"
1412.6745	q-fin	q-fin.MF q-fin.RM	Risk measuring under liquidity risk	"  We present a general framework for measuring the liquidity risk. The
theoretical framework defines a class of risk measures that incorporate the
liquidity risk into the standard risk measures. We consider a one-period risk
measurement model. The liquidity risk is defined as the risk that a given
security or a portfolio of securities cannot be easily sold or bought by the
financial institutions without causing significant changes in prices. The new
risk measures present some differences with respect to the standard risk
measures. In particular, they are increasing monotonic and convex cash
sub-additive on long positions. The contrary, in certain situations, holds for
the sell positions. For the long positions case, we provide these new risk
measures with a dual representation. In some specific cases also the sell
positions can be equipped with a dual representation. We apply our framework to
the situation in which financial institutions break up large trades into many
small ones. Dual representation results are also obtained. We give many
practical examples of risk measures and derive for each of them the respective
capital requirement. As a particular example, we discuss the VaR measure.
"
1412.7227	q-fin	q-fin.GN physics.soc-ph	"An $H$ theorem for Boltzmann's equation for the Yard-Sale Model of asset
  exchange"	"  In recent work, Boltzmann and Fokker-Planck equations were derived for the
""Yard-Sale Model"" of asset exchange. For the version of the model without
redistribution, it was conjectured, based on numerical evidence, that the
time-asymptotic state of the model was oligarchy -- complete concentration of
wealth by a single individual. In this work, we prove that conjecture by
demonstrating that the Gini coefficient, a measure of inequality commonly used
by economists, is an $H$ function of both the Boltzmann and Fokker-Planck
equations for the model.
"
1412.7647	q-fin	q-fin.RM	Tail Risk Constraints and Maximum Entropy	"  In the world of modern financial theory, portfolio construction has
traditionally operated under at least one of two central assumptions: the
constraints are derived from a utility function and/or the multivariate
probability distribution of the underlying asset returns is fully known. In
practice, both the performance criteria and the informational structure are
markedly different: risk-taking agents are mandated to build portfolios by
primarily constraining the tails of the portfolio return to satisfy VaR, stress
testing, or expected shortfall (CVaR) conditions, and are largely ignorant
about the remaining properties of the probability distributions. As an
alternative, we derive the shape of portfolio distributions which have maximum
entropy subject to real-world left-tail constraints and other expectations. Two
consequences are (i) the left-tail constraints are sufficiently powerful to
overide other considerations in the conventional theory, rendering individual
portfolio components of limited relevance; and (ii) the ""barbell"" payoff
(maximal certainty/low risk on one side, maximum uncertainty on the other)
emerges naturally from this construction.
"
1501.00434	q-fin	q-fin.EC physics.soc-ph q-fin.GN	Monetary Policy and Dark Corners in a stylized Agent-Based Model	"  We extend in a minimal way the stylized model introduced in in ""Tipping
Points in Macroeconomic Agent Based Models"" [JEDC 50, 29-61 (2015)], with the
aim of investigating the role and efficacy of monetary policy of a `Central
Bank' that sets the interest rate such as to steer the economy towards a
prescribed inflation and employment level. Our major finding is that provided
its policy is not too aggressive (in a sense detailed in the paper) the Central
Bank is successful in achieving its goals. However, the existence of different
equilibrium states of the economy, separated by phase boundaries (or ""dark
corners""), can cause the monetary policy itself to trigger instabilities and be
counter-productive. In other words, the Central Bank must navigate in a narrow
window: too little is not enough, too much leads to instabilities and wildly
oscillating economies. This conclusion strongly contrasts with the prediction
of DSGE models.
"
1501.01504	q-fin	q-fin.PM math.OC	"Optimal investment under behavioural criteria in incomplete diffusion
  market models"	"  The most commonly accepted model for investors' preferences is expected
utility theory. More recently, other theories have emerged and pose new
challenges to mathematics. The present paper treats preferences of cumulative
prospect theory (CPT), where an ""S-shaped"" utility function is considered (i.e.
convex up to a certain point and concave from there on). Also, distorted
probability measures are applied for calculating the utility of a given
position with respect to a (possibly random) benchmark $G$. Such problems have
heretofore been solved essentially for complete continuous-time market models
only. In the present paper we make a step forward and consider incomplete
models of a diffusion type where the return of the investment in consideration
depends on some economic factors. Our main result asserts, under mild
assumptions, the existence of an optimal strategy when the driving noise of the
economic factors is independent of that of the investment and the rate of
return is non-negative. We are also able to accommodate models of a specific
type where the factor may have non-zero correlation with the investment.
"
1501.01573	q-fin	q-fin.PM q-fin.RM	The Temporal Dimension of Risk	"  Multi-period measures of risk account for the path that the value of an
investment portfolio takes. In the context of probabilistic risk measures, the
focus has traditionally been on the magnitude of investment loss and not on the
dimension associated with the passage of time. In this paper, the concept of
temporal path-dependent risk measure is mathematically formalized to capture
the risk associated with the temporal dimension of a stochastic process. We
discuss the properties of temporal measures of risk and show that they can
never be coherent. We then study the temporal dimension of investment drawdown,
its duration, which measures the length of excursions below a running maximum.
Its properties in the context of risk measures are analyzed both theoretically
and empirically. In particular, we show that duration captures serial
correlation in the returns of two major asset classes. We conclude by
discussing the challenges of path-dependent temporal risk estimation in
practice.
"
1501.02007	q-fin	q-fin.RM q-fin.MF	Shortfall Deviation Risk: An alternative to risk measurement	"  We present the Shortfall Deviation Risk (SDR), a risk measure that represents
the expected loss that occurs with certain probability penalized by the
dispersion of results that are worse than such an expectation. SDR combines
Expected Shortfall (ES) and Shortfall Deviation (SD), which we also introduce,
contemplating two fundamental pillars of the risk concept, the probability of
adverse events and the variability of an expectation, and considers extreme
results. We demonstrate that SD is a generalized deviation measure, whereas SDR
is a coherent risk measure. We achieve the dual representation of SDR, and we
discuss issues such as its representation by a weighted ES, acceptance sets,
convexity, continuity and the relationship with stochastic dominance.
Illustrations with real and simulated data allow us to conclude that SDR offers
greater protection in risk measurement compared with VaR and ES, especially in
times of significant turbulence in riskier scenarios.
"
1501.04682	q-fin	q-fin.ST cs.CE q-fin.CP q-fin.EC	"Toward robust early-warning models: A horse race, ensembles and model
  uncertainty"	"  This paper presents first steps toward robust models for crisis prediction.
We conduct a horse race of conventional statistical methods and more recent
machine learning methods as early-warning models. As individual models are in
the literature most often built in isolation of other methods, the exercise is
of high relevance for assessing the relative performance of a wide variety of
methods. Further, we test various ensemble approaches to aggregating the
information products of the built models, providing a more robust basis for
measuring country-level vulnerabilities. Finally, we provide approaches to
estimating model uncertainty in early-warning exercises, particularly model
performance uncertainty and model output uncertainty. The approaches put
forward in this paper are shown with Europe as a playground. Generally, our
results show that the conventional statistical approaches are outperformed by
more advanced machine learning methods, such as k-nearest neighbors and neural
networks, and particularly by model aggregation approaches through ensemble
learning.
"
1501.04992	q-fin	q-fin.GN physics.soc-ph	"Interactions between financial and environmental networks in OECD
  countries"	"  We analyse a multiplex of networks between OECD countries during the decade
2002-2010, which consists of five financial layers, given by foreign direct
investment, equity securities, short-term, long-term and total debt securities,
and five environmental layers, given by emissions of N O x, P M 10 SO 2, CO 2
equivalent and the water footprint associated with international trade. We
present a new measure of cross-layer correlations between flows in different
layers based on reciprocity. For the assessment of results, we implement a null
model for this measure based on the exponential random graph theory. We find
that short-term financial flows are more correlated with environmental flows
than long-term investments. Moreover, the correlations between reverse
financial and environmental flows (i.e. flows of different layers going in
opposite directions) are generally stronger than correlations between synergic
flows (flows going in the same direction). This suggests a trade-off between
financial and environmental layers, where, more financialised countries display
higher correlations between outgoing financial flows and incoming environmental
flows from lower financialised countries, which could have important policy
implications. Five countries are identified as hubs in this finance-environment
multiplex: The United States, France, Germany, Belgium-Luxembourg and the
United Kingdom.
"
1501.05176	q-fin	q-fin.ST	Bin Size Independence in Intra-day Seasonalities for Relative Prices	"  In this paper we perform a statistical analysis over the returns and relative
prices of the CAC $40$ and the S\&P $500$ with the purpose of analyzing the
intra-day seasonalities of single and cross-sectional stock dynamics. In order
to do that, we characterized the dynamics of a stock (or a set of stocks) by
the evolution of the moments of its returns (and relative prices) during a
typical day. We show that these intra-day seasonalities are independent of the
size of the bin, and the index we consider, (but characteristic for each index)
for the case of the relative prices but not for the case of the returns.
Finally, we suggest how this bin size independence could be used to
characterize ""atypical days"" for indexes and ""anomalous behaviours"" in stocks.
"
1501.05893	q-fin	q-fin.PR math.PR	Arbitrage-Free Pricing of XVA -- Part I: Framework and Explicit Examples	"  We develop a novel framework for computing the total valuation adjustment
(XVA) of a European claim accounting for funding costs, counterparty credit
risk, and collateralization. Based on no-arbitrage arguments, we derive the
nonlinear backward stochastic differential equations (BSDEs) associated with
the replicating portfolios of long and short positions in the claim. This leads
to the definition of buyer's and seller's XVA which in turn identify a
no-arbitrage interval. When borrowing and lending rates coincide we provide a
fully explicit expression for the uniquely determined price of XVA, expressed
as a percentage of the price of the traded claim, and for the corresponding
replication strategies. This extends the result of Piterbarg by incorporating
the effect of premature contract termination due to default risk of the trader
and of his counterparty.
"
1501.06084	q-fin	q-fin.CP	"Convergence of an Euler scheme for a hybrid stochastic-local volatility
  model with stochastic rates in foreign exchange markets"	"  We study the Heston-Cox-Ingersoll-Ross++ stochastic-local volatility model in
the context of foreign exchange markets and propose a Monte Carlo simulation
scheme which combines the full truncation Euler scheme for the stochastic
volatility component and the stochastic domestic and foreign short interest
rates with the log-Euler scheme for the exchange rate. We establish the
exponential integrability of full truncation Euler approximations for the
Cox-Ingersoll-Ross process and find a lower bound on the explosion time of
these exponential moments. Under a full correlation structure and a realistic
set of assumptions on the so-called leverage function, we prove the strong
convergence of the exchange rate approximations and deduce the convergence of
Monte Carlo estimators for a number of vanilla and path-dependent options.
Then, we perform a series of numerical experiments for an autocallable barrier
dual currency note.
"
1501.07297	q-fin	q-fin.RM math.PR	"Multivariate Stop loss Mixed Erlang Reinsurance risk: Aggregation,
  Capital allocation and Default risk"	"  In this paper, we address the aggregation of dependent stop loss reinsurance
risks where the dependence among the ceding insurer(s) risks is governed by the
Sarmanov distribution and each individual risk belongs to the class of Erlang
mixtures. We investigate the effects of the ceding insurer(s) risk dependencies
on the reinsurer risk profile by deriving a closed formula for the distribution
function of the aggregated stop loss reinsurance risk. Furthermore,
diversification effects from aggregating reinsurance risks are examined by
deriving a closed expression for the risk capital needed for the whole
portfolio of the reinsurer and also the allocated risk capital for each
business unit under the TVaR capital allocation principle. Moreover, given the
risk capital that the reinsurer holds, we express the default probability of
the reinsurer analytically. In case the reinsurer is in default, we determine
analytical expressions for the amount of the aggregate reinsured unpaid losses
and the unpaid losses of each reinsured line of business of the ceding
insurer(s). These results are illustrated by numerical examples.
"
1501.07404	q-fin	q-fin.CP	Liquidity costs: a new numerical methodology and an empirical study	"  We consider rate swaps which pay a fixed rate against a floating rate in
presence of bid-ask spread costs. Even for simple models of bid-ask spread
costs, there is no explicit strategy optimizing an expected function of the
hedging error. We here propose an efficient algorithm based on the stochastic
gradient method to compute an approximate optimal strategy without solving a
stochastic control problem. We validate our algorithm by numerical experiments.
We also develop several variants of the algorithm and discuss their
performances in terms of the numerical parameters and the liquidity cost.
"
1501.07480	q-fin	q-fin.MF q-fin.PM	Portfolio Optimization under Shortfall Risk Constraint	"  This paper solves a utility maximization problem under utility-based
shortfall risk constraint, by proposing an approach using Lagrange multiplier
and convex duality. Under mild conditions on the asymptotic elasticity of the
utility function and the loss function, we find an optimal wealth process for
the constrained problem and characterize the bi-dual relation between the
respective value functions of the constrained problem and its dual. This
approach applies to both complete and incomplete markets. Moreover, the
extension to more complicated cases is illustrated by solving the problem with
a consumption process added. Finally, we give an example of utility and loss
functions in the Black-Scholes market where the solutions have explicit forms.
"
1501.07778	q-fin	q-fin.TR	Foreign Exchange Market Microstructure and the WM/Reuters 4pm Fix	"  A market fix serves as a benchmark for foreign exchange (FX) execution, and
is employed by many institutional investors to establish an exact reference at
which execution takes place. The currently most popular FX fix is the World
Market Reuters (WM/R) 4pm fix. Execution at the WM/R 4pm fix is a service
offered by FX brokers (normally banks), who deliver execution at the fix
provided they obtain the trade order until a certain time prior to 4pm. In this
paper, we study the market microstructure around 4pm. We demonstrate that
market dynamics can be distinguished from other times during the day through
increased volatility and size of movements. Our findings question the aggregate
benefit to the client base of using the 4pm fix in its current form.
"
1502.00680	q-fin	q-fin.TR nlin.AO physics.data-an physics.soc-ph stat.AP	Quasi-Centralized Limit Order Books	"  A quasi-centralized limit order book (QCLOB) is a limit order book (LOB) in
which financial institutions can only access the trading opportunities offered
by counterparties with whom they possess sufficient bilateral credit. We
perform an empirical analysis of a recent, high-quality data set from a large
electronic trading platform that utilizes QCLOBs to facilitate trade. We find
many significant differences between our results and those widely reported for
other LOBs. We also uncover a remarkable empirical universality: although the
distributions describing order flow and market state vary considerably across
days, a simple, linear rescaling causes them to collapse onto a single curve.
Motivated by this finding, we propose a semi-parametric model of order flow and
market state in a QCLOB on a single trading day. Our model provides similar
performance to that of parametric curve-fitting techniques, while being simpler
to compute and faster to implement.
"
1502.01125	q-fin	q-fin.CP q-fin.TR	"Equilibrium Pricing in an Order Book Environment: Case Study for a Spin
  Model"	"  When modelling stock market dynamics, the price formation is often based on
an equilbrium mechanism. In real stock exchanges, however, the price formation
is goverend by the order book. It is thus interesting to check if the resulting
stylized facts of a model with equilibrium pricing change, remain the same or,
more generally, are compatible with the order book environment. We tackle this
issue in the framework of a case study by embedding the
Bornholdt-Kaizoji-Fujiwara spin model into the order book dynamics. To this
end, we use a recently developed agent based model that realistically
incorporates the order book. We find realistic stylized facts. We conclude for
the studied case that equilibrium pricing is not needed and that the
corresponding assumption of a ""fundamental"" price may be abandoned.
"
1502.02926	q-fin	q-fin.MF	Consistent Recalibration of Yield Curve Models	"  The analytical tractability of affine (short rate) models, such as the
Vasicek and the Cox-Ingersoll-Ross models, has made them a popular choice for
modelling the dynamics of interest rates. However, in order to account properly
for the dynamics of real data, these models need to exhibit time-dependent or
even stochastic parameters. This in turn breaks their tractability, and
modelling and simulating becomes an arduous task. We introduce a new class of
Heath-Jarrow-Morton (HJM) models that both fit the dynamics of real market data
and remain tractable. We call these models consistent recalibration (CRC)
models. These CRC models appear as limits of concatenations of forward rate
increments, each belonging to a Hull-White extended affine factor model with
possibly different parameters. That is, we construct HJM models from ""tangent""
affine models. We develop a theory for a continuous path version of such models
and discuss their numerical implementations within the Vasicek and
Cox-Ingersoll-Ross frameworks.
"
1502.03252	q-fin	q-fin.RM math.PR	"Diversification, protection of liability holders and regulatory
  arbitrage"	"  Any solvency regime for financial institutions should be aligned with the
fundamental objectives of regulation: protecting liability holders and securing
the stability of the financial system. The first objective leads to consider
surplus-invariant capital adequacy tests, i.e. tests that do not depend on the
surplus of a financial institution. We provide a complete characterization of
closed, convex, surplus-invariant capital adequacy tests that highlights an
inherent tension between surplus-invariance and the desire to give credit for
diversification. The second objective leads to requiring consistency of capital
adequacy tests across jurisdictions. Of particular importance in this respect
are capital adequacy tests that remain invariant under a change of
num\'{e}raire. We establish an intimate link between surplus- and num\'{e}raire
invariant tests.
"
1502.03254	q-fin	q-fin.PR math.PR	"Mass at zero in the uncorrelated SABR model and implied volatility
  asymptotics"	"  We study the mass at the origin in the uncorrelated SABR stochastic
volatility model, and derive several tractable expressions, in particular when
time becomes small or large. As an application--in fact the original motivation
for this paper--we derive small-strike expansions for the implied volatility
when the maturity becomes short or large. These formulae, by definition
arbitrage free, allow us to quantify the impact of the mass at zero on existing
implied volatility approximations, and in particular how correct/erroneous
these approximations become.
"
1502.03656	q-fin	stat.CO q-fin.CP stat.ML	Quasi-Newton particle Metropolis-Hastings	"  Particle Metropolis-Hastings enables Bayesian parameter inference in general
nonlinear state space models (SSMs). However, in many implementations a random
walk proposal is used and this can result in poor mixing if not tuned correctly
using tedious pilot runs. Therefore, we consider a new proposal inspired by
quasi-Newton algorithms that may achieve similar (or better) mixing with less
tuning. An advantage compared to other Hessian based proposals, is that it only
requires estimates of the gradient of the log-posterior. A possible application
is parameter inference in the challenging class of SSMs with intractable
likelihoods. We exemplify this application and the benefits of the new proposal
by modelling log-returns of future contracts on coffee by a stochastic
volatility model with $\alpha$-stable observations.
"
1502.03901	q-fin	q-fin.MF math.PR	"Multivariate Subordination using Generalised Gamma Convolutions with
  Applications to V.G. Processes and Option Pricing"	"  We unify and extend a number of approaches related to constructing
multivariate Variance-Gamma (V.G.) models for option pricing. An overarching
model is derived by subordinating multivariate Brownian motion to a
subordinator from the Thorin (1977) class of generalised Gamma convolution
subordinators. A class of models due to Grigelionis (2007), which contains the
well-known Madan-Seneta V.G. model, is of this type, but our multivariate
generalization is considerably wider, allowing in particular for processes with
infinite variation and a variety of dependencies between the underlying
processes. Multivariate classes developed by P\'erez-Abreu and Stelzer (2012)
and Semeraro (2008) and Guillaume (2013) are also submodels. The new models are
shown to be invariant under Esscher transforms, and quite explicit expressions
for canonical measures (and transition densities in some cases) are obtained,
which permit applications such as option pricing using PIDEs or tree based
methodologies. We illustrate with best-of and worst-of European and American
options on two assets.
"
1502.04359	q-fin	q-fin.MF math.PR q-fin.TR	"A weak law of large numbers for a limit order book model with fully
  state dependent order dynamics"	"  This paper studies a limit order book (LOB) model, in which the order
dynamics depend on both, the current best available prices and the current
volume density functions. For the joint dynamics of the best bid price, the
best ask price, and the standing volume densities on both sides of the LOB we
derive a weak law of large numbers, which states that the LOB model converges
to a continuous-time limit when the size of an individual order as well as the
tick size tend to zero and the order arrival rate tends to infinity. In the
scaling limit the two volume densities follow each a non-linear PDE coupled
with two non-linear ODEs that describe the best bid and ask price.
"
1502.05920	q-fin	q-fin.MF math.OC q-fin.PM	Robust Utility Maximization with L\'evy Processes	"  We study a robust portfolio optimization problem under model uncertainty for
an investor with logarithmic or power utility. The uncertainty is specified by
a set of possible L\'evy triplets; that is, possible instantaneous drift,
volatility and jump characteristics of the price process. We show that an
optimal investment strategy exists and compute it in semi-closed form.
Moreover, we provide a saddle point analysis describing a worst-case model.
"
1502.06074	q-fin	q-fin.MF q-fin.PR	Coping with Negative Short-Rates	"  We discuss a simple extension of the Ho and Lee model with generic
time-dependent drift in which: 1) we compute bond prices analytically; 2) the
yield curve is sensible and the asymptotic yield is positive; and 3) our
analytical solution provides a clean and simple way of separating volatility
from the drift in the short-rate process. Our extension amounts to introducing
one or two reflecting barriers for the underlying Brownian motion (as opposed
to the short-rate), which allows to have more realistic time-dependent drift
(as opposed to constant drift). In our model the spectrum -- or, roughly, the
set of short-rate values contributing to bond and other claim prices -- is
discrete and positive. We discuss how to calibrate our model using empirical
yield data by fitting three parameters and then read off the time-dependent
drift.
"
1502.06106	q-fin	q-fin.PR math.PR	"Arbitrage-Free Pricing of XVA - Part II: PDE Representation and
  Numerical Analysis"	"  We study the semilinear partial differential equation (PDE) associated with
the non-linear BSDE characterizing buyer's and seller's XVA in a framework that
allows for asymmetries in funding, repo and collateral rates, as well as for
early contract termination due to counterparty credit risk. We show the
existence of a unique classical solution to the PDE by first proving the
existence and uniqueness of a viscosity solution and then its regularity. We
use the uniqueness result to conduct a thorough numerical study illustrating
how funding costs, repo rates, and counterparty credit risk contribute to
determine the total valuation adjustment.
"
1502.06557	q-fin	stat.ME q-fin.CP stat.AP stat.CO stat.ML	"Iteratively reweighted adaptive lasso for conditional heteroscedastic
  time series with applications to AR-ARCH type processes"	"  Shrinkage algorithms are of great importance in almost every area of
statistics due to the increasing impact of big data. Especially time series
analysis benefits from efficient and rapid estimation techniques such as the
lasso. However, currently lasso type estimators for autoregressive time series
models still focus on models with homoscedastic residuals. Therefore, an
iteratively reweighted adaptive lasso algorithm for the estimation of time
series models under conditional heteroscedasticity is presented in a
high-dimensional setting. The asymptotic behaviour of the resulting estimator
is analysed. It is found that the proposed estimation procedure performs
substantially better than its homoscedastic counterpart. A special case of the
algorithm is suitable to compute the estimated multivariate AR-ARCH type models
efficiently. Extensions to the model like periodic AR-ARCH, threshold AR-ARCH
or ARMA-GARCH are discussed. Finally, different simulation results and
applications to electricity market data and returns of metal prices are shown.
"
1502.06681	q-fin	q-fin.MF math.OC math.PR	"Arbitrage, hedging and utility maximization using semi-static trading
  strategies with American options"	"  We consider a financial market where stocks are available for dynamic
trading, and European and American options are available for static trading
(semi-static trading strategies). We assume that the American options are
infinitely divisible, and can only be bought but not sold. In the first part of
the paper, we work within the framework without model ambiguity. We first get
the fundamental theorem of asset pricing (FTAP). Using the FTAP, we get the
dualities for the hedging prices of European and American options. Based on the
hedging dualities, we also get the duality for the utility maximization. In the
second part of the paper, we consider the market which admits non-dominated
model uncertainty. We first establish the hedging result, and then using the
hedging duality we further get the FTAP. Due to the technical difficulty
stemming from the non-dominancy of the probability measure set, we use a
discretization technique and apply the minimax theorem.
"
1502.06736	q-fin	cond-mat.stat-mech math.PR q-fin.MF	Rotational invariant estimator for general noisy matrices	"  We investigate the problem of estimating a given real symmetric signal matrix
$\textbf{C}$ from a noisy observation matrix $\textbf{M}$ in the limit of large
dimension. We consider the case where the noisy measurement $\textbf{M}$ comes
either from an arbitrary additive or multiplicative rotational invariant
perturbation. We establish, using the Replica method, the asymptotic global law
estimate for three general classes of noisy matrices, significantly extending
previously obtained results. We give exact results concerning the asymptotic
deviations (called overlaps) of the perturbed eigenvectors away from the true
ones, and we explain how to use these overlaps to ""clean"" the noisy eigenvalues
of $\textbf{M}$. We provide some numerical checks for the different estimators
proposed in this paper and we also make the connection with some well known
results of Bayesian statistics.
"
1502.07961	q-fin	q-fin.RM	Measures of Systemic Risk	"  Systemic risk refers to the risk that the financial system is susceptible to
failures due to the characteristics of the system itself. The tremendous cost
of systemic risk requires the design and implementation of tools for the
efficient macroprudential regulation of financial institutions. The current
paper proposes a novel approach to measuring systemic risk.
  Key to our construction is a rigorous derivation of systemic risk measures
from the structure of the underlying system and the objectives of a financial
regulator. The suggested systemic risk measures express systemic risk in terms
of capital endowments of the financial firms. Their definition requires two
ingredients: a cash flow or value model that assigns to the capital allocations
of the entities in the system a relevant stochastic outcome; and an
acceptability criterion, i.e. a set of random outcomes that are acceptable to a
regulatory authority. Systemic risk is measured by the set of allocations of
additional capital that lead to acceptable outcomes. We explain the conceptual
framework and the definition of systemic risk measures, provide an algorithm
for their computation, and illustrate their application in numerical case
studies.
  Many systemic risk measures in the literature can be viewed as the minimal
amount of capital that is needed to make the system acceptable after
aggregating individual risks, hence quantify the costs of a bail-out. In
contrast, our approach emphasizes operational systemic risk measures that
include both ex post bailout costs as well as ex ante capital requirements and
may be used to prevent systemic crises.
"
1503.00127	q-fin	physics.soc-ph q-fin.GN	How crude oil prices shape the global division of labour	"  Our work sheds new light on the role of oil prices in shaping the world
economy by investigating flows of goods and services through global value
chains between 1960 and 2011, by means of Markov Chain and network analysis. We
show that over that time period the international division of labor and trade
patterns are tightly linked to the price of oil. We demonstrate that this
correlation does not depend on the balance of payments nor on the nominal value
of trade or trade agreements; it is instead linked to the way the Global Value
Chains (GVCs) shape global trade. Our study suggests that transport played an
important structural role in shaping GVCs.
"
1503.00421	q-fin	physics.soc-ph q-fin.ST	"State and group dynamics of world stock market by principal component
  analysis"	"  We study the dynamic interactions and structural changes in global financial
indices in the years 1998-2012. We apply a principal component analysis (PCA)
to cross-correlation coefficients of the stock indices. We calculate the
correlations between principal components (PCs) and each asset, known as PC
coefficients. A change in market state is identified as a change in the first
PC coefficients. Some indices do not show significant change of PCs in market
state during crises. The indices exposed to the invested capitals in the stock
markets are at the minimum level of risk. Using the first two PC coefficients,
we identify indices that are similar and more strongly correlated than the
others. We observe that the European indices form a robust group over the
observation period. The dynamics of the individual indices within the group
increase in similarity with time, and the dynamics of indices are more similar
during the crises. Furthermore, the group formation of indices changes position
in two-dimensional spaces due to crises. Finally, after a financial crisis, the
difference of PCs between the European and American indices narrows.
"
1503.00529	q-fin	q-bio.PE nlin.AO physics.soc-ph q-fin.EC q-fin.GN	Diversity waves in collapse-driven population dynamics	"  Populations of species in ecosystems are often constrained by availability of
resources within their environment. In effect this means that a growth of one
population, needs to be balanced by comparable reduction in populations of
others. In neutral models of biodiversity all populations are assumed to change
incrementally due to stochastic births and deaths of individuals. Here we
propose and model another redistribution mechanism driven by abrupt and severe
collapses of the entire population of a single species freeing up resources for
the remaining ones. This mechanism may be relevant e.g. for communities of
bacteria, with strain-specific collapses caused e.g. by invading
bacteriophages, or for other ecosystems where infectious diseases play an
important role.
  The emergent dynamics of our system is cyclic ""diversity waves"" triggered by
collapses of globally dominating populations. The population diversity peaks at
the beginning of each wave and exponentially decreases afterwards. Species
abundances are characterized by a bimodal time-aggregated distribution with the
lower peak formed by populations of recently collapsed or newly introduced
species, while the upper peak - species that has not yet collapsed in the
current wave. In most waves both upper and lower peaks are composed of several
smaller peaks. This self-organized hierarchical peak structure has a long-term
memory transmitted across several waves. It gives rise to a scale-free tail of
the time-aggregated population distribution with a universal exponent of 1.7.
We show that diversity wave dynamics is robust with respect to variations in
the rules of our model such as diffusion between multiple environments,
species-specific growth and extinction rates, and bet-hedging strategies.
"
1503.00621	q-fin	q-fin.RM q-fin.GN	Leveraging the network: a stress-test framework based on DebtRank	"  We develop a novel stress-test framework to monitor systemic risk in
financial systems. The modular structure of the framework allows to accommodate
for a variety of shock scenarios, methods to estimate interbank exposures and
mechanisms of distress propagation. The main features are as follows. First,
the framework allows to estimate and disentangle not only first-round effects
(i.e. shock on external assets) and second-round effects (i.e. distress induced
in the interbank network), but also third-round effects induced by possible
fire sales. Second, it allows to monitor at the same time the impact of shocks
on individual or groups of financial institutions as well as their
vulnerability to shocks on counterparties or certain asset classes. Third, it
includes estimates for loss distributions, thus combining network effects with
familiar risk measures such as VaR and CVaR. Fourth, in order to perform
robustness analyses and cope with incomplete data, the framework features a
module for the generation of sets of networks of interbank exposures that are
coherent with the total lending and borrowing of each bank. As an illustration,
we carry out a stress-test exercise on a dataset of listed European banks over
the years 2008-2013. We find that second-round and third-round effects dominate
first-round effects, therefore suggesting that most current stress-test
frameworks might lead to a severe underestimation of systemic risk.
"
1503.00913	q-fin	q-fin.TR	"Understanding Financial Market States Using Artificial Double Auction
  Market"	"  The ultimate value of theories of the fundamental mechanisms comprising the
asset price in financial systems will be reflected in the capacity of such
theories to understand these systems. Although the models that explain the
various states of financial markets offer substantial evidences from the fields
of finance, mathematics, and even physics to explain states observed in the
real financial markets, previous theories that attempt to fully explain the
complexities of financial markets have been inadequate. In this study, we
propose an artificial double auction market as an agent-based model approach to
study the origin of complex states in the financial markets, characterizing
important parameters with an investment strategy that can cover the dynamics of
the financial market. The investment strategy of chartist traders after market
information arrives should reduce market stability originating in the price
fluctuations of risky assets. However, fundamentalist traders strategically
submit orders with a fundamental value and, thereby stabilize the market. We
construct a continuous double auction market and find that the market is
controlled by a fraction of chartists, P_{c}. We show that mimicking real
financial markets state, which emerges in real financial systems, is given
between approximately P_{c} = 0.40 and P_{c} = 0.85, but that mimicking the
efficient market hypothesis state can be generated in a range of less than
P_{c} = 0.40. In particular, we observe that the mimicking market collapse
state created in a value greater than P_{c} = 0.85, in which a liquidity
shortage occurs, and the phase transition behavior is P_{c} = 0.85.
"
1503.00961	q-fin	q-fin.MF math.OC math.PR q-fin.PM	Optimally Investing to Reach a Bequest Goal	"  We determine the optimal strategy for investing in a Black-Scholes market in
order to maximize the probability that wealth at death meets a bequest goal
$b$, a type of goal-seeking problem, as pioneered by Dubins and Savage (1965,
1976). The individual consumes at a constant rate $c$, so the level of wealth
required for risklessly meeting consumption equals $c/r$, in which $r$ is the
rate of return of the riskless asset.
  Our problem is related to, but different from, the goal-reaching problems of
Browne (1997). First, Browne (1997, Section 3.1) maximizes the probability that
wealth reaches $b < c/r$ before it reaches $a < b$. Browne's game ends when
wealth reaches $b$. By contrast, for the problem we consider, the game
continues until the individual dies or until wealth reaches 0; reaching $b$ and
then falling below it before death does not count.
  Second, Browne (1997, Section 4.2) maximizes the expected discounted reward
of reaching $b > c/r$ before wealth reaches $c/r$. If one interprets his
discount rate as a hazard rate, then our two problems are {\it mathematically}
equivalent for the special case for which $b > c/r$, with ruin level $c/r$.
However, we obtain different results because we set the ruin level at 0,
thereby allowing the game to continue when wealth falls below $c/r$.
"
1503.03726	q-fin	q-fin.RM	Bounds for randomly shared risk of heavy-tailed loss factors	"  For a risk vector $V$, whose components are shared among agents by some
random mechanism, we obtain asymptotic lower and upper bounds for the
individual agents' exposure risk and the aggregated risk in the market. Risk is
measured by Value-at-Risk or Conditional Tail Expectation. We assume Pareto
tails for the components of $V$ and arbitrary dependence structure in a
multivariate regular variation setting. Upper and lower bounds are given by
asymptotically independent and fully dependent components of $V$ with respect
to the tail index $\alpha$ being smaller or larger than 1. Counterexamples,
where for non-linear aggregation functions no bounds are available, complete
the picture.
"
1503.05655	q-fin	q-fin.RM	Option Pricing Beyond Black-Scholes Based on Double-Fractional Diffusion	"  We show how the prices of options can be determined with the help of
double-fractional differential equation in such a way that their inclusion in a
portfolio of stocks provides a more reliable hedge against dramatic price drops
that the use of options whose prices were fixed by the Black-Scholes formula.
"
1503.05909	q-fin	math.ST math.PR q-fin.CP stat.TH	Principal Components Analysis for Semimartingales and Stochastic PDE	"  In this work, we develop a novel principal component analysis (PCA) for
semimartingales by introducing a suitable spectral analysis for the quadratic
variation operator. Motivated by high-dimensional complex systems typically
found in interest rate markets, we investigate correlation in high-dimensional
high-frequency data generated by continuous semimartingales. In contrast to the
traditional PCA methodology, the directions of large variations are not
deterministic, but rather they are bounded variation adapted processes which
maximize quadratic variation almost surely. This allows us to reduce
dimensionality from high-dimensional semimartingale systems in terms of
quadratic covariation rather than the usual covariance concept.
  The proposed methodology allows us to investigate space-time data driven by
multi-dimensional latent semimartingale state processes. The theory is applied
to discretely-observed stochastic PDEs which admit finite-dimensional
realizations. In particular, we provide consistent estimators for
finite-dimensional invariant manifolds for Heath-Jarrow-Morton models. More
importantly, components of the invariant manifold associated to volatility and
drift dynamics are consistently estimated and identified. The proposed
methodology is illustrated with both simulated and real data sets.
"
1503.06020	q-fin	physics.soc-ph q-fin.GN	"Insights in Economical Complexity in Spain: the hidden boost of migrants
  in international tradings"	"  We consider extensive data on Spanish international trades and population
composition and, through statistical-mechanics and graph-theory driven
analysis, we unveil that the social network made of native and foreign-born
individuals plays a role in the evolution and in the diversification of trades.
Indeed, migrants naturally provide key information on policies and needs in
their native countries, hence allowing firm's holders to leverage transactional
costs of exports and duties. As a consequence, international trading is
affordable for a larger basin of firms and thus results in an increased number
of transactions, which, in turn, implies a larger diversification of
international traded products. These results corroborate the novel scenario
depicted by ""Economical Complexity"", where the pattern of production and trade
of more developed countries is highly diversified. We also address a central
question in Economics, concerning the existence of a critical threshold for
migrants (within a given territorial district) over which they effectively
contribute to boost international trades: in our physically-driven picture,
this phenomenon corresponds to the emergence of a phase transition and,
tackling the problem from this perspective, results in a novel successful
quantitative route. Finally, we can infer that the pattern of interaction
between native and foreign-born population exhibits small-world features as
small diameter, large clustering, and weak ties working as optimal cut-edge, in
complete agreement with findings in ""Social Complexity"".
"
1503.07676	q-fin	q-fin.CP q-fin.RM	Sensitivity and Computational Complexity in Financial Networks	"  Modern financial networks exhibit a high degree of interconnectedness and
determining the causes of instability and contagion in financial networks is
necessary to inform policy and avoid future financial collapse. In the American
Economic Review, Elliott, Golub and Jackson proposed a simple model for
capturing the dynamics of complex financial networks. In Elliott, Golub and
Jackson's model, each institution in the network can buy underlying assets or
percentage shares in other institutions (cross-holdings) and if any
institution's value drops below a critical threshold value, its value suffers
an additional failure cost.
  This work shows that even in simple model put forward by Elliott, Golub and
Jackson there are fundamental barriers to understanding the risks that are
inherent in a network. First, if institutions are not required to maintain a
minimum amount of self-holdings, an $\epsilon$ change in investments by a
single institution can have an arbitrarily magnified influence on the net worth
of the institutions in the system. This sensitivity result shows that if
institutions have small self-holdings, then estimating the market value of an
institution requires almost perfect information about every cross-holding in
the system. Second, we show that even if a regulator has complete information
about all cross-holdings in the system, it may be computationally intractable
to even estimate the number of failures that could be caused by an arbitrarily
small shock to the system. Together, these results show that any uncertainty in
the cross-holdings or values of the underlying assets can be amplified by the
network to arbitrarily large uncertainty in the valuations of institutions in
the network.
"
1503.08013	q-fin	q-fin.PM	A Robust Statistics Approach to Minimum Variance Portfolio Optimization	"  We study the design of portfolios under a minimum risk criterion. The
performance of the optimized portfolio relies on the accuracy of the estimated
covariance matrix of the portfolio asset returns. For large portfolios, the
number of available market returns is often of similar order to the number of
assets, so that the sample covariance matrix performs poorly as a covariance
estimator. Additionally, financial market data often contain outliers which, if
not correctly handled, may further corrupt the covariance estimation. We
address these shortcomings by studying the performance of a hybrid covariance
matrix estimator based on Tyler's robust M-estimator and on Ledoit-Wolf's
shrinkage estimator while assuming samples with heavy-tailed distribution.
Employing recent results from random matrix theory, we develop a consistent
estimator of (a scaled version of) the realized portfolio risk, which is
minimized by optimizing online the shrinkage intensity. Our portfolio
optimization method is shown via simulations to outperform existing methods
both for synthetic and real market data.
"
1503.08123	q-fin	math.ST q-fin.MF q-fin.RM stat.TH	Higher order elicitability and Osband's principle	"  A statistical functional, such as the mean or the median, is called
elicitable if there is a scoring function or loss function such that the
correct forecast of the functional is the unique minimizer of the expected
score. Such scoring functions are called strictly consistent for the
functional. The elicitability of a functional opens the possibility to compare
competing forecasts and to rank them in terms of their realized scores. In this
paper, we explore the notion of elicitability for multi-dimensional functionals
and give both necessary and sufficient conditions for strictly consistent
scoring functions. We cover the case of functionals with elicitable components,
but we also show that one-dimensional functionals that are not elicitable can
be a component of a higher order elicitable functional. In the case of the
variance this is a known result. However, an important result of this paper is
that spectral risk measures with a spectral measure with finite support are
jointly elicitable if one adds the `correct' quantiles. A direct consequence of
applied interest is that the pair (Value at Risk, Expected Shortfall) is
jointly elicitable under mild conditions that are usually fulfilled in risk
management applications.
"
1503.08465	q-fin	q-fin.CP	Anomalous volatility scaling in high frequency financial data	"  Volatility of intra-day stock market indices computed at various time
horizons exhibits a scaling behaviour that differs from what would be expected
from fractional Brownian motion (fBm). We investigate this anomalous scaling by
using empirical mode decomposition (EMD), a method which separates time series
into a set of cyclical components at different time-scales. By applying the EMD
to fBm, we retrieve a scaling law that relates the variance of the components
to a power law of the oscillating period. In contrast, when analysing 22
different stock market indices, we observe deviations from the fBm and Brownian
motion scaling behaviour. We discuss and quantify these deviations, associating
them to the characteristics of financial markets, with larger deviations
corresponding to less developed markets.
"
1503.08586	q-fin	q-fin.RM	"New class of distortion risk measures and their tail asymptotics with
  emphasis on VaR"	"  Distortion risk measures are extensively used in finance and insurance
applications because of their appealing properties. We present three methods to
construct new class of distortion functions and measures. The approach involves
the composting methods, the mixing methods and the approach that based on the
theory of copula. Subadditivity is an important property when aggregating risks
in order to preserve the benefits of diversification. However, Value at risk
(VaR), as the most well-known example of distortion risk measure is not always
globally subadditive, except of elliptically distributed risks. In this paper,
instead of study subadditivity we investigate the tail subadditivity for VaR
and other distortion risk measures. In particular, we demonstrate that VaR is
tail subadditive for the case where the support of risk is bounded. Various
examples are also presented to illustrate the results.
"
1503.08589	q-fin	q-fin.MF math.PR	Local risk-minimization for Barndorff-Nielsen and Shephard models	"  We obtain explicit representations of locally risk-minimizing strategies of
call and put options for the Barndorff-Nielsen and Shephard models, which are
Ornstein--Uhlenbeck-type stochastic volatility models. Using Malliavin calculus
for Levy processes, Arai and Suzuki (2015) obtained a formula for locally
risk-minimizing strategies for Levy markets under many additional conditions.
Supposing mild conditions, we make sure that the Barndorff-Nielsen and Shephard
models satisfy all the conditions imposed in Arai and Suzuki (2015). Among
others, we investigate the Malliavin differentiability of the density of the
minimal martingale measure. Moreover, some numerical experiments for locally
risk-minimizing strategies are introduced.
"
1504.01026	q-fin	q-fin.MF q-fin.PM	Diversity-Weighted Portfolios with Negative Parameter	"  We analyze a negative-parameter variant of the diversity-weighted portfolio
studied by Fernholz, Karatzas, and Kardaras (Finance Stoch 9(1):1-27, 2005),
which invests in each company a fraction of wealth inversely proportional to
the company's market weight (the ratio of its capitalization to that of the
entire market). We show that this strategy outperforms the market with
probability one, under a non-degeneracy assumption on the volatility structure
and the assumption that the market weights admit a positive lower bound.
Several modifications of this portfolio, which outperform the market under
milder versions of this ""no-failure"" condition, are put forward, one of which
is rank-based. An empirical study suggests that such strategies as studied here
have indeed the potential to outperform the market and to be preferable
investment opportunities, even under realistic proportional transaction costs.
"
1504.01857	q-fin	q-fin.RM	DebtRank: A microscopic foundation for shock propagation	"  The DebtRank algorithm has been increasingly investigated as a method to
estimate the impact of shocks in financial networks, as it overcomes the
limitations of the traditional default-cascade approaches. Here we formulate a
dynamical ""microscopic"" theory of instability for financial networks by
iterating balance sheet identities of individual banks and by assuming a simple
rule for the transfer of shocks from borrowers to lenders. By doing so, we
generalise the DebtRank formulation, both providing an interpretation of the
effective dynamics in terms of basic accounting principles and preventing the
underestimation of losses on certain network topologies. Depending on the
structure of the interbank leverage matrix the dynamics is either stable, in
which case the asymptotic state can be computed analytically, or unstable,
meaning that at least one bank will default. We apply this framework to a
dataset of the top listed European banks in the period 2008 - 2013. We find
that network effects can generate an amplification of exogenous shocks of a
factor ranging between three (in normal periods) and six (during the crisis)
when we stress the system with a 0.5% shock on external (i.e. non-interbank)
assets for all banks.
"
1504.03074	q-fin	q-fin.PR math.AP	On a method of solving the Black-Scholes Equation	"  The paper proposes a different method of solving a simplified version of the
Black-Scholes equation. This paper will discuss the importance of the
Black-Scholes equation and its applications in finance.
"
1504.03232	q-fin	q-fin.EC q-fin.GN	Economic inequality and mobility in kinetic models for social sciences	"  Statistical evaluations of the economic mobility of a society are more
difficult than measurements of the income distribution, because they require to
follow the evolution of the individuals' income for at least one or two
generations. In micro-to-macro theoretical models of economic exchanges based
on kinetic equations, the income distribution depends only on the asymptotic
equilibrium solutions, while mobility estimates also involve the detailed
structure of the transition probabilities of the model, and are thus an
important tool for assessing its validity. Empirical data show a remarkably
general negative correlation between economic inequality and mobility, whose
explanation is still unclear. It is therefore particularly interesting to study
this correlation in analytical models. In previous work we investigated the
behavior of the Gini inequality index in kinetic models in dependence on
several parameters which define the binary interactions and the taxation and
redistribution processes: saving propensity, taxation rates gap, tax evasion
rate, welfare means-testing etc. Here, we check the correlation of mobility
with inequality by analyzing the mobility dependence from the same parameters.
According to several numerical solutions, the correlation is confirmed to be
negative.
"
1504.03238	q-fin	q-fin.MF	Polynomial term structure models	"  In this article, we explore a class of tractable interest rate models that
have the property that the price of a zero-coupon bond can be expressed as a
polynomial of a state diffusion process. Our results include a classification
of all such time-homogeneous single-factor models in the spirit of Filipovic's
maximal degree theorem for exponential polynomial models, as well as an
explicit characterisation of the set of feasible parameters in the case when
the factor process is bounded. Extensions to time-inhomogeneous and
multi-factor polynomial models are also considered.
"
1504.03644	q-fin	q-fin.MF math.PR q-fin.PR	Pathwise super-replication via Vovk's outer measure	"  Since Hobson's seminal paper [D. Hobson: Robust hedging of the lookback
option. In: Finance Stoch. (1998)] the connection between model-independent
pricing and the Skorokhod embedding problem has been a driving force in robust
finance. We establish a general pricing-hedging duality for financial
derivatives which are susceptible to the Skorokhod approach.
  Using Vovk's approach to mathematical finance we derive a model-independent
super-replication theorem in continuous time, given information on finitely
many marginals. Our result covers a broad range of exotic derivatives,
including lookback options, discretely monitored Asian options, and options on
realized variance.
"
1504.03733	q-fin	stat.ME q-fin.RM	Switching-GAS Copula Models With Application to Systemic Risk	"  Recent financial disasters have emphasised the need to accurately predict
extreme financial losses and their consequences for the institutions belonging
to a given financial market. The ability of econometric models to predict
extreme events strongly relies on their flexibility to account for the highly
nonlinear and asymmetric dependence observed in financial returns. We develop a
new class of flexible Copula models where the evolution of the dependence
parameters follow a Markov-Switching Generalised Autoregressive Score (SGASC)
dynamics. Maximum Likelihood estimation is consistently performed using the
Inference Functions for Margins (IFM) approach and a version of the
Expectation-Maximisation (EM) algorithm specifically tailored to this class of
models. The SGASC models are then used to estimate the Conditional
Value-at-Risk (CoVaR), which is defined as the VaR of a given asset conditional
on another asset (or portfolio) being in financial distress, and the
Conditional Expected Shortfall (CoES). Our empirical investigation shows that
the proposed SGASC models are able to explain and predict the systemic risk
contribution of several European countries. Moreover, we also find that the
SGASC models outperform competitors using several CoVaR backtesting procedures.
"
1504.04774	q-fin	q-fin.RM q-fin.CP	"Time-consistency of risk measures with GARCH volatilities and their
  estimation"	"  In this paper we study time-consistent risk measures for returns that are
given by a GARCH(1,1) model. We present a construction of risk measures based
on their static counterparts that overcomes the lack of time-consistency. We
then study in detail our construction for the risk measures Value-at-Risk (VaR)
and Average Value-at-Risk (AVaR). While in the VaR case we can derive an
analytical formula for its time-consistent counterpart, in the AVaR case we
derive lower and upper bounds to its time-consistent version. Furthermore, we
incorporate techniques from Extreme Value Theory (EVT) to allow for a more
tail-geared statistical analysis of the corresponding risk measures. We
conclude with an application of our results to a data set of stock prices.
"
1505.02292	q-fin	q-fin.RM	Wrong-Way Bounds in Counterparty Credit Risk Management	"  We study the problem of finding the worst-case joint distribution of a set of
risk factors given prescribed multivariate marginals and a nonlinear loss
function. We show that when the risk measure is CVaR, and the distributions are
discretized, the problem can be conveniently solved using linear programming
technique. The method has applications to any situation where marginals are
provided, and bounds need to be determined on total portfolio risk. This arises
in many financial contexts, including pricing and risk management of exotic
options, analysis of structured finance instruments, and aggregation of
portfolio risk across risk types. Applications to counterparty credit risk are
emphasized, and they include assessing wrong-way risk in the credit valuation
adjustment, and counterparty credit risk measurement. Lastly a detailed
application of the algorithm for counterparty risk measurement to a real
portfolio case is also presented in this paper.
"
1505.02416	q-fin	q-fin.MF q-fin.PM	"Portfolio optimisation beyond semimartingales: shadow prices and
  fractional Brownian motion"	"  While absence of arbitrage in frictionless financial markets requires price
processes to be semimartingales, non-semimartingales can be used to model
prices in an arbitrage-free way, if proportional transaction costs are taken
into account. In this paper, we show, for a class of price processes which are
not necessarily semimartingales, the existence of an optimal trading strategy
for utility maximisation under transaction costs by establishing the existence
of a so-called shadow price. This is a semimartingale price process, taking
values in the bid ask spread, such that frictionless trading for that price
process leads to the same optimal strategy and utility as the original problem
under transaction costs. Our results combine arguments from convex duality with
the stickiness condition introduced by P. Guasoni. They apply in particular to
exponential utility and geometric fractional Brownian motion. In this case, the
shadow price is an Ito process. As a consequence we obtain a rather surprising
result on the pathwise behaviour of fractional Brownian motion: the
trajectories may touch an Ito process in a one-sided manner without reflection.
"
1505.02644	q-fin	q-fin.GN	"A Profit-maximization Model for a Company that Sells an Arbitrary Number
  of Products"	"  One of the problems faced by a firm that sells certain commodities is to
determine the number of products that it must supply in order to maximize its
profit. In this article, the authors give an answer to this problem of economic
interest. The proposed problem is a generalization of the results obtained by
Stirzaker (Probability and Random Variables: A Beginner's Guide, 1999) and
Kupferman (Lecture Notes in Probability, 2009) where the authors do not present
a situation where the sale of a quantity from some commodities is constrained
by the marketing of another. In addition, the described procedure is simple and
can be successfully applied to any number of commodities. The obtained results
can be easily put into practice.
"
1505.03587	q-fin	q-fin.PR cs.CC cs.FL math.LO	Pricing complexity options	"  We consider options that pay the complexity deficiency of a sequence of up
and down ticks of a stock upon exercise. We study the price of European and
American versions of this option numerically for automatic complexity, and
theoretically for Kolmogorov complexity. We also consider run complexity, which
is a restricted form of automatic complexity.
"
1505.04060	q-fin	q-fin.GN	"Forecasting Financial Extremes: A Network Degree Measure of
  Super-exponential Growth"	"  Investors in stock market are usually greedy during bull markets and scared
during bear markets. The greed or fear spreads across investors quickly. This
is known as the herding effect, and often leads to a fast movement of stock
prices. During such market regimes, stock prices change at a super-exponential
rate and are normally followed by a trend reversal that corrects the previous
over reaction. In this paper, we construct an indicator to measure the
magnitude of the super-exponential growth of stock prices, by measuring the
degree of the price network, generated from the price time series. Twelve major
international stock indices have been investigated. Error diagram tests show
that this new indicator has strong predictive power for financial extremes,
both peaks and troughs. By varying the parameters used to construct the error
diagram, we show the predictive power is very robust. The new indicator has a
better performance than the LPPL pattern recognition indicator.
"
1505.04648	q-fin	q-fin.CP	Chebyshev Interpolation for Parametric Option Pricing	"  Recurrent tasks such as pricing, calibration and risk assessment need to be
executed accurately and in real-time. Simultaneously we observe an increase in
model sophistication on the one hand and growing demands on the quality of risk
management on the other. To address the resulting computational challenges, it
is natural to exploit the recurrent nature of these tasks. We concentrate on
Parametric Option Pricing (POP) and show that polynomial interpolation in the
parameter space promises to reduce run-times while maintaining accuracy. The
attractive properties of Chebyshev interpolation and its tensorized extension
enable us to identify criteria for (sub)exponential convergence and explicit
error bounds. We show that these results apply to a variety of European
(basket) options and affine asset models. Numerical experiments confirm our
findings. Exploring the potential of the method further, we empirically
investigate the efficiency of the Chebyshev method for multivariate and
path-dependent options.
"
1505.05256	q-fin	q-fin.MF	"Small-time asymptotics for Gaussian self-similar stochastic volatility
  models"	"  We consider the class of self-similar Gaussian stochastic volatility models,
and compute the small-time (near-maturity) asymptotics for the corresponding
asset price density, the call and put pricing functions, and the implied
volatilities. Unlike the well-known model-free behavior for extreme-strike
asymptotics, small-time behaviors of the above depend heavily on the model, and
require a control of the asset price density which is uniform with respect to
the asset price variable, in order to translate into results for call prices
and implied volatilities. Away from the money, we express the asymptotics
explicitly using the volatility process' self-similarity parameter $H$, its
first Karhunen-Loeve eigenvalue at time 1, and the latter's multiplicity.
Several model-free estimators for $H$ result. At the money, a separate study is
required: the asymptotics for small time depend instead on the integrated
variance's moments of orders 1/2 and 3/2, and the estimator for $H$ sees an
affine adjustment, while remaining model-free.
"
1505.06053	q-fin	cond-mat.stat-mech q-fin.ST	Record statistics for random walk bridges	"  We investigate the statistics of records in a random sequence
$\{x_B(0)=0,x_B(1),\cdots, x_B(n)=x_B(0)=0\}$ of $n$ time steps. The sequence
$x_B(k)$'s represents the position at step $k$ of a random walk `bridge' of $n$
steps that starts and ends at the origin. At each step, the increment of the
position is a random jump drawn from a specified symmetric distribution. We
study the statistics of records and record ages for such a bridge sequence, for
different jump distributions. In absence of the bridge condition, i.e., for a
free random walk sequence, the statistics of the number and ages of records
exhibits a `strong' universality for all $n$, i.e., they are completely
independent of the jump distribution as long as the distribution is continuous.
We show that the presence of the bridge constraint destroys this strong `all
$n$' universality. Nevertheless a `weaker' universality still remains for large
$n$, where we show that the record statistics depends on the jump distributions
only through a single parameter $0<\mu\le 2$, known as the L\'evy index of the
walk, but are insensitive to the other details of the jump distribution. We
derive the most general results (for arbitrary jump distributions) wherever
possible and also present two exactly solvable cases. We present numerical
simulations that verify our analytical results.
"
1505.07313	q-fin	q-fin.MF math.PR	"Optimal Multiple Stopping with Negative Discount Rate and Random
  Refraction Times under Levy Models"	"  This paper studies a class of optimal multiple stopping problems driven by
L\'evy processes. Our model allows for a negative effective discount rate,
which arises in a number of financial applications, including stock loans and
real options, where the strike price can potentially grow at a higher rate than
the original discount factor. Moreover, successive exercise opportunities are
separated by i.i.d. random refraction times. Under a wide class of two-sided
L\'evy models with a general random refraction time, we rigorously show that
the optimal strategy to exercise successive call options is uniquely
characterized by a sequence of up-crossing times. The corresponding optimal
thresholds are determined explicitly in the single stopping case and
recursively in the multiple stopping case.
"
1505.07484	q-fin	q-fin.RM stat.AP	"Fitting a distribution to Value-at-Risk and Expected Shortfall, with an
  application to covered bonds"	"  Covered bonds are a specific example of senior secured debt. If the issuer of
the bonds defaults the proceeds of the assets in the cover pool are used for
their debt service. If in this situation the cover pool proceeds do not suffice
for the debt service, the creditors of the bonds have recourse to the issuer's
assets and their claims are pari passu with the claims of the creditors of
senior unsecured debt. Historically, covered bonds have been very safe
investments. During their more than two hundred years of existence, investors
never suffered losses due to missed payments from covered bonds. From a risk
management perspective, therefore modelling covered bonds losses is mainly of
interest for estimating the impact that the asset encumbrance by the cover pool
has on the loss characteristics of the issuer's senior unsecured debt. We
explore one-period structural modelling approaches for covered bonds and senior
unsecured debt losses with one and two asset value variables respectively.
Obviously, two-assets models with separate values of the cover pool and the
issuer's remaining portfolio allow for more realistic modelling. However, we
demonstrate that exact calibration of such models may be impossible. We also
investigate a one-asset model in which the riskiness of the cover pool is
reflected by a risk-based adjustment of the encumbrance ratio of the issuer's
assets.
"
1505.07533	q-fin	math.PR math.OC q-fin.MF	Optimal Stopping with Random Maturity under Nonlinear Expectations	"  We analyze an optimal stopping problem with random maturity under a nonlinear
expectation with respect to a weakly compact set of mutually singular
probabilities $\mathcal{P}$. The maturity is specified as the hitting time to
level $0$ of some continuous index process at which the payoff process is even
allowed to have a positive jump. When $\mathcal{P}$ is a collection of
semimartingale measures, the optimal stopping problem can be viewed as a {\it
discretionary} stopping problem for a player who can influence both drift and
volatility of the dynamic of underlying stochastic flow.
"
1505.07705	q-fin	q-fin.MF	"An analytic recursive method for optimal multiple stopping: Canadization
  and phase-type fitting"	"  We study an optimal multiple stopping problem for call-type payoff driven by
a spectrally negative Levy process. The stopping times are separated by
constant refraction times, and the discount rate can be positive or negative.
The computation involves a distribution of the Levy process at a constant
horizon and hence the solutions in general cannot be attained analytically.
Motivated by the maturity randomization (Canadization) technique by Carr
(1998), we approximate the refraction times by independent, identically
distributed Erlang random variables. In addition, fitting random jumps to
phase-type distributions, our method involves repeated integrations with
respect to the resolvent measure written in terms of the scale function of the
underlying Levy process. We derive a recursive algorithm to compute the value
function in closed form, and sequentially determine the optimal exercise
thresholds. A series of numerical examples are provided to compare our analytic
formula to results from Monte Carlo simulation.
"
1506.00082	q-fin	q-fin.MF math.PR	"Weak Convergence of Path-Dependent SDEs in Basket CDS Pricing with
  Contagion Risk"	"  We investigate the computational aspects of the basket CDS pricing with
counterparty risk under a credit contagion model of multinames. This model
enables us to capture the systematic volatility increases in the market
triggered by a particular bankruptcy. The drawback of this problem is its
analytical complication due to its path-dependent functional, which bears a
potential failure in its convergence of numerical approximation under standing
assumptions. In this paper we find sufficient conditions for the desired
convergence of the functionals associated with a class of path-dependent
stochastic differential equations. The main ingredient is to identify the weak
convergence of the approximated solution to the underlying path-dependent
stochastic differential equation.
"
1506.00088	q-fin	math.ST q-fin.ST stat.TH	Semimartingale detection and goodness-of-fit tests	"  In quantitative finance, we often fit a parametric semimartingale model to
asset prices. To ensure our model is correct, we must then perform
goodness-of-fit tests. In this paper, we give a new goodness-of-fit test for
volatility-like processes, which is easily applied to a variety of
semimartingale models. In each case, we reduce the problem to the detection of
a semimartingale observed under noise. In this setting, we then describe a
wavelet-thresholding test, which obtains adaptive and near-optimal detection
rates.
"
1506.00166	q-fin	q-fin.MF math.OC math.PR	Optimal Investment to Minimize the Probability of Drawdown	"  We determine the optimal investment strategy in a Black-Scholes financial
market to minimize the so-called {\it probability of drawdown}, namely, the
probability that the value of an investment portfolio reaches some fixed
proportion of its maximum value to date. We assume that the portfolio is
subject to a payout that is a deterministic function of its value, as might be
the case for an endowment fund paying at a specified rate, for example, at a
constant rate or at a rate that is proportional to the fund's value.
"
1506.00236	q-fin	q-fin.GN physics.soc-ph	"The gradual evolution of buyer--seller networks and their role in
  aggregate fluctuations"	"  Buyer--seller relationships among firms can be regarded as a longitudinal
network in which the connectivity pattern evolves as each firm receives
productivity shocks. Based on a data set describing the evolution of
buyer--seller links among 55,608 firms over a decade and structural equation
modeling, we find some evidence that interfirm networks evolve reflecting a
firm's local decisions to mitigate adverse effects from neighbor firms through
interfirm linkage, while enjoying positive effects from them. As a result, link
renewal tends to have a positive impact on the growth rates of firms. We also
investigate the role of networks in aggregate fluctuations.
"
1506.00937	q-fin	q-fin.RM	Financial Contagion and Asset Liquidation Strategies	"  This paper provides a framework for modeling the financial system with
multiple illiquid assets during a crisis. This work generalizes the paper by
Amini, Filipovic and Minca (2016) by allowing for differing liquidation
strategies. The main result is a proof of sufficient conditions for the
existence of an equilibrium liquidation strategy with corresponding unique
clearing payments and liquidation prices. An algorithm for computing the
maximal clearing payments and prices is provided.
"
1506.01467	q-fin	math.AP math.PR q-fin.PR	A system of non-local parabolic PDE and application to option pricing	"  This paper includes a proof of well-posedness of an initial-boundary value
problem involving a system of degenerate non-local parabolic PDE which
naturally arises in the study of derivative pricing in a generalized market
model. In a semi-Markov modulated GBM model the locally risk minimizing price
function satisfies a special case of this problem. We study the well-posedness
of the problem via a Volterra integral equation of second kind. A probabilistic
approach, in particular the method of conditioning on stopping times is used
for showing uniqueness.
"
1506.01513	q-fin	cs.SI q-fin.TR	Social signals and algorithmic trading of Bitcoin	"  The availability of data on digital traces is growing to unprecedented sizes,
but inferring actionable knowledge from large-scale data is far from being
trivial. This is especially important for computational finance, where digital
traces of human behavior offer a great potential to drive trading strategies.
We contribute to this by providing a consistent approach that integrates
various datasources in the design of algorithmic traders. This allows us to
derive insights into the principles behind the profitability of our trading
strategies. We illustrate our approach through the analysis of Bitcoin, a
cryptocurrency known for its large price fluctuations. In our analysis, we
include economic signals of volume and price of exchange for USD, adoption of
the Bitcoin technology, and transaction volume of Bitcoin. We add social
signals related to information search, word of mouth volume, emotional valence,
and opinion polarization as expressed in tweets related to Bitcoin for more
than 3 years. Our analysis reveals that increases in opinion polarization and
exchange volume precede rising Bitcoin prices, and that emotional valence
precedes opinion polarization and rising exchange volumes. We apply these
insights to design algorithmic trading strategies for Bitcoin, reaching very
high profits in less than a year. We verify this high profitability with robust
statistical methods that take into account risk and trading costs, confirming
the long-standing hypothesis that trading based social media sentiment has the
potential to yield positive returns on investment.
"
1506.01660	q-fin	q-fin.ST cond-mat.stat-mech	"Transition from lognormal to chi-square superstatistics for financial
  time series"	"  Share price returns on different time scales can be well modelled by a
superstatistical dynamics. Here we provide an investigation which type of
superstatistics is most suitable to properly describe share price dynamics on
various time scales. It is shown that while chi-square superstatistics works
well on a time scale of days, on a much smaller time scale of minutes the price
changes are better described by lognormal superstatistics. The system dynamics
thus exhibits a transition from lognormal to chi-square superstatistics as a
function of time scale. We discuss a more general model interpolating between
both statistics which fits the observed data very well. We also present results
on correlation functions of the extracted superstatistical volatility
parameter, which exhibits exponential decay for returns on large time scales,
whereas for returns on small time scales there are long-range correlations and
power-law decay.
"
1506.03106	q-fin	q-fin.EC	"Business cycle synchronization within the European Union: A wavelet
  cohesion approach"	"  In this paper, we map the process of business cycle synchronization across
the European Union. We study this synchronization by applying wavelet
techniques, particularly the cohesion measure with time-varying weights. This
novel approach allows us to study the dynamic relationship among selected
countries from a different perspective than the usual time-domain models.
Analyzing monthly data from 1990 to 2014, we show an increasing co-movement of
the Visegrad countries with the European Union after the countries began
preparing for the accession to the European Union. With particular focus on the
Visegrad countries we show that participation in a currency union possibly
increases the co-movement. Furthermore, we find a high degree of
synchronization in long-term horizons by analyzing the Visegrad Four and
Southern European countries' synchronization with the core countries of the
European Union.
"
1506.03347	q-fin	q-fin.EC	Time-scale analysis of co-movement in EU sovereign bond markets	"  We study the co-movement of the 10-year sovereign bond yields of 11 EU
countries. Our analysis is focused mainly on changes in co-movement during the
financial crisis period, especially around two significant dates - the fall of
Lehman Brothers, September 15, 2008, and the announcement of the increase of
Greece's public deficit on October 20, 2009. We study co-movement dynamics
using wavelet analysis, which allows us to observe how co-movement changes
across frequencies and over time. We divide the countries into three groups:
the core of the Eurozone, the periphery of the Eurozone and the states outside
the Eurozone. The results indicate that co-movement decreased considerably
during the crisis period for all country pairs but that there are significant
differences among the groups. Furthermore, we demonstrate that the co-movement
of bond yields is frequency (scale) dependent.
"
1506.03597	q-fin	q-fin.EC	"How log-normal is your country? An analysis of the statistical
  distribution of the exported volumes of products"	"  We have considered the statistical distributions of the volumes of the
different products exported by 148 countries. We have found that the form of
these distributions is not unique but heavily depends on the level of
development of the nation, as expressed by macroeconomic indicators like GDP,
GDP per capita, total export and a recently introduced measure for countries'
economic complexity called fitness. We have identified three major classes: a)
an incomplete log-normal shape, truncated on the left side, for the less
developed countries, b) a complete log-normal, with a wider range of volumes,
for nations characterized by intermediate economy, and c) a strongly asymmetric
shape for countries with a high degree of development. The ranking curves of
the exported volumes from each country seldom cross each other, showing a clear
hierarchy of export volumes. Finally, the log-normality hypothesis has been
checked for the distributions of all the 148 countries through different tests,
Kolmogorov-Smirnov and Cramer-Von Mises, confirming that it cannot be rejected
only for the countries of intermediate economy.
"
1506.03621	q-fin	q-fin.PR math.PR math.ST stat.TH	Convergence of Estimated Option Price in a Regime switching Market	"  In an observed generalized semi-Markov regime, estimation of transition rate
of regime switching leads towards calculation of locally risk minimizing option
price. Despite the uniform convergence of estimated step function of transition
rate, to meet the existence of classical solution of the modified price
equation, the estimator is approximated in the class of smooth functions and
furthermore, the convergence is established. Later, the existence of the
solution of the modified price equation is verified and the point-wise
convergence of such approximation of option price is proved to answer the
tractability of its application in Finance. To demonstrate the consistency in
result a numerical experiment has been reported.
"
1506.04063	q-fin	math.PR math.OC q-fin.MF	Optimal Skorokhod embedding under finitely-many marginal constraints	"  The Skorokhod embedding problem aims to represent a given probability measure
on the real line as the distribution of Brownian motion stopped at a chosen
stopping time. In this paper, we consider an extension of the optimal Skorokhod
embedding problem to the case of finitely-many marginal constraints. Using the
classical convex duality approach together with the optimal stopping theory, we
obtain the duality results which are formulated by means of probability
measures on an enlarged space. We also relate these results to the problem of
martingale optimal transport under multiple marginal constraints.
"
1506.06069	q-fin	q-fin.EC	Resolute refinements of social choice correspondences	"  Many classical social choice correspondences are resolute only in the case of
two alternatives and an odd number of individuals. Thus, in most cases, they
admit several resolute refinements, each of them naturally interpreted as a
tie-breaking rule, satisfying different properties. In this paper we look for
classes of social choice correspondences which admit resolute refinements
fulfilling suitable versions of anonymity and neutrality. In particular,
supposing that individuals and alternatives have been exogenously partitioned
into subcommittees and subclasses, we find out arithmetical conditions on the
sizes of subcommittees and subclasses that are necessary and sufficient for
making any social choice correspondence which is efficient, anonymous with
respect to subcommittees, neutral with respect to subclasses and possibly
immune to the reversal bias admit a resolute refinement sharing the same
properties.
"
1506.06608	q-fin	q-fin.MF	Model-free Superhedging Duality	"  In a model free discrete time financial market, we prove the superhedging
duality theorem, where trading is allowed with dynamic and semi-static
strategies. We also show that the initial cost of the cheapest portfolio that
dominates a contingent claim on every possible path $\omega \in \Omega$, might
be strictly greater than the upper bound of the no-arbitrage prices. We
therefore characterize the subset of trajectories on which this duality gap
disappears and prove that it is an analytic set.
"
1506.06669	q-fin	q-fin.EC stat.AP	"Understanding the Impact of Microcredit Expansions: A Bayesian
  Hierarchical Analysis of 7 Randomised Experiments"	"  Bayesian hierarchical models are a methodology for aggregation and synthesis
of data from heterogeneous settings, used widely in statistics and other
disciplines. I apply this framework to the evidence from 7 randomized
experiments of expanding access to microcredit to assess the general impact of
the intervention on household outcomes and the heterogeneity in this impact
across sites. The results suggest that the effect of microcredit is likely to
be positive but small relative to control group average levels, and the
possibility of a negative impact cannot be ruled out. By contrast, common
meta-analytic methods that pool all the data without assessing the
heterogeneity misleadingly produce ""statistically significant"" results in 2 of
the 6 household outcomes. Standard pooling metrics for the studies indicate on
average 60% pooling on the treatment effects, suggesting that the site-specific
effects are reasonably externally valid, and thus informative for each other
and for the general case. The cross-study heterogeneity is almost entirely
generated by heterogeneous effects for the 27% households who previously
operated businesses before microcredit expansion, although this group is likely
to see much larger impacts overall. A Ridge regression procedure to assess the
correlations between site-specific covariates and treatment effects indicates
that the remaining heterogeneity is strongly correlated with differences in
economic variables, but not with differences in study design protocols. The
average interest rate and the average loan size have the strongest correlation
with the treatment effects, and both are negative.
"
1506.06997	q-fin	q-fin.CP	"Nonparametric and arbitrage-free construction of call surfaces using
  l1-recovery"	"  This paper is devoted to the application of an $l_1$ -minimisation technique
to construct an arbitrage-free call-option surface. We propose a
nononparametric approach to obtaining model-free call option surfaces that are
perfectly consistent with market quotes and free of static arbitrage. The
approach is inspired from the compressed-sensing framework that is used in
signal processing to deal with under-sampled signals. We address the problem of
fitting the call-option surface to sparse option data. To illustrate the
methodology, we proceed to the construction of the whole call-price surface of
the S\&P500 options, taking into account the arbitrage possibilities in the
time direction. The resulting object is a surface free of both butterfly and
calendar-spread arbitrage that matches the original market points. We then move
on to an FX application, namely the HKD/USD call-option surface.
"
1506.07432	q-fin	physics.soc-ph q-fin.EC	"Modelling complex systems of heterogeneous agents to better design
  sustainability transitions policy"	"  This article proposes a fundamental methodological shift in the modelling of
policy interventions for sustainability transitions in order to account for
complexity (e.g. self-reinforcing mechanism arising from multi-agent
interactions) and agent heterogeneity (e.g. differences in consumer and
investment behaviour). We first characterise the uncertainty faced by climate
policy-makers and its implications for investment decision-makers. We then
identify five shortcomings in the equilibrium and optimisation-based approaches
most frequently used to inform sustainability policy: (i) their normative,
optimisation-based nature, (ii) their unrealistic reliance on the
full-rationality of agents, (iii) their inability to account for mutual
influences among agents and capture related self-reinforcing (positive
feedback) processes, (iv) their inability to represent multiple solutions and
path-dependency, and (v) their inability to properly account for agent
heterogeneity. The aim of this article is to introduce an alternative modelling
approach based on complexity dynamics and agent heterogeneity, and explore its
use in four key areas of sustainability policy, namely (1) technology adoption
and diffusion, (2) macroeconomic impacts of low-carbon policies, (3)
interactions between the socio-economic system and the natural environment, and
(4) the anticipation of policy outcomes. The practical relevance of the
proposed methodology is discussed by reference to four applications: the
diffusion of transport technology, the impact of low-carbon investment on
income and employment, the management of cascading uncertainties, and the
cross-sectoral impact of biofuels policies. The article calls for a fundamental
methodological shift aligning the modelling of the socio-economic system with
that of the climatic system, for a combined and realistic understanding of the
impact of sustainability policies.
"
1506.07554	q-fin	q-fin.CP	Double-jump stochastic volatility model for VIX: evidence from VVIX	"  The paper studies the continuous-time dynamics of VIX with stochastic
volatility and jumps in VIX and volatility. Built on the general parametric
affine model with stochastic volatility and jump in logarithm of VIX, we derive
a linear relation between the stochastic volatility factor and VVIX index. We
detect the existence of co-jump of VIX and VVIX and put forward a double-jump
stochastic volatility model for VIX through its joint property with VVIX. With
VVIX index as a proxy for the stochastic volatility, we use MCMC method to
estimate the dynamics of VIX. Comparing nested models on VIX, we show the jump
in VIX and the volatility factor is statistically significant. The jump
intensity is also statedependent. We analyze the impact of jump factor on the
VIX dynamics.
"
1506.08127	q-fin	q-fin.MF math.PR	"Martingale property of exponential semimartingales: a note on explicit
  conditions and applications to financial models"	"  We give a collection of explicit sufficient conditions for the true
martingale property of a wide class of exponentials of semimartingales. We
express the conditions in terms of semimartingale characteristics. This turns
out to be very convenient in financial modeling in general. Especially it
allows us to carefully discuss the question of well-definedness of
semimartingale Libor models, whose construction crucially relies on a sequence
of measure changes.
"
1506.08408	q-fin	q-fin.MF math.PR	On magnitude, asymptotics and duration of drawdowns for L\'{e}vy models	"  This paper considers magnitude, asymptotics and duration of drawdowns for
some L\'{e}vy processes. First, we revisit some existing results on the
magnitude of drawdowns for spectrally negative L\'{e}vy processes using an
approximation approach. For any spectrally negative L\'{e}vy process whose
scale functions are well-behaved at $0+$, we then study the asymptotics of
drawdown quantities when the threshold of drawdown magnitude approaches zero.
We also show that such asymptotics is robust to perturbations of additional
positive compound Poisson jumps. Finally, thanks to the asymptotic results and
some recent works on the running maximum of L\'{e}vy processes, we derive the
law of duration of drawdowns for a large class of L\'{e}vy processes (with a
general spectrally negative part plus a positive compound Poisson structure).
The duration of drawdowns is also known as the ""Time to Recover"" (TTR) the
historical maximum, which is a widely used performance measure in the fund
management industry. We find that the law of duration of drawdowns
qualitatively depends on the path type of the spectrally negative component of
the underlying L\'{e}vy process.
"
1506.09184	q-fin	math.PR math.OC q-fin.MF	On the Robust Dynkin Game	"  We study a robust Dynkin game over a set of mutually singular probabilities.
We first prove that for the conservative player of the game, her lower and
upper value processes coincide (i.e. She has a value process $V $ in the game).
Such a result helps people connect the robust Dynkin game with second-order
doubly reflected backward stochastic differential equations. Also, we show that
the value process $V$ is a submartingale under an appropriately defined
nonlinear expectations up to the first time $\tau_*$ when $V$ meets the lower
payoff process $L$. If the probability set is weakly compact, one can even find
an optimal triplet. The mutual singularity of probabilities in causes major
technical difficulties. To deal with them, we use some new methods including
two approximations with respect to the set of stopping times. The mutual
singularity of probabilities causes major technical difficulties. To deal with
them, we use some new methods including two approximations with respect to the
set of stopping times
"
1507.00208	q-fin	q-fin.PR q-fin.MF	"The Long-Term Swap Rate and a General Analysis of Long-Term Interest
  Rates"	"  We introduce here for the first time the long-term swap rate, characterised
as the fair rate of an overnight indexed swap with infinitely many exchanges.
Furthermore we analyse the relationship between the long-term swap rate, the
long-term yield, see [4], [5], and [25], and the long-term simple rate,
considered in [8] as long-term discounting rate. We finally investigate the
existence of these long-term rates in two term structure methodologies, the
Flesaker-Hughston model and the linear-rational model.
"
1507.00244	q-fin	q-fin.RM q-fin.ST	"Expected Shortfall is jointly elicitable with Value at Risk -
  Implications for backtesting"	"  In this note, we comment on the relevance of elicitability for backtesting
risk measure estimates. In particular, we propose the use of Diebold-Mariano
tests, and show how they can be implemented for Expected Shortfall (ES), based
on the recent result of Fissler and Ziegel (2015) that ES is jointly elicitable
with Value at Risk.
"
1507.00671	q-fin	math.PR math.OC q-fin.MF	Complete Duality for Martingale Optimal Transport on the Line	"  We study the optimal transport between two probability measures on the real
line, where the transport plans are laws of one-step martingales. A quasi-sure
formulation of the dual problem is introduced and shown to yield a complete
duality theory for general marginals and measurable reward (cost) functions:
absence of a duality gap and existence of dual optimizers. Both properties are
shown to fail in the classical formulation. As a consequence of the duality
result, we obtain a general principle of cyclical monotonicity describing the
geometry of optimal transports.
"
1507.00894	q-fin	q-fin.EC	Inequality and risk aversion in economies open to altruistic attitudes	"  This paper attempts to find a relationship between agents' risk aversion and
inequality of incomes. Specifically, a model is proposed for the evolution in
time of surplus/deficit distribution, and the long-time distributions are
characterized almost completely. They turn out to be weak Pareto laws with
exponent linked to the relative risk aversion index which, in turn, is supposed
to be the same for every agent. On the one hand, the aforesaid link is
expressed by an affine transformation. On the other hand, the level of the
relative risk aversion index results from a frequency distribution of
observable quantities stemming from how agents interact in an economic sense.
Combination of these facts is conducive to the specification of qualitative and
quantitative characteristics of actions fit for the control of income
concentration.
"
1507.01033	q-fin	q-fin.ST	"Estimation of integrated quadratic covariation with endogenous sampling
  times"	"  When estimating high-frequency covariance (quadratic covariation) of two
arbitrary assets observed asynchronously, simple assumptions, such as
independence, are usually imposed on the relationship between the prices
process and the observation times. In this paper, we introduce a general
endogenous two-dimensional nonparametric model. Because an observation is
generated whenever an auxiliary process called observation time process hits
one of the two boundary processes, it is called the hitting boundary process
with time process (HBT) model. We establish a central limit theorem for the
Hayashi-Yoshida (HY) estimator under HBT in the case where the price process
and the observation price process follow a continuous Ito process. We obtain an
asymptotic bias. We provide an estimator of the latter as well as a
bias-corrected HY estimator of the high-frequency covariance. In addition, we
give a consistent estimator of the associated standard error.
"
1507.01125	q-fin	math.PR math.OC q-fin.PR	Tightness and duality of martingale transport on the Skorokhod space	"  The martingale optimal transport aims to optimally transfer a probability
measure to another along the class of martingales. This problem is mainly
motivated by the robust superhedging of exotic derivatives in financial
mathematics, which turns out to be the corresponding Kantorovich dual. In this
paper we consider the continuous-time martingale transport on the Skorokhod
space of cadlag paths. Similar to the classical setting of optimal transport,
we introduce different dual problems and establish the corresponding dualities
by a crucial use of the S-topology and the dynamic programming principle.
"
1507.01847	q-fin	q-fin.RM	"The Effects of Leverage Requirements and Fire Sales on Financial
  Contagion via Asset Liquidation Strategies in Financial Networks"	"  This paper provides a framework for modeling the financial system with
multiple illiquid assets when liquidation of illiquid assets is caused by
failure to meet a leverage requirement. This extends the network model of
Cifuentes, Shin & Ferrucci (2005) which incorporates a single asset with fire
sales and capital adequacy ratio. This also extends the network model of
Feinstein (2015) which incorporates multiple illiquid assets with fire sales
and no leverage ratios. We prove existence of equilibrium clearing payments and
liquidation prices for a known liquidation strategy when leverage requirements
are required. We also prove sufficient conditions for the existence of an
equilibrium liquidation strategy with corresponding clearing payments and
liquidation prices. Finally we calibrate network models to asset and liability
data for 50 banks in the United States from 2007-2014 in order to draw
conclusions on systemic risk as a function of leverage requirements.
"
1507.02025	q-fin	q-fin.EC q-fin.MF q-fin.PM q-fin.RM	Diversification Preferences in the Theory of Choice	"  Diversification represents the idea of choosing variety over uniformity.
Within the theory of choice, desirability of diversification is axiomatized as
preference for a convex combination of choices that are equivalently ranked.
This corresponds to the notion of risk aversion when one assumes the
von-Neumann-Morgenstern expected utility model, but the equivalence fails to
hold in other models. This paper studies axiomatizations of the concept of
diversification and their relationship to the related notions of risk aversion
and convex preferences within different choice theoretic models. Implications
of these notions on portfolio choice are discussed. We cover model-independent
diversification preferences, preferences within models of choice under risk,
including expected utility theory and the more general rank-dependent expected
utility theory, as well as models of choice under uncertainty axiomatized via
Choquet expected utility theory. Remarks on interpretations of diversification
preferences within models of behavioral choice are given in the conclusion.
"
1507.02651	q-fin	q-fin.PR math.OC math.PR	"Model-independent bounds for Asian options: a dynamic programming
  approach"	"  We consider the problem of finding model-independent bounds on the price of
an Asian option, when the call prices at the maturity date of the option are
known. Our methods differ from most approaches to model-independent pricing in
that we consider the problem as a dynamic programming problem, where the
controlled process is the conditional distribution of the asset at the maturity
date. By formulating the problem in this manner, we are able to determine the
model-independent price through a PDE formulation. Notably, this approach does
not require specific constraints on the payoff function (e.g. convexity), and
would appear to generalise to many related problems.
"
1507.02847	q-fin	q-fin.CP q-fin.PR	"Switching to non-affine stochastic volatility: A closed-form expansion
  for the Inverse Gamma model"	"  This paper introduces the Inverse Gamma (IGa) stochastic volatility model
with time-dependent parameters, defined by the volatility dynamics
$dV_{t}=\kappa_{t}\left(\theta_{t}-V_{t}\right)dt+\lambda_{t}V_{t}dB_{t}$. This
non-affine model is much more realistic than classical affine models like the
Heston stochastic volatility model, even though both are as parsimonious (only
four stochastic parameters). Indeed, it provides more realistic volatility
distribution and volatility paths, which translate in practice into more robust
calibration and better hedging accuracy, explaining its popularity among
practitioners. In order to price vanilla options with IGa volatility, we
propose a closed-form volatility-of-volatility expansion. Specifically, the
price of a European put option with IGa volatility is approximated by a
Black-Scholes price plus a weighted combination of Black-Scholes greeks, where
the weights depend only on the four time-dependent parameters of the model.
This closed-form pricing method allows for very fast pricing and calibration to
market data. The overall quality of the approximation is very good, as shown by
several calibration tests on real-world market data where expansion prices are
compared favorably with Monte Carlo simulation results. This paper shows that
the IGa model is as simple, more realistic, easier to implement and faster to
calibrate than classical transform-based affine models. We therefore hope that
the present work will foster further research on non-affine models like the
Inverse Gamma stochastic volatility model, all the more so as this robust model
is of great interest to the industry.
"
1507.03141	q-fin	q-fin.ST	Bifurcation patterns of market regime transition	"  In this paper mechanisms of reversion - momentum transition are considered.
Two basic nonlinear mechanisms are highlighted: a slow and fast bifurcation. A
slow bifurcation leads to the equilibrium evolution, preceded by stability loss
delay of a control parameter. A single order parameter is introduced by
Markovian chain diffusion, which plays a role of a precursor. A fast
bifurcation is formed by a singular fusion of unstable and stable equilibrium
states. The effect of a precatastrophic range compression is observed before
the discrete change of a system. A diffusion time scaling is presented as a
precursor of the fast bifurcation. The efficiency of both precursors in a
currency market was illustrated by simulation of a prototype of a trading
system.
"
1507.04065	q-fin	q-fin.EC cs.GT cs.SI physics.soc-ph	Reputational Learning and Network Dynamics	"  In many real world networks agents are initially unsure of each other's
qualities and must learn about each other over time via repeated interactions.
This paper is the first to provide a methodology for studying the dynamics of
such networks, taking into account that agents differ from each other, that
they begin with incomplete information, and that they must learn through past
experiences which connections/links to form and which to break. The network
dynamics in our model vary drastically from the dynamics in models of complete
information. With incomplete information and learning, agents who provide high
benefits will develop high reputations and remain in the network, while agents
who provide low benefits will drop in reputation and become ostracized. We
show, among many other things, that the information to which agents have access
and the speed at which they learn and act can have a tremendous impact on the
resulting network dynamics. Using our model, we can also compute the ex ante
social welfare given an arbitrary initial network, which allows us to
characterize the socially optimal network structures for different sets of
agents. Importantly, we show through examples that the optimal network
structure depends sharply on both the initial beliefs of the agents, as well as
the rate of learning by the agents. Due to the potential negative consequences
of ostracism, it may be necessary to place agents with lower initial
reputations at less central positions within the network.
"
1507.04167	q-fin	q-fin.EC	"Axiomatization of the Choquet integral for 2-dimensional heterogeneous
  product sets"	"  We prove a representation theorem for the Choquet integral model. The
preference relation is defined on a two-dimensional heterogeneous product set
$X = X_1 \times X_2$ where elements of $X_1$ and $X_2$ are not necessarily
comparable with each other. However, making such comparisons in a meaningful
way is necessary for the construction of the Choquet integral (and any
rank-dependent model). We construct the representation, study its uniqueness
properties, and look at applications in multicriteria decision analysis,
state-dependent utility theory, and social choice. Previous axiomatizations of
this model, developed for decision making under uncertainty, relied heavily on
the notion of comonotocity and that of a ""constant act"". However, that requires
$X$ to have a special structure, namely, all factors of this set must be
identical. Our characterization does not assume commensurateness of criteria a
priori, so defining comonotonicity becomes impossible.
"
1507.04387	q-fin	q-fin.PR math.OC	One bank problem in the federal funds market	"  The model of this paper gives a convenient strategy that a bank in the
federal funds market can use in order to maximize its profit in a
contemporaneous reserve requirement (CRR) regime. The reserve requirements are
determined by the demand deposit process, modelled as a Brownian motion with
drift. We propose a new model in which the cumulative funds purchases and sales
are discounted at possible different rates. We formulate and solve the problem
of finding the bank's optimal strategy. The model can be extended to involve
the bank's asset size and we obtain that, under some conditions, the optimal
upper barrier for fund sales is a linear function of the asset size. As a
consequence, the bank net purchase amount is linear in the asset size.
"
1507.04848	q-fin	q-fin.GN physics.soc-ph	"Violation of Invariance of Measurement for GDP Growth Rate and its
  Consequences"	"  The aim here is to address the origins of sustainability for the real growth
rate in the United States. For over a century of observations on the real GDP
per capita of the United States a sustainable two percent growth rate has been
observed. To find an explanation for this observation I consider the impact of
utility preferences and the effect of mobility of labor \& capital on every
provided measurement. Mobility of labor results in heterogenous rates of
increase in prices which is called Baumol's cost disease phenomenon.
Heterogeneous rates of inflation then make it impossible to define an invariant
measure for the real growth rate. Paradoxical and ambiguous results already
have been observed when different measurements provided by the World Bank have
been compared with the ones from the systems of national accounts (SNA). Such
ambiguity is currently being discussed in economy. I define a toy model for
caring out measurements in order to state that this ambiguity can be very
significant. I provide examples in which GDP expands 5 folds while measurements
percept an expansion around 2 folds. Violation of invariance of the
measurements leads to state that it is hard to compare the growth rate of GDP
for a smooth growing country such as the U.S. with a fast growing country such
as China. Besides, I state that to extrapolate the time that economy of China
passes the economy of the US we need to consider local metric of the central
banks of both countries. Finally I conclude that it is our method of
measurements that leads us to percept the sustainable growth rate.
"
1507.05203	q-fin	q-fin.GN q-fin.ST	"Stochastic model of financial markets reproducing scaling and memory in
  volatility return intervals"	"  We investigate the volatility return intervals in the NYSE and FOREX markets.
We explain previous empirical findings using a model based on the interacting
agent hypothesis instead of the widely-used efficient market hypothesis. We
derive macroscopic equations based on the microscopic herding interactions of
agents and find that they are able to reproduce various stylized facts of
different markets and different assets with the same set of model parameters.
We show that the power-law properties and the scaling of return intervals and
other financial variables have a similar origin and could be a result of a
general class of non-linear stochastic differential equations derived from a
master equation of an agent system that is coupled by herding interactions.
Specifically, we find that this approach enables us to recover the volatility
return interval statistics as well as volatility probability and spectral
densities for the NYSE and FOREX markets, for different assets, and for
different time-scales. We find also that the historical S\&P500 monthly series
exhibits the same volatility return interval properties recovered by our
proposed model. Our statistical results suggest that human herding is so strong
that it persists even when other evolving fluctuations perturbate the financial
system.
"
1507.08713	q-fin	q-fin.PM math.OC math.PR	"Minimizing the Probability of Lifetime Drawdown under Constant
  Consumption"	"  We assume that an individual invests in a financial market with one riskless
and one risky asset, with the latter's price following geometric Brownian
motion as in the Black-Scholes model. Under a constant rate of consumption, we
find the optimal investment strategy for the individual who wishes to minimize
the probability that her wealth drops below some fixed proportion of her
maximum wealth to date, the so-called probability of {\it lifetime drawdown}.
If maximum wealth is less than a particular value, $m^*$, then the individual
optimally invests in such a way that maximum wealth never increases above its
current value. By contrast, if maximum wealth is greater than $m^*$ but less
than the safe level, then the individual optimally allows the maximum to
increase to the safe level.
"
1508.00607	q-fin	q-fin.EC	Existence of continuous euclidean embeddings for a weak class of orders	"  We prove that if $X$ is a topological space that admits Debreu's classical
utility theorem (eg.\ $X$ is separable and connected, second countable, etc.),
then order relations on $X$ satisfying milder completeness conditions can be
continuously embedded in $\mathbb R^I$ for $I$ some index set. In the
particular case where $X$ is a compact metric space, this closes a conjecture
of Nishimura \& Ok (2015). We also show that when $\mathbb R^I$ is given a
non-standard partial order coinciding with Pareto improvement, the analogous
embedding theorem fails to hold in the continuous case.
"
1508.02473	q-fin	math.ST q-fin.EC stat.ML stat.TH	Bridging AIC and BIC: a new criterion for autoregression	"  We introduce a new criterion to determine the order of an autoregressive
model fitted to time series data. It has the benefits of the two well-known
model selection techniques, the Akaike information criterion and the Bayesian
information criterion. When the data is generated from a finite order
autoregression, the Bayesian information criterion is known to be consistent,
and so is the new criterion. When the true order is infinity or suitably high
with respect to the sample size, the Akaike information criterion is known to
be efficient in the sense that its prediction performance is asymptotically
equivalent to the best offered by the candidate models; in this case, the new
criterion behaves in a similar manner. Different from the two classical
criteria, the proposed criterion adaptively achieves either consistency or
efficiency depending on the underlying true model. In practice where the
observed time series is given without any prior information about the model
specification, the proposed order selection criterion is more flexible and
robust compared with classical approaches. Numerical results are presented
demonstrating the adaptivity of the proposed technique when applied to various
datasets.
"
1508.02824	q-fin	q-fin.RM stat.AP	"Asyptotic Normality for Maximum Likelihood Estimation and Operational
  Risk"	"  Operational risk models commonly employ maximum likelihood estimation (MLE)
to fit loss data to heavy-tailed distributions. Yet several desirable
properties of MLE (e.g. asymptotic normality) are generally valid only for
large sample-sizes, a situation rarely encountered in operational risk. In this
paper, we study how asymptotic normality does--or does not--hold for common
severity distributions in operational risk models. We then apply these results
to evaluate errors caused by failure of asymptotic normality in constructing
confidence intervals around the MLE fitted parameters.
"
1508.02919	q-fin	q-fin.MF q-fin.EC q-fin.RM	Identification of Insurance Models with Multidimensional Screening	"  This paper addresses the identification of insurance models with
multidimensional screening where insurees have private information about their
risk and risk aversion. The model includes a random damage and the possibility
of several claims. Screening of insurees relies on their certainty equivalence.
The paper then investigates how data availability on the number of offered
coverages and reported claims affects the identification of the model
primitives under four different scenarios. We show that the model structure is
identified despite bunching due to multidimensional screening and/or a finite
number of offered coverages. The observed number of claims plays a key role in
the identification of the joint distribution of risk and risk aversion. In
addition, the paper derives all the restrictions imposed by the model on
observables. Our results are constructive with explicit equations for
estimation and model testing.
"
1508.03373	q-fin	math.PR math.OC q-bio.NC q-fin.MF	"A martingale analysis of first passage times of time-dependent Wiener
  diffusion models"	"  Research in psychology and neuroscience has successfully modeled decision
making as a process of noisy evidence accumulation to a decision bound. While
there are several variants and implementations of this idea, the majority of
these models make use of a noisy accumulation between two absorbing boundaries.
A common assumption of these models is that decision parameters, e.g., the rate
of accumulation (drift rate), remain fixed over the course of a decision,
allowing the derivation of analytic formulas for the probabilities of hitting
the upper or lower decision threshold, and the mean decision time. There is
reason to believe, however, that many types of behavior would be better
described by a model in which the parameters were allowed to vary over the
course of the decision process.
  In this paper, we use martingale theory to derive formulas for the mean
decision time, hitting probabilities, and first passage time (FPT) densities of
a Wiener process with time-varying drift between two time-varying absorbing
boundaries. This model was first studied by Ratcliff (1980) in the two-stage
form, and here we consider the same model for an arbitrary number of stages
(i.e. intervals of time during which parameters are constant). Our calculations
enable direct computation of mean decision times and hitting probabilities for
the associated multistage process. We also provide a review of how martingale
theory may be used to analyze similar models employing Wiener processes by
re-deriving some classical results. In concert with a variety of numerical
tools already available, the current derivations should encourage mathematical
analysis of more complex models of decision making with time-varying evidence.
"
1508.03533	q-fin	physics.soc-ph q-fin.GN	Detecting early signs of the 2007-2008 crisis in the world trade	"  Since 2007, several contributions have tried to identify early-warning
signals of the financial crisis. However, the vast majority of analyses has
focused on financial systems and little theoretical work has been done on the
economic counterpart. In the present paper we fill this gap and employ the
theoretical tools of network theory to shed light on the response of world
trade to the financial crisis of 2007 and the economic recession of 2008-2009.
We have explored the evolution of the bipartite World Trade Web (WTW) across
the years 1995-2010, monitoring the behavior of the system both before and
after 2007. Our analysis shows early structural changes in the WTW topology:
since 2003, the WTW becomes increasingly compatible with the picture of a
network where correlations between countries and products are progressively
lost. Moreover, the WTW structural modification can be considered as concluded
in 2010, after a seemingly stationary phase of three years. We have also
refined our analysis by considering specific subsets of countries and products:
the most statistically significant early-warning signals are provided by the
most volatile macrosectors, especially when measured on developing countries,
suggesting the emerging economies as being the most sensitive ones to the
global economic cycles.
"
1508.03924	q-fin	q-fin.EC	Optimal Taxation with Endogenous Default under Incomplete Markets	"  In a dynamic economy, we characterize the fiscal policy of the government
when it levies distortionary taxes and issues defaultable bonds to finance its
stochastic expenditure. Default may occur in equilibrium as it prevents the
government from incurring in future tax distortions that would come along with
the service of the debt. Households anticipate the possibility of default
generating endogenous credit limits. These limits hinder the government's
ability to smooth taxes using debt, implying more volatile and less serially
correlated fiscal policies, higher borrowing costs and lower levels of
indebtedness. In order to exit temporary financial autarky following a default
event, the government has to repay a random fraction of the defaulted debt. We
show that the optimal fiscal and renegotiation policies have implications
aligned with the data.
"
1508.04332	q-fin	q-fin.GN physics.soc-ph	Forecasting stock market returns over multiple time horizons	"  In this paper we seek to demonstrate the predictability of stock market
returns and explain the nature of this return predictability. To this end, we
introduce investors with different investment horizons into the news-driven,
analytic, agent-based market model developed in Gusev et al. (2015). This
heterogeneous framework enables us to capture dynamics at multiple timescales,
expanding the model's applications and improving precision. We study the
heterogeneous model theoretically and empirically to highlight essential
mechanisms underlying certain market behaviors, such as transitions between
bull- and bear markets and the self-similar behavior of price changes. Most
importantly, we apply this model to show that the stock market is nearly
efficient on intraday timescales, adjusting quickly to incoming news, but
becomes inefficient on longer timescales, where news may have a long-lasting
nonlinear impact on dynamics, attributable to a feedback mechanism acting over
these horizons. Then, using the model, we design algorithmic strategies that
utilize news flow, quantified and measured, as the only input to trade on
market return forecasts over multiple horizons, from days to months. The
backtested results suggest that the return is predictable to the extent that
successful trading strategies can be constructed to harness this
predictability.
"
1508.04512	q-fin	q-fin.ST q-fin.CP	LIBOR troubles: anomalous movements detection based on Maximum Entropy	"  According to the definition of the London Interbank Offered Rate (LIBOR),
contributing banks should give fair estimates of their own borrowing costs in
the interbank market. Between 2007 and 2009, several banks made inappropriate
submissions of LIBOR, sometimes motivated by profit-seeking from their trading
positions. In 2012, several newspapers' articles began to cast doubt on LIBOR
integrity, leading surveillance authorities to conduct investigations on banks'
behavior. Such procedures resulted in severe fines imposed to involved banks,
who recognized their financial inappropriate conduct. In this paper, we uncover
such unfair behavior by using a forecasting method based on the Maximum Entropy
principle. Our results are robust against changes in parameter settings and
could be of great help for market surveillance.
"
1508.04754	q-fin	q-fin.ST	"Currency target zone modeling: An interplay between physics and
  economics"	"  We study the performance of the euro/Swiss franc exchange rate in the
extraordinary period from September 6, 2011 and January 15, 2015 when the Swiss
National Bank enforced a minimum exchange rate of 1.20 Swiss francs per euro.
Based on the analogy between Brownian motion in finance and physics, the
first-order effect of such a steric constraint would enter a priori in the form
of a repulsive entropic force associated with the paths crossing the barrier
that are forbidden. Non-parametric empirical estimates of drift and volatility
show that the predicted first-order analogy between economics and physics are
incorrect. The clue is to realise that the random walk nature of financial
prices results from the continuous anticipations of traders about future
opportunities, whose aggregate actions translate into an approximate efficient
market with almost no arbitrage opportunities. With the Swiss National Bank
stated commitment to enforce the barrier, traders's anticipation of this action
leads to a vanishing drift together with a volatility of the exchange rate that
depends on the distance to the barrier. We give direct quantitative empirical
evidence that this effect is well described by Krugman's target zone model
[P.R. Krugman. The Quarterly Journal of Economics, 106(3):669-682, 1991].
Motivated by the insights from this economical model, we revise the initial
economics-physics analogy and show that, within the context of hindered
diffusion, the two systems can be described with the same mathematics after
all. Using a recently proposed extended analogy in terms of a colloidal
Brownian particle embedded in a fluid of molecules associated with the
underlying order book, we derive that, close to the restricting boundary, the
dynamics of both systems is described by a stochastic differential equation
with a very small constant drift and a linear diffusion coefficient.
"
1508.04883	q-fin	q-fin.PM q-fin.RM	Heterotic Risk Models	"  We give a complete algorithm and source code for constructing what we refer
to as heterotic risk models (for equities), which combine: i) granularity of an
industry classification; ii) diagonality of the principal component factor
covariance matrix for any sub-cluster of stocks; and iii) dramatic reduction of
the factor covariance matrix size in the Russian-doll risk model construction.
This appears to prove a powerful approach for constructing out-of-sample stable
short-lookback risk models. Thus, for intraday mean-reversion alphas based on
overnight returns, Sharpe ratio optimization using our heterotic risk models
sizably improves the performance characteristics compared to weighted
regressions based on principal components or industry classification. We also
give source code for: a) building statistical risk models; and ii) Sharpe ratio
optimization with homogeneous linear constraints and position bounds.
"
1508.05233	q-fin	q-fin.MF math.OC math.PR	Super-replication in Fully Incomplete Markets	"  In this work we introduce the notion of fully incomplete markets. We prove
that for these markets the super-replication price coincide with the model free
super-replication price. Namely, the knowledge of the model does not reduce the
super-replication price. We provide two families of fully incomplete models:
stochastic volatility models and rough volatility models. Moreover, we give
several computational examples. Our approach is purely probabilistic.
"
1508.06117	q-fin	q-fin.CP	Bermudan options by simulation	"  The aim of this study is to devise numerical methods for dealing with very
high-dimensional Bermudan-style derivatives. For such problems, we quickly see
that we can at best hope for price bounds, and we can only use a simulation
approach. We use the approach of Barraquand & Martineau which proposes that the
reward process should be treated as if it were Markovian, and then uses this to
generate a stopping rule and hence a lower bound on the price. Using the dual
approach introduced by Rogers, and Haugh & Kogan, this approximate Markov
process leads us to hedging strategies, and upper bounds on the price. The
methodology is generic, and is illustrated on eight examples of varying levels
of difficulty. Run times are largely insensitive to dimension.
"
1508.06182	q-fin	q-fin.CP cs.DS math.OC q-fin.PM quant-ph	Solving the Optimal Trading Trajectory Problem Using a Quantum Annealer	"  We solve a multi-period portfolio optimization problem using D-Wave Systems'
quantum annealer. We derive a formulation of the problem, discuss several
possible integer encoding schemes, and present numerical examples that show
high success rates. The formulation incorporates transaction costs (including
permanent and temporary market impact), and, significantly, the solution does
not require the inversion of a covariance matrix. The discrete multi-period
portfolio optimization problem we solve is significantly harder than the
continuous variable problem. We present insight into how results may be
improved using suitable software enhancements, and why current quantum
annealing technology limits the size of problem that can be successfully solved
today. The formulation presented is specifically designed to be scalable, with
the expectation that as quantum annealing technology improves, larger problems
will be solvable using the same techniques.
"
1508.06236	q-fin	q-fin.CP q-fin.MF	A computational spectral approach to interest rate models	"  The Polynomial Chaos Expansion (PCE) technique recovers a finite second order
random variable exploiting suitable linear combinations of orthogonal
polynomials which are functions of a given stochas- tic quantity {\xi}, hence
acting as a kind of random basis. The PCE methodology has been developed as a
mathematically rigorous Uncertainty Quantification (UQ) method which aims at
providing reliable numerical estimates for some uncertain physical quantities
defining the dynamic of certain engineering models and their related
simulations. In the present paper we exploit the PCE approach to analyze some
equity and interest rate models considering, without loss of generality, the
one dimensional case. In particular we will take into account those models
which are based on the Geometric Brownian Motion (gBm), e.g. the Vasicek model,
the CIR model, etc. We also provide several numerical applications and results
which are discussed for a set of volatility values. The latter allows us to
test the PCE technique on a quite large set of different scenarios, hence
providing a rather complete and detailed investigation on PCE-approximation's
features and properties, such as the convergence of statistics, distribution
and quantiles. Moreover we give results concerning both an efficiency and an
accuracy study of our approach by comparing our outputs with the ones obtained
adopting the Monte Carlo approach in its standard form as well as in its
enhanced version.
"
1508.06797	q-fin	math.AP q-fin.PR	"Lie Symmetry Analysis of the Black-Scholes-Merton Model for European
  Options with Stochastic Volatility"	"  We perform a classification of the Lie point symmetries for the
Black--Scholes--Merton Model for European options with stochastic volatility,
$\sigma$, in which the last is defined by a stochastic differential equation
with an Orstein--Uhlenbeck term. In this model, the value of the option is
given by a linear (1 + 2) evolution partial differential equation in which the
price of the option depends upon two independent variables, the value of the
underlying asset, $S$, and a new variable, $y$. We find that for arbitrary
functional form of the volatility, $\sigma(y)$, the (1 + 2) evolution equation
always admits two Lie point symmetries in addition to the automatic linear
symmetry and the infinite number of solution symmetries. However, when
$\sigma(y)=\sigma_{0}$ and as the price of the option depends upon the second
Brownian motion in which the volatility is defined, the (1 + 2) evolution is
not reduced to the Black--Scholes--Merton Equation, the model admits five Lie
point symmetries in addition to the linear symmetry and the infinite number of
solution symmetries. We apply the zeroth-order invariants of the Lie symmetries
and we reduce the (1 + 2) evolution equation to a linear second-order ordinary
differential equation. Finally, we study two models of special interest, the
Heston model and the Stein--Stein model.
"
1508.07428	q-fin	q-fin.ST	Time-dependent scaling patterns in high frequency financial data	"  We measure the influence of different time-scales on the dynamics of
financial market data. This is obtained by decomposing financial time series
into simple oscillations associated with distinct time-scales. We propose two
new time-varying measures: 1) an amplitude scaling exponent and 2) an
entropy-like measure. We apply these measures to intraday, 30-second sampled
prices of various stock indices. Our results reveal intraday trends where
different time-horizons contribute with variable relative amplitudes over the
course of the trading day. Our findings indicate that the time series we
analysed have a non-stationary multifractal nature with predominantly
persistent behaviour at the middle of the trading session and anti-persistent
behaviour at the open and close. We demonstrate that these deviations are
statistically significant and robust.
"
1508.07505	q-fin	q-fin.ST q-fin.RM	"Early warning of large volatilities based on recurrence interval
  analysis in Chinese stock markets"	"  Being able to forcast extreme volatility is a central issue in financial risk
management. We present a large volatility predicting method based on the
distribution of recurrence intervals between volatilities exceeding a certain
threshold $Q$ for a fixed expected recurrence time $\tau_Q$. We find that the
recurrence intervals are well approximated by the $q$-exponential distribution
for all stocks and all $\tau_Q$ values. Thus a analytical formula for
determining the hazard probability $W(\Delta t |t)$ that a volatility above $Q$
will occur within a short interval $\Delta t$ if the last volatility exceeding
$Q$ happened $t$ periods ago can be directly derived from the $q$-exponential
distribution, which is found to be in good agreement with the empirical hazard
probability from real stock data. Using these results, we adopt a
decision-making algorithm for triggering the alarm of the occurrence of the
next volatility above $Q$ based on the hazard probability. Using a ""receiver
operator characteristic"" (ROC) analysis, we find that this predicting method
efficiently forecasts the occurrance of large volatility events in real stock
data. Our analysis may help us better understand reoccurring large volatilities
and more accurately quantify financial risks in stock markets.
"
1508.07561	q-fin	math.PR q-fin.MF	"A BSDE arising in an exponential utility maximization problem in a pure
  jump market model"	"  We consider the problem of utility maximization with exponential preferences
in a market where the traded stock/risky asset price is modelled as a
L\'evy-driven pure jump process (i.e. the driving L\'evy process has no
Brownian component). In this setting, we study the terminal utility
optimization problem in the presence of a European contingent claim. We
consider in detail the BSDE (backward stochastic differential equation)
characterising the value function when using an exponential utility function.
First we analyse the well-definedness of the generator. This leads to some
conditions on the market model related to conditions for the market to admit no
free lunches. Then we give bounds on the candidate optimal strategy.
  Thereafter, we discuss the example of a cross-hedging problem and, under
severe assumptions on the structure of the claim, we give explicit solutions.
Finally, we establish an explicit solution for a related BSDE with a suitable
terminal condition but a simpler generator.
"
1508.07891	q-fin	q-fin.TR q-fin.ST	A reduced-form model for level-1 limit order books	"  One popular approach to model the limit order books dynamics of the best bid
and ask at level-1 is to use the reduced-form diffusion approximations. It is
well known that the biggest contributing factor to the price movement is the
imbalance of the best bid and ask. We investigate the data of the level-1 limit
order books of a basket of stocks and study the numerical evidence of drift,
correlation, volatility and their dependence on the imbalance. Based on the
numerical discoveries, we develop a nonparametric discrete model for the
dynamics of the best bid and ask, which can be approximated by a reduced-form
model with analytical tractability that can fit the empirical data of
correlation, volatilities and probability of price movement simultaneously.
"
1509.00217	q-fin	q-fin.ST q-fin.CP	"A permutation Information Theory tour through different interest rate
  maturities: the Libor case"	"  This paper analyzes Libor interest rates for seven different maturities and
referred to operations in British Pounds, Euro, Swiss Francs and Japanese Yen,
during the period years 2001 to 2015. The analysis is performed by means of two
quantifiers derived from Information Theory: the permutation Shannon entropy
and the permutation Fisher information measure. An anomalous behavior in the
Libor is detected in all currencies except Euro during the years 2006--2012.
The stochastic switch is more severe in 1, 2 and 3 months maturities. Given the
special mechanism of Libor setting, we conjecture that the behavior could have
been produced by the manipulation that was uncovered by financial authorities.
We argue that our methodology is pertinent as a market overseeing instrument.
"
1509.00372	q-fin	q-fin.TR q-fin.ST	"Electricity Price Forecasting using Sale and Purchase Curves: The
  X-Model"	"  Our paper aims to model and forecast the electricity price by taking a
completely new perspective on the data. It will be the first approach which is
able to combine the insights of market structure models with extensive and
modern econometric analysis. Instead of directly modeling the electricity price
as it is usually done in time series or data mining approaches, we model and
utilize its true source: the sale and purchase curves of the electricity
exchange. We will refer to this new model as X-Model, as almost every
deregulated electricity price is simply the result of the intersection of the
electricity supply and demand curve at a certain auction. Therefore we show an
approach to deal with a tremendous amount of auction data, using a subtle data
processing technique as well as dimension reduction and lasso based estimation
methods. We incorporate not only several known features, such as seasonal
behavior or the impact of other processes like renewable energy, but also
completely new elaborated stylized facts of the bidding structure. Our model is
able to capture the non-linear behavior of the electricity price, which is
especially useful for predicting huge price spikes. Using simulation methods we
show how to derive prediction intervals for probabilistic forecasting. We
describe and show the proposed methods for the day-ahead EPEX spot price of
Germany and Austria.
"
1509.01144	q-fin	q-fin.PR math.PR q-fin.CP	Cointegrating Jumps: an Application to Energy Facilities	"  Based on the concept of self-decomposable random variables we discuss the
application of a model for a pair of dependent Poisson processes to energy
facilities. Due to the resulting structure of the jump events we can see the
self-decomposability as a form of cointegration among jumps. In the context of
energy facilities, the application of our approach to model power or gas
dynamics and to evaluate transportation assets seen as spread options is
straightforward. We study the applicability of our methodology first assuming a
Merton market model with two underlying assets; in a second step we consider
price dynamics driven by an exponential mean-reverting Geometric
Ornstein-Uhlenbeck plus compound Poisson that are commonly used in the energy
field. In this specific case we propose a price spot dynamics for each
underlying that has the advantage of being treatable to find non-arbitrage
conditions. In particular we can find close-form formulas for vanilla options
so that the price and the Greeks of spread options can be calculated in close
form using the Margrabe formula (if the strike is zero) or some other well
known approximation.
"
1509.01479	q-fin	q-fin.CP	"A mixed Monte Carlo and PDE variance reduction method for foreign
  exchange options under the Heston-CIR model"	"  In this paper, the valuation of European and path-dependent options in
foreign exchange (FX) markets is considered when the currency exchange rate
evolves according to the Heston model combined with the Cox-Ingersoll-Ross
dynamics for the stochastic domestic and foreign short interest rates. The
mixed Monte Carlo/PDE method requires that we simulate only the paths of the
squared volatility and the two interest rates, while an ""inner""
Black-Scholes-type expectation is evaluated by means of a PDE. This can lead to
a substantial variance reduction and complexity improvements under certain
circumstances depending on the contract and the model parameters. In this work,
we establish the uniform boundedness of moments of the exchange rate process
and its approximation, and prove strong convergence in $L^p$ ($p\geq1$) of the
latter. Then, we carry out a variance reduction analysis and obtain accurate
approximations for quantities of interest. All theoretical contributions can be
extended to multi-factor short rates in a straightforward manner. Finally, we
illustrate the efficiency of the method for the four-factor Heston-CIR model
through a detailed quantitative assessment.
"
1509.01483	q-fin	q-fin.GN physics.soc-ph	On the emergence of scale-free production networks	"  We propose a simple dynamical model of the formation of production networks
among monopolistically competitive firms. The model subsumes the standard
general equilibrium approach \`a la Arrow-Debreu but displays a wide set of
potential dynamic behaviors. It robustly reproduces key stylized facts of
firms' demographics. Our main result is that competition between intermediate
good producers generically leads to the emergence of scale-free production
networks.
"
1509.01966	q-fin	q-fin.ST	"Forecasting Electricity Spot Prices using Lasso: On Capturing the
  Autoregressive Intraday Structure"	"  In this paper we present a regression based model for day-ahead electricity
spot prices. We estimate the considered linear regression model by the lasso
estimation method. The lasso approach allows for many possible parameters in
the model, but also shrinks and sparsifies the parameters automatically to
avoid overfitting. Thus, it is able to capture the autoregressive intraday
dependency structure of the electricity price well. We discuss in detail the
estimation results which provide insights to the intraday behavior of
electricity prices. We perform an out-of-sample forecasting study for several
European electricity markets. The results illustrate well that the efficient
lasso based estimation technique can exhibit advantages from two popular model
approaches.
"
1509.02179	q-fin	q-fin.CP stat.ME	Kriging Metamodels and Experimental Design for Bermudan Option Pricing	"  We investigate two new strategies for the numerical solution of optimal
stopping problems within the Regression Monte Carlo (RMC) framework of
Longstaff and Schwartz. First, we propose the use of stochastic kriging
(Gaussian process) meta-models for fitting the continuation value. Kriging
offers a flexible, nonparametric regression approach that quantifies
approximation quality. Second, we connect the choice of stochastic grids used
in RMC to the Design of Experiments paradigm. We examine space-filling and
adaptive experimental designs; we also investigate the use of batching with
replicated simulations at design sites to improve the signal-to-noise ratio.
Numerical case studies for valuing Bermudan Puts and Max-Calls under a variety
of asset dynamics illustrate that our methods offer significant reduction in
simulation budgets over existing approaches.
"
1509.02711	q-fin	physics.soc-ph q-fin.GN	Inequality measures in kinetic exchange models of wealth distributions	"  In this paper, we study the inequality indices for some models of wealth
exchange. We calculated Gini index and newly introduced k-index and compare the
results with reported empirical data available for different countries. We have
found lower and upper bounds for the indices and discuss the efficiencies of
the models. Some exact analytical calculations are given for a few cases. We
also exactly compute the quantities for Gamma and double Gamma distributions.
"
1509.04952	q-fin	q-fin.CP q-fin.GN	Estimating Tipping Points in Feedback-Driven Financial Networks	"  Much research has been conducted arguing that tipping points at which complex
systems experience phase transitions are difficult to identify. To test the
existence of tipping points in financial markets, based on the alternating
offer strategic model we propose a network of bargaining agents who mutually
either cooperate or where the feedback mechanism between trading and price
dynamics is driven by an external ""hidden"" variable R that quantifies the
degree of market overpricing. Due to the feedback mechanism, R fluctuates and
oscillates over time, and thus periods when the market is underpriced and
overpriced occur repeatedly. As the market becomes overpriced, bubbles are
created that ultimately burst in a market crash. The probability that the index
will drop in the next year exhibits a strong hysteresis behavior from which we
calculate the tipping point. The probability distribution function of R has a
bimodal shape characteristic of small systems near the tipping point. By
examining the S&P500 index we illustrate the applicability of the model and
demonstate that the financial data exhibits a hysteresis and a tipping point
that agree with the model predictions. We report a cointegration between the
returns of the S&P 500 index and its intrinsic value.
"
1509.06210	q-fin	q-fin.MF math.PR	"The pricing of contingent claims and optimal positions in asymptotically
  complete markets"	"  We study utility indifference prices and optimal purchasing quantities for a
contingent claim, in an incomplete semi-martingale market, in the presence of
vanishing hedging errors and/or risk aversion. Assuming that the average
indifference price converges to a well defined limit, we prove that optimally
taken positions become large in absolute value at a specific rate. We draw
motivation from and make connections to Large Deviations theory, and in
particular, the celebrated G\""{a}rtner-Ellis theorem. We analyze a series of
well studied examples where this limiting behavior occurs, such as fixed
markets with vanishing risk aversion, the basis risk model with high
correlation, models of large markets with vanishing trading restrictions and
the Black-Scholes-Merton model with either vanishing default probabilities or
vanishing transaction costs. Lastly, we show that the large claim regime could
naturally arise in partial equilibrium models.
"
1509.06315	q-fin	q-fin.ST	Universality of market superstatistics	"  We use a continuous-time random walk (CTRW) to model market fluctuation data
from times when traders experience excessive losses or excessive profits. We
analytically derive ""superstatistics"" that accurately model empirical market
activity data (supplied by Bogachev, Ludescher, Tsallis, and Bunde)that exhibit
transition thresholds. We measure the interevent times between excessive losses
and excessive profits, and use the mean interevent time as a control variable
to derive a universal description of empirical data collapse. Our
superstatistic value is a weighted sum of two components, (i) a powerlaw
corrected by the lower incomplete gamma function, which asymptotically tends
toward robustness but initially gives an exponential, and (ii) a powerlaw
damped by the upper incomplete gamma function, which tends toward the power-law
only during short interevent times. We find that the scaling shape exponents
that drive both components subordinate themselves and a ""superscaling""
configuration emerges. We use superstatistics to describe the hierarchical
activity when component (i) reproduces the negative feedback and component (ii)
reproduces the stylized fact of volatility clustering. Our results indicate
that there is a functional (but not literal) balance between excessive profits
and excessive losses that can be described using the same body of
superstatistics, but different calibration values and driving parameters.
"
1509.06457	q-fin	q-fin.TR cs.CE stat.ML	Identifying collusion groups using spectral clustering	"  In an illiquid stock, traders can collude and place orders on a predetermined
price and quantity at a fixed schedule. This is usually done to manipulate the
price of the stock or to create artificial liquidity in the stock, which may
mislead genuine investors. Here, the problem is to identify such group of
colluding traders. We modeled the problem instance as a graph, where each
trader corresponds to a vertex of the graph and trade corresponds to edges of
the graph. Further, we assign weights on edges depending on total volume, total
number of trades, maximum change in the price and commonality between two
vertices. Spectral clustering algorithms are used on the constructed graph to
identify colluding group(s). We have compared our results with simulated data
to show the effectiveness of spectral clustering to detecting colluding groups.
Moreover, we also have used parameters of real data to test the effectiveness
of our algorithm.
"
1509.06612	q-fin	q-fin.EC q-fin.GN	Mathematical Analysis of the Historical Economic Growth	"  Data describing historical economic growth are analysed. Included in the
analysis is the world and regional economic growth. The analysis demonstrates
that historical economic growth had a natural tendency to follow hyperbolic
distributions. Parameters describing hyperbolic distributions have been
determined. A search for takeoffs from stagnation to growth produced negative
results. This analysis throws a new light on the interpretation of the
mechanism of the historical economic growth and suggests new lines of research.
"
1509.07953	q-fin	q-fin.PM	Optimal trading strategies - a time series approach	"  Motivated by recent advances in the spectral theory of auto-covariance
matrices, we are led to revisit a reformulation of Markowitz' mean-variance
portfolio optimization approach in the time domain. In its simplest incarnation
it applies to a single traded asset and allows to find an optimal trading
strategy which - for a given return - is minimally exposed to market price
fluctuations. The model is initially investigated for a range of synthetic
price processes, taken to be either second order stationary, or to exhibit
second order stationary increments. Attention is paid to consequences of
estimating auto-covariance matrices from small finite samples, and
auto-covariance matrix cleaning strategies to mitigate against these are
investigated. Finally we apply our framework to real world data.
"
1509.08110	q-fin	q-fin.PM	Performance v. Turnover: A Story by 4,000 Alphas	"  We analyze empirical data for 4,000 real-life trading portfolios (U.S.
equities) with holding periods of about 0.7-19 trading days. We find a simple
scaling C ~ 1/T, where C is cents-per-share, and T is the portfolio turnover.
Thus, the portfolio return R has no statistically significant dependence on the
turnover T. We also find a scaling R ~ V^X, where V is the portfolio
volatility, and the power X is around 0.8-0.85 for holding periods up to 10
days or so. To our knowledge, this is the only publicly available empirical
study on such a large number of real-life trading portfolios/alphas.
"
1509.09133	q-fin	q-fin.RM math.PR q-fin.MF	Dynamics of multivariate default system in random environment	"  We consider a multivariate default system where random environmental
information is available. We study the dynamics of the system in a general
setting and adopt the point of view of change of probability measures. We also
make a link with the density approach in the credit risk modelling. In the
particular case where no environmental information is concerned, we pay a
special attention to the phenomenon of system weakened by failures as in the
classical reliability system.
"
1510.00352	q-fin	q-fin.MF nlin.CD	Retarded action principle and self-financing portfolio dynamics	"  We derive a consistent differential representation for the dynamics of a
self-financing portfolio for different hedging strategies. In the basis of the
derivation there is the so called ""retarded action principle"", which represents
the causality in the evolution of dependent stochastic variables. We
demonstrate this principle on example of a vanilla and a storage option.
"
1510.01890	q-fin	math.PR q-fin.MF	Semi-static completeness and robust pricing by informed investors	"  We consider a continuous-time financial market that consists of securities
available for dynamic trading, and securities only available for static
trading. We work in a robust framework where a set of non-dominated models is
given. The concept of semi-static completeness is introduced: it corresponds to
having exact replication by means of semi-static strategies. We show that
semi-static completeness is equivalent to an extremality property, and give a
characterization of the induced filtration structure. Furthermore, we consider
investors with additional information and, for specific types of extra
information, we characterize the models that are semi-statically complete for
the informed investors. Finally, we provide some examples where robust pricing
for informed and uninformed agents can be done over semi-statically complete
models.
"
1510.02808	q-fin	q-fin.PM math.PR	Universal portfolios in stochastic portfolio theory	"  Consider a family of portfolio strategies with the aim of achieving the
asymptotic growth rate of the best one. The idea behind Cover's universal
portfolio is to build a wealth-weighted average which can be viewed as a
buy-and-hold portfolio of portfolios. When an optimal portfolio exists, the
wealth-weighted average converges to it by concentration of wealth. Working
under a discrete time and pathwise setup, we show under suitable conditions
that the distribution of wealth in the family satisfies a pathwise large
deviation principle as time tends to infinity. Our main result extends Cover's
portfolio to the nonparametric family of functionally generated portfolios in
stochastic portfolio theory and establishes its asymptotic universality.
"
1510.03205	q-fin	q-fin.ST q-fin.TR	Price response in correlated financial markets: empirical results	"  Previous studies of the stock price response to individual trades focused on
single stocks. We empirically investigate the price response of one stock to
the trades of other stocks. How large is the impact of one stock on others and
vice versa? -- This impact of trades on the price change across stocks appears
to be transient instead of permanent. Performing different averages, we
distinguish active and passive responses. The two average responses show
different characteristic dependences on the time lag. The passive response
exhibits a shorter response period with sizeable volatilities, and the active
response a longer period. We also study the response for a given stock with
respect to different sectors and to the whole market. Furthermore, we compare
the self-response with the various cross-responses. The correlation of the
trade signs is a short-memory process for a pair of stocks, but it turns into a
long-memory process when averaged over different pairs of stocks.
"
1510.03223	q-fin	q-fin.MF	Hedging with Temporary Price Impact	"  We consider the problem of hedging a European contingent claim in a Bachelier
model with transient price impact as proposed by Almgren and Chriss. Following
the approach of Rogers and Singh and Naujokat and Westray, the hedging problem
can be regarded as a cost optimal tracking problem of the frictionless hedging
strategy. We solve this problem explicitly for general predictable target
hedging strategies. It turns out that, rather than towards the current target
position, the optimal policy trades towards a weighted average of expected
future target positions. This generalizes an observation of Garleanu and
Pedersen from their homogenous Markovian optimal investment problem to a
general hedging problem. Our findings complement a number of previous studies
in the literature on optimal strategies in illiquid markets where the
frictionless strategy is confined to diffusions. The consideration of general
predictable reference strategies is made possible by the use of a convex
analysis approach instead of the more common dynamic programming methods.
"
1510.04910	q-fin	q-fin.ST	"Detrended cross-correlations between returns, volatility, trading
  activity, and volume traded for the stock market companies"	"  We consider a few quantities that characterize trading on a stock market in a
fixed time interval: logarithmic returns, volatility, trading activity (i.e.,
the number of transactions), and volume traded. We search for the power-law
cross-correlations among these quantities aggregated over different time units
from 1 min to 10 min. Our study is based on empirical data from the American
stock market consisting of tick-by-tick recordings of 31 stocks listed in Dow
Jones Industrial Average during the years 2008-2011. Since all the considered
quantities except the returns show strong daily patterns related to the
variable trading activity in different parts of a day, which are the best
evident in the autocorrelation function, we remove these patterns by detrending
before we proceed further with our study. We apply the multifractal detrended
cross-correlation analysis with sign preserving (MFCCA) and show that the
strongest power-law cross-correlations exist between trading activity and
volume traded, while the weakest ones exist (or even do not exist) between the
returns and the remaining quantities. We also show that the strongest
cross-correlations are carried by those parts of the signals that are
characterized by large and medium variance. Our observation that the most
convincing power-law cross-correlations occur between trading activity and
volume traded reveals the existence of strong fractal-like coupling between
these quantities.
"
1510.04967	q-fin	cs.MA q-fin.GN	A simple agent-based spatial model of the economy: tools for policy	"  This study simulates the evolution of artificial economies in order to
understand the tax relevance of administrative boundaries in the quality of
life of its citizens. The modeling involves the construction of a computational
algorithm, which includes citizens, bounded into families; firms and
governments; all of them interacting in markets for goods, labor and real
estate. The real estate market allows families to move to dwellings with higher
quality or lower price when the families capitalize property values. The goods
market allows consumers to search on a flexible number of firms choosing by
price and proximity. The labor market entails a matching process between firms
(location) and candidates (qualification). The government may be configured
into one, four or seven distinct sub-national governments. The role of
government is to collect taxes on the value added of firms in its territory and
invest the taxes into higher levels of quality of life for residents. The model
does not have a credit market. The results suggest that the configuration of
administrative boundaries is relevant to the levels of quality of life arising
from the reversal of taxes. The model with seven regions is more dynamic, with
higher GDP values, but more unequal and heterogeneous across regions. The
simulation with only one region is more homogeneously poor. The study seeks to
contribute to a theoretical and methodological framework as well as to
describe, operationalize and test computer models of public finance analysis,
with explicitly spatial and dynamic emphasis. Several alternatives of expansion
of the model for future research are described. Moreover, this study adds to
the existing literature in the realm of simple microeconomic computational
models, specifying structural relationships between local governments and
firms, consumers and dwellings mediated by distance.
"
1510.05118	q-fin	q-fin.ST stat.ME	"Networks, Dynamic Factors, and the Volatility Analysis of
  High-Dimensional Financial Series"	"  We consider weighted directed networks for analysing, over the period
2000-2013, the interdependencies between volatilities of a large panel of
stocks belonging to the S\&P100 index. In particular, we focus on the so-called
{\it Long-Run Variance Decomposition Network} (LVDN), where the nodes are
stocks, and the weight associated with edge $(i,j)$ represents the proportion
of $h$-step-ahead forecast error variance of variable $i$ accounted for by
variable $j$'s innovations. To overcome the curse of dimensionality, we
decompose the panel into a component driven by few global, market-wide,
factors, and an idiosyncratic one modelled by means of a sparse vector
autoregression (VAR) model. Inversion of the VAR together with suitable
identification restrictions, produces the estimated network, by means of which
we can assess how {\it systemic} each firm is.~Our analysis demonstrates the
prominent role of financial firms as sources of contagion, especially during
the~2007-2008 crisis.
"
1510.05123	q-fin	q-fin.PM q-fin.TR	Optimal growth trajectories with finite carrying capacity	"  We consider the problem of finding optimal strategies that maximize the
average growth-rate of multiplicative stochastic processes. For a geometric
Brownian motion the problem is solved through the so-called Kelly criterion,
according to which the optimal growth rate is achieved by investing a constant
given fraction of resources at any step of the dynamics. We generalize these
finding to the case of dynamical equations with finite carrying capacity, which
can find applications in biology, mathematical ecology, and finance. We
formulate the problem in terms of a stochastic process with multiplicative
noise and a non-linear drift term that is determined by the specific functional
form of carrying capacity. We solve the stochastic equation for two classes of
carrying capacity functions (power laws and logarithmic), and in both cases
compute optimal trajectories of the control parameter. We further test the
validity of our analytical results using numerical simulations.
"
1510.05510	q-fin	q-fin.CP	"Mathematical Foundations of Realtime Equity Trading. Liquidity Deficit
  and Market Dynamics. Automated Trading Machines"	"  We postulates, and then show experimentally, that liquidity deficit is the
driving force of the markets. In the first part of the paper a kinematic of
liquidity deficit is developed. The calculus-like approach, which is based on
Radon--Nikodym derivatives and their generalization, allows us to calculate
important characteristics of observable market dynamics. In the second part of
the paper this calculus is used in an attempt to build a dynamic equation in
the form: future price tend to the value maximizing the number of shares traded
per unit time. To build a practical automated trading machine P&L dynamics
instead of price dynamics is considered. This allows a trading automate
resilient to catastrophic P&L drains to be built. The results are very
promising, yet when all the fees and trading commissions are taken into
account, are close to breakeven. In the end of the paper important criteria for
automated trading systems are presented. We list the system types that can and
cannot make money on the market. These criteria can be successfully applied not
only by automated trading machines, but also by a human trader.
"
1510.05875	q-fin	q-fin.MF math.NA	An elementary approach to the option pricing problem	"  Our goal here is to discuss the pricing problem of European and American
options in discrete time using elementary calculus so as to be an easy
reference for first year undergraduate students. Using the binomial model we
compute the fair price of European and American options. We explain the notion
of Arbitrage and the notion of the fair price of an option using common sense.
We give a criterion that the holder can use to decide when it is appropriate to
exercise the option. We prove the put-call parity formulas for both European
and American options and we discuss the relation between American and European
options. We give also the bounds for European and American options. We also
discuss the portfolio's optimization problem and the fair value in the case
where the holder can not produce the opposite portfolio.
"
1510.06809	q-fin	q-fin.EC	"A Link between Sequential Semi-anonymous Nonatomic Games and their Large
  Finite Counterparts"	"  We show that equilibria of a sequential semi-anonymous nonatomic game (SSNG)
can be adopted by players in corresponding large but finite dynamic games to
achieve near-equilibrium payoffs. Such equilibria in the form of random
state-to-action rules are parsimonious in form and easy to execute, as they are
both oblivious of past history and blind to other players' present states. Our
transient results can be extended to a stationary case, where the finite
counterparts are special discounted stochastic games. The kind of equilibria we
adopt for SSNG are similar to distributional equilibria that are well
understood in literature, and they themselves are shown to exist.
"
1510.06946	q-fin	math.ST q-fin.EC q-fin.ST stat.TH	"Quantile Cross-Spectral Measures of Dependence between Economic
  Variables"	"  In this paper we introduce quantile cross-spectral analysis of multiple time
series which is designed to detect general dependence structures emerging in
quantiles of the joint distribution in the frequency domain. We argue that this
type of dependence is natural for economic time series but remains invisible
when the traditional analysis is employed. To illustrate how such dependence
structures can arise between variables in different parts of the joint
distribution and across frequencies, we consider quantile vector autoregression
processes. We define new estimators which capture the general dependence
structure, provide a detailed analysis of their asymptotic properties and
discuss how to conduct inference for a general class of possibly nonlinear
processes. In an empirical illustration we examine one of the most prominent
time series in economics and shed new light on the dependence of bivariate
stock market returns.
"
1510.07030	q-fin	q-fin.RM math.PR	Law invariant risk measures and information divergences	"  A one-to-one correspondence is drawn between law invariant risk measures and
divergences, which we define as functionals of pairs of probability measures on
arbitrary standard Borel spaces satisfying a few natural properties.
Divergences include many classical information divergence measures, such as
relative entropy and $f$-divergences. Several properties of divergence and
their duality with law invariant risk measures are developed, most notably
relating their chain rules or additivity properties with certain notions of
time consistency for dynamic law invariant risk measures known as acceptance
and rejection consistency. These properties are linked also to a peculiar
property of the acceptance sets on the level of distributions, analogous to
results of Weber on weak acceptance and rejection consistency. Finally, the
examples of shortfall risk measures and optimized certainty equivalents are
discussed in some detail, and it is shown that the relative entropy is
essentially the only divergence satisfying the chain rule.
"
1510.07280	q-fin	q-fin.ST physics.data-an	"Uncovering the evolution of non-stationary stochastic variables: the
  example of asset volume-price fluctuations"	"  We present a framework for describing the evolution of stochastic observables
having a non-stationary distribution of values. The framework is applied to
empirical volume-prices from assets traded at the New York stock exchange.
Using Kullback-Leibler divergence we evaluate the best model out from four
biparametric models standardly used in the context of financial data analysis.
In our present data sets we conclude that the inverse $\Gamma$-distribution is
a good model, particularly for the distribution tail of the largest
volume-price fluctuations. Extracting the time-series of the corresponding
parameter values we show that they evolve in time as stochastic variables
themselves. For the particular case of the parameter controlling the
volume-price distribution tail we are able to extract an Ornstein-Uhlenbeck
equation which describes the fluctuations of the largest volume-prices observed
in the data. Finally, we discuss how to bridge from the stochastic evolution of
the distribution parameters to the stochastic evolution of the (non-stationary)
observable and put our conclusions into perspective for other applications in
geophysics and biology.
"
1510.07599	q-fin	q-fin.ST	"An empirical analysis of the relationships between crude oil, gold and
  stock markets"	"  This paper analyzes the direction of the causality between crude oil, gold
and stock markets for the largest economy in the world with respect to such
markets, the US. To do so, we apply non-linear Granger causality tests. We find
a nonlinear causal relationship among the three markets considered, with the
causality going in all directions, when the full sample and different
subsamples are considered. However, we find a unidirectional nonlinear causal
relationship between the crude oil and gold market (with the causality only
going from oil price changes to gold price changes) when the subsample runs
from the first date of any year between the mid-1990s and 2001 to last
available data (February 5, 2015). The latter result may explain the lack of
consensus existing in the literature about the direction of the causal link
between the crude oil and gold markets.
"
1510.07888	q-fin	q-fin.EC cs.GT	Exchanging Goods Using Valuable Money	"  A group of people wishes to use money to exchange goods efficiently over
several time periods. However, there are disadvantages to using any of the
goods as money, and in addition fiat money issued in the form of notes or coins
will be valueless in the final time period, and hence in all earlier periods.
Also, Walrasian market prices are determined only up to an arbitrary rescaling.
Nevertheless we show that it is possible to devise a system which uses money to
exchange goods and in which money has a determinate positive value. In this
system, tokens are initially supplied to all traders by a central authority and
recovered by a purchase tax. All trades must be made using tokens or promissory
notes for tokens. This mechanism controls the flow rather than the stock of
money: it introduces some trading frictions, some redistribution of wealth, and
some distortion of prices, but these effects can all be made small.
"
1511.00026	q-fin	q-fin.MF math.PR	Pathwise no-arbitrage in a class of Delta hedging strategies	"  We consider a strictly pathwise setting for Delta hedging exotic options,
based on F\""ollmer's pathwise It\=o calculus. Price trajectories are
$d$-dimensional continuous functions whose pathwise quadratic variations and
covariations are determined by a given local volatility matrix. The existence
of Delta hedging strategies in this pathwise setting is established via
existence results for recursive schemes of parabolic Cauchy problems and via
the existence of functional Cauchy problems on path space. Our main results
establish the nonexistence of pathwise arbitrage opportunities in classes of
strategies containing these Delta hedging strategies and under relatively mild
conditions on the local volatility matrix.
"
1511.00884	q-fin	q-fin.CP	"Magic points in finance: Empirical integration for parametric option
  pricing"	"  We propose an offline-online procedure for Fourier transform based option
pricing. The method supports the acceleration of such essential tasks of
mathematical finance as model calibration, real-time pricing, and, more
generally, risk assessment and parameter risk estimation. We adapt the
empirical magic point interpolation method of Barrault, Nguyen, Maday and
Patera (2004) to parametric Fourier pricing. In the offline phase, a quadrature
rule is tailored to the family of integrands of the parametric pricing problem.
In the online phase, the quadrature rule then yields fast and accurate
approximations of the option prices. Under analyticity assumptions the pricing
error decays exponentially. Numerical experiments in one dimension confirm our
theoretical findings and show a significant gain in efficiency, even for
examples beyond the scope of the theoretical results.
"
1511.01460	q-fin	q-fin.CP q-fin.PR	LSV models with stochastic interest rates and correlated jumps	"  Pricing and hedging exotic options using local stochastic volatility models
drew a serious attention within the last decade, and nowadays became almost a
standard approach to this problem. In this paper we show how this framework
could be extended by adding to the model stochastic interest rates and
correlated jumps in all three components. We also propose a new fully implicit
modification of the popular Hundsdorfer and Verwer and Modified Craig-Sneyd
finite-difference schemes which provides second order approximation in space
and time, is unconditionally stable and preserves positivity of the solution,
while still has a linear complexity in the number of grid nodes.
"
1511.01529	q-fin	q-fin.GN math.OC	A Dynamic Model of Functioning of a Bank	"  In this paper, we analyze dynamic programming as a novel approach to solve
the problem of maximizing the profits of a bank. The mathematical model of the
problem and the description of a bank's work is described in this paper. The
problem is then approached using the method of dynamic programming. Dynamic
programming makes sure that the solutions obtained are globally optimal and
numerically stable. The optimization process is set up as a discrete
multi-stage decision process and solved with the help of dynamic programming.
"
1511.03159	q-fin	q-fin.MF math.FA	On the C-property and $w^*$-representations of risk measures	"  We identify a large class of Orlicz spaces $X$ for which the topology
$\sigma(X,X_n^\sim)$ fails the C-property introduced in [7]. We also establish
a variant of the C-property and use it to prove a $w^*$-representation theorem
for proper convex increasing functionals on dual Banach lattices that satisfy a
suitable version of Delbaen's Fatou property. Our results apply, in particular,
to risk measures on all Orlicz spaces over $[0,1]$ which is not $L_1[0,1]$.
"
1511.03616	q-fin	math.OC math.PR q-fin.EC	Moral hazard under ambiguity	"  In this paper, we extend the Holmstro\""om and Milgrom problem [47] by adding
uncertainty about the volatility of the output for both the Agent and the
Principal. We study more precisely the impact of the ""Nature"" playing against
the Agent and the Principal by choosing the worst possible volatility of the
output. We solve the first--best and the second--best problems associated with
this framework and we show that optimal contracts are in a class of contracts
similar to [14, 15], linear with respect to the output and its quadratic
variation. We compare our results with the classical problem in [47].
"
1511.03704	q-fin	q-fin.MF	Foundations for Wash Sales	"  Consider an ephemeral sale-and-repurchase of a security resulting in the same
position before the sale and after the repurchase. A sale-and-repurchase is a
wash sale if these transactions result in a loss within $\pm 30$ calendar days.
Since a portfolio is essentially the same after a wash sale, any tax advantage
from such a loss is not allowed. That is, after a wash sale a portfolio is
unchanged so any loss captured by the wash sale is deemed to be solely for tax
advantage and not investment purposes.
  This paper starts by exploring variations of the birthday problem to model
wash sales. The birthday problem is: Determine the number of independent and
identically distributed random variables required so there is a probability of
at least 1/2 that two or more of these random variables share the same outcome.
This paper gives necessary conditions for wash sales based on variations on the
birthday problem. This allows us to answer questions such as: What is the
likelihood of a wash sale in an unmanaged portfolio where purchases and sales
are independent, uniform, and random? This paper ends by exploring the
Littlewood-Offord problem as it relates capital gains and losses with wash
sales.
"
1511.03876	q-fin	math.OC q-fin.RM stat.AP	On the aggregation of experts' information in Bonus-Malus systems	"  We present in this paper a new premium computation principle based on the use
of prior information from multiple sources for computing the premium charged to
a policyholder. Under this framework, based on the use of Ordered Weighted
Averaging (OWA) operators, we propose alternative collective and Bayes premiums
and describe some approaches to compute them. Several examples illustrates the
new framework for premium computation.
"
1511.04096	q-fin	q-fin.TR q-fin.MF	"A Stochastic Model of Order Book Dynamics using Bouncing Geometric
  Brownian Motions"	"  We consider a limit order book, where buyers and sellers register to trade a
security at specific prices. The largest price buyers on the book are willing
to offer is called the market bid price, and the smallest price sellers on the
book are willing to accept is called the market ask price. Market ask price is
always greater than market bid price, and these prices move upwards and
downwards due to new arrivals, market trades, and cancellations. We model these
two price processes as ""bouncing geometric Brownian motions (GBMs)"", which are
defined as exponentials of two mutually reflected Brownian motions. We then
modify these bouncing GBMs to construct a discrete time stochastic process of
trading times and trading prices, which is parameterized by a positive
parameter $\delta$. Under this model, it is shown that the inter-trading times
are inverse Gaussian distributed, and the logarithmic returns between
consecutive trading times follow a normal inverse Gaussian distribution. Our
main results show that the logarithmic trading price process is a renewal
reward process, and under a suitable scaling, this process converges to a
standard Brownian motion as $\delta\to 0$. We also prove that the modified ask
and bid processes approach the original bouncing GBMs as $\delta\to0$. Finally,
we derive a simple and effective prediction formula for trading prices, and
illustrate the effectiveness of the prediction formula with an example using
real stock price data.
"
1511.04116	q-fin	q-fin.TR	Latency and liquidity provision in a limit order book	"  We use a recent, high-quality data set from Nasdaq to perform an empirical
analysis of order flow in a limit order book (LOB) before and after the arrival
of a market order. For each of the stocks that we study, we identify a sequence
of distinct phases across which the net flow of orders differs considerably. We
note some of our results are consist with the widely reported phenomenon of
stimulated refill, but that others are not. We therefore propose alternative
mechanical and strategic motivations for the behaviour that we observe. Based
on our findings, we argue that strategic liquidity providers consider both
adverse selection and expected waiting costs when deciding how to act.
"
1511.04764	q-fin	q-fin.PM q-fin.RM	Shrinkage = Factor Model	"  Shrunk sample covariance matrix is a factor model of a special form combining
some (typically, style) risk factor(s) and principal components with a
(block-)diagonal factor covariance matrix. As such, shrinkage, which
essentially inherits out-of-sample instabilities of the sample covariance
matrix, is not an alternative to multifactor risk models but one out of myriad
possible regularization schemes. We give an example of a scheme designed to be
less prone to said instabilities. We contextualize this within multifactor
models.
"
1511.04768	q-fin	q-fin.PM	"Optimal Investment with Transaction Costs under Cumulative Prospect
  Theory in Discrete Time"	"  We study optimal investment problems under the framework of cumulative
prospect theory (CPT). A CPT investor makes investment decisions in a
single-period financial market with transaction costs. The objective is to seek
the optimal investment strategy that maximizes the prospect value of the
investor's final wealth. We obtain the optimal investment strategy explicitly
in two examples. An economic analysis is conducted to investigate the impact of
the transaction costs and risk aversion on the optimal investment strategy.
"
1511.04863	q-fin	q-fin.MF	"Representation of homothetic forward performance processes in stochastic
  factor models via ergodic and infinite horizon BSDE"	"  In an incomplete market, with incompleteness stemming from stochastic factors
imperfectly correlated with the underlying stocks, we derive representations of
homothetic (power, exponential and logarithmic) forward performance processes
in factor-form using ergodic BSDE. We also develop a connection between the
forward processes and infinite horizon BSDE, and, moreover, with risk-sensitive
optimization. In addition, we develop a connection, for large time horizons,
with a family of classical homothetic value function processes with random
endowments.
"
1511.06320	q-fin	q-fin.RM math.PR	"Intragroup transfers, intragroup diversification and their risk
  assessment"	"  When assessing group solvency, an important question is to what extent
intragroup transfers may be considered, as this determines to which extent
diversification can be achieved. We suggest a framework to describe the
families of admissible transfers that range from the free movement of capital
to excluding any transactions. The constraints on admissible transactions are
described as random closed sets. The paper focuses on the corresponding
solvency tests that amount to the existence of acceptable selections of the
random sets of admissible transactions.
"
1511.06873	q-fin	q-fin.TR q-fin.GN	"Patterns of trading profiles at the Nordic Stock Exchange. A
  correlation-based approach"	"  We investigate the trading behavior of Finnish individual investors trading
the stocks selected to compute the OMXH25 index in 2003 by tracking the
individual daily investment decisions. We verify that the set of investors is a
highly heterogeneous system under many aspects. We introduce a correlation
based method that is able to detect a hierarchical structure of the trading
profiles of heterogeneous individual investors. We verify that the detected
hierarchical structure is highly overlapping with the cluster structure
obtained with the approach of statistically validated networks when an
appropriate threshold of the hierarchical trees is used. We also show that the
combination of the correlation based method and of the statistically validated
method provides a way to expand the information about the clusters of investors
with similar trading profiles in a robust and reliable way.
"
1511.07359	q-fin	q-fin.TR	Optimal Trading with Linear and (small) Non-Linear Costs	"  We reconsider the problem of optimal trading in the presence of linear and
quadratic costs, for arbitrary linear costs but in the limit where quadratic
costs are small. Using matched asymptotic expansion techniques, we find that
the trading speed vanishes inside a band that is narrower than in the absence
of quadratic costs, by an amount that scales as the one-third power of
quadratic costs. Outside of the band, we find three regimes: a small boundary
layer where the velocity vanishes linearly with the distance to the band, an
intermediate region where the velocity behaves as a square-root of that
distance, and a far region where it becomes linear. Our solution is consistent
with available numerical results. We determine the conditions in which our
expansion is useful in practical applications, and generalize our solution to
other forms of non-linear costs.
"
1511.07821	q-fin	stat.AP q-fin.CP	Box-Cox transformation of firm size data in statistical analysis	"  Firm size data usually do not show the normality that is often assumed in
statistical analysis such as regression analysis. In this study we focus on two
firm size data: the number of employees and sale. Those data deviate
considerably from a normal distribution. To improve the normality of those data
we transform them by the Box-Cox transformation with appropriate parameters.
The Box-Cox transformation parameters are determined so that the transformed
data best show the kurtosis of a normal distribution. It is found that the two
firm size data transformed by the Box-Cox transformation show strong linearity.
This indicates that the number of employees and sale have the similar property
as a firm size indicator. The Box-Cox parameters obtained for the firm size
data are found to be very close to zero. In this case the Box-Cox
transformations are approximately a log-transformation. This suggests that the
firm size data we used are approximately log-normal distributions.
"
1511.08194	q-fin	q-fin.MF	Integration with respect to model-free price paths with jumps	"  For every adapted, c\`agl\`ad process (strategy) $G$ and typical c\`adl\`ag
price paths whose jumps satisfy some mild growth condition we define integral
$G\cdot S$ as a limit of simple integrals.
"
1511.08409	q-fin	math.OC q-fin.TR	Optimal Real-Time Bidding Strategies	"  The ad-trading desks of media-buying agencies are increasingly relying on
complex algorithms for purchasing advertising inventory. In particular,
Real-Time Bidding (RTB) algorithms respond to many auctions -- usually Vickrey
auctions -- throughout the day for buying ad-inventory with the aim of
maximizing one or several key performance indicators (KPI). The optimization
problems faced by companies building bidding strategies are new and interesting
for the community of applied mathematicians. In this article, we introduce a
stochastic optimal control model that addresses the question of the optimal
bidding strategy in various realistic contexts: the maximization of the
inventory bought with a given amount of cash in the framework of audience
strategies, the maximization of the number of conversions/acquisitions with a
given amount of cash, etc. In our model, the sequence of auctions is modeled by
a Poisson process and the \textit{price to beat} for each auction is modeled by
a random variable following almost any probability distribution. We show that
the optimal bids are characterized by a Hamilton-Jacobi-Bellman equation, and
that almost-closed form solutions can be found by using a fluid limit.
Numerical examples are also carried out.
"
1511.08466	q-fin	q-fin.PR	Approximate Option Pricing in the L\'evy Libor Model	"  In this paper we consider the pricing of options on interest rates such as
caplets and swaptions in the L\'evy Libor model developed by Eberlein and
\""Ozkan (2005). This model is an extension to L\'evy driving processes of the
classical log-normal Libor market model (LMM) driven by a Brownian motion.
Option pricing is significantly less tractable in this model than in the LMM
due to the appearance of stochastic terms in the jump part of the driving
process when performing the measure changes which are standard in pricing of
interest rate derivatives. To obtain explicit approximation for option prices,
we propose to treat a given L\'evy Libor model as a suitable perturbation of
the log-normal LMM. The method is inspired by recent works by Cern\'y, Denkl
and Kallsen (2013) and M\'enass\'e and Tankov (2015). The approximate option
prices in the L\'evy Libor model are given as the corresponding LMM prices plus
correction terms which depend on the characteristics of the underlying L\'evy
process and some additional terms obtained from the LMM model.
"
1511.08718	q-fin	q-fin.CP	Full and fast calibration of the Heston stochastic volatility model	"  This paper presents an algorithm for a complete and efficient calibration of
the Heston stochastic volatility model. We express the calibration as a
nonlinear least squares problem. We exploit a suitable representation of the
Heston characteristic function and modify it to avoid discontinuities caused by
branch switchings of complex functions. Using this representation, we obtain
the analytical gradient of the price of a vanilla option with respect to the
model parameters, which is the key element of all variants of the objective
function. The interdependency between the components of the gradient enables an
efficient implementation which is around ten times faster than a numerical
gradient. We choose the Levenberg-Marquardt method to calibrate the model and
do not observe multiple local minima reported in previous research.
Two-dimensional sections show that the objective function is shaped as a narrow
valley with a flat bottom. Our method is the fastest calibration of the Heston
model developed so far and meets the speed requirement of practical trading.
"
1511.08830	q-fin	q-fin.GN physics.data-an physics.soc-ph q-fin.RM q-fin.ST	"Disentangling bipartite and core-periphery structure in financial
  networks"	"  A growing number of systems are represented as networks whose architecture
conveys significant information and determines many of their properties.
Examples of network architecture include modular, bipartite, and core-periphery
structures. However inferring the network structure is a non trivial task and
can depend sometimes on the chosen null model. Here we propose a method for
classifying network structures and ranking its nodes in a statistically
well-grounded fashion. The method is based on the use of Belief Propagation for
learning through Entropy Maximization on both the Stochastic Block Model (SBM)
and the degree-corrected Stochastic Block Model (dcSBM). As a specific
application we show how the combined use of the two ensembles -SBM and dcSBM-
allows to disentangle the bipartite and the core-periphery structure in the
case of the e-MID interbank network. Specifically we find that, taking into
account the degree, this interbank network is better described by a bipartite
structure, while using the SBM the core-periphery structure emerges only when
data are aggregated for more than a week.
"
1511.08997	q-fin	q-fin.CP	Realized Volatility Analysis in A Spin Model of Financial Markets	"  We calculate the realized volatility in the spin model of financial markets
and examine the returns standardized by the realized volatility. We find that
moments of the standardized returns agree with the theoretical values of
standard normal variables. This is the first evidence that the return dynamics
of the spin financial market is consistent with the view of the
mixture-of-distribution hypothesis that also holds in the real financial
markets.
"
1512.00227	q-fin	q-fin.MF	"A Framework for Analyzing Stochastic Jumps in Finance based on Belief
  and Knowledge"	"  We introduce a formal language IE that is a variant of the language PAL
developed in [van Benthem 2011] by adding a belief operator and a common belief
operator,specializing to stochastic analysis. A constant symbol in the language
denotes a stochastic process so that we can represent several financial events
as formulae in the language, which is expected to be clues of analyzing the
moments that some stochastic jumps such as financial crises occur based on
knowledge and belief of individuals or those shared within groups of
individuals. In order to represent beliefs, we use sigma-complete Boolean
algebras as generalized sigma-algebras. We use the representation for
constructing a model in which the interpretations of the formulae written in
the language IE reside. The model also uses some new categories for integrating
several components appeared in the theory into one.
"
1512.01230	q-fin	physics.soc-ph q-fin.GN	A Theory of Individualism, Collectivism and Economic Outcomes	"  This paper presents a dynamic model to study the impact on the economic
outcomes in different societies during the Malthusian Era of individualism
(time spent working alone) and collectivism (complementary time spent working
with others). The model is driven by opposing forces: a greater degree of
collectivism provides a higher safety net for low quality workers but a greater
degree of individualism allows high quality workers to leave larger bequests.
The model suggests that more individualistic societies display smaller
populations, greater per capita income and greater income inequality. Some
(limited) historical evidence is consistent with these predictions.
"
1512.01267	q-fin	q-fin.EC	Key drivers of EU budget allocation: Does power matter?	"  We examine the determinants of the EU budget expenditures allocation among
different countries. In line with earlier literature, we consider two
alternative explanations for the EU budget distribution: political power vs.
needs view. Extending the original data set from Kauppi and Widgr\'en (2004),
we analyze the robustness of their predictions when applying a different
measure of power and more sophisticated econometric techniques. We conclude
that the nucleolus is a good alternative to the Shapley-Shubik index in
distributive situations such as the case of EU budget allocation. Our results
also show that when explaining budget shares, the relative weight of political
power based on the nucleolus is lower than the predictions of previous studies
based on the Shapley-Shubik index.
"
1512.01488	q-fin	q-fin.MF	Arbitrage and Hedging in model-independent markets with frictions	"  We provide a Fundamental Theorem of Asset Pricing and a Superhedging Theorem
for a model independent discrete time financial market with proportional
transaction costs. We consider a probability-free version of the Robust No
Arbitrage condition introduced in Schachermayer ['04] and show that this is
equivalent to the existence of Consistent Price Systems. Moreover, we prove
that the superhedging price for a claim g coincides with the frictionless
superhedging price of g for a suitable process in the bid-ask spread.
"
1512.01698	q-fin	q-fin.MF	Purely pathwise probability-free Ito integral	"  This paper gives several simple constructions of the pathwise Ito integral
$\int_0^t\phi d\omega$ for an integrand $\phi$ and a price path $\omega$ as
integrator, with $\phi$ and $\omega$ satisfying various topological and
analytical conditions. The definitions are purely pathwise in that neither
$\phi$ nor $\omega$ are assumed to be paths of stochastic processes, and the
Ito integral exists almost surely in a non-probabilistic financial sense. For
example, one of the results shows the existence of $\int_0^t\phi d\omega$ for a
cadlag integrand $\phi$ and a cadlag integrator $\omega$ with jumps bounded in
a predictable manner.
"
1512.02233	q-fin	physics.soc-ph q-fin.GN	"The hidden hyperbolic geometry of international trade: World Trade Atlas
  1870-2013"	"  Here, we present the World Trade Atlas 1870-2013, a collection of annual
world trade maps in which distance combines economic size and the different
dimensions that affect international trade beyond mere geography. Trade
distances, which are based on a gravity model predicting the existence of
significant trade channels, are such that the closer countries are in trade
space, the greater their chance of becoming connected. The atlas provides us
with information regarding the long-term evolution of the international trade
system and demonstrates that, in terms of trade, the world is not flat but
hyperbolic, as a reflection of its complex architecture. The departure from
flatness has been increasing since World War I, meaning that differences in
trade distances are growing and trade networks are becoming more hierarchical.
Smaller-scale economies are moving away from other countries except for the
largest economies; meanwhile those large economies are increasing their chances
of becoming connected worldwide. At the same time, Preferential Trade
Agreements do not fit in perfectly with natural communities within the trade
space and have not necessarily reduced internal trade barriers. We discuss an
interpretation in terms of globalization, hierarchization, and localization;
three simultaneous forces that shape the international trade system.
"
1512.02310	q-fin	q-fin.ST	Sparse Mean-Variance Portfolios: A Penalized Utility Approach	"  This paper considers mean-variance optimization under uncertainty,
specifically when one desires a sparsified set of optimal portfolio weights.
From the standpoint of a Bayesian investor, our approach produces a small
portfolio from many potential assets while acknowledging uncertainty in asset
returns and parameter estimates. We demonstrate the procedure using static and
dynamic models for asset returns.
"
1512.03164	q-fin	q-fin.EC q-fin.GN	Unified Growth Theory Contradicted by the Economic Growth in Africa	"  One of the fundamental postulates of the Unified Growth Theory is the claimed
existence of three distinctly different regimes of economic growth governed by
three distinctly different mechanisms of growth. However, Galor also proposed
that the timing of these regimes is different for developed countries and for
less-developed countries. Africa is the perfect example of economic growth in
less-developed countries. The data used by Galor, but never properly
investigated, are now analysed. They turn out to be in dramatic contradiction
of this theory.
"
1512.03259	q-fin	q-fin.PR	"Derivative pricing for a multi-curve extension of the Gaussian,
  exponentially quadratic short rate model"	"  The recent financial crisis has led to so-called multi-curve models for the
term structure. Here we study a multi-curve extension of short rate models
where, in addition to the short rate itself, we introduce short rate spreads.
In particular, we consider a Gaussian factor model where the short rate and the
spreads are second order polynomials of Gaussian factor processes. This leads
to an exponentially quadratic model class that is less well known than the
exponentially affine class. In the latter class the factors enter linearly and
for positivity one considers square root factor processes. While the square
root factors in the affine class have more involved distributions, in the
quadratic class the factors remain Gaussian and this leads to various
advantages, in particular for derivative pricing. After some preliminaries on
martingale modeling in the multi-curve setup, we concentrate on pricing of
linear and optional derivatives. For linear derivatives, we exhibit an
adjustment factor that allows one to pass from pre-crisis single curve values
to the corresponding post-crisis multi-curve values.
"
1512.03618	q-fin	q-fin.EC q-fin.GN	Macroeconomic Dynamics of Assets, Leverage and Trust	"  A macroeconomic model based on the economic variables (i) assets, (ii)
leverage (defined as debt over asset) and (iii) trust (defined as the maximum
sustainable leverage) is proposed to investigate the role of credit in the
dynamics of economic growth, and how credit may be associated with both
economic performance and confidence. Our first notable finding is the mechanism
of reward/penalty associated with patience, as quantified by the return on
assets. In regular economies where the EBITA/Assets ratio is larger than the
cost of debt, starting with a trust higher than leverage results in the highest
long-term return on assets (which can be seen as a proxy for economic growth).
Our second main finding concerns a recommendation for the reaction of a central
bank to an external shock that affects negatively the economic growth. We find
that late policy intervention in the model economy results in the highest
long-term return on assets and largest asset value. But this comes at the cost
of suffering longer from the crisis until the intervention occurs. The
phenomenon can be ascribed to the fact that postponing intervention allows
trust to increase first, and it is most effective to intervene when trust is
high. These results derive from two fundamental assumptions underlying our
model: (a) trust tends to increase when it is above leverage; (b) economic
agents learn optimally to adjust debt for a given level of trust and amount of
assets. Using a Markov Switching Model for the EBITA/Assets ratio, we have
successfully calibrated our model to the empirical data of the return on equity
of the EURO STOXX 50 for the time period 2000-2013. We find that dynamics of
leverage and trust can be highly non-monotonous with curved trajectories, as a
result of the nonlinear coupling between the variables.
"
1512.04460	q-fin	q-fin.RM physics.soc-ph	"Distress propagation in complex networks: the case of non-linear
  DebtRank"	"  We consider a dynamical model of distress propagation on complex networks,
which we apply to the study of financial contagion in networks of banks
connected to each other by direct exposures. The model that we consider is an
extension of the DebtRank algorithm, recently introduced in the literature. The
mechanics of distress propagation is very simple: When a bank suffers a loss,
distress propagates to its creditors, who in turn suffer losses, and so on. The
original DebtRank assumes that losses are propagated linearly between connected
banks. Here we relax this assumption and introduce a one-parameter family of
non-linear propagation functions. As a case study, we apply this algorithm to a
data-set of 183 European banks, and we study how the stability of the system
depends on the non-linearity parameter under different stress-test scenarios.
We find that the system is characterized by a transition between a regime where
small shocks can be amplified and a regime where shocks do not propagate, and
that the overall stability of the system increases between 2008 and 2013.
"
1512.04916	q-fin	q-fin.CP	Deep Learning Stock Volatility with Google Domestic Trends	"  We have applied a Long Short-Term Memory neural network to model S&P 500
volatility, incorporating Google domestic trends as indicators of the public
mood and macroeconomic factors. In a held-out test set, our Long Short-Term
Memory model gives a mean absolute percentage error of 24.2%, outperforming
linear Ridge/Lasso and autoregressive GARCH benchmarks by at least 31%. This
evaluation is based on an optimal observation and normalization scheme which
maximizes the mutual information between domestic trends and daily volatility
in the training set. Our preliminary investigation shows strong promise for
better predicting stock behavior via deep learning and neural network models.
"
1512.05066	q-fin	q-fin.GN cs.SY physics.soc-ph	"Analyses of Aggregate Fluctuations of Firm Network Based on the
  Self-Organized Criticality Model"	"  This study examine the difference in the size of avalanches among industries
triggered by demand shocks, which can be rephrased by control of the economy or
fiscal policy, and by using the production-inventory model and observed data.
We obtain the following results. (1) The size of avalanches follows power law.
(2) The mean sizes of avalanches for industries are diverse but their standard
deviations highly overlap. (3) We compare the simulation with an input-output
table and with the actual policies. They are compatible.
"
1512.05074	q-fin	q-fin.GN q-fin.EC	Unified Growth Theory Contradicted by the Economic Growth in Asia	"  Historical economic growth in Asia (excluding Japan) is analysed. It is shown
that Unified Growth Theory is contradicted by the data, which were used (but
not analysed) during the formulation of this theory. Unified Growth Theory does
not explain the mechanism of economic growth. It explains the mechanism of
Malthusian stagnation, which did not exist and it explains the mechanism of the
transition from stagnation to growth that did not happen. The data show that
the economic growth in Asia was never stagnant but hyperbolic. The alleged
dramatic takeoff around 1900 or around any other time did not happen. However,
the theory contains also a dangerous and strongly-misleading concept that after
a long epoch of stagnation we have now entered the epoch of sustained economic
growth, the concept creating the sense of security. The opposite is true. After
the epoch of sustained and secure economic growth we have now entered the epoch
of a fast-increasing and insecure economic growth.
"
1512.06309	q-fin	q-fin.GN q-fin.EC	"Unified Growth Theory Contradicted by the Economic Growth in the Former
  USSR"	"  Historical economic growth in countries of the former USSR is analysed. It is
shown that Unified Growth Theory is contradicted by the data, which were used,
but not analysed, during the formulation of this theory. Unified Growth Theory
does not explain the mechanism of economic growth. It explains the mechanism of
Malthusian stagnation, which did not exist and it explains the mechanism of the
transition from stagnation to growth that did not happen. Unified Growth Theory
is full of stories but it is hard to decide which of them are reliable because
they are based on unprofessional examination of data. The data show that the
economic growth in the former USSR was never stagnant but hyperbolic.
Industrial Revolution did not boost the economic growth in the former USSR.
Unified Growth Theory needs to be revised or replaced by a reliable theory to
reconcile it with data and to avoid creating the unwarranted sense of security
about the current economic growth.
"
1512.06454	q-fin	q-fin.MF	"Consistent Re-Calibration of the Discrete-Time Multifactor Vasi\v{c}ek
  Model"	"  The discrete-time multifactor Vasi\v{c}ek model is a tractable Gaussian spot
rate model. Typically, two- or three-factor versions allow one to capture the
dependence structure between yields with different times to maturity in an
appropriate way. In practice, re-calibration of the model to the prevailing
market conditions leads to model parameters that change over time. Therefore,
the model parameters should be understood as being time-dependent or even
stochastic. Following the consistent re-calibration (CRC) approach, we
construct models as concatenations of yield curve increments of Hull-White
extended multifactor Vasi\v{c}ek models with different parameters. The CRC
approach provides attractive tractable models that preserve the no-arbitrage
premise. As a numerical example, we fit Swiss interest rates using CRC
multifactor Vasi\v{c}ek models.
"
1512.06812	q-fin	q-fin.MF	Uniform bounds for Black--Scholes implied volatility	"  In this note, Black--Scholes implied volatility is expressed in terms of
various optimisation problems. From these representations, upper and lower
bounds are derived which hold uniformly across moneyness and call price.
Various symmetries of the Black--Scholes formula are exploited to derive new
bounds from old. These bounds are used to reprove asymptotic formulae for
implied volatility at extreme strikes and/or maturities.
"
1512.07337	q-fin	q-fin.PR	MVA Transfer Pricing	"  This article prices OTC derivatives with either an exogenously determined
initial margin profile or endogenously approximated initial margin. In the
former case, margin valuation adjustment (MVA) is defined as the liability-side
discounted expected margin profile, while in the latter, an extended partial
differential equation is derived and solved for an all-in fair value,
decomposable into coherent CVA, FVA and MVA. For uncollateralized customer
trades, MVA can be transferred to the customer via an extension of the
liability-side pricing theory. For BCBS-IOSCO covered OTC derivatives, a market
maker has to charge financial counterparties a bid-ask spread to transfer its
funding cost. An IM multiplier is applied to calibrate to external IM models to
allow portfolio incremental pricing. In particular, a link to ISDA SIMM for
equity, commodity and fx risks is established through the PDE with its vega and
curvature IM components captured fully. Numerical examples are given for swaps
and equity portfolios and offer a plausible attribution of recent CME-LCH basis
spread widening to elevated MVA accompanying dealers' hedging of customer
flows.
"
1512.07340	q-fin	q-fin.PR	"Liability-side Pricing of Swaps and Coherent CVA and FVA by
  Regression/Simulation"	"  An uncollateralized swap hedged back-to-back by a CCP swap is used to
introduce FVA. The open IR01 of FVA, however, is a sure sign of risk not being
fully hedged, a theoretical no-arbitrage pricing concern, and a bait to lure
market risk capital, a practical business concern. By dynamically trading the
CCP swap, with the liability-side counterparty provides counterparty exposure
hedge and swap funding, we find that the uncollateralized swap can be fully
replicated, leaving out no IR01 leakage. The fair value of the swap is obtained
by applying to swap's net cash flows a discount rate switching to
counterparty's bond curve if the swap is a local asset or one's own curve if a
liability, and the total valuation adjustment is the present value of cost of
funding the risk-free price discounted at the same switching rate. FVA is
redefined as a liquidity or funding basis component of total valuation
adjustment, coherent with CVA, the default risk component. A Longstaff-Schwartz
style least-square regression and simulation is introduced to compute the
recursive fair value and adjustments. A separately developed finite difference
scheme is used to test and find regression necessary to decouple the discount
rate switch. Preliminary results show the impact of counterparty risk to swap
hedge ratios, swap bid/ask spreads, and valuation adjustments, and considerable
errors of calculating CVA by discounting cash flow or potential future
exposure.
"
1512.08067	q-fin	q-fin.EC	Unified Growth Theory Contradicted by the Economic Growth in Europe	"  Historical economic growth in Western and Eastern Europe is analysed. These
regions should have produced the best and the most convincing confirmation of
the Unified Growth Theory because they, and in particular Western Europe, were
the centre of the Industrial Revolution, which according to Galor was the prime
engine of economic growth. However, the data for Western and Eastern Europe
show a remarkable disagreement with the Unified Growth Theory. There is no
connection, whatever, between the data and the Unified Growth Theory. The data
show that there was never a transition from stagnation to growth because there
was no stagnation. Industrial Revolution, which should have the strongest
influence in these regions, had absolutely no impact on changing the economic
growth trajectories. The alleged remarkable or stunning escape from Malthusian
trap did not happen because there was no trap. Unified Growth Theory does not
explain the mechanism of the economic growth because its explanations are based
on mythical features, which did not exist, the features contradicted by data.
This theory needs to be either thoroughly revised or most likely replaced by a
theory supported by a professional analysis of economic growth data.
"
1512.08098	q-fin	math.OC q-fin.PM	On a Generalization of Markowitz Preference Relation	"  Given two families of continuous functions $u$ and $v$ on a topological space
$X$, we define a preorder $R=R(u,v)$ on $X$ by the condition that any member of
$u$ is an $R$-increasing and any member of $v$ is an $R$-decreasing function.
It turns out that if the topological space $X$ is quasi-compact and
sequentially compact, then any element of $X$ is $R$-dominated by an
$R$-maximal element of $X$. In particular, since the $(n-1)$-dimensional
simplex is a compact subset of the real $n$-dimensional vector space, then
considering its members as portfolios consisting of $n$ financial assets, we
obtain the classical 1952 result of Harry Markowitz that any portfolio is
dominated by an efficient portfolio. Moreover, several other examples of
possible application of this general setup are presented.
"
1512.09280	q-fin	q-fin.RM	"On the Fractal Geometry of the Balance Sheet and the Fractal Index of
  Insolvency Risk"	"  This paper reviews the economic and theoretical foundations of insolvency
risk measurement and capital adequacy rules. The proposed new measure of
insolvency risk is constructed by disentangling assets, debt and equity at the
micro-prudential firm level. This new risk index is the Firm Insolvency Risk
Index (FIRI) which is symmetrical, proportional and scale invariant. We
demonstrate that the balance sheet can be shown to evolve with a fractal
pattern. As such we construct a fractal index that can measure the risk of
assets. This index can differentiate between the similarity and dissimilarity
in asset risk, and it will also possess the properties of being self-similar
and invariant to firm characteristics that make up its asset composition hence
invariant to all types of risk derived from assets. Self-similarity and scale
invariance across the cross section allows direct comparison of degrees of risk
in assets. This is by comparing the risk dissimilarity of assets. Being
naturally bounded to its highest upper bound, (0,2], the fractal index is able
to serve like a risk thermometer. We assign geometric probabilities of
insolvency P (equity is equal or less than 0 conditional on debt being greater
than 0).
"
1601.00085	q-fin	q-fin.EC q-fin.GN	"Dynamic Multi-Factor Bid-Offer Adjustment Model: A Feedback Mechanism
  for Dealers (Market Makers) to Deal (Grapple) with the Uncertainty Principle
  of the Social Sciences"	"  The author seeks to develop a model to alter the bid-offer spread, currently
quoted by market makers, that varies with the market and trading conditions.
The dynamic nature of financial markets and trading, as with the rest of social
sciences, where changes can be observed and decisions can be made by
participants to influence the system, means that this model has to be adaptive
and include a feedback loop that alters the bid-offer adjustment based on the
modifications observed in the market and trading conditions, without a
significant time delay.
  The factors used to adjust the spread are price volatility, which is publicly
observable, and trade count and volume, which are generally known only to the
market maker, in various instruments over different historical durations in
time. The contributions of each factor to the bid-offer adjustment are computed
separately and then consolidated to produce a very adaptive bid-offer
quotation. The author uses the currency markets to build the sample model
because they are extremely liquid and trading in them is not as transparent as
other financial instruments, such as equities. Simulating the number of trades
and the average size of trades from a lognormal distribution, the parameters of
the lognormal distributions are chosen such that the total volume in a certain
interval matches the volume publicly mentioned by currency trading firms. This
methodology can easily be extended to other financial instruments and possibly
to any product with the ability to make electronic price quotations, or can
even be used to periodically perform manual price updates on products that are
traded non-electronically.
"
1601.00092	q-fin	q-fin.GN	Hyperinflation in Brazil, Israel, and Nicaragua revisited	"  The aim of this work is to address the description of hyperinflation regimes
in economy. The spirals of hyperinflation developed in Brazil, Israel, and
Nicaragua are revisited. This new analysis of data indicates that the episodes
occurred in Brazil and Nicaragua can be understood within the frame of the
model available in the literature, which is based on a nonlinear feedback (NLF)
characterized by an exponent $\beta>0$. In the NLF model the accumulated
consumer price index carries a finite time singularity of the type
$1/(t_c-t)^{(1- \beta)/\beta}$ determining a critical time $t_c$ at which the
economy would crash. It is shown that in the case of Brazil the entire episode
cannot be described with a unique set of parameters because the time series was
strongly affected by a change of policy. This fact gives support to the ""so
called"" Lucas critique, who stated that model's parameters usually change once
policy changes. On the other hand, such a model is not able to provide any
$t_c$ in the case of the weaker hyperinflation occurred in Israel. It is shown
that in this case the fit of data yields $\beta \to 0$. This limit leads to the
linear feedback formulation which does not predict any $t_c$. An extension for
the NLF model is suggested.
"
1601.00175	q-fin	q-fin.PM	"Minimax perfect stopping rules for selling an asset near its ultimate
  maximum"	"  We study the problem of selling an asset near its ultimate maximum in the
minimax setting. The regret-based notion of a perfect stopping time is
introduced. A perfect stopping time is uniquely characterized by its optimality
properties and has the following form: one should sell the asset if its price
deviates from the running maximum by a certain time-dependent quantity. The
related selling rule improves any earlier one and cannot be improved by further
delay. The results, which are applicable to a quite general price model, are
illustrated by several examples.
"
1601.00233	q-fin	q-fin.GN physics.soc-ph	"Long-run evolution of the global economy - Part 2: Hindcasts of
  innovation and growth"	"  Long-range climate forecasts use integrated assessment models to link the
global economy to greenhouse gas emissions. This paper evaluates an alternative
economic framework outlined in part 1 of this study (Garrett, 2014) that
approaches the global economy using purely physical principles rather than
explicitly resolved societal dynamics. If this model is initialized with
economic data from the 1950s, it yields hindcasts for how fast global economic
production and energy consumption grew between 2000 and 2010 with skill scores
> 90 % relative to a model of persistence in trends. The model appears to
attain high skill partly because there was a strong impulse of discovery of
fossil fuel energy reserves in the mid-twentieth century that helped
civilization to grow rapidly as a deterministic physical response. Forecasting
the coming century may prove more of a challenge because the effect of the
energy impulse appears to have nearly run its course. Nonetheless, an
understanding of the external forces that drive civilization may help
development of constrained futures for the coupled evolution of civilization
and climate during the Anthropocene.
"
1601.00354	q-fin	q-fin.MF q-fin.GN	Black-Litterman model with intuitionistic fuzzy posterior return	"  The main objective is to present a some variant of the Black - Litterman
model. We consider the canonical case when priori return is determined by means
such excess return from the CAPM market portfolio which is derived using
reverse optimization method. Then the a priori return is at risk quantified
uncertainty. On the side, intensive discussion shows that the experts' views
are under knightian uncertainty. For this reason, we propose such variant of
the Black - Litterman model in which the experts' views are described as
intuitionistic fuzzy number. The existence of posterior return is proved for
this case.We show that then posterior return is an intuitionistic fuzzy
probabilistic set.
"
1601.00566	q-fin	q-fin.ST	No Stable Distributions in Finance, please!	"  Failure of the main argument for the use of heavy tailed distribution in
Finance is given. More precisely, one cannot observe so many outliers for
Cauchy or for symmetric stable distributions as we have in reality.
keywords:outliers; financial indexes; heavy tails; Cauchy distribution; stable
distributions
"
1601.00679	q-fin	q-fin.EC	"Essay on the State of Research and Innovation in France and the European
  Union"	"  Innovation in the economy is an important engine of growth and no economy,
whatever its complexity and degree of advancement, whether it is based on
industry, agriculture, high tech or the providing of services, can be truly
healthy without innovating actors within it. The aim of this work, done by an
applied mathematician working in finance, not by an economist or a lawyer,
isn't to provide an exhaustive view of the all the mechanisms in France and in
Europe that aim at fostering innovation in the economy and to offer solutions
for removing all the roadblocks that still hinder innovation; indeed such a
study would go far beyond the scope of this study. What I modestly attempted to
achieve in this study was firstly to draw a panorama of what is working and
what needs to perfected as far as innovation is concerned in France and Europe,
then secondly to offer some solutions and personal thoughts to boost
innovation.
"
1601.00712	q-fin	q-fin.PM math.OC	"Multistage Portfolio Optimization: A Duality Result in Conic Market
  Models"	"  We prove a general duality result for multi-stage portfolio optimization
problems in markets with proportional transaction costs. The financial market
is described by Kabanov's model of foreign exchange markets over a finite
probability space and finite-horizon discrete time steps. This framework allows
us to compare vector-valued portfolios under a partial ordering, so that our
model does not require liquidation into some numeraire at terminal time.
  We embed the vector-valued portfolio problem into the set-optimization
framework, and generate a problem dual to portfolio optimization. Using recent
results in the development of set optimization, we then show that a strong
duality relationship holds between the problems.
"
1601.00903	q-fin	q-fin.GN	Long memory and multifractality: A joint test	"  The properties of statistical tests for hypotheses concerning the parameters
of the multifractal model of asset returns (MMAR) are investigated, using Monte
Carlo techniques. We show that, in the presence of multifractality,
conventional tests of long memory tend to over-reject the null hypothesis of no
long memory. Our test addresses this issue by jointly estimating long memory
and multifractality. The estimation and test procedures are applied to exchange
rate data for 12 currencies. In 11 cases, the exchange rate returns are
accurately described by compounding a NIID series with a multifractal
time-deformation process. There is no evidence of long memory.
"
1601.00919	q-fin	q-fin.CP	"Exponential integrability properties of Euler discretization schemes for
  the Cox-Ingersoll-Ross process"	"  We analyze exponential integrability properties of the Cox-Ingersoll-Ross
(CIR) process and its Euler discretizations with various types of truncation
and reflection at 0. These properties play a key role in establishing the
finiteness of moments and the strong convergence of numerical approximations
for a class of stochastic differential equations arising in finance. We prove
that both implicit and explicit Euler-Maruyama discretizations for the CIR
process preserve the exponential integrability of the exact solution for a wide
range of parameters, and find lower bounds on the explosion time.
"
1601.00940	q-fin	q-fin.PR	Pricing barrier options with discrete dividends	"  The presence of discrete dividends complicates the derivation and form of
pricing formulas even for vanilla options. Existing analytic, numerical, and
theoretical approximations provide results of varying quality and performance.
Here, we compare the analytic approach, developed and effective for European
puts and calls, of Buryak and Guo with the formulas, designed in the context of
barrier option pricing, of Dai and Chiu.
"
1601.00991	q-fin	q-fin.PM	101 Formulaic Alphas	"  We present explicit formulas - that are also computer code - for 101
real-life quantitative trading alphas. Their average holding period
approximately ranges 0.6-6.4 days. The average pair-wise correlation of these
alphas is low, 15.9%. The returns are strongly correlated with volatility, but
have no significant dependence on turnover, directly confirming an earlier
result based on a more indirect empirical analysis. We further find empirically
that turnover has poor explanatory power for alpha correlations.
"
1601.01128	q-fin	q-fin.CP math.PR q-fin.PR	"Option pricing in the model with stochastic volatility driven by
  Ornstein--Uhlenbeck process. Simulation"	"  We consider a discrete-time approximation of paths of an Ornstein--Uhlenbeck
process as a mean for estimation of a price of European call option in the
model of financial market with stochastic volatility. The Euler--Maruyama
approximation scheme is implemented. We determine the estimates for the option
price for predetermined sets of parameters. The rate of convergence of the
price and an average volatility when discretization intervals tighten are
determined. Discretization precision is analyzed for the case where the exact
value of the price can be derived.
"
1601.01352	q-fin	q-fin.MF math.PR	A unified view of LIBOR models	"  We provide a unified framework for modeling LIBOR rates using general
semimartingales as driving processes and generic functional forms to describe
the evolution of the dynamics. We derive sufficient conditions for the model to
be arbitrage-free which are easily verifiable, and for the LIBOR rates to be
true martingales under the respective forward measures. We discuss when the
conditions are also necessary and comment on further desirable properties such
as those leading to analytical tractability and positivity of rates. This
framework allows to consider several popular models in the literature, such as
LIBOR market models driven by Brownian motion or jump processes, the L\'evy
forward price model as well as the affine LIBOR model, under one umbrella.
Moreover, we derive structural results about LIBOR models and show, in
particular, that only models where the forward price is an exponentially affine
function of the driving process preserve their structure under different
forward measures.
"
1601.01553	q-fin	q-fin.TR q-fin.MF	"Modelling and Measuring the Irrational behaviour of Agents in Financial
  Markets: Discovering the Psychological Soliton"	"  Following a Geometrical Brownian Motion extension into an Irrational
Fractional Brownian Motion model, we re-examine agent behaviour reacting to
time dependent news on the log-returns thereby modifying a financial market
evolution. We specifically discuss the role of financial news or economic
information positive or negative feedback of such irrational (or contrarian)
agents upon the price evolution. We observe a kink-like effect reminiscent of
soliton behaviour, suggesting how analysts' forecasts errors induce stock
prices to adjust accordingly, thereby proposing a measure of the irrational
force in a market.
"
1601.01710	q-fin	q-fin.MF q-fin.TR	A Semi-Markovian Modeling of Limit Order Markets	"  R. Cont and A. de Larrard (SIAM J. Finan. Math, 2013) introduced a tractable
stochastic model for the dynamics of a limit order book, computing various
quantities of interest such as the probability of a price increase or the
diffusion limit of the price process. As suggested by empirical observations,
we extend their framework to 1) arbitrary distributions for book events
inter-arrival times (possibly non-exponential) and 2) both the nature of a new
book event and its corresponding inter-arrival time depend on the nature of the
previous book event. We do so by resorting to Markov renewal processes to model
the dynamics of the bid and ask queues. We keep analytical tractability via
explicit expressions for the Laplace transforms of various quantities of
interest. We justify and illustrate our approach by calibrating our model to
the five stocks Amazon, Apple, Google, Intel and Microsoft on June 21^{st}
2012. As in R. Cont and A. de Larrard, the bid-ask spread remains constant
equal to one tick, only the bid and ask queues are modeled (they are
independent from each other and get reinitialized after a price change), and
all orders have the same size.
"
1601.01753	q-fin	physics.soc-ph q-fin.ST	"Geography and distance effect on financial dynamics in the Chinese stock
  market"	"  Geography effect is investigated for the Chinese stock market including the
Shanghai and Shenzhen stock markets, based on the daily data of individual
stocks. The Shanghai city and the Guangdong province can be identified in the
stock geographical sector. By investigating a geographical correlation on a
geographical parameter, the stock location is found to have an impact on the
financial dynamics, except for the financial crisis time of the Shenzhen
market. Stock distance effect is further studied, with a crossover behavior
observed for the stock distance distribution. The probability of the short
distance is much greater than that of the long distance. The average stock
correlation is found to weakly decay with the stock distance for the Shanghai
stock market, but stays nearly stable for different stock distance for the
Shenzhen stock market.
"
1601.01771	q-fin	q-fin.EC	"Teaching Economics and Providing Visual ""Big Pictures"""	"  The goal of this paper is to investigate the importance of providing visual
""big pictures"" in the teaching of economics. The plurality and variety of
concepts, variables, diagrams, and models involved in economics can be a source
of confusion for many economics students. However, reviewing the existing
literature on the importance of providing visual ""big pictures"" in the process
of learning suggests that furnishing students with a visual ""big picture"" that
illustrates the ways through which those numerous, diverse concepts are
connected to each other could be an effective solution to clear up the
mentioned mental chaos. As a practical example, this paper introduces a ""big
picture"" that can be used as a good resource in intermediate macroeconomics
classes. This figure presents twenty-seven commonly-discussed macroeconomic
diagrams in the intermediate macroeconomics course, and gives little detail on
some of these diagrams, aiming at helping students to get the whole picture at
once on a single piece of paper. This macroeconomics big picture mostly focuses
on the routes through which common diagrams in macroeconomics are connected to
each other, and finally introduces the general macroeconomic equilibrium that
is graphically derived through those connections.
"
1601.01804	q-fin	q-fin.GN q-fin.EC	"Unified Growth Theory Contradicted by the Economic Growth in Latin
  America"	"  Historical economic growth in Latin America is analysed using the data of
Maddison. Unified Growth Theory is found to be contradicted by these data in
the same way as it is contradicted by the economic growth in Africa, Asia,
former USSR, Western Europe, Eastern Europe and by the world economic growth.
Paradoxically, Unified Growth Theory is repeatedly and consistently
contradicted by the same data, which were used, but never properly analysed,
during the formulation of this theory. Unified Growth Theory does not explain
the mechanism of the economic growth because it explains features contradicted
by data. This theory is based fundamentally on the unfortunate lack of
understanding of the properties of hyperbolic distribution and on the
unscientific analysis of data. There was no transition from stagnation to
growth at the end of the alleged Malthusian regime because the economic growth
was hyperbolic. There was no escape from Malthusian trap because there was no
trap. There was no takeoff. On the contrary, at the time of the alleged takeoff
economic growth started to be diverted to a slower trajectory. Unified Growth
Theory is dissociated from the reality. This theory needs to be revised or
replaced. In its present form, it is a collection of irrelevant stories based
on impressions and on the unscientific use of data.
"
1601.01811	q-fin	math.PR q-fin.MF	Brownian Bridges on Random Intervals	"  The issue of giving an explicit description of the flow of information
concerning the time of bankruptcy of a company (or a state) arriving on the
market is tackled by defining a bridge process starting from zero and
conditioned to be equal to zero when the default occurs. This enables to catch
some empirical facts on the behavior of financial markets: when the bridge
process is away from zero, investors can be relatively sure that the default
will not happen immediately. However, when the information process is close to
zero, market agents should be aware of the risk of an imminent default. In this
sense the bridge process leaks information concerning the default before it
occurs. The objective of this first paper on Brownian bridges on stochastic
intervals is to provide the basic properties of these processes.
"
1601.01980	q-fin	q-fin.ST physics.data-an	Irreversibility of financial time series: a graph-theoretical approach	"  The relation between time series irreversibility and entropy production has
been recently investigated in thermodynamic systems operating away from
equilibrium. In this work we explore this concept in the context of financial
time series. We make use of visibility algorithms to quantify in
graph-theoretical terms time irreversibility of 35 financial indices evolving
over the period 1998-2012. We show that this metric is complementary to
standard measures based on volatility and exploit it to both classify periods
of financial stress and to rank companies accordingly. We then validate this
approach by finding that a projection in principal components space of
financial years based on time irreversibility features clusters together
periods of financial stress from stable periods. Relations between
irreversibility, efficiency and predictability are briefly discussed.
"
1601.01987	q-fin	q-fin.TR	Deep Learning for Limit Order Books	"  This paper develops a new neural network architecture for modeling spatial
distributions (i.e., distributions on R^d) which is computationally efficient
and specifically designed to take advantage of the spatial structure of limit
order books. The new architecture yields a low-dimensional model of price
movements deep into the limit order book, allowing more effective use of
information from deep in the limit order book (i.e., many levels beyond the
best bid and best ask). This ""spatial neural network"" models the joint
distribution of the state of the limit order book at a future time conditional
on the current state of the limit order book. The spatial neural network
outperforms other models such as the naive empirical model, logistic regression
(with nonlinear features), and a standard neural network architecture. Both
neural networks strongly outperform the logistic regression model. Due to its
more effective use of information deep in the limit order book, the spatial
neural network especially outperforms the standard neural network in the tail
of the distribution, which is important for risk management applications. The
models are trained and tested on nearly 500 stocks. Techniques from deep
learning such as dropout are employed to improve performance. Due to the
significant computational challenges associated with the large amount of data,
models are trained with a cluster of 50 GPUs.
"
1601.02149	q-fin	q-fin.PR stat.ME	"Computing semiparametric bounds on the expected payments of insurance
  instruments via column generation"	"  It has been recently shown that numerical semiparametric bounds on the
expected payoff of fi- nancial or actuarial instruments can be computed using
semidefinite programming. However, this approach has practical limitations.
Here we use column generation, a classical optimization technique, to address
these limitations. From column generation, it follows that practical univari-
ate semiparametric bounds can be found by solving a series of linear programs.
In addition to moment information, the column generation approach allows the
inclusion of extra information about the random variable; for instance,
unimodality and continuity, as well as the construction of corresponding
worst/best-case distributions in a simple way.
"
1601.02246	q-fin	q-fin.PR math.PR	Negative interest rates: why and how?	"  The interest rates (or nominal yields) can be negative, this is an
unavoidable fact which has already been visible during the Great Depression
(1929-39). Nowadays we can find negative rates easily by e.g. auditing. Several
theoretical and practical ideas how to model and eventually overcome empirical
negative rates can be suggested, however, they are far beyond a simple
practical realization. In this paper we discuss the dynamical reasons why
negative interest rates can happen in the second order differential dynamics
and how they can influence the variance and expectation of the interest rate
process. Such issues are highly practical, involving e.g. banking sector and
pension securities.
"
1601.02407	q-fin	q-fin.ST	"Decomposition of Time Series Data of Stock Markets and its Implications
  for Prediction: An Application for the Indian Auto Sector"	"  With the rapid development and evolution of sophisticated algorithms for
statistical analysis of time series data, the research community has started
spending considerable effort in technical analysis of such data. Forecasting is
also an area which has witnessed a paradigm shift in its approach. In this
work, we have used the time series of the index values of the Auto sector in
India during January 2010 to December 2015 for a deeper understanding of the
behavior of its three constituent components, e.g., the Trend, the Seasonal
component, and the Random component. Based on this structural analysis, we have
also designed three approaches for forecasting and also computed their accuracy
in prediction using suitably chosen training and test data sets. The results
clearly demonstrate the accuracy of our decomposition results and efficiency of
our forecasting techniques, even in presence of a dominant Random component in
the time series.
"
1601.02677	q-fin	q-fin.EC physics.soc-ph	Dependence of technological improvement on artifact interactions	"  Empirical research has shown performance improvement of many different
technological domains occurs exponentially but with widely varying improvement
rates. What causes some technologies to improve faster than others do? Previous
quantitative modeling research has identified artifact interactions, where a
design change in one component influences others, as an important determinant
of improvement rates. The models predict that improvement rate for a domain is
proportional to the inverse of the domain interaction parameter. However, no
empirical research has previously studied and tested the dependence of
improvement rates on artifact interactions. A challenge to testing the
dependence is that any method for measuring interactions has to be applicable
to a wide variety of technologies. Here we propose a patent-based method that
is both technology domain-agnostic and less costly than alternative methods. We
use textual content from patent sets in 27 domains to find the influence of
interactions on improvement rates. Qualitative analysis identified six specific
keywords that signal artifact interactions. Patent sets from each domain were
then examined to determine the total count of these 6 keywords in each domain,
giving an estimate of artifact interactions in each domain. It is found that
improvement rates are positively correlated with the inverse of the total count
of keywords with correlation coefficient of +0.56 with a p-value of 0.002. The
empirical results agree with model predictions and support the suggestion that
domains with higher number of artifacts interactions (higher complexity) will
improve at a slower pace.
"
1601.02990	q-fin	physics.soc-ph q-fin.GN	The invisible hand and the rational agent are behind bubbles and crashes	"  The substantial turmoil created by both 2000 dot-com crash and 2008 subprime
crisis has fueled the belief that the two classical paradigms of economics,
which are the invisible hand and the rational agent, are not appropriate to
describe market dynamics and should be abandoned at the benefit of alternative
new theoretical concepts. At odd with such a view, using a simple model of
choice dynamics from sociophysics, the invisible hand and the rational agent
paradigms are given a new legitimacy. Indeed, it is sufficient to introduce the
holding of a few intermediate mini market aggregations by agents sharing their
own private information, to recenter the invisible hand and the rational agent
at the heart of market self regulation including the making of bubbles and
their subsequent crashes. In so doing, an elasticity is discovered in the
market efficiency mechanism due to the existence of agents anticipation. This
elasticity is found to create spontaneous bubbles, which are rationally
founded, and at the same time, it provokes crashes when the limit of elasticity
is reached. Although the findings disclose a path to put an end to the
bubble-crash phenomena, it is argued to be rationality not feasible.
"
1601.03015	q-fin	q-fin.RM	Credit risk: Taking fluctuating asset correlations into account	"  In structural credit risk models, default events and the ensuing losses are
both derived from the asset values at maturity. Hence it is of utmost
importance to choose a distribution for these asset values which is in
accordance with empirical data. At the same time, it is desirable to still
preserve some analytical tractability. We achieve both goals by putting forward
an ensemble approach for the asset correlations. Consistently with the data, we
view them as fluctuating quantities, for which we may choose the average
correlation as homogeneous. Thereby we can reduce the number of parameters to
two, the average correlation between assets and the strength of the
fluctuations around this average value. Yet, the resulting asset value
distribution describes the empirical data well. This allows us to derive the
distribution of credit portfolio losses. With Monte-Carlo simulations for the
Value at Risk and Expected Tail Loss we validate the assumptions of our
approach and demonstrate the necessity of taking fluctuating correlations into
account.
"
1601.03067	q-fin	physics.soc-ph q-fin.GN stat.AP	International Trade: a Reinforced Urn Network Model	"  We propose a unified modelling framework that theoretically justifies the
main empirical regularities characterizing the international trade network.
Each country is associated to a Polya urn whose composition controls the
propensity of the country to trade with other countries. The urn composition is
updated through the walk of the Reinforced Urn Process of Muliere et al.
(2000). The model implies a local preferential attachment scheme and a power
law right tail behaviour of bilateral trade flows. Different assumptions on the
urns' reinforcement parameters account for local clustering, path-shortening
and sparsity. Likelihood-based estimation approaches are facilitated by
feasible likelihood analytical derivation in various network settings. A
simulated example and the empirical results on the international trade network
are discussed.
"
1601.03171	q-fin	q-fin.RM	On a law of large numbers for insurance risks	"  This note presents a kind of the strong law of large numbers for an insurance
risk caused by a single catastrophic event rather than by an accumulation of
independent and identically distributed risks. We derive this result by a large
diversification effect resulting from optimal allocation of the risk to many
reinsurers or investors.
"
1601.03380	q-fin	q-fin.MF math.OC	Quantile hedging on markets with proportional transaction costs	"  In the paper a problem of risk measures on a discrete-time market model with
transaction costs is studied. Strategy effectiveness and shortfall risk is
introduced. This paper is a generalization of quantile hedging presented in
[4].
"
1601.03388	q-fin	q-fin.MF math.OC	Large losses - probability minimizing approach	"  The probability minimizing problem of large losses of portfolio in discrete
and continuous time models is studied. This gives a generalization of quantile
hedging presented in [3].
"
1601.03435	q-fin	q-fin.RM q-fin.PM	Asymptotic Analysis for Optimal Dividends in a Dual Risk Model	"  The dual risk model is a popular model in finance and insurance, which is
often used to model the wealth process of a venture capital or high tech
company. Optimal dividends have been extensively studied in the literature for
the dual risk model. It is well known that the value function of this optimal
control problem does not yield closed-form solutions except in some special
cases. In this paper, we study the asymptotics of the optimal dividends problem
when the parameters of the model go to either zero or infinity. Our results
provide insights to the optimal strategies and the optimal values when the
parameters are extreme.
"
1601.03562	q-fin	q-fin.MF math.OC math.PR q-fin.PM	Convex duality for stochastic differential utility	"  This paper introduces a dual problem to study a continuous-time consumption
and investment problem with incomplete markets and stochastic differential
utility. For Epstein-Zin utility, duality between the primal and dual problems
is established. Consequently the optimal strategy of the consumption and
investment problem is identified without assuming several technical conditions
on market model, utility specification, and agent's admissible strategy.
Meanwhile the minimizer of the dual problem is identified as the utility
gradient of the primal value and is economically interpreted as the ""least
favorable"" completion of the market.
"
1601.03574	q-fin	math.PR q-fin.MF	Generalization of Doob decomposition Theorem	"  In the paper, we introduce the notion of a local regular supermartingale
relative to a convex set of equivalent measures and prove for it an optional
Doob decomposition in the discrete case. This Theorem is a generalization of
the famous Doob decomposition onto the case of supermartingales relative to a
convex set of equivalent measures.
"
1601.03688	q-fin	cond-mat.stat-mech q-bio.GN q-fin.ST	"Inter-occurrence times and universal laws in finance, earthquakes and
  genomes"	"  A plethora of natural, artificial and social systems exist which do not
belong to the Boltzmann-Gibbs (BG) statistical-mechanical world, based on the
standard additive entropy $S_{BG}$ and its associated exponential BG factor.
Frequent behaviors in such complex systems have been shown to be closely
related to $q$-statistics instead, based on the nonadditive entropy $S_q$ (with
$S_1=S_{BG}$), and its associated $q$-exponential factor which generalizes the
usual BG one. In fact, a wide range of phenomena of quite different nature
exist which can be described and, in the simplest cases, understood through
analytic (and explicit) functions and probability distributions which exhibit
some universal features. Universality classes are concomitantly observed which
can be characterized through indices such as $q$. We will exhibit here some
such cases, namely concerning the distribution of inter-occurrence (or
inter-event) times in the areas of finance, earthquakes and genomes.
"
1601.04093	q-fin	q-fin.EC	A Statistical Model of Inequality	"  This paper develops a nonparametric statistical model of wealth distribution
that imposes little structure on the fluctuations of household wealth. In this
setting, we use new techniques to obtain a closed-form household-by-household
characterization of the stable distribution of wealth and show that this
distribution is shaped entirely by two factors - the reversion rates (a measure
of cross-sectional mean reversion) and idiosyncratic volatilities of wealth
across different ranked households. By estimating these factors, our model can
exactly match the U.S. wealth distribution. This provides information about the
current trajectory of inequality as well as estimates of the distributional
effects of progressive capital taxes. We find evidence that the U.S. wealth
distribution might be on a temporarily unstable trajectory, thus suggesting
that further increases in top wealth shares are likely in the near future. For
capital taxes, we find that a small tax levied on just 1% of households
substantially reshapes the distribution of wealth and reduces inequality.
"
1601.04210	q-fin	q-fin.MF	Speculative Futures Trading under Mean Reversion	"  This paper studies the problem of trading futures with transaction costs when
the underlying spot price is mean-reverting. Specifically, we model the spot
dynamics by the Ornstein-Uhlenbeck (OU), Cox-Ingersoll-Ross (CIR), or
exponential Ornstein-Uhlenbeck (XOU) model. The futures term structure is
derived and its connection to futures price dynamics is examined. For each
futures contract, we describe the evolution of the roll yield, and compute
explicitly the expected roll yield. For the futures trading problem, we
incorporate the investor's timing option to enter or exit the market, as well
as a chooser option to long or short a futures upon entry. This leads us to
formulate and solve the corresponding optimal double stopping problems to
determine the optimal trading strategies. Numerical results are presented to
illustrate the optimal entry and exit boundaries under different models. We
find that the option to choose between a long or short position induces the
investor to delay market entry, as compared to the case where the investor
pre-commits to go either long or short.
"
1601.04341	q-fin	q-fin.ST q-fin.GN	"Negative oil price bubble is likely to burst in March - May 2016. A
  forecast on the basis of the law of log-periodical dynamics"	"  Data analysis with log-periodical parametrization of the Brent oil price
dynamics has allowed to estimate (very approximately) the date when the dashing
collapse of the Brent oil price will achieve the absolute minimum level
(corresponding to the so-called singularity point), after which there will
occur a rather rapid rebound, whereas the accelerating fall of the oil prices
which started in mid-2014 will come to an end. This is likely to happen in the
period between March, 24th and May, 15th, 2016. An analogous estimate (though a
more exact one) was made for the date of the burst of the nearest negative
""sub-bubble"", which is likely to occur between 19.01 and 02.02.2016
(importantly, this estimate will allow to verify the robustness of the
developed forecast in the very nearest days). However, this will not mean a
start of a new uninterrupted global growth - the fall will soon continue,
breaking new ""anti-records"". The fall will only finally stop after passing the
abovementioned point of the main negative bubble singularity somewhere between
March 24th and May 15th, 2016 (if, of course, the oil market remains at the
disposal of speculators, and no massive interventions of macro actors are
made). Importantly, our calculations have also shown that after mid-2014 we are
dealing not with an antibubble (when price collapse goes on in a damped and
almost unstoppable regime) in the world oil market, but with a negative bubble,
when prices collapse in an accelerated mode, and there can be particularly
powerful collapses with particularly strong destabilizing effect near the
singularity point. On the other hand, negative bubbles can be better
manipulated by the actions of the macro actors.
"
1601.04351	q-fin	q-fin.RM stat.AP	On bivariate lifetime modelling in life insurance applications	"  Insurance and annuity products covering several lives require the modelling
of the joint distribution of future lifetimes. In the interest of simplifying
calculations, it is common in practice to assume that the future lifetimes
among a group of people are independent. However, extensive research over the
past decades suggests otherwise. In this paper, a copula approach is used to
model the dependence between lifetimes within a married couple \eH{using data
from a large Canadian insurance company}. As a novelty, the age difference and
the \eH{gender} of the elder partner are introduced as an argument of the
dependence parameter. \green{Maximum likelihood techniques are} thus
implemented for the parameter estimation. Not only do the results make clear
that the correlation decreases with age difference, but also the dependence
between the lifetimes is higher when husband is older than wife. A
goodness-of-fit procedure is applied in order to assess the validity of the
model. Finally, considering several products available on the life insurance
market, the paper concludes with practical illustrations.
"
1601.04478	q-fin	q-fin.PM q-fin.GN	"The Excess Returns of ""Quality"" Stocks: A Behavioral Anomaly"	"  This note investigates the causes of the quality anomaly, which is one of the
strongest and most scalable anomalies in equity markets. We explore two
potential explanations. The ""risk view"", whereby investing in high quality
firms is somehow riskier, so that the higher returns of a quality portfolio are
a compensation for risk exposure. This view is consistent with the Efficient
Market Hypothesis. The other view is the ""behavioral view"", which states that
some investors persistently underestimate the true value of high quality firms.
We find no evidence in favor of the ""risk view"": The returns from investing in
quality firms are abnormally high on a risk-adjusted basis, and are not prone
to crashes. We provide novel evidence in favor of the ""behavioral view"": In
their forecasts of future prices, and while being overall overoptimistic,
analysts systematically underestimate the future return of high quality firms,
compared to low quality firms.
"
1601.04535	q-fin	q-fin.ST cs.CY physics.data-an q-fin.CP	"A nonlinear impact: evidences of causal effects of social media on
  market prices"	"  Online social networks offer a new way to investigate financial markets'
dynamics by enabling the large-scale analysis of investors' collective
behavior. We provide empirical evidence that suggests social media and stock
markets have a nonlinear causal relationship. We take advantage of an extensive
data set composed of social media messages related to DJIA index components. By
using information-theoretic measures to cope for possible nonlinear causal
coupling between social media and stock markets systems, we point out stunning
differences in the results with respect to linear coupling. Two main
conclusions are drawn: First, social media significant causality on stocks'
returns are purely nonlinear in most cases; Second, social media dominates the
directional coupling with stock market, an effect not observable within linear
modeling. Results also serve as empirical guidance on model adequacy in the
investigation of sociotechnical and financial systems.
"
1601.04557	q-fin	q-fin.RM	"Crunching Mortality and Life Insurance Portfolios with extended
  CreditRisk+"	"  Using an extended version of the credit risk model CreditRisk+, we develop a
flexible framework with numerous applications amongst which we find stochastic
mortality modelling, forecasting of death causes as well as profit and loss
modelling of life insurance and annuity portfolios which can be used in
(partial) internal models under Solvency II. Yet, there exists a fast and
numerically stable algorithm to derive loss distributions exactly, even for
large portfolios. We provide various estimation procedures based on publicly
available data. Compared to the Lee-Carter model, we have a more flexible
framework, get tighter bounds and can directly extract several sources of
uncertainty. Straight-forward model validation techniques are available.
"
1601.04686	q-fin	q-fin.EC q-fin.GN	"Unified Growth Theory Contradicted by the Absence of Takeoffs in the
  Gross Domestic Product"	"  Data describing historical economic growth are analysed. They demonstrate
convincingly that the takeoffs from stagnation to growth, claimed in the
Unified Growth Theory, never happened. This theory is again contradicted by
data, which were used, but never properly analysed, during its formulation. The
absence of the claimed takeoffs demonstrates also that the postulate of the
differential takeoffs is contradicted by data.
"
1601.04949	q-fin	q-fin.EC q-fin.TR	General Equilibrium and Recession Phenomenon	"  The theorems we proved describe the structure of economic equilibrium in the
exchange economy model. We have studied the structure of property vectors under
given structure of demand vectors at which given price vector is equilibrium
one. On this ground, we describe the general structure of the equilibrium state
and give characteristic of equilibrium state describing economic recession. The
theory developed is applied to explain the state of the economy in some
European countries.
"
1601.05081	q-fin	q-fin.GN physics.pop-ph	"Econo- and socio- physics based remarks on the economical growth of the
  World"	"  It has been shown that the long term evolution of the Gross Product of the
World after World War II can be well portrayed by the exponential function with
the crossover at the year 1973, cinsiding with the Oil Crisis onset. For the
the Standard and Poor 500 index the single exponential behavior extends down to
at least the mid of the nineteen century. It is notable that the detailed
short-term insight focused on the last quarter of century revealed the
emergence of the power like dependence. However, such dependences can be
introduced only when taking into account the behavior at reference-baselines
years. The possible relationship to the growth/death evolution of
microorganisms is also discussed. The report proposes the new discussion of the
past and nowadays time of the global economy. It recalls econonophysics and
sociophysics as disciplines within which the effective parameterization of
trends is possible. Finally, possible future trends are discussed.
"
1601.05199	q-fin	q-fin.PM stat.ME	Portfolio Optimisation Under Flexible Dynamic Dependence Modelling	"  Signals coming from multivariate higher order conditional moments as well as
the information contained in exogenous covariates, can be effectively exploited
by rational investors to allocate their wealth among different risky investment
opportunities. This paper proposes a new flexible dynamic copula model being
able to explain and forecast the time-varying shape of large dimensional asset
returns distributions. Moreover, we let the univariate marginal distributions
to be driven by an updating mechanism based on the scaled score of the
conditional distribution. This framework allows us to introduce time-variation
in up to the fourth moment of the conditional distribution. The time-varying
dependence pattern is subsequently modelled as function of a latent Markov
Switching process, allowing also for the inclusion of exogenous covariates in
the dynamic updating equation. We empirically assess that the proposed model
substantially improves the optimal portfolio allocation of rational investors
maximising their expected utility.
"
1601.05306	q-fin	q-fin.PR q-fin.MF	"On ""A General Framework for Pricing Asian Options Under Markov
  Processes"""	"  Cai, Song and Kou (2015) [Cai, N., Y. Song, S. Kou (2015) A general framework
for pricing Asian options under Markov processes. Oper. Res. 63(3): 540-554]
made a breakthrough by proposing a general framework for pricing both
discretely and continuously monitored Asian options under one-dimensional
Markov processes. In this note, under the setting of continuous-time Markov
chain (CTMC), we explicitly carry out the inverse Z-transform and the inverse
Laplace transform respectively for the discretely and the continuously
monitored cases. The resulting explicit single Laplace transforms improve their
Theorem 2, p.543, and numerical studies demonstrate the gain in efficiency.
"
1601.05872	q-fin	math.PR q-fin.PR	The value of foresight	"  Suppose you have one unit of stock, currently worth 1, which you must sell
before time $T$. The Optional Sampling Theorem tells us that whatever stopping
time we choose to sell, the expected discounted value we get when we sell will
be 1. Suppose however that we are able to see $a$ units of time into the
future, and base our stopping rule on that; we should be able to do better than
expected value 1. But how much better can we do? And how would we exploit the
additional information? The optimal solution to this problem will never be
found, but in this paper we establish remarkably close bounds on the value of
the problem, and we derive a fairly simple exercise rule that manages to
extract most of the value of foresight.
"
1601.06204	q-fin	q-fin.RM q-fin.CP q-fin.MF	RiskRank: Measuring interconnected risk	"  This paper proposes RiskRank as a joint measure of cyclical and
cross-sectional systemic risk. RiskRank is a general-purpose aggregation
operator that concurrently accounts for risk levels for individual entities and
their interconnectedness. The measure relies on the decomposition of systemic
risk into sub-components that are in turn assessed using a set of risk measures
and their relationships. For this purpose, motivated by the development of the
Choquet integral, we employ the RiskRank function to aggregate risk measures,
allowing for the integration of the interrelation of different factors in the
aggregation process. The use of RiskRank is illustrated through a real-world
case in a European setting, in which we show that it performs well in
out-of-sample analysis. In the example, we provide an estimation of systemic
risk from country-level risk and cross-border linkages.
"
1601.06420	q-fin	q-bio.NC math.PR q-fin.MF	"Explicit moments of decision times for single- and double-threshold
  drift-diffusion processes"	"  We derive expressions for the first three moments of the decision time (DT)
distribution produced via first threshold crossings by sample paths of a
drift-diffusion equation. The ""pure"" and ""extended"" diffusion processes are
widely used to model two-alternative forced choice decisions, and, while simple
formulae for accuracy, mean DT and coefficient of variation are readily
available, third and higher moments and conditioned moments are not generally
available. We provide explicit formulae for these, describe their behaviors as
drift rates and starting points approach interesting limits, and, with the
support of numerical simulations, discuss how trial-to-trial variability of
drift rates, starting points, and non-decision times affect these behaviors in
the extended diffusion model. Both unconditioned moments and those conditioned
on correct and erroneous responses are treated. We argue that the results will
assist in exploring mechanisms of evidence accumulation and in fitting
parameters to experimental data.
"
1601.06477	q-fin	q-fin.MF q-fin.PR	"Long Forward Probabilities, Recovery and the Term Structure of Bond Risk
  Premiums"	"  We show that the martingale component in the long-term factorization of the
stochastic discount factor due to Alvarez and Jermann (2005) and Hansen and
Scheinkman (2009) is highly volatile, produces a downward-sloping term
structure of bond Sharpe ratios, and implies that the long bond is far from
growth optimality. In contrast, the long forward probabilities forecast an
upward sloping term structure of bond Sharpe ratios that starts from zero for
short-term bonds and implies that the long bond is growth optimal. Thus,
transition independence and degeneracy of the martingale component are
implausible assumptions in the bond market.
"
1601.06651	q-fin	stat.ML q-fin.TR	"Testing for Causality in Continuous Time Bayesian Network Models of
  High-Frequency Data"	"  Continuous time Bayesian networks are investigated with a special focus on
their ability to express causality. A framework is presented for doing
inference in these networks. The central contributions are a representation of
the intensity matrices for the networks and the introduction of a causality
measure. A new model for high-frequency financial data is presented. It is
calibrated to market data and by the new causality measure it performs better
than older models.
"
1601.06995	q-fin	q-fin.PR math.PR	"Moment explosions, implied volatility and local volatility at extreme
  strikes"	"  We consider a stochastic volatility model where the moment generating
function of the logarithmic price is finite only on part of the real line.
Using a new Tauberian result obtained in [1] and [2], we show that the
knowledge of the moment generating function near its critical moment gives a
sharp asymptotic expansion (with an error of order o(1)) of the local
volatility and implied volatility for small and large strikes. We apply our
theoretical estimates to Gatheral's SVI parametrization of the implied
volatility and Heston's model.
"
1601.07593	q-fin	cs.IT math.IT q-fin.PM	Sufficiency on the Stock Market	"  It is well-known that there are a number of relations between theoretical
finance theory and information theory. Some of these relations are exact and
some are approximate. In this paper we will explore some of these relations and
determine under which conditions the relations are exact. It turns out that
portfolio theory always leads to Bregman divergences. The Bregman divergence is
only proportional to information divergence in situations that are essentially
equal to the type of gambling studied by Kelly. This can be related an abstract
sufficiency condition.
"
1601.07626	q-fin	q-fin.PM	Trading-profit attribution for the size factor	"  An algorithm was recently introduced by INTECH for the purposes of estimating
the trading-profit contribution of systematic rebalancing to the relative
return of rules-based investment strategies. We apply this methodology to
analyze the size factor through the use of equal-weighted portfolios. These
strategies combine a natural exposure to the size factor with a simple
understanding within the framework of Stochastic Portfolio Theory, furnishing a
natural test subject for the attribution algorithm.
"
1601.07628	q-fin	q-fin.PM	Portfolio Optimization in the Stochastic Portfolio Theory Framework	"  I discuss some theoretical results with a view to motivate some practical
choices in portfolio optimization. Even though the setting is not completely
general (for example, the covariance matrix is assumed to be non-singular), I
attempt to highlight the features that have practical relevance. The
mathematical setting is Stochastic Portfolio Theory, which is flexible enough
to describe most realistic assets, and it has been successfully employed for
managing equity portfolios since 1987.
"
1601.07707	q-fin	q-fin.TR q-fin.ST	"Micro-foundation using percolation theory of the finite-time singular
  behavior of the crash hazard rate in a class of rational expectation bubbles"	"  We present a plausible micro-founded model for the previously postulated
power law finite time singular form of the crash hazard rate in the
Johansen-Ledoit-Sornette model of rational expectation bubbles. The model is
based on a percolation picture of the network of traders and the concept that
clusters of connected traders share the same opinion. The key ingredient is the
notion that a shift of position from buyer to seller of a sufficiently large
group of traders can trigger a crash. This provides a formula to estimate the
crash hazard rate by summation over percolation clusters above a minimum size
of a power sa (with a > 1) of the cluster sizes s, similarly to a generalized
percolation susceptibility. The power sa of cluster sizes emerges from the
super-linear dependence of group activity as a function of group size,
previously documented in the literature. The crash hazard rate exhibits
explosive finite-time singular behaviors when the control parameter (fraction
of occupied sites, or density of traders in the network) approaches the
percolation threshold pc. Realistic dynamics are generated by modelling the
density of traders on the percolation network by an Ornstein-Uhlenbeck process,
whose memory controls the spontaneous excursion of the control parameter close
to the critical region of bubble formation. Our numerical simulations recover
the main stylized properties of the JLS model with intermittent explosive
super-exponential bubbles interrupted by crashes.
"
1601.07716	q-fin	physics.soc-ph q-fin.GN	"Regional Oil Extraction and Consumption: A simple production model for
  the next 35 years Part I"	"  The growing conflicts in and about oil exporting regions and speculations
about volatile oil prices during the last decade have renewed the public
interest in predictions for the near future oil production and consumption.
Unfortunately, studies from only 10 years ago, which tried to forecast the oil
production during the next 20-30 years, failed to make accurate predictions for
today's global oil production and consumption. Forecasts using economic growth
scenarios, overestimated the actual oil production, while models which tried to
estimate the maximum future oil production/year, using the official country oil
reserve data, predicted a too low production.
  In this paper, a new approach to model the maximal future regional and thus
global oil production (part I) and consumption (part II) during the next
decades is proposed.
  Our analysis of the regional oil production data during past decades shows
that, in contrast to periods when production was growing and growth rates
varied greatly from one country to another, remarkable similarities are found
during the plateau and decline periods of different countries. Following this
model, the particular production phase of each major oil producing country and
region is determined essentially only from the recent past oil production data.
Using these data, the model is then used to predict the production from all
major oil producing countries, regions and continents up to the year 2050. The
limited regional and global potential to compensate this decline with
unconventional oil and oil-equivalents is also presented.
"
1601.07776	q-fin	cs.SI physics.soc-ph q-fin.GN	The ecology of social interactions in online and offline environments	"  The rise in online social networking has brought about a revolution in social
relations. However, its effects on offline interactions and its implications
for collective well-being are still not clear and are under-investigated. We
study the ecology of online and offline interaction in an evolutionary game
framework where individuals can adopt different strategies of socialization.
Our main result is that the spreading of self-protective behaviors to cope with
hostile social environments can lead the economy to non-socially optimal
stationary states.
"
1601.07792	q-fin	cs.GT q-fin.EC	Predicting Human Cooperation	"  The Prisoner's Dilemma has been a subject of extensive research due to its
importance in understanding the ever-present tension between individual
self-interest and social benefit. A strictly dominant strategy in a Prisoner's
Dilemma (defection), when played by both players, is mutually harmful.
Repetition of the Prisoner's Dilemma can give rise to cooperation as an
equilibrium, but defection is as well, and this ambiguity is difficult to
resolve. The numerous behavioral experiments investigating the Prisoner's
Dilemma highlight that players often cooperate, but the level of cooperation
varies significantly with the specifics of the experimental predicament. We
present the first computational model of human behavior in repeated Prisoner's
Dilemma games that unifies the diversity of experimental observations in a
systematic and quantitatively reliable manner. Our model relies on data we
integrated from many experiments, comprising 168,386 individual decisions. The
computational model is composed of two pieces: the first predicts the
first-period action using solely the structural game parameters, while the
second predicts dynamic actions using both game parameters and history of play.
Our model is extremely successful not merely at fitting the data, but in
predicting behavior at multiple scales in experimental designs not used for
calibration, using only information about the game structure. We demonstrate
the power of our approach through a simulation analysis revealing how to best
promote human cooperation.
"
1601.07864	q-fin	math.NA q-fin.CP	On construction of boundary preserving numerical schemes	"  Our aim in this note is to extend the semi discrete technique by combine it
with the split step method. We apply our new method to the Ait-Sahalia model
and propose an explicit and positivity preserving numerical scheme.
"
1601.07900	q-fin	q-fin.ST	Critical value of the total debt in view of the debts durations	"  Parastatistic distribution of a total debt owed to a large number of
creditors considered in relation to the duration of these debts. The process of
debt calculation depends on the fractal dimension of economic system in which
this process takes place. Two actual variants of these dimensions are
investigated. Critical values for these variants are determined. These critical
values represent the levels after that borrower bankruptcy occurs. The
calculation of the critical value is performed by two independent methods: as
the point where the entropy of the system reaches its maximum value, and as the
point where the chemical potential is zero, which corresponds to the
termination of payments on the debt. Both methods lead to the same critical
value. When the velocity of money circulation decrease, it is found for what
dimensions critical debt value is increased and for what it is decreased in the
case when the velocity of money circulation is increased.
"
1601.07961	q-fin	q-fin.MF q-fin.PM	"Exact solutions for optimal execution of portfolios transactions and the
  Riccati equation"	"  We propose two methods to obtain exact solutions for the Almgren-Chriss model
about optimal execution of portfolio transactions. In the first method we
rewrite the Almgren-Chriss equation and find two exact solutions. In the second
method, employing a general reparametrized time, we show that the
Almgren-Chriss equation can be reduced to some known equations which can be
exactly solved in different cases.For this last case we obtain a quantity
conserved. In addition, we show that in both methods the Almgren-Chriss
equation is equivalent to a Riccati equation.
"
1601.08099	q-fin	q-fin.MF math.DS q-fin.ST stat.OT	"Chaos in Fractionally Integrated Generalized Autoregressive Conditional
  Heteroskedastic Processes"	"  Fractionally integrated generalized autoregressive conditional
heteroskedasticity (FIGARCH) arises in modeling of financial time series.
FIGARCH is essentially governed by a system of nonlinear stochastic difference
equations ${u_t}$ = ${z_t}$ $(1-\sum\limits_{j=1}^q \beta_j L^j)\sigma_{t}^2 =
\omega+(1-\sum\limits_{j=1}^q \beta_j L^j - (\sum\limits_{k=1}^p \varphi_k L^k)
(1-L)^d) u_t^2$, where $\omega\in$ R, and $\beta_j\in$ R are constant
parameters, $\{u_t\}_{{t\in}^+}$ and $\{\sigma_t\}_{{t\in}^+}$ are the discrete
time real valued stochastic processes which represent FIGARCH (p,d,q) and
stochastic volatility, respectively. Moreover, L is the backward shift
operator, i.e. $L^d u_t \equiv u_{t-d}$ (d is the fractional differencing
parameter 0$<$d$<$1).
  In this work, we have studied the chaoticity properties of FIGARCH (p,d,q)
processes by computing mutual information, correlation dimensions, FNNs (False
Nearest Neighbour), the Lyapunov exponents, and for both the stochastic
difference equation given above and for the financial time series. We have
observed that maximal Lyapunov exponents are negative, therefore, it can be
suggested that FIGARCH (p,d,q) is not deterministic chaotic process.
"
1601.08155	q-fin	q-fin.PM	"Expert Opinions and Logarithmic Utility Maximization for Multivariate
  Stock Returns with Gaussian Drift"	"  This paper investigates optimal trading strategies in a financial market with
multidimensional stock returns where the drift is an unobservable multivariate
Ornstein-Uhlenbeck process. Information about the drift is obtained by
observing stock returns and expert opinions. The latter provide unbiased
estimates on the current state of the drift at discrete points in time.
  The optimal trading strategy of investors maximizing expected logarithmic
utility of terminal wealth depends on the filter which is the conditional
expectation of the drift given the available information. We state filtering
equations to describe its dynamics for different information settings. Between
expert opinions this is the Kalman filter. The conditional covariance matrices
of the filter follow ordinary differential equations of Riccati type. We rely
on basic theory about matrix Riccati equations to investigate their properties.
Firstly, we consider the asymptotic behaviour of the covariance matrices for an
increasing number of expert opinions on a finite time horizon. Secondly, we
state conditions for the convergence of the covariance matrices on an infinite
time horizon with regularly arriving expert opinions.
  Finally, we derive the optimal trading strategy of an investor. The optimal
expected logarithmic utility of terminal wealth, the value function, is a
functional of the conditional covariance matrices. Hence, our analysis of the
covariance matrices allows us to deduce properties of the value function.
"
1602.00090	q-fin	q-fin.EC q-fin.GN	"A Simple extension of Dematerialization Theory: Incorporation of
  Technical Progress and the Rebound Effect"	"  Dematerialization is the reduction in the quantity of materials needed to
produce something useful over time. Dematerialization fundamentally derives
from ongoing increases in technical performance but it can be counteracted by
demand rebound - increases in usage because of increased value (or decreased
cost) that also results from increasing technical performance. A major question
then is to what extent technological performance improvement can offset and is
offsetting continuously increasing economic consumption. This paper contributes
to answering this question by offering some simple quantitative extensions to
the theory of dematerialization. The paper then empirically examines the
materials consumption trends as well as cost trends for a large set of
materials and a few modern artifacts over the past decades. In each of 57 cases
examined, the particular combinations of demand elasticity and technical
performance rate improvement are not consistent with dematerialization.
Overall, the theory extension and empirical examination indicate that there is
no dematerialization occurring even for cases of information technology with
rapid technical progress. Thus, a fully passive policy stance that relies on
unfettered technological change is not supported by our results.
"
1602.00094	q-fin	q-fin.MF	CoCos under short-term uncertainty	"  In this paper we analyze an extension of the Jeanblanc and Valchev (2005)
model by considering a short-term uncertainty model with two noises. It is a
combination of the ideas of Duffie and Lando (2001) and Jeanblanc and Valchev
(2005): share quotations of the firm are available at the financial market, and
these can be seen as noisy information about the fundamental value, or the
firm's asset, from which a low level produces the credit event. We assume there
are also reports of the firm, release times, where this short-term uncertainty
disappears. This credit event model is used to describe conversion and default
in a CoCo bond.
"
1602.00159	q-fin	q-fin.EC	"Empirical Methods for Dynamic Power Law Distributions in the Social
  Sciences"	"  This paper introduces nonparametric econometric methods that characterize
general power law distributions under basic stability conditions. These methods
extend the literature on power laws in the social sciences in several
directions. First, we show that any stationary distribution in a random growth
setting is shaped entirely by two factors - the idiosyncratic volatilities and
reversion rates (a measure of cross-sectional mean reversion) for different
ranks in the distribution. This result is valid regardless of how growth rates
and volatilities vary across different economic agents, and hence applies to
Gibrat's law and its extensions. Second, we present techniques to estimate
these two factors using panel data. Third, we show how our results offer a
structural explanation for a generalized size effect in which higher-ranked
processes grow more slowly than lower-ranked processes on average. Finally, we
employ our empirical methods using panel data on commodity prices and show that
our techniques accurately describe the empirical distribution of relative
commodity prices. We also show the existence of a generalized ""size"" effect for
commodities, as predicted by our econometric theory.
"
1602.00235	q-fin	q-fin.MF	Model-Free Discretisation-Invariant Swap Contracts	"  Realised pay-offs for discretisation-invariant swaps are those which satisfy
a restricted `aggregation property' of Neuberger [2012] for twice continuously
differentiable deterministic functions of a multivariate martingale. They are
initially characterised as solutions to a second-order system of PDEs, then
those pay-offs based on martingale and log-martingale processes alone form a
vector space. Hence there exist an infinite variety of other variance and
higher-moment risk premia that are less prone to bias than standard variance
swaps because their option replication portfolios have no discrete-monitoring
or jump errors. Their fair values are also independent of the monitoring
partition. A sub-class consists of pay-offs with fair values that are further
free from numerical integration errors over option strikes. Here exact pricing
and hedging is possible via dynamic trading strategies on a few vanilla puts
and calls. An S&P 500 empirical study on higher-moment and other DI swaps
concludes.
"
1602.00256	q-fin	stat.AP q-fin.MF	"Some Contra-Arguments for the Use of Stable Distributions in Financial
  Modeling"	"  In the present paper, we discuss contra-arguments concerning the use of
Pareto-Lev\'y distributions for modeling in Finance. It appears that such
probability laws do not provide sufficient number of outliers observed in real
data. Connection with the classical limit theorem for heavy-tailed
distributions with such type of models is also questionable. The idea of
alternative modeling is given.
"
1602.00358	q-fin	q-fin.TR	Trading Strategy with Stochastic Volatility in a Limit Order Book Market	"  In this paper, we employ the Heston stochastic volatility model to describe
the stock's volatility and apply the model to derive and analyze the optimal
trading strategies for dealers in a security market. We also extend our study
to option market making for options written on stocks in the presence of
stochastic volatility. Mathematically, the problem is formulated as a
stochastic optimal control problem and the controlled state process is the
dealer's mark-to-market wealth. Dealers in the security market can optimally
determine their ask and bid quotes on the underlying stocks or options
continuously over time. Their objective is to maximize an expected profit from
transactions with a penalty proportional to the variance of cumulative
inventory cost.
"
1602.00619	q-fin	q-fin.PR	Stock loans with liquidation	"  We derive a ""semi-analytic"" solution for a stock loan in which the lender
forces liquidation when the loan-to-collateral ratio drops beneath a certain
threshold. We use this to study the sensitivity of the contract to model
parameters.
"
1602.00629	q-fin	q-fin.ST	How to improve accuracy for DFA technique	"  This paper extends the existing literature on empirical estimation of the
confidence intervals associated to the Detrended Fluctuation Analysis (DFA). We
used Montecarlo simulation to evaluate the confidence intervals. Varying the
parameters in DFA technique, we point out the relationship between those and
the standard deviation of H. The parameters considered are the finite time
length L, the number of divisors d used and the values of those. We found that
all these parameters play a crucial role, determining the accuracy of the
estimation of H.
"
1602.00839	q-fin	q-fin.TR	"A Tale of Two Consequences: Intended and Unintended Outcomes of the
  Japan TOPIX Tick Size Changes"	"  We look at the effect of the tick size changes on the TOPIX 100 index names
made by the Tokyo Stock Exchange on Jan-14-2014 and Jul-22-2104. The intended
consequence of the change is price improvement and shorter time to execution.
We look at security level metrics that include the spread, trading volume,
number of trades and the size of trades to establish whether this goal is
accomplished. An unintended effect might be the reduction in execution sizes,
which would then mean that institutions with large orders would have greater
difficulty in sourcing liquidity. We look at a sample of real orders to see if
the execution costs have gone up across the orders since the implementation of
this change.
  We study the mechanisms that affect how securities are traded on an exchange,
before delving into the specifics of the TSE tick size events. Some of the
topics we explore are: The Venue Menu and How to Increase Revenue; To Automate
or Not to Automate; Microstructure under the Microscope; The Price of
Connections to High (and Faraway) Places; Speed Thrills but Kills; Pick a Size
for the Perfect Tick; TSE Tick Size Experiments, Then and Now; Sergey Bubka and
the Regulators; Bird`s Eye View; Deep Dive; Possibilities for a Deeper Dive;
Does Tick Size Matter? Tick Size Does Matter!
"
1602.00865	q-fin	q-fin.PR q-fin.RM q-fin.ST	Tail Risk Premia for Long-Term Equity Investors	"  We use the P&L on a particular class of swaps, representing variance and
higher moments for log returns, as estimators in our empirical study on the
S&P500 that investigates the factors determining variance and higher-moment
risk premia. This class is the discretisation invariant sub-class of swaps with
Neuberger's aggregating characteristics. Besides the market excess return,
momentum is the dominant driver for both skewness and kurtosis risk premia,
which exhibit a highly significant negative correlation. By contrast, the
variance risk premium responds positively to size and negatively to growth, and
the correlation between variance and tail risk premia is relatively low
compared with previous research, particularly at high sampling frequencies.
These findings extend prior research on determinants of these risk premia.
Furthermore, our meticulous data-construction methodology avoids unwanted
artefacts which distort results.
"
1602.00899	q-fin	math.PR math.OC q-fin.MF	"Smooth solutions to discounted reward control problems with unbounded
  discount rate and financial applications"	"  We consider a discounted reward control problem in continuous time stochastic
environment where the discount rate might be an unbounded function of the
control process. We provide a set of general assumptions to ensure that there
exists a smooth classical solution to the corresponding HJB equation. Moreover,
some verification reasoning are provided and the possible extension to dynamic
games is discussed. At the end of the paper consumption - investment problems
arising in financial economics are considered.
"
1602.00931	q-fin	q-fin.GN	Should employers pay their employees better? An asset pricing approach	"  We uncover a new anomaly in asset pricing that is linked to the remuneration:
the more a company spends on salaries and benefits per employee, the better its
stock performs, on average. Moreover, the companies adopting similar
remuneration policies share a common risk, which is comparable to that of the
value premium. For this purpose,we set up an original methodology that uses
firm financial characteristics to build factors that are less correlated than
in the standard asset pricing methodology. We quantify the importance of these
factors from an asset pricing perspective by introducing the factor correlation
level as a directly accessible proxy of eigenvalues of the correlation matrix.
A rational explanation of the remuneration anomaly involves the positive
correlation between pay and employee performance.
"
1602.01070	q-fin	q-fin.MF math.PR	"A note on utility maximization with transaction costs and random
  endoment: num\'eraire-based model and convex duality"	"  In this note, we study the utility maximization problem on the terminal
wealth under proportional transaction costs and bounded random endowment. In
particular, we restrict ourselves to the num\'eraire-based model and work with
utility functions only supporting R+. Under the assumption of existence of
consistent price systems and natural regularity conditions, standard convex
duality results are established. Precisely, we first enlarge the dual domain
from the collection of martingale densities associated with consistent price
systems to a set of finitely additive measures; then the dual formulation of
the utility maximization problem can be regarded as an extension of the paper
of Cvitani\'c-Schachermayer-Wang (2001) to the context under proportional
transaction costs.
"
1602.01271	q-fin	q-fin.EC	"On the parameter identifiability problem in Agent Based economical
  models"	"  Identifiability of parameters is a fundamental prerequisite for model
identification. It concerns uniqueness of the model parameters determined from
experimental or simulated observations. This dissertation specifically deals
with structural or a priori identifiability: whether or not parameters can be
identified from a given model structure and experimental measurements. We
briefly present the identifiability problem in linear and non linear dynamical
model. We compare DSGE and Agent Based model (ABM) in terms of identifiability
of the structural parameters and we finally discuss limits and perspective of
numerical protocols to test global identifiability in case of ergodic and
markovian economical systems.
"
1602.01578	q-fin	physics.soc-ph q-fin.GN	Modeling the relation between income and commuting distance	"  We discuss the distribution of commuting distances and its relation to
income. Using data from Denmark, the UK, and the US, we show that the commuting
distance is (i) broadly distributed with a slow decaying tail that can be
fitted by a power law with exponent $\gamma \approx 3$ and (ii) an average
growing slowly as a power law with an exponent less than one that depends on
the country considered. The classical theory for job search is based on the
idea that workers evaluate the wage of potential jobs as they arrive
sequentially through time, and extending this model with space, we obtain
predictions that are strongly contradicted by our empirical findings. We
propose an alternative model that is based on the idea that workers evaluate
potential jobs based on a quality aspect and that workers search for jobs
sequentially across space. We also assume that the density of potential jobs
depends on the skills of the worker and decreases with the wage. The predicted
distribution of commuting distances decays as $1/r^{3}$ and is independent of
the distribution of the quality of jobs. We find our alternative model to be in
agreement with our data. This type of approach opens new perspectives for the
modeling of mobility.
"
1602.01960	q-fin	q-fin.ST q-fin.MF	Multiple Wavelet Coherency Analysis and Forecasting of Metal Prices	"  The assessment of co-movement among metals is crucial to better understand
the behaviors of the metal prices and the interactions with others that affect
the changes in prices. In this study, both Wavelet Analysis and VARMA (Vector
Autoregressive Moving Average) models are utilized. First, Multiple Wavelet
Coherence (MWC), where Wavelet Analysis is needed, is utilized to determine
dynamic correlation time interval and scales. VARMA is then used for
forecasting which results in reduced errors.
  The daily prices of steel, aluminium, copper and zinc between 10.05.2010 and
29.05.2014 are analyzed via wavelet analysis to highlight the interactions.
Results uncover interesting dynamics between mentioned metals in the
time-frequency space. VARMA (1,1) model forecasting is carried out considering
the daily prices between 14.11.2011 and 16.11.2012 where the interactions are
quite high and prediction errors are found quite limited with respect to
ARMA(1.1). It is shown that dynamic co-movement detection via four variables
wavelet coherency analysis in the determination of VARMA time interval enables
to improve forecasting power of ARMA by decreasing forecasting errors.
"
1602.02011	q-fin	q-fin.PR math.PR q-fin.MF	Issues with the Smith-Wilson method	"  The objective of the present paper is to analyse various features of the
Smith-Wilson method used for discounting under the EU regulation Solvency II,
with special attention to hedging. In particular, we show that all key rate
duration hedges of liabilities beyond the Last Liquid Point will be peculiar.
Moreover, we show that there is a connection between the occurrence of negative
discount factors and singularities in the convergence criterion used to
calibrate the model. The main tool used for analysing hedges is a novel
stochastic representation of the Smith-Wilson method. Further, we provide
necessary conditions needed in order to construct similar, but hedgeable,
discount curves.
"
1602.02185	q-fin	q-fin.ST stat.ME	"Sparse Kalman Filtering Approaches to Covariance Estimation from High
  Frequency Data in the Presence of Jumps"	"  Estimation of the covariance matrix of asset returns from high frequency data
is complicated by asynchronous returns, market mi- crostructure noise and
jumps. One technique for addressing both asynchronous returns and market
microstructure is the Kalman-EM (KEM) algorithm. However the KEM approach
assumes log-normal prices and does not address jumps in the return process
which can corrupt estimation of the covariance matrix.
  In this paper we extend the KEM algorithm to price models that include jumps.
We propose two sparse Kalman filtering approaches to this problem. In the first
approach we develop a Kalman Expectation Conditional Maximization (KECM)
algorithm to determine the un- known covariance as well as detecting the jumps.
For this algorithm we consider Laplace and the spike and slab jump models, both
of which promote sparse estimates of the jumps. In the second method we take a
Bayesian approach and use Gibbs sampling to sample from the posterior
distribution of the covariance matrix under the spike and slab jump model.
Numerical results using simulated data show that each of these approaches
provide for improved covariance estima- tion relative to the KEM method in a
variety of settings where jumps occur.
"
1602.02348	q-fin	q-fin.EC cs.DL	"Economic and Technological Complexity: A Model Study of Indicators of
  Knowledge-based Innovation Systems"	"  The Economic Complexity Index (ECI; Hidalgo & Hausmann, 2009) measures the
complexity of national economies in terms of product groups. Analogously to
ECI, a Patent Complexity Index (PatCI) can be developed on the basis of a
matrix of nations versus patent classes. Using linear algebra, the three
dimensions: countries, product groups, and patent classes can be combined into
a measure of ""Triple Helix"" complexity (THCI) including the trilateral
interaction terms between knowledge production, wealth generation, and
(national) control. THCI can be expected to capture the extent of systems
integration between the global dynamics of markets (ECI) and technologies
(PatCI) in each national system of innovation. We measure ECI, PatCI, and THCI
during the period 2000-2014 for the 34 OECD member states, the BRICS countries,
and a group of emerging and affiliated economies (Argentina, Hong Kong,
Indonesia, Malaysia, Romania, and Singapore). The three complexity indicators
are correlated between themselves; but the correlations with GDP per capita are
virtually absent. Of the world's major economies, Japan scores highest on all
three indicators, while China has been increasingly successful in combining
economic and technological complexity. We could not reproduce the correlation
between ECI and average income that has been central to the argument about the
fruitfulness of the economic complexity approach.
"
1602.02542	q-fin	stat.ME q-fin.PM stat.AP	"Dynamic Spatial Autoregressive Models with Autoregressive and
  Heteroskedastic Disturbances"	"  We propose a new class of models specifically tailored for spatio-temporal
data analysis. To this end, we generalize the spatial autoregressive model with
autoregressive and heteroskedastic disturbances, i.e. SARAR(1,1), by exploiting
the recent advancements in Score Driven (SD) models typically used in time
series econometrics. In particular, we allow for time-varying spatial
autoregressive coefficients as well as time-varying regressor coefficients and
cross-sectional standard deviations. We report an extensive Monte Carlo
simulation study in order to investigate the finite sample properties of the
Maximum Likelihood estimator for the new class of models as well as its
flexibility in explaining several dynamic spatial dependence processes. The new
proposed class of models are found to be economically preferred by rational
investors through an application in portfolio optimization.
"
1602.02735	q-fin	q-fin.TR	"Linear models for the impact of order flow on prices I. Propagators:
  Transient vs. History Dependent Impact"	"  Market impact is a key concept in the study of financial markets and several
models have been proposed in the literature so far. The Transient Impact Model
(TIM) posits that the price at high frequency time scales is a linear
combination of the signs of the past executed market orders, weighted by a
so-called propagator function. An alternative description -- the History
Dependent Impact Model (HDIM) -- assumes that the deviation between the
realised order sign and its expected level impacts the price linearly and
permanently. The two models, however, should be extended since prices are a
priori influenced not only by the past order flow, but also by the past
realisation of returns themselves. In this paper, we propose a two-event
framework, where price-changing and non price-changing events are considered
separately. Two-event propagator models provide a remarkable improvement of the
description of the market impact, especially for large tick stocks, where the
events of price changes are very rare and very informative. Specifically the
extended approach captures the excess anti-correlation between past returns and
subsequent order flow which is missing in one-event models. Our results
document the superior performances of the HDIMs even though only in minor
relative terms compared to TIMs. This is somewhat surprising, because HDIMs are
well grounded theoretically, while TIMs are, strictly speaking, inconsistent.
"
1602.02907	q-fin	math.ST math.PR q-fin.PR stat.TH	"Simulation of volatility modulated Volterra processes using hyperbolic
  stochastic partial differential equations"	"  We propose a finite difference scheme to simulate solutions to a certain type
of hyperbolic stochastic partial differential equation (HSPDE). These solutions
can in turn estimate so called volatility modulated Volterra (VMV) processes
and L\'{e}vy semistationary (LSS) processes, which is a class of processes that
have been employed to model turbulence, tumor growth and electricity forward
and spot prices. We will see that our finite difference scheme converges to the
solution of the HSPDE as we take finer and finer partitions for our finite
difference scheme in both time and space. Finally, we demonstrate our method
with an example from the energy finance literature.
"
1602.03011	q-fin	q-fin.TR	Unravelling the trading invariance hypothesis	"  We confirm and substantially extend the recent empirical result of Andersen
et al. \cite{Andersen2015}, where it is shown that the amount of risk $W$
exchanged in the E-mini S\&P futures market (i.e. price times volume times
volatility) scales like the 3/2 power of the number of trades $N$. We show that
this 3/2-law holds very precisely across 12 futures contracts and 300 single US
stocks, and across a wide range of time scales. However, we find that the
""trading invariant"" $I=W/N^{3/2}$ proposed by Kyle and Obizhaeva is in fact
quite different for different contracts, in particular between futures and
single stocks. Our analysis suggests $I/{\cal C}$ as a more natural candidate,
where $\cal C$ is the average spread cost of a trade, defined as the average of
the trade size times the bid-ask spread. We also establish two more complex
scaling laws for the volatility $\sigma$ and the traded volume $V$ as a
function of $N$, that reveal the existence of a characteristic number of trades
$N_0$ above which the expected behaviour $\sigma \sim \sqrt{N}$ and $V \sim N$
hold, but below which strong deviations appear, induced by the size of
the~tick.
"
1602.03043	q-fin	q-fin.TR	The square-root impact law also holds for option markets	"  Many independent studies on stocks and futures contracts have established
that market impact is proportional to the square-root of the executed volume.
Is market impact quantitatively similar for option markets as well? In order to
answer this question, we have analyzed the impact of a large proprietary data
set of option trades. We find that the square-root law indeed holds in that
case. This finding supports the argument for a universal underlying mechanism.
"
1602.03271	q-fin	q-fin.ST	"A study of co-movements between oil price, stock index and exchange rate
  under a cross-bicorrelation perspective: the case of Mexico"	"  In this chapter we studied the nonlinear co-movements between the Mexican
Crude Oil price, the Mexican Stock Market Index and the USD/MXN Exchange Rate,
for the sample period from 1994 to date. We used a battery of nonlinear tests,
cf. (Patterson & Ashley, 2000) and one multivariate test, in order to determine
the dynamic co-movement exerted from the oil prices to the stock and exchange
rate markets. Such co-movement and time windows are exposed using the Brooks &
Hinich (1999) cross- bicorrelation statistical test. The effects of oil spills
on other markets have been studied from different angles and on several
financial assets. In this study, we focus our attention on the detection, not
only of the correlations amongst markets but on the epochs in which such
nonlinear dependence might occur. This is important in order to understand
better, how the markets that drive the economy interact with each other. We
hope to contribute to the literature with such findings, filling a gap in the
emerging markets context, in particular, for the Mexican case.
"
1602.03402	q-fin	q-fin.MF q-fin.PR	"Pricing options on forwards in energy markets: the role of mean
  reversion's speed"	"  Consider the problem of pricing options on forwards in energy markets, when
spot prices follow a geometric multi-factor model in which several rates of
mean reversion appear. In this paper we investigate the role played by slow
mean reversion when pricing and hedging options. In particular, we determine
both upper and lower bounds for the error one makes neglecting low rates of
mean reversion in the spot price dynamics.
"
1602.03505	q-fin	q-fin.RM	"Basel III capital surcharges for G-SIBs fail to control systemic risk
  and can cause pro-cyclical side effects"	"  In addition to constraining bilateral exposures of financial institutions,
there are essentially two options for future financial regulation of systemic
risk (SR): First, financial regulation could attempt to reduce the financial
fragility of global or domestic systemically important financial institutions
(G-SIBs or D-SIBs), as for instance proposed in Basel III. Second, future
financial regulation could attempt strengthening the financial system as a
whole. This can be achieved by re-shaping the topology of financial networks.
We use an agent-based model (ABM) of a financial system and the real economy to
study and compare the consequences of these two options. By conducting three
""computer experiments"" with the ABM we find that re-shaping financial networks
is more effective and efficient than reducing leverage. Capital surcharges for
G-SIBs can reduce SR, but must be larger than those specified in Basel III in
order to have a measurable impact. This can cause a loss of efficiency. Basel
III capital surcharges for G-SIBs can have pro-cyclical side effects.
"
1602.03944	q-fin	q-fin.ST q-fin.TR	Modelling intensities of order flows in a limit order book	"  We propose a parametric model for the simulation of limit order books. We
assume that limit orders, market orders and cancellations are submitted
according to point processes with state-dependent intensities. We propose new
functional forms for these intensities, as well as new models for the placement
of limit orders and cancellations. For cancellations, we introduce the concept
of ""priority index"" to describe the selection of orders to be cancelled in the
order book. Parameters of the model are estimated using likelihood
maximization. We illustrate the performance of the model by providing extensive
simulation results, with a comparison to empirical data and a standard Poisson
reference.
"
1602.04352	q-fin	physics.soc-ph q-fin.GN	"On the topologic structure of economic complex networks: Empirical
  evidence from large scale payment network of Estonia"	"  This paper presents the first topological analysis of the economic structure
of an entire country based on payments data obtained from Swedbank. This data
set is exclusive in its kind because around 80% of Estonia's bank transactions
are done through Swedbank, hence, the economic structure of the country can be
reconstructed. Scale-free networks are commonly observed in a wide array of
different contexts such as nature and society. In this paper, the nodes are
comprised by customers of the bank (legal entities) and the links are
established by payments between these nodes. We study the scaling-free and
structural properties of this network. We also describe its topology,
components and behaviors. We show that this network shares typical structural
characteristics known in other complex networks: degree distributions follow a
power law, low clustering coefficient and low average shortest path length. We
identify the key nodes of the network and perform simulations of resiliency
against random and targeted attacks of the nodes with two different approaches.
With this, we find that by identifying and studying the links between the nodes
is possible to perform vulnerability analysis of the Estonian economy with
respect to economic shocks.
"
1602.04363	q-fin	cond-mat.stat-mech q-fin.GN quant-ph	Path probability of stochastic motion: A functional approach	"  The path probability of a particle undergoing stochastic motion is studied by
the use of functional technique, and the general formula is derived for the
path probability distribution functional. The probability of finding paths
inside a tube/band, the center of which is stipulated by a given path, is
analytically evaluated in a way analogous to continuous measurements in quantum
mechanics. Then, the formalism developed here is applied to the stochastic
dynamics of stock price in finance.
"
1602.04372	q-fin	q-fin.CP	Local Volatility Models in Commodity Markets and Online Calibration	"  We introduce a local volatility model for the valuation of options on
commodity futures by using European vanilla option prices. The corresponding
calibration problem is addressed within an online framework, allowing the use
of multiple price surfaces. Since uncertainty in the observation of the
underlying future prices translates to uncertainty in data locations, we
propose a model-based adjustment of such prices that improves reconstructions
and smile adherence. In order to tackle the ill-posedness of the calibration
problem we incorporate a priori information through a judiciously designed
Tikhonov-type regularization. Extensive empirical tests with market as well as
synthetic data are used to demonstrate the effectiveness of the methodology and
algorithms.
"
1602.04423	q-fin	q-fin.EC q-fin.CP	Market Dynamics. On Supply and Demand Concepts	"  The disbalance of Supply and Demand is typically considered as the driving
force of the markets. However, the measurement or estimation of Supply and
Demand at price different from the execution price is not possible even after
the transaction. An approach in which Supply and Demand are always matched, but
the rate $I=dv/dt$ (number of units traded per unit time) of their matching
varies, is proposed. The state of the system is determined not by a price $p$,
but by a probability distribution defined as the square of a wavefunction
$\psi(p)$. The equilibrium state $\psi^{[H]}$ is postulated to be the one
giving maximal $I$ and obtained from maximizing the matching rate functional
$<I\psi^2(p)>/<\psi^2(p)>$, i.e. solving the dynamic equation of the form
""future price tend to the value maximizing the number of shares traded per unit
time"". An application of the theory in a quasi--stationary case is
demonstrated. This transition from Supply and Demand concept to Liquidity
Deficit concept, described by the matching rate $I$, allows to operate only
with observable variables, and have a theory applicable to practical problems.
"
1602.04466	q-fin	q-fin.EC q-fin.GN	"Mediation with near insolvent defaulting suppliers: a linear
  optimisation model to find an optimal outcome"	"  This paper presents a model to describe contractual dispute resolution by
mediation in situations where a defaulting supplier is near insolvent. While
each party has internal constraints, and if alternate performances are
available, such as more costly alternative goods, the proposed approach allows
the mediator to find an optimal solution. The notion of optimality is presented
as adherence to the initial contract, therefore optimising a value function for
the non defaulting party. The proposed model includes describing the evolution
over time of each party's perceived constraints using a phasor like approach
with a modulation to the core constraints phasing out of the real part and
phasing in the imaginary part of complex numbers. The offers related to
alternative performances by the defaulting party are modelled by a Gompertz
function, being an exponential learning curve of the supplier in regards to the
reaction to its offers, limited by another exponential function when
approaching its internal constraints. Furthermore, the model takes into account
the discount associated to the delay in the delivery time of the alternative
performances.
"
1602.04656	q-fin	q-fin.MF q-fin.PM	Dividend maximization in a hidden Markov switching model	"  In this paper we study the valuation problem of an insurance company by
maximizing the expected discounted future dividend payments in a model with
partial information that allows for a changing economic environment. The
surplus process is modeled as a Brownian motion with drift. This drift depends
on an underlying Markov chain the current state of which is assumed to be
unobservable. The different states of the Markov chain thereby represent
different phases of the economy. We apply results from filtering theory to
overcome uncertainty and then we give an analytic characterization of the
optimal value function. Finally, we present a numerical study covering various
scenarios to get a clear picture of how dividends should be paid out.
"
1602.04660	q-fin	q-fin.MF	Bayesian Dividend Optimization and Finite Time Ruin Probabilities	"  We consider the valuation problem of an (insurance) company under partial
information. Therefore we use the concept of maximizing discounted future
dividend payments. The firm value process is described by a diffusion model
with constant and observable volatility and constant but unknown drift
parameter. For transforming the problem to a problem with complete information,
we derive a suitable filter. The optimal value function is characterized as the
unique viscosity solution of the associated Hamilton-Jacobi-Bellman equation.
We state a numerical procedure for approximating both the optimal dividend
strategy and the corresponding value function. Furthermore, threshold
strategies are discussed in some detail. Finally, we calculate the probability
of ruin in the uncontrolled and controlled situation.
"
1602.04662	q-fin	q-fin.MF math.OC	"Optimal Control of an Energy Storage Facility Under a Changing Economic
  Environment and Partial Information"	"  In this paper we consider an energy storage optimization problem in finite
time in a model with partial information that allows for a changing economic
environment. The state process consists of the storage level controlled by the
storage manager and the energy price process, which is a diffusion process the
drift of which is assumed to be unobservable. We apply filtering theory to find
an alternative state process which is adapted to our observation filtration.
For this alternative state process we derive the associated
Hamilton-Jacobi-Bellman equation and solve the optimization problem
numerically. This results in a candidate for the optimal policy for which it is
a-priori not clear whether the controlled state process exists. Hence, we prove
an existence and uniqueness result for a class of time-inhomogeneous stochastic
differential equations with discontinuous drift and singular diffusion
coefficient. Finally, we apply our result to prove admissibility of the
candidate optimal control.
"
1602.04902	q-fin	q-fin.PM q-fin.RM	Multifactor Risk Models and Heterotic CAPM	"  We give a complete algorithm and source code for constructing general
multifactor risk models (for equities) via any combination of style factors,
principal components (betas) and/or industry factors. For short horizons we
employ the Russian-doll risk model construction to obtain a nonsingular factor
covariance matrix. This generalizes the heterotic risk model construction to
include arbitrary non-industry risk factors as well as industry risk factors
with generic ""weights"". The aim of sharing our proprietary know-how with the
investment community is to encourage organic risk model building. The
presentation is intended to be essentially self-contained and pedagogical. So,
stop wasting money and complaining, start building risk models and enjoy!
"
1602.04946	q-fin	q-fin.MF	A pathwise approach to continuous-time trading	"  This paper develops a mathematical framework for the analysis of
continuous-time trading strategies which, in contrast to the classical setting
of continuous-time mathematical finance, does not rely on stochastic integrals
or other probabilistic notions. Our purely analytic framework allows for the
derivation of a pathwise self-financial condition for continuous-time trading
strategies, which is consistent with the classical definition in case a
probability model is introduced. Our first proposition provides us with a
pathwise definition of the gain process for a large class of continuous-time,
path-dependent, self-finacing trading strategies, including the important class
of 'delta-hedging' strategies, and is based on the recently developed
'non-anticipative functional calculus'. Two versions of the statement involve
respectively continuous and c\`adl\`ag price paths. The second proposition is a
pathwise replication result that generalizes the ones obtained in the classical
framework of diffusion models. Moreover, it gives an explicit and purely
pathwise formula for the hedging error of delta-hedging strategies for
path-dependent derivatives across a given set of scenarios. We also provide an
economic justification of our main assumption on price paths.
"
1602.04975	q-fin	q-fin.PM math.PR	Dynamic portfolio selection without risk-free assets	"  We consider the mean--variance portfolio optimization problem under the game
theoretic framework and without risk-free assets. The problem is solved
semi-explicitly by applying the extended Hamilton--Jacobi--Bellman equation.
Although the coefficient of risk aversion in our model is a constant, the
optimal amounts of money invested in each stock still depend on the current
wealth in general. The optimal solution is obtained by solving a system of
ordinary differential equations whose existence and uniqueness are proved and a
numerical algorithm as well as its convergence speed are provided. Different
from portfolio selection with risk-free assets, our value function is quadratic
in the current wealth, and the equilibrium allocation is linearly sensitive to
the initial wealth. Numerical results show that this model performs better than
both the classical one and the variance model in a bull market.
"
1602.05323	q-fin	q-fin.ST	"Filterbased Stochastic Volatility in Continuous-Time Hidden Markov
  Models"	"  Regime-switching models, in particular Hidden Markov Models (HMMs) where the
switching is driven by an unobservable Markov chain, are widely-used in
financial applications, due to their tractability and good econometric
properties. In this work we consider HMMs in continuous time with both constant
and switching volatility. In the continuous-time model with switching
volatility the underlying Markov chain could be observed due to this stochastic
volatility, and no estimation (filtering) of it is needed (in theory), while in
the discretized model or the model with constant volatility one has to filter
for the underlying Markov chain. The motivations for continuous-time models are
explicit computations in finance. To have a realistic model with unobservable
Markov chain in continuous time and good econometric properties we introduce a
regime-switching model where the volatility depends on the filter for the
underlying chain and state the filtering equations. We prove an approximation
result for a fixed information filtration and further motivate the model by
considering social learning arguments. We analyze its relation to the switching
volatility model and present a convergence result for the discretized model. We
then illustrate its econometric properties by considering numerical
simulations.
"
1602.05471	q-fin	q-fin.MF	Robust Financial Bubbles	"  We study the concept of financial bubble in a market model endowed with a set
of probability measures, typically mutually singular to each other. In this
setting we introduce the notions of robust bubble and robust fundamental value
in a consistent way with the existing literature in the case a unique prior
exists. The notion of no dominance is also investigated under the uncertainty
framework. Finally, we provide concrete examples illustrating our results.
"
1602.05484	q-fin	q-fin.MF	Robust Mean-Variance Hedging via G-Expectation	"  In this paper we study mean-variance hedging under the G-expectation
framework. Our analysis is carried out by exploiting the G-martingale
representation theorem and the related probabilistic tools, in a contin- uous
financial market with two assets, where the discounted risky one is modeled as
a symmetric G-martingale. By tackling progressively larger classes of
contingent claims, we are able to explicitly compute the optimal strategy under
general assumptions on the form of the contingent claim.
"
1602.05541	q-fin	q-fin.CP math.PR	"Alpha-CIR Model with Branching Processes in Sovereign Interest Rate
  Modelling"	"  We introduce a class of interest rate models, called the $\alpha$-CIR model,
which gives a natural extension of the standard CIR model by adopting the
$\alpha$-stable L{\'e}vy process and preserving the branching property. This
model allows to describe in a unified and parsimonious way several recent
observations on the sovereign bond market such as the persistency of low
interest rate together with the presence of large jumps at local extent. We
emphasize on a general integral representation of the model by using random
fields, with which we establish the link to the CBI processes and the affine
models. Finally we analyze the jump behaviors and in particular the large
jumps, and we provide numerical illustrations.
"
1602.05718	q-fin	q-fin.EC	"The Postulate of the Three Regimes of Economic Growth Contradicted by
  Data"	"  Economic growth in Western Europe, Eastern Europe, Asia, countries of the
former USSR, Africa and Latin America were analysed. It is demonstrated that
the fundamental postulate of the Unified Growth Theory about the existence of
the three regimes of growth (Malthusian regime, post-Malthusian regime and
sustained-growth regime) is contradicted by data. These regimes did not exist.
In particular, there was no escape from the Malthusian trap because there was
no trap. Economic growth in all these regions was not stagnant but hyperbolic.
Unified Growth Theory is fundamentally incorrect. However, this theory is also
dangerously misleading because it claims a transition from the endless epoch of
stagnation to the new era of sustained economic growth, the interpretation
creating the sense of security and a promise of prosperity. The data show that
the opposite is true. Economic growth in the past was sustained and secure.
Now, it is supported by the increasing ecological deficit. The long-term
sustained and secure economic growth has yet to be created. It did not happen
automatically, as suggested incorrectly by the Unified Growth Theory.
"
1602.05749	q-fin	q-fin.RM q-fin.ST	"Value-at-Risk and backtesting with the APARCH model and the standardized
  Pearson type IV distribution"	"  We examine the efficiency of the Asymmetric Power ARCH (APARCH) model in the
case where the residuals follow the standardized Pearson type IV distribution.
The model is tested with a variety of loss functions and the efficiency is
examined via application of several statistical tests and risk measures. The
results indicate that the APARCH model with the standardized Pearson type IV
distribution is accurate, within the general financial risk modeling
perspective, providing the financial analyst with an additional skewed
distribution for incorporation in the risk management tools.
"
1602.05758	q-fin	q-fin.MF math.OC	"On optimal strategies for utility maximizers in the Arbitrage Pricing
  Model"	"  We consider a popular model of microeconomics with countably many assets: the
Arbitrage Pricing Model. We study the problem of optimal investment under an
expected utility criterion and look for conditions ensuring the existence of
optimal strategies. Previous results required a certain restrictive hypothesis
on the tails of asset return distributions. Using a different method, we manage
to remove this hypothesis, at the price of stronger assumptions on the moments
of asset returns.
"
1602.05858	q-fin	q-fin.PM q-fin.ST	On the Profitability of Optimal Mean Reversion Trading Strategies	"  We study the profitability of optimal mean reversion trading strategies in
the US equity market. Different from regular pair trading practice, we apply
maximum likelihood method to construct the optimal static pairs trading
portfolio that best fits the Ornstein-Uhlenbeck process, and rigorously
estimate the parameters. Therefore, we ensure that our portfolios match the
mean-reverting process before trading. We then generate contrarian trading
signals using the model parameters. We also optimize the thresholds and the
length of in-sample period by multiple tests. In nine good pair examples, we
can see that our pairs exhibit high Sharpe ratio (above 1.9) over the in-sample
period and out-of-sample period. In particular, Crown Castle International
Corp. (CCI) and HCP, Inc. (HCP) achieve a Sharpe ratio of 2.326 during
in-sample period and a Sharpe ratio of 2.425 in out-of-sample test. Crown
Castle International Corp. (CCI) and Realty Income Corporation (O) achieve a
Sharpe ratio of 2.405 and 2.903 respectively during in-sample period and
out-of-sample period.
"
1602.06101	q-fin	math.PR q-bio.QM q-fin.MF	"Density analysis of non-Markovian BSDEs and applications to biology and
  finance"	"  In this paper, we provide conditions which ensure that stochastic Lipschitz
BSDEs admit Malliavin differentiable solutions. We investigate the problem of
existence of densities for the first components of solutions to general
path-dependent stochastic Lipschitz BSDEs and obtain results for the second
components in particular cases. We apply these results to both the study of a
gene expression model in biology and to the classical pricing problems in
mathematical finance.
"
1602.06188	q-fin	q-fin.EC physics.soc-ph	Blunt Honesty, Incentives, and Knowledge Exchange	"  We propose a simple mechanism to facilitate the buying and selling of useful,
bluntly honest information. The for-profit, arm's length knowledge exchange
this mechanism enables may dramatically increase the pace of scientific
progress.
"
1602.06189	q-fin	q-fin.PR	Accrual valuation and mark to market adjustment	"  This paper provides intuition on the relationship of accrual and
mark-to-market valuation for cash and forward interest rate trades. Discounted
cashflow valuation is compared to spread-based valuation for forward trades,
which explains the trader's view on valuation. This is followed by Taylor
series approximation for cash trades, uncovering simple intuition behind
accrual valuation and mark-to-market adjustment. It is followed by the PNL
example modelled in R. Within the Taylor approximation framework, theta and
delta are explained. The concept of deferral is explained taking Forward Rate
Agreement (FRA) as an example.
"
1602.06213	q-fin	q-fin.TR cs.SI cs.SY q-fin.CP	Modeling Stock Price Dynamics with Fuzzy Opinion Networks	"  We propose a mathematical model for the word-of-mouth communications among
stock investors through social networks and explore how the changes of the
investors' social networks influence the stock price dynamics and vice versa.
An investor is modeled as a Gaussian fuzzy set (a fuzzy opinion) with the
center and standard deviation as inputs and the fuzzy set itself as output.
Investors are connected in the following fashion: the center input of an
investor is taken as the average of the neighbors' outputs, where two investors
are neighbors if their fuzzy opinions are close enough to each other, and the
standard deviation (uncertainty) input is taken with local, global or external
reference schemes to model different scenarios of how investors define
uncertainties. The centers and standard deviations of the fuzzy opinions are
the expected prices and their uncertainties, respectively, that are used as
inputs to the price dynamic equation. We prove that with the local reference
scheme the investors converge to different groups in finite time, while with
the global or external reference schemes all investors converge to a consensus
within finite time and the consensus may change with time in the external
reference case. We show how to model trend followers, contrarians and
manipulators within this mathematical framework and prove that the biggest
enemy of a manipulator is the other manipulators. We perform Monte Carlo
simulations to show how the model parameters influence the price dynamics, and
we apply a modified version of the model to the daily closing prices of fifteen
top banking and real estate stocks in Hong Kong for the recent two years from
Dec. 5, 2013 to Dec. 4, 2015 and discover that a sharp increase of the combined
uncertainty is a reliable signal to predict the reversal of the current price
trend.
"
1602.06234	q-fin	q-fin.GN q-fin.EC	Household Income Distribution in the USA	"  In this article we present an alternative model for the distribution of
household incomes in the United States. We provide arguments from two differing
perspectives which both yield the proposed income distribution curve, and then
fit this curve to empirical data on household income distribution obtained from
the United States Census Bureau.
"
1602.06295	q-fin	q-fin.GN cs.DS	Solar energy production: Short-term forecasting and risk management	"  Electricity production via solar energy is tackled via short-term forecasts
and risk management. Our main tool is a new setting on time series. It allows
the definition of ""confidence bands"" where the Gaussian assumption, which is
not satisfied by our concrete data, may be abandoned. Those bands are quite
convenient and easily implementable. Numerous computer simulations are
presented.
"
1602.06585	q-fin	q-fin.RM q-fin.GN	"Credit risk and companies' inter-organizational networks: Assessing
  impact of suppliers and buyers on CDS spreads"	"  Companies do not operate in a vacuum. As companies move towards an
increasingly specialized production function and their reach is becoming truly
global, their aptitude in managing and shaping their inter-organizational
network is a determining factor in measuring their health. Current models of
company financial health often lack variables explaining the
inter-organizational network, and as such, assume that (1) all networks are the
same and (2) the performance of partners do not impact companies. This paper
aims to be a first step in the direction of removing these assumptions.
Specifically, the impact is illustrated by examining the effects of customer
and supplier concentrations and partners' credit risk on credit-default swap
(CDS) spreads while controlling for credit risk and size. We rely upon
supply-chain data from Bloomberg that provides insight into companies'
relationships. The empirical results show that a well diversified customer
network lowers CDS spread, while having stable partners with low default
probabilities increase spreads. The latter result suggests that successful
companies do not focus on building a stable eco-system around themselves, but
instead focus on their own profit maximization at the cost of the financial
health of their suppliers' and customers'. At a more general level, the results
indicate the importance of considering the inter-organizational networks, and
highlight the value of including network variables in credit risk models.
"
1602.06685	q-fin	q-fin.MF	"Non-concave optimal investment and no-arbitrage: a measure theoretical
  approach"	"  We consider non-concave and non-smooth random utility functions with do- main
of definition equal to the non-negative half-line. We use a dynamic pro-
gramming framework together with measurable selection arguments to establish
both the no-arbitrage condition characterization and the existence of an
optimal portfolio in a (generically incomplete) discrete-time financial market
model with finite time horizon. In contrast to the existing literature, we
propose to consider a probability space which is not necessarily complete.
"
1602.06855	q-fin	q-fin.EC nlin.AO physics.data-an physics.soc-ph	Tsallis statistics in the income distribution of Brazil	"  This paper discusses the empirical evidence of Tsallis statistical functions
in the personal income distribution of Brazil. Yearly samples from 1978 to 2014
were linearized by the q-logarithm and straight lines were fitted to the entire
range of the income data in all samples, producing a two-parameters-only single
function representation of the whole distribution in every year. The results
showed that the time evolution of the parameters is periodic and plotting one
in terms of the other reveals a cycle mostly clockwise. It was also found that
the empirical data oscillate periodically around the fitted straight lines with
the amplitude growing as the income values increase. Since the entire income
data range can be fitted by a single function, this raises questions on
previous results claiming that the income distribution is constituted by a well
defined two-classes-base income structure, since such a division in two very
distinct income classes might not be an intrinsic property of societies, but a
consequence of an a priori fitting-choice procedure that may leave aside
possibly important income dynamics at the intermediate levels.
"
1602.06935	q-fin	physics.soc-ph cond-mat.stat-mech cs.SI q-fin.GN	The noisy voter model on complex networks	"  We propose a new analytical method to study stochastic, binary-state models
on complex networks. Moving beyond the usual mean-field theories, this
alternative approach is based on the introduction of an annealed approximation
for uncorrelated networks, allowing to deal with the network structure as
parametric heterogeneity. As an illustration, we study the noisy voter model, a
modification of the original voter model including random changes of state. The
proposed method is able to unfold the dependence of the model not only on the
mean degree (the mean-field prediction) but also on more complex averages over
the degree distribution. In particular, we find that the degree heterogeneity
---variance of the underlying degree distribution--- has a strong influence on
the location of the critical point of a noise-induced, finite-size transition
occurring in the model, on the local ordering of the system, and on the
functional form of its temporal correlations. Finally, we show how this latter
point opens the possibility of inferring the degree heterogeneity of the
underlying network by observing only the aggregate behavior of the system as a
whole, an issue of interest for systems where only macroscopic, population
level variables can be measured.
"
1602.06943	q-fin	q-fin.GN	"Bunching of numbers in a non-ideal roulette: the key to winning
  strategies"	"  Chances of a gambler are always lower than chances of a casino in the case of
an ideal, mathematically perfect roulette, if the capital of the gambler is
limited and the minimum and maximum allowed bets are limited by the casino.
However, a realistic roulette is not ideal: the probabilities of realisation of
different numbers slightly deviate. Describing this deviation by a statistical
distribution with a width {\delta} we find a critical {\delta} that equalizes
chances of gambler and casino in the case of a simple strategy of the game: the
gambler always puts equal bets to the last N numbers. For up-critical {\delta}
the expected return of the roulette becomes positive. We show that the dramatic
increase of gambler's chances is a manifestation of bunching of numbers in a
non-ideal roulette. We also estimate the critical starting capital needed to
ensure the low risk game for an indefinite time.
"
1602.06968	q-fin	q-fin.TR	"Limit Order Book and its modelling in terms of Gibbs Grand-Canonical
  Ensemble"	"  In the domain of the so called Econophysics some attempts already have been
made for applying the theory of Thermodynamics and Statistical Mechanics to
economics and financial markets. In this paper a similar approach is made from
a different perspective, trying to model the limit order book and price
formation process of a given stock by the Grand-Canonical Gibbs Ensemble for
the bid and ask processes. As a consequence we can define in a meaningful way
expressions for the temperatures of the ensembles of bid orders and of ask
orders, which are a function of maximum bid, minimum ask and closure prices of
the stock as well as of the exchanged volume of shares. It is demonstrated that
the difference between the ask and bid orders temperatures can be related to
the VAO (Volume Accumulation Oscillator) indicator, empirically defined in
Technical Analysis of stock markets. Furthermore the distributions for bid and
ask orders derived by the theory can be subject to well defined validations
against real data, giving a falsifiable character to the model.
"
1602.07300	q-fin	q-fin.EC physics.soc-ph	When does inequality freeze an economy?	"  Inequality and its consequences are the subject of intense recent debate.
Using a simplified model of the economy, we address the relation between
inequality and liquidity, the latter understood as the frequency of economic
exchanges. Assuming a Pareto distribution of wealth for the agents, that is
consistent with empirical findings, we find an inverse relation between wealth
inequality and overall liquidity. We show that an increase in the inequality of
wealth results in an even sharper concentration of the liquid financial
resources. This leads to a congestion of the flow of goods and the arrest of
the economy when the Pareto exponent reaches one.
"
1602.07452	q-fin	q-fin.GN	"Contagion in the world's stock exchanges seen as a set of coupled
  oscillators"	"  We study how the phenomenon of contagion can take place in the network of the
world's stock exchanges due to the behavioral trait ""blindeness to small
changes"". On large scale individual, the delay in the collective response may
significantly change the dynamics of the overall system. We explicitely insert
a term describing the behavioral phenomenon in a system of equations that
describe the build and release of stress across the worldwide stock markets. In
the mathematical formulation of the model, each stock exchange acts as an
integrate-and-fire oscillator. Calibration on market data validate the model.
  One advantage of the integrate-and-fire dynamics is that it enables for a
direct identification of cause and effect of price movements, without the need
for statistical tests such as for example Granger causality tests often used in
the identification of causes of contagion. Our methodology can thereby identify
the most relevant nodes with respect to onset of contagion in the network of
stock exchanges, as well as identify potential periods of high vulnerability of
the network. The model is characterized by a separation of time scales created
by a slow build up of stresses, for example due to (say monthly/yearly)
macroeconomic factors, and then a fast (say hourly/daily) release of stresses
through ""price-quakes"" of price movements across the worlds network of stock
exchanges.
"
1602.07628	q-fin	q-fin.EC	"The Invisible Hand of Laplace: the Role of Market Structure in Price
  Convergence and Oscillation"	"  A fundamental question about a market is under what conditions, and then how
rapidly, does price signaling cause price equilibration. Qualitatively, this
ought to depend on how well-connected the market is. We address this question
quantitatively for a certain class of Arrow-Debreu markets with continuous-time
proportional t\^{a}tonnement dynamics. We show that the algebraic connectivity
of the market determines the effectiveness of price signaling equilibration.
This also lets us study the rate of external noise that a market can tolerate
and still maintain near-equilibrium prices.
"
1602.07910	q-fin	q-fin.MF	Polynomial Diffusion Models for Life Insurance Liabilities	"  In this paper we study the pricing and hedging problem of a portfolio of life
insurance products under the benchmark approach, where the reference market is
modelled as driven by a state variable following a polynomial diffusion on a
compact state space. Such a model guarantees not only the positivity of the OIS
short rate and the mortality intensity, but also the possibility of
approximating both pricing formula and hedging strategy of a large class of
life insurance products by explicit formulas.
"
1602.08258	q-fin	q-fin.ST	"Modified Profile Likelihood Inference and Interval Forecast of the Burst
  of Financial Bubbles"	"  We present a detailed methodological study of the application of the modified
profile likelihood method for the calibration of nonlinear financial models
characterised by a large number of parameters. We apply the general approach to
the Log-Periodic Power Law Singularity (LPPLS) model of financial bubbles. This
model is particularly relevant because one of its parameters, the critical time
$t_c$ signalling the burst of the bubble, is arguably the target of choice for
dynamical risk management. However, previous calibrations of the LPPLS model
have shown that the estimation of $t_c$ is in general quite unstable. Here, we
provide a rigorous likelihood inference approach to determine $t_c$, which
takes into account the impact of the other nonlinear (so-called ""nuisance"")
parameters for the correct adjustment of the uncertainty on $t_c$. This
provides a rigorous interval estimation for the critical time, rather than a
point estimation in previous approaches. As a bonus, the interval estimations
can also be obtained for the nuisance parameters ($m,\omega$, damping), which
can be used to improve filtering of the calibration results. We show that the
use of the modified profile likelihood method dramatically reduces the number
of local extrema by constructing much simpler smoother log-likelihood
landscapes. The remaining distinct solutions can be interpreted as genuine
scenarios that unfold as the time of the analysis flows, which can be compared
directly via their likelihood ratio. Finally, we develop a multi-scale profile
likelihood analysis to visualize the structure of the financial data at
different scales (typically from 100 to 750 days). We test the methodology
successfully on synthetic price time series and on three well-known historical
financial bubbles.
"
1602.08270	q-fin	q-fin.TR physics.soc-ph	Order Book, Financial Markets and Self-Organized Criticality	"  We present a simple order book mechanism that regulates an artificial
financial market with self-organized criticality dynamics and fat tails of
returns distribution. The model shows the role played by individual imitation
in determining trading decisions, while fruitfully replicates typical aggregate
market behavior as the ""self-fulfilling prophecy"". We also address the role of
random traders as a possible decentralized solution to dampen market
fluctuations.
"
1602.08374	q-fin	physics.soc-ph q-fin.GN	"Spatio-temporal analysis of micro economic activities in Rome reveals
  patterns of mixed-use urban evolution"	"  Understanding urban growth is one with understanding how society evolves to
satisfy the needs of its individuals in sharing a common space and adapting to
the territory. We propose here a quantitative analysis of the historical
development of a large urban area by investigating the spatial distribution and
the age of commercial activities in the whole city of Rome. We find that the
age of activities of various categories presents a very interesting double
exponential trend, with a transition possibly related to the long-term
economical effects determined by the oil crisis of the Seventies. The
diversification of commercial categories, studied through various measures of
entropy, shows, among other interesting features, a saturating behaviour with
the density of activities. Moreover, different couples of commercial categories
exhibit over the years a tendency to attract in space. Our results demonstrate
that the spatio-temporal distribution of commercial activities can provide
important insights on the urbanisation processes at work, revealing specific
and not trivial socio-economical dynamics, as the presence of crisis periods
and expansion trends, and contributing to the characterisation of the maturity
of urban areas.
"
1602.08429	q-fin	q-fin.GN	No such thing as a risk-neutral market	"  A very brief history of relative valuation in neoclassical finance since 1973
is presented, with attention to core currency issues for emerging economies.
Price formation is considered in the context of hierarchical causality, with
discussion focussed on identifying mathematical modelling challenges for robust
and transparent regulation of interactions.
"
1602.08442	q-fin	q-fin.GN physics.soc-ph	"Escaping the trap of 'blocking': a kinetic model linking economic
  development and political competition"	"  In this paper we present a kinetic model with stochastic game-type
interactions, analyzing the relationship between the level of political
competition in a society and the degree of economic liberalization. The above
issue regards the complex interactions between economy and institutional
policies intended to introduce technological innovations in a society, where
technological innovations are intended in a broad sense comprehending reforms
critical to production. A special focus is placed on the political replacement
effect described in a macroscopic model by Acemoglu and Robinson (AR-model,
henceforth), which can determine the phenomenon of innovation 'blocking',
possibly leading to economic backwardness. One of the goals of our modelization
is to obtain a mesoscopic dynamical model whose macroscopic outputs are
qualitatively comparable with stylized facts of the AR-model. A set of
numerical solutions is presented showing the non monotonous relationship
between economic liberization and political competition, which can be
considered as an emergent phenomenon of the complex socio-economic interaction
dynamic.
"
1602.08533	q-fin	q-fin.EC q-fin.MF	A Rank-Based Approach to Zipf's Law	"  An Atlas model is a rank-based system of continuous semimartingales for which
the steady-state values of the processes follow a power law, or Pareto
distribution. For a power law, the log-log plot of these steady-state values
versus rank is a straight line. Zipf's law is a power law for which the slope
of this line is -1. In this note, rank-based conditions are found under which
an Atlas model will follow Zipf's law. An advantage of this rank-based approach
is that it provides information about the dynamics of systems that result in
Zipf's law.
"
1602.09071	q-fin	q-fin.EC	Fairs for e-commerce: the benefits of aggregating buyers and sellers	"  In recent years, many new and interesting models of successful online
business have been developed. Many of these are based on the competition
between users, such as online auctions, where the product price is not fixed
and tends to rise. Other models, including group-buying, are based on
cooperation between users, characterized by a dynamic price of the product that
tends to go down. There is not yet a business model in which both sellers and
buyers are grouped in order to negotiate on a specific product or service. The
present study investigates a new extension of the group-buying model, called
fair, which allows aggregation of demand and supply for price optimization, in
a cooperative manner. Additionally, our system also aggregates products and
destinations for shipping optimization. We introduced the following new
relevant input parameters in order to implement a double-side aggregation: (a)
price-quantity curves provided by the seller; (b) waiting time, that is, the
longer buyers wait, the greater discount they get; (c) payment time, which
determines if the buyer pays before, during or after receiving the product; (d)
the distance between the place where products are available and the place of
shipment, provided in advance by the buyer or dynamically suggested by the
system. To analyze the proposed model we implemented a system prototype and a
simulator that allow to study effects of changing some input parameters. We
analyzed the dynamic price model in fairs having one single seller and a
combination of selected sellers. The results are very encouraging and motivate
further investigation on this topic.
"
1602.09078	q-fin	q-fin.PR q-fin.CP	"Pricing and Hedging GMWB in the Heston and in the Black-Scholes with
  Stochastic Interest Rate Models"	"  Valuing Guaranteed Minimum Withdrawal Benefit (GMWB) has attracted
significant attention from both the academic field and real world financial
markets. As remarked by Yang and Dai, the Black and Scholes framework seems to
be inappropriate for such a long maturity products. Also Chen Vetzal and
Forsyth in showed that the price of these products is very sensitive to
interest rate and volatility parameters. We propose here to use a stochastic
volatility model (Heston model) and a Black Scholes model with stochastic
interest rate (Hull White model). For this purpose we present four numerical
methods for pricing GMWB variables annuities: a hybrid tree-finite difference
method and a Hybrid Monte Carlo method, an ADI finite difference scheme, and a
Standard Monte Carlo method. These methods are used to determine the
no-arbitrage fee for the most popular versions of the GMWB contract, and to
calculate the Greeks used in hedging. Both constant withdrawal, optimal
surrender and optimal withdrawal strategies are considered. Numerical results
are presented which demonstrate the sensitivity of the no-arbitrage fee to
economic, contractual and longevity assumptions.
"
1603.00568	q-fin	q-fin.RM stat.AP	"The Value of A Statistical Life in Absence of Panel Data: What can we
  do?"	"  In this paper I show how reliable estimates of the Value of a Statistical
Life (VSL) can be obtained using cross sectional data using Garen's
instrumental variable (IV) approach. The increase in the range confidence
intervals due to the IV setup can be reduced by a factor of 3 by using a proxy
to risk attitude. In order state the ""precision"" of the cross sectional VSL
estimates I estimate the VSL using Chilean panel data and use them as benchmark
for different cross sectional specifications. The use of the proxy eliminates
need for using hard-to-find instruments for the job risk level and narrows the
confidence intervals for the workers in the Chilean labor market for the year
2009.
"
1603.00736	q-fin	q-fin.GN	"Puzzling properties of the historical growth rate of income per capita
  explained"	"  Galor discovered many mysteries of the growth process. He lists them in his
Unified Growth Theory and wonders how they can be explained. Close inspection
of his mysteries reveals that they are of his own creation. They do not exist.
He created them by his habitually distorted presentation of data. One of his
self-created mysteries is the mystery of the alleged sudden spurt in the growth
rate of income per capita. This sudden spurt never happened. In order to
understand the growth rate of income per capita, its mathematical properties
are now explored and explained. The explanation is illustrated using the
historical world economic growth. Galor also wonders about the sudden spurt in
the growth rate of population. We show that this sudden spurt was also created
by the distorted presentation of data. The mechanism of the historical economic
growth and of the growth of human population is yet to be explained but it
would be unproductive to try to explain the non-existing and self-created
mysteries of the growth process described in the scientifically unacceptable
Unified Growth Theory. However, the problem is much deeper than just the
examination of this theory. Demographic Growth Theory is based on the incorrect
but deeply entrenched postulates developed by accretion over many years and now
generally accepted in the economic and demographic research, postulates
revolving around the concept of Malthusian stagnation and around a transition
from stagnation to growth. The study presented here and earlier similar
publications show that these postulates need to be replaced by interpretations
based on the mathematical analysis of data and on the correct understanding of
hyperbolic distributions.
"
1603.00751	q-fin	cs.LG q-fin.GN	"Equity forecast: Predicting long term stock price movement using machine
  learning"	"  Long term investment is one of the major investment strategies. However,
calculating intrinsic value of some company and evaluating shares for long term
investment is not easy, since analyst have to care about a large number of
financial indicators and evaluate them in a right manner. So far, little help
in predicting the direction of the company value over the longer period of time
has been provided from the machines. In this paper we present a machine
learning aided approach to evaluate the equity's future price over the long
time. Our method is able to correctly predict whether some company's value will
be 10% higher or not over the period of one year in 76.5% of cases.
"
1603.00850	q-fin	q-fin.EC physics.soc-ph	"Tipping elements and climate-economic shocks: Pathways toward integrated
  assessment"	"  The literature on the costs of climate change often draws a link between
climatic 'tipping points' and large economic shocks, frequently called
'catastrophes'. The use of the phrase 'tipping points' in this context can be
misleading. In popular and social scientific discourse, 'tipping points'
involve abrupt state changes. For some climatic 'tipping points,' the
commitment to a state change may occur abruptly, but the change itself may be
rate-limited and take centuries or longer to realize. Additionally, the
connection between climatic 'tipping points' and economic losses is tenuous,
though emerging empirical and process-model-based tools provide pathways for
investigating it. We propose terminology to clarify the distinction between
'tipping points' in the popular sense, the critical thresholds exhibited by
climatic and social 'tipping elements,' and 'economic shocks'. The last may be
associated with tipping elements, gradual climate change, or non-climatic
triggers. We illustrate our proposed distinctions by surveying the literature
on climatic tipping elements, climatically sensitive social tipping elements,
and climate-economic shocks, and we propose a research agenda to advance the
integrated assessment of all three.
"
1603.01041	q-fin	q-fin.RM math.ST stat.AP stat.ME stat.TH	"Estimating Quantile Families of Loss Distributions for Non-Life
  Insurance Modelling via L-moments"	"  This paper discusses different classes of loss models in non-life insurance
settings. It then overviews the class Tukey transform loss models that have not
yet been widely considered in non-life insurance modelling, but offer
opportunities to produce flexible skewness and kurtosis features often required
in loss modelling. In addition, these loss models admit explicit quantile
specifications which make them directly relevant for quantile based risk
measure calculations. We detail various parameterizations and sub-families of
the Tukey transform based models, such as the g-and-h, g-and-k and g-and-j
models, including their properties of relevance to loss modelling.
  One of the challenges with such models is to perform robust estimation for
the loss model parameters that will be amenable to practitioners when fitting
such models. In this paper we develop a novel, efficient and robust estimation
procedure for estimation of model parameters in this family Tukey transform
models, based on L-moments. It is shown to be more robust and efficient than
current state of the art methods of estimation for such families of loss models
and is simple to implement for practical purposes.
"
1603.01103	q-fin	q-fin.ST	"Regularities and Discrepancies of Credit Default Swaps: a Data Science
  approach through Benford's Law"	"  In this paper, we search whether the Benford's law is applicable to monitor
daily changes in sovereign Credit Default Swaps (CDS) quotes, which are
acknowledged to be complex systems of economic content. This test is of
paramount importance since the CDS of a country proxy its health and
probability to default, being associated to an insurance against the event of
its default. We fit the Benford's law to the daily changes in sovereign CDS
spreads for 13 European countries, - both inside and outside the European Union
and European Monetary Union. Two different tenors for the sovereign CDS
contracts are considered: 5 yrs and 10 yrs, - the former being the reference
and most liquid one. The time period under investigation is 2008-2015 which
includes the period of distress caused by the European sovereign debt crisis.
Moreover, (i) an analysis over relevant sub-periods is carried out, (ii)
several insights are provided also by implementing the tracking of the
Benford's law over moving windows. The main test for checking the conformance
to Benford's law is - as usual - the $\chi^{2}$ test, whose values are
presented and discussed for all cases. The analysis is further completed by
elaborations based on Chebyshev's distance and Kullback and Leibler's
divergence. The results highlight differences by countries and tenors. In
particular, these results suggest that liquidity seems to be associated to
higher levels of distortion. Greece - representing a peculiar case - shows a
very different path with respect to the other European countries.
"
1603.01231	q-fin	q-fin.CP q-fin.GN	"Stock prices, inflation and inflation uncertainty in the U.S.: Testing
  the long-run relationship considering Dow Jones sector indexes"	"  We test for the long-run relationship between stock prices, inflation and its
uncertainty for different U.S. sector stock indexes, over the period 2002M7 to
2015M10. For this purpose we use a cointegration analysis with one structural
break to capture the crisis effect, and we assess the inflation uncertainty
based on a time-varying unobserved component model. In line with recent
empirical studies we discover that in the long-run, the inflation and its
uncertainty negatively impact the stock prices, opposed to the well-known
Fisher effect. In addition we show that for several sector stock indexes the
negative effect of inflation and its uncertainty vanishes after the crisis
setup. However, in the short-run the results provide evidence in the favor of a
negative impact of uncertainty, while the inflation has no significant
influence on stock prices, except for the consumption indexes. The
consideration of business cycle effects confirms our findings, which proves
that the results are robust, both for the long-and the short-run relationships.
"
1603.01288	q-fin	q-fin.MF	Option spanning beyond $L_p$-models	"  \begin{abstract} The aim of this paper is to study the spanning power of
options in a static financial market that allows non-integrable assets. Our
findings extend and unify the results in [8,9,18] for $L_p$-models. We also
apply the spanning power properties to the pricing problem. In particular, we
show that prices on call and put options of a limited liability asset can be
uniquely extended by arbitrage to all marketed contingent claims written on the
asset.
"
1603.01308	q-fin	stat.ME q-fin.ST stat.AP	Dynamic Adaptive Mixture Models	"  In this paper we propose a new class of Dynamic Mixture Models (DAMMs) being
able to sequentially adapt the mixture components as well as the mixture
composition using information coming from the data. The information driven
nature of the proposed class of models allows to exactly compute the full
likelihood and to avoid computer intensive simulation schemes. An extensive
Monte Carlo experiment reveals that the new proposed model can accurately
approximate the more complicated Stochastic Dynamic Mixture Model previously
introduced in the literature as well as other kind of models. The properties of
the new proposed class of models are discussed through the paper and an
application in financial econometrics is reported.
"
1603.01341	q-fin	q-fin.TR	"Hong Kong - Shanghai Connect / Hong Kong - Beijing Disconnect (?),
  Scaling the Great Wall of Chinese Securities Trading Costs"	"  We utilize a fundamentally different model of trading costs to look at the
effect of the opening of the Hong Kong Shanghai Connect that links the stock
exchanges in the two cities, arguably the biggest event in international
business and finance since Christopher Columbus set sail for India. We design a
novel methodology that compensates for the lack of data on trading costs in
China. We estimate trading costs across similar positions on the dual listed
set of securities in Hong Kong and China, hoping to provide useful pieces of
information to help scale 'The Great Wall of Chinese Securities Trading Costs'.
We then compare actual and estimated trading costs on a sample of real orders
across the Hong Kong securities in the dual listed pair to establish the
accuracy of our measurements.
  The primary question we seek to address is 'Which market would be better to
trade to gain exposure to the same (or similar) set of securities or sectors?'
We find that trading costs on Shanghai, which might have been lower than Hong
Kong, might have become higher leading up to the Connect. What remains to be
seen is whether this increase in trading costs is a temporary equilibrium due
to the frenzy to gain exposure to Chinese securities or whether this phenomenon
will persist once the two markets start becoming more and more tightly coupled.
  It would be interesting to see if this pioneering policy will lead to
securities exchanges across the globe linking up one another, creating a trade
anything, anywhere and anytime marketplace. Looking beyond mere trading costs,
such studies can be used to gather some evidence on what effect the mode of
governance and other aspects of life in one country have on another country,
once they start joining up their financial markets.
"
1603.01397	q-fin	stat.AP q-fin.GN q-fin.ST	"Latent class analyisis for reliable measure of inflation expectation in
  the indian public"	"  The main aim of this paper is to inspect the properties of survey based on
households inflation expectations, conducted by Reserve Bank of India. It is
theorized that the respondents answers are exaggerated by extreme response
bias. Latent class analysis has been hailed as a promising technique for
studying measurement errors in surveys, because the model produces estimates of
the error rates associated with a given question of the questionnaire. I have
identified a model with optimum performance and hence categorize the objective
as well as reliable classifiers or otherwise.
"
1603.01580	q-fin	q-fin.ST q-fin.TR	Cross-response in correlated financial markets: individual stocks	"  Previous studies of the stock price response to trades focused on the
dynamics of single stocks, i.e. they addressed the self-response. We
empirically investigate the price response of one stock to the trades of other
stocks in a correlated market, i.e. the cross-responses. How large is the
impact of one stock on others and vice versa? -- This impact of trades on the
price change across stocks appears to be transient instead of permanent as we
discuss from the viewpoint of market efficiency. Furthermore, we compare the
self-responses on different scales and the self- and cross-responses on the
same scale. We also find that the cross-correlation of the trade signs turns
out to be a short-memory process.
"
1603.01586	q-fin	q-fin.ST q-fin.TR	Average cross-responses in correlated financial market	"  There are non-vanishing price responses across different stocks in correlated
financial markets. We further study this issue by performing different
averages, which identify active and passive cross-responses. The two average
cross-responses show different characteristic dependences on the time lag. The
passive cross-response exhibits a shorter response period with sizeable
volatilities, while the corresponding period for the active cross-response is
longer. The average cross-responses for a given stock are evaluated either with
respect to the whole market or to different sectors. Using the response
strength, the influences of individual stocks are identified and discussed.
Moreover, the various cross-responses as well as the average cross-responses
are compared with the self-responses. In contrast, the short memory of trade
sign cross-correlation for stock pairs, the sign cross-correlation has long
memory when averaged over different pairs of stocks.
"
1603.01685	q-fin	q-fin.EC q-fin.GN	Mathematical analysis of historical income per capita distributions	"  Data describing historical growth of income per capita [Gross Domestic
Product per capita (GDP/cap)] for the world economic growth and for the growth
in Western Europe, Eastern Europe, Asia, former USSR, Africa and Latin America
are analysed. They follow closely the linearly-modulated hyperbolic
distributions represented by the ratios of hyperbolic distributions obtained by
fitting the GDP and population data. Results of this analysis demonstrate that
income per capita was increasing monotonically. There was no stagnation and
there were no transitions from stagnation to growth. The usually postulated
dramatic escapes from the Malthusian trap never happened because there was no
trap. Unified Growth Theory is fundamentally incorrect because its central
postulates are contradicted repeatedly by data, which were used but never
analysed during the formulation of this theory. The large body of
readily-available data opens new avenues for the economic and demographic
research. They show that certain fundamental postulates revolving around the
concept of Malthusian stagnation need to be replaced by the evidence-based
interpretations. Within the range of analysable data, which for the growth of
population extends down to 10,000 BC, growth of human population and economic
growth were hyperbolic. There was no Malthusian stagnation and there were no
transitions to distinctly faster trajectories. Industrial Revolution had no
impact on changing growth trajectories.
"
1603.01865	q-fin	math.PR q-fin.MF	"Exponentially concave functions and high dimensional stochastic
  portfolio theory"	"  We consider the following problem in stochastic portfolio theory. Are there
portfolios that are relative arbitrages with respect to the market portfolio
over very short periods of time under realistic assumptions? We answer a
slightly relaxed question affirmative in the following high dimensional sense,
where dimension refers to the number of stocks being traded. Very roughly,
suppose that for every dimension we have a continuous semimartingale market
such that (i) the vector of market weights in decreasing order has a stationary
regularly varying tail with an index between $-1$ and $-1/2$ and (ii) zero is
not a limit point of the relative volatilities of the stocks. Then, given a
probability $\eta < 1$ arbitrarily close to one, two arbitrarily small
$\epsilon, \delta >0$, and an arbitrarily high positive amount $M$, for all
high enough dimensions, it is possible to construct a functionally generated
portfolio such that, with probability at least $\eta$, its relative value with
respect to the market at time $\delta$ is at least $M$, and never goes below
$(1-\epsilon)$ during $[0, \delta]$. There are two phase transitions; if the
index of the tail is less than $-1$ or larger than $-1/2$. The construction
uses properties of regular variation, high-dimensional convex geometry and
concentration of measure under Dirichlet distributions. We crucially use the
notion of $(K,N)$ convex functions introduced by Erbar, Kuwada, Sturm in the
context of curvature-dimension conditions and Bochner's inequalities.
"
1603.02354	q-fin	q-fin.PM	Stock Selection as a Problem in Phylogenetics -- Evidence from the ASX	"  We report the results of fifteen sets of portfolio selection simulations
using stocks in the ASX200 index for the period May 2000 to December 2013. We
investigated five portfolio selection methods, randomly and from within
industrial groups, and three based on neighbor-Net phylogenetic networks. We
report that using random, industrial groups, or neighbor-Net phylogenetic
networks alone rarely produced statistically significant reduction in risk,
though in four out of the five cases in which it did so, the portfolios
selected using the phylogenetic networks had the lowest risk. However, we
report that when using the neighbor-Net phylogenetic networks in combination
with industry group selection that substantial reductions in portfolio return
spread were achieved.
"
1603.02867	q-fin	q-fin.MF math.OC math.PR	"Convex duality in optimal investment and contingent claim valuation in
  illiquid markets"	"  This paper studies convex duality in optimal investment and contingent claim
valuation in markets where traded assets may be subject to nonlinear trading
costs and portfolio constraints. Under fairly general conditions, the dual
expressions decompose into tree terms, corresponding to the agent's risk
preferences, trading costs and portfolio constraints, respectively. The dual
representations are shown to be valid when the market model satisfies an
appropriate generalization of the no-arbitrage condition and the agent's
utility function satisfies an appropriate generalization of asymptotic
elasticity conditions. When applied to classical liquid market models or models
with bid-ask spreads, we recover well-known pricing formulas in terms of
martingale measures and consistent price systems. Building on the general
theory of convex stochastic optimization, we also derive optimality conditions
in terms of an extended notion of a ""shadow price"".
"
1603.02874	q-fin	q-fin.ST q-fin.CP q-fin.PR	"Libor at crossroads: stochastic switching detection using information
  theory quantifiers"	"  This paper studies the 28 time series of Libor rates, classified in seven
maturities and four currencies), during the last 14 years. The analysis was
performed using a novel technique in financial economics: the
Complexity-Entropy Causality Plane. This planar representation allows the
discrimination of different stochastic and chaotic regimes. Using a temporal
analysis based on moving windows, this paper unveals an abnormal movement of
Libor time series arround the period of the 2007 financial crisis. This
alteration in the stochastic dynamics of Libor is contemporary of what press
called ""Libor scandal"", i.e. the manipulation of interest rates carried out by
several prime banks. We argue that our methodology is suitable as a market
watch mechanism, as it makes visible the temporal redution in informational
efficiency of the market.
"
1603.02896	q-fin	q-fin.PR	"Small-time asymptotics for basket options -- the bi-variate SABR model
  and the hyperbolic heat kernel on $\mathbb{H}^3$"	"  We compute a sharp small-time estimate for the price of a basket call under a
bi-variate SABR model with both $\beta$ parameters equal to $1$ and three
correlation parameters, which extends the work of Bayer,Friz&Laurence [BFL14]
for the multivariate Black-Scholes flat vol model. The result follows from the
heat kernel on hyperbolic space for $n=3$ combined with the Bellaiche [Bel81]
heat kernel expansion and Laplace's method, and we give numerical results which
corroborate our asymptotic formulae. Similar to the Black-Scholes case, we find
that there is a phase transition from one ""most-likely"" path to two most-likely
paths beyond some critical $K^*$.
"
1603.02902	q-fin	q-fin.CP	Interacting Default Intensity with Hidden Markov Process	"  In this paper we consider a reduced-form intensity-based credit risk model
with a hidden Markov state process. A filtering method is proposed for
extracting the underlying state given the observation processes. The method may
be applied to a wide range of problems. Based on this model, we derive the
joint distribution of multiple default times without imposing stringent
assumptions on the form of default intensities. Closed-form formulas for the
distribution of default times are obtained which are then applied to solve a
number of practical problems such as hedging and pricing credit derivatives.
The method and numerical algorithms presented may be applicable to various
forms of default intensities.
"
1603.03012	q-fin	q-fin.CP	Capital Valuation Adjustment and Funding Valuation Adjustment	"  In the aftermath of the 2007 global financial crisis, banks started
reflecting into derivative pricing the cost of capital and collateral funding
through XVA metrics. Here XVA is a catch-all acronym whereby X is replaced by a
letter such as C for credit, D for debt, F for funding, K for capital and so
on, and VA stands for valuation adjustment. This behaviour is at odds with
economies where markets for contingent claims are complete, whereby trades
clear at fair valuations and the costs for capital and collateral are both
irrelevant to investment decisions. In this paper, we set forth a mathematical
formalism for derivative portfolio management in incomplete markets for banks.
A particular emphasis is given to the problem of finding optimal strategies for
retained earnings which ensure a sustainable dividend policy.
"
1603.03458	q-fin	q-fin.RM cs.SI	Financial contagion in investment funds	"  Many new models for measuring financial contagion have been presented
recently. While these models have not been specified for investment funds
directly, there are many similarities that could be explored to extend the
models. In this work we explore ideas developed about financial contagion to
create a network of investment funds using both cross-holding of quotas and a
bipartite network of funds and assets. Using data from the Brazilian asset
management market we analyze not only the contagion pattern but also the
structure of this network and how this model can be used to assess the
stability of the market.
"
1603.03538	q-fin	q-fin.MF math.OC math.PR q-fin.PM	"Asymptotic Optimal Strategy for Portfolio Optimization in a Slowly
  Varying Stochastic Environment"	"  In this paper, we study the portfolio optimization problem with general
utility functions and when the return and volatility of underlying asset are
slowly varying. An asymptotic optimal strategy is provided within a specific
class of admissible controls under this problem setup. Specifically, we first
establish a rigorous first order approximation of the value function associated
to a fixed zeroth order suboptimal trading strategy, which is given by the
heuristic argument in [J.-P. Fouque, R. Sircar and T. Zariphopoulou, {\it
Mathematical Finance}, 2016]. Then, we show that this zeroth order suboptimal
strategy is asymptotically optimal in a specific family of admissible trading
strategies. Finally, we show that our assumptions are satisfied by a particular
fully solvable model.
"
1603.03874	q-fin	q-fin.PR	"Analysis of the nonlinear option pricing model under variable
  transaction costs"	"  In this paper we analyze a nonlinear Black--Scholes model for option pricing
under variable transaction costs. The diffusion coefficient of the nonlinear
parabolic equation for the price $V$ is assumed to be a function of the
underlying asset price and the Gamma of the option. We show that the
generalizations of the classical Black--Scholes model can be analyzed by means
of transformation of the fully nonlinear parabolic equation into a quasilinear
parabolic equation for the second derivative of the option price. We show
existence of a classical smooth solution and prove useful bounds on the option
prices. Furthermore, we construct an effective numerical scheme for
approximation of the solution. The solutions are obtained by means of the
efficient numerical discretization scheme of the Gamma equation. Several
computational examples are presented.
"
1603.04017	q-fin	stat.ML q-fin.ST	Clustering Financial Time Series: How Long is Enough?	"  Researchers have used from 30 days to several years of daily returns as
source data for clustering financial time series based on their correlations.
This paper sets up a statistical framework to study the validity of such
practices. We first show that clustering correlated random variables from their
observed values is statistically consistent. Then, we also give a first
empirical answer to the much debated question: How long should the time series
be? If too short, the clusters found can be spurious; if too long, dynamics can
be smoothed out.
"
1603.04099	q-fin	q-fin.CP q-fin.RM	Contagion and Stability in Financial Networks	"  This paper investigates two mechanisms of financial contagion that are,
firstly, the correlated exposure of banks to the same source of risk, and
secondly the direct exposure of banks in the interbank market. It will consider
a random network of banks which are connected through the inter-bank market and
will discuss the desirable level of banks exposure to the same sources of risk,
that is investment in similar portfolios, for different levels of network
connectivity when peering through the lens of the systemic cost incurred to the
economy from the banks simultaneous failure. It demonstrates that for all
levels of network connectivity, certain levels of diversifying individual banks
diversifications are not optimum under any condition. So, given an acceptable
level of systemic cost, the regulator could let banks decrease their capital
buffers by moving away from the non-optimum area.
"
1603.05142	q-fin	q-fin.EC physics.soc-ph q-fin.RM	"Can banks default overnight? Modeling endogenous contagion on O/N
  interbank market"	"  We propose a new model of the liquidity driven banking system focusing on
overnight interbank loans. This significant branch of the interbank market is
commonly neglected in the banking system modeling and systemic risk analysis.
We construct a model where banks are allowed to use both the interbank and the
securities markets to manage their liquidity demand and supply as driven by
prudential requirements in a volatile environment. The network of interbank
loans is dynamic and simulated every day. We show how only the intrasystem cash
fluctuations, without any external shocks, may lead to systemic defaults, what
may be a symptom of the self-organized criticality of the system. We also
analyze the impact of different prudential regulations and market conditions on
the interbank market resilience. We confirm that central bank's asset purchase
programs, limiting the declines in government bond prices, can successfully
stabilize bank's liquidity demand. The model can be used to analyze the
interbank market impact of macroprudential tools.
"
1603.05181	q-fin	physics.soc-ph q-fin.GN	"Strength of weak layers in cascading failures on multiplex networks:
  case of the international trade network"	"  Many real-world complex systems across natural, social, and economical
domains consist of manifold layers to form multiplex networks. The multiple
network layers give rise to nonlinear effect for the emergent dynamics of
systems. Especially, weak layers that can potentially play significant role in
amplifying the vulnerability of multiplex networks might be shadowed in the
aggregated single-layer network framework which indiscriminately accumulates
all layers. Here we present a simple model of cascading failure on multiplex
networks of weight-heterogeneous layers. By simulating the model on the
multiplex network of international trades, we found that the multiplex model
produces more catastrophic cascading failures which are the result of emergent
collective effect of coupling layers, rather than the simple sum thereof.
Therefore risks can be systematically underestimated in single-layer network
analyses because the impact of weak layers can be overlooked. We anticipate
that our simple theoretical study can contribute to further investigation and
design of optimal risk-averse real-world complex systems.
"
1603.05294	q-fin	q-fin.GN stat.AP	Modeling and Estimation of the Risk When Choosing a Provider	"  The paper provides an algorithm for the risk estimation when a company
selects an outsourcing service provider for innovation product. Calculations
are based on expert surveys conducted among customers and among providers of
outsourcing. The surveys assessed the degree of materiality of species at risk.
"
1603.05313	q-fin	q-fin.TR q-fin.CP	Market Dynamics vs. Statistics: Limit Order Book Example	"  Commonly used limit order book attributes are empirically considered based on
NASDAQ ITCH data. It is shown that some of them have the properties drastically
different from the ones assumed in many market dynamics study. Because of this
difference we propose to make a transition from ""Statistical"" type of order
book study (typical for academics) to ""Dynamical"" type of study (typical for
market practitioners). Based on market data analysis we conclude, that most of
market dynamics information is contained in attributes with spikes (e.g.
executed trades flow $I=dv/dt$), there is no any ""stationary case"" on the
market and typical market dynamics is a ""fast excitation and then slow
relaxation"" type of behavior with a wide distribution of excitation frequencies
and relaxation times. A computer code, providing full depth order book
information and recently executed trades is available from authors [1].
"
1603.05373	q-fin	q-fin.RM	Sharp convex bounds on the aggregate sums--An alternative proof	"  It is well known that a random vector with given marginal distributions is
comonotonic if and only if it has the largest sum with respect to the convex
order [ Kaas, Dhaene, Vyncke, Goovaerts, Denuit (2002), A simple geometric
proof that comonotonic risks have the convex-largest sum, ASTIN Bulletin 32,
71-80. Cheung (2010), Characterizing a comonotonic random vector by the
distribution of the sum of its components, Insurance: Mathematics and Economics
47(2), 130-136] and that a random vector with given marginal distributions is
mutually exclusive if and only if it has the minimal convex sum [Cheung and Lo
(2014), Characterizing mutual exclusivity as the strongest negative
multivariate dependence structure, Insurance: Mathematics and Economics 55,
180-190]. In this note, we give a new proof of this two results using the
theories of distortion risk measure and expected utility.
"
1603.05828	q-fin	cs.SI cs.GT math.DS q-fin.EC	"Online Networks, Social Interaction and Segregation: An Evolutionary
  Approach"	"  We have developed an evolutionary game model, where agents can choose between
two forms of social participation: interaction via online social networks and
interaction by exclusive means of face-to-face encounters. We illustrate the
societal dynamics that the model predicts, in light of the empirical evidence
provided by previous literature. We then assess their welfare implications. We
show that dynamics, starting from a world in which online social interaction is
less gratifying than offline encounters, will lead to the extinction of the
sub-population of online networks users, thereby making Facebook and alike
disappear in the long run. Furthermore, we show that the higher the propensity
for discrimination between the two sub-populations of socially active
individuals, the greater the probability that individuals will ultimately
segregate themselves, making society fall into a social poverty trap.
"
1603.05914	q-fin	q-fin.RM physics.soc-ph stat.AP	Statistically validated network of portfolio overlaps and systemic risk	"  Common asset holding by financial institutions, namely portfolio overlap, is
nowadays regarded as an important channel for financial contagion with the
potential to trigger fire sales and thus severe losses at the systemic level.
In this paper we propose a method to assess the statistical significance of the
overlap between pairs of heterogeneously diversified portfolios, which then
allows us to build a validated network of financial institutions where links
indicate potential contagion channels due to realized portfolio overlaps. The
method is implemented on a historical database of institutional holdings
ranging from 1999 to the end of 2013, but can be in general applied to any
bipartite network where the presence of similar sets of neighbors is of
interest. We find that the proportion of validated network links (i.e., of
statistically significant overlaps) increased steadily before the 2007-2008
global financial crisis and reached a maximum when the crisis occurred. We
argue that the nature of this measure implies that systemic risk from fire
sales liquidation was maximal at that time. After a sharp drop in 2008,
systemic risk resumed its growth in 2009, with a notable acceleration in 2013,
reaching levels not seen since 2007. We finally show that market trends tend to
be amplified in the portfolios identified by the algorithm, such that it is
possible to have an informative signal about financial institutions that are
about to suffer (enjoy) the most significant losses (gains).
"
1603.05937	q-fin	q-fin.PM q-fin.RM	How to Combine a Billion Alphas	"  We give an explicit algorithm and source code for computing optimal weights
for combining a large number N of alphas. This algorithm does not cost O(N^3)
or even O(N^2) operations but is much cheaper, in fact, the number of required
operations scales linearly with N. We discuss how in the absence of binary or
quasi-binary clustering of alphas, which is not observed in practice, the
optimization problem simplifies when N is large. Our algorithm does not require
computing principal components or inverting large matrices, nor does it require
iterations. The number of risk factors it employs, which typically is limited
by the number of historical observations, can be sizably enlarged via using
position data for the underlying tradables.
"
1603.06047	q-fin	q-fin.PM q-fin.EC q-fin.GN	"The Circle of Investment: Connecting the Dots of the Portfolio
  Management Cycle..."	"  We will look at the entire cycle of the investment process relating to all
aspects of, formulating an investment hypothesis, constructing a portfolio
based on that, executing the trades to implement it, on-going risk management,
periodically measuring the performance of the portfolio, and rebalancing the
portfolio either due to an increase in the risk parameters or due to a
deviation from the intended asset allocation. We provide several illustrative
analogies that are meant to intuitively explain the pleasures and the pitfalls
that can arise while managing a portfolio. If we consider the entire investment
management procedure as being akin to connecting the dots of a circle, then the
Circle of Investment can be represented as a dotted circle with many dots
falling approximately on the circumference and with no clue about the exact
location of the centre or the length of the radius. We represent the investment
process as a dotted circle since there is a lot of ambiguity in the various
steps involved. The circle also indicates the repetitive nature of many steps
that are continuously carried out while investing. This work introduces two new
points pertaining to this dotted circle and improves the ability, to understand
how far-off this dotted circle is, from a more well-defined circle and, to
create a well-formed circle. The two innovations we introduce are:
  1. The first, relating to the limitations that apply to any finding in the
social sciences, would be the additional point we introduce that lies near the
centre of the circle. We title this as, 'The Uncertainty Principle of the
Social Sciences'.
  2. The second, relating to establishing confidence levels in a systematic
manner for each view we associate with a security or group of securities as
required by the Black-Litterman framework, would be the new point we present
near the circumference of the circle.
"
1603.06183	q-fin	q-fin.PM	Risk-Constrained Kelly Gambling	"  We consider the classic Kelly gambling problem with general distribution of
outcomes, and an additional risk constraint that limits the probability of a
drawdown of wealth to a given undesirable level. We develop a bound on the
drawdown probability; using this bound instead of the original risk constraint
yields a convex optimization problem that guarantees the drawdown risk
constraint holds. Numerical experiments show that our bound on drawdown
probability is reasonably close to the actual drawdown risk, as computed by
Monte Carlo simulation. Our method is parametrized by a single parameter that
has a natural interpretation as a risk-aversion parameter, allowing us to
systematically trade off asymptotic growth rate and drawdown risk. Simulations
show that this method yields bets that out perform fractional-Kelly bets for
the same drawdown risk level or growth rate. Finally, we show that a natural
quadratic approximation of our convex problem is closely connected to the
classical mean-variance Markowitz portfolio selection problem.
"
1603.06196	q-fin	q-fin.GN physics.soc-ph	"Switching Economics for Physics and the Carbon Price Inflation: Problems
  in Integrated Assessment Models and their Implications"	"  Integrated Assessment Models (IAMs) are mainstay tools for assessing the
long-term interactions between climate and the economy and for deriving optimal
policy responses in the form of carbon prices. IAMs have been criticized for
controversial discount rate assumptions, arbitrary climate damage functions,
and the inadequate handling of potentially catastrophic climate outcomes. We
review these external shortcomings for prominent IAMs before turning our focus
on an internal modeling fallacy: the widespread misapplication of the Constant
Elasticity of Substitution (CES) function for the technology transitions
modeled by IAMs. Applying CES, an economic modeling approach, on technical
factor inputs over long periods where an entire factor (the greenhouse gas
emitting fossil fuel inputs) must be substituted creates artifacts that fail to
match the S-curve patterns observed historically. A policy critical result, the
monotonically increasing cost of carbon, a universal feature of IAMs, is called
into question by showing that it is unrealistic as it is an artifact of the
modeling approach and not representative of the technical substitutability
potential nor of the expected cost of the technologies. We demonstrate this
first through a simple but representative example of CES application on the
energy system and with a sectoral discussion of the actual fossil substitution
costs. We propose a methodological modification using dynamically varying
elasticity of substitution as a plausible alternative to model the energy
transition in line with the historical observations and technical realities
within the existing modeling systems. Nevertheless, a fundamentally different
approach based on physical energy principles would be more appropriate.
"
1603.06312	q-fin	math.PR math.OC q-fin.MF	A rank based mean field game in the strong formulation	"  We discuss a natural game of competition and solve the corresponding mean
field game with \emph{common noise} when agents' rewards are \emph{rank
dependent}. We use this solution to provide an approximate Nash equilibrium for
the finite player game and obtain the rate of convergence.
"
1603.06389	q-fin	q-fin.PR math.PR	No-arbitrage bounds for the forward smile given marginals	"  We explore the robust replication of forward-start straddles given quoted
(Call and Put options) market data. One approach to this problem classically
follows semi-infinite linear programming arguments, and we propose a
discretisation scheme to reduce its dimensionality and hence its complexity.
Alternatively, one can consider the dual problem, consisting in finding optimal
martingale measures under which the upper and the lower bounds are attained.
Semi-analytical solutions to this dual problem were proposed by Hobson and
Klimmek (2013) and by Hobson and Neuberger (2008). We recast this dual approach
as a finite dimensional linear programme, and reconcile numerically, in the
Black-Scholes and in the Heston model, the two approaches.
"
1603.06558	q-fin	q-fin.TR	Universal trading under proportional transaction costs	"  The theory of optimal trading under proportional transaction costs has been
considered from a variety of perspectives. In this paper, we show that all the
results can be interpreted using a universal law, illustrating the results in
trading algorithm design.
"
1603.07488	q-fin	math.PR q-fin.MF	Conic Martingales from Stochastic Integrals	"  In this paper we introduce the concept of conic martingales}. This class
refers to stochastic processes having the martingale property, but that evolve
within given (possibly time-dependent) boundaries. We first review some results
about the martingale property of solution to driftless stochastic differential
equations. We then provide a simple way to construct and handle such processes.
Specific attention is paid to martingales in $[0,1]$. One of these martingales
proves to be analytically tractable. It is shown that up to shifting and
rescaling constants, it is the only martingale (with the trivial constant,
Brownian motion and Geometric Brownian motion) having a separable coefficient
$\sigma(t,y)=g(t)h(y)$ and that can be obtained via a time-homogeneous mapping
of Gaussian diffusions. The approach is exemplified to the modeling of
stochastic conditional survival probabilities in the univariate (both
conditional and unconditional to survival) and bivariate cases.
"
1603.07615	q-fin	q-fin.MF math.OC	A Note on the Optimal Dividends Paid in a Foreign Currency	"  We consider an insurance entity endowed with an initial capital and a surplus
process modelled as a Brownian motion with drift. It is assumed that the
company seeks to maximise the cumulated value of expected discounted dividends,
which are declared or paid in a foreign currency. The currency fluctuation is
modelled as a L\'evy process. We consider both cases: restricted and
unrestricted dividend payments. It turns out that the value function and the
optimal strategy can be calculated explicitly.
"
1603.07682	q-fin	cs.GT q-fin.EC	Descending Price Optimally Coordinates Search	"  Investigating potential purchases is often a substantial investment under
uncertainty. Standard market designs, such as simultaneous or English auctions,
compound this with uncertainty about the price a bidder will have to pay in
order to win. As a result they tend to confuse the process of search both by
leading to wasteful information acquisition on goods that have already found a
good purchaser and by discouraging needed investigations of objects,
potentially eliminating all gains from trade. In contrast, we show that the
Dutch auction preserves all of its properties from a standard setting without
information costs because it guarantees, at the time of information
acquisition, a price at which the good can be purchased. Calibrations to
start-up acquisition and timber auctions suggest that in practice the social
losses through poor search coordination in standard formats are an order of
magnitude or two larger than the (negligible) inefficiencies arising from
ex-ante bidder asymmetries.
"
1603.07822	q-fin	q-fin.ST stat.ME	"On clustering financial time series: a need for distances between
  dependent random variables"	"  The following working document summarizes our work on the clustering of
financial time series. It was written for a workshop on information geometry
and its application for image and signal processing. This workshop brought
several experts in pure and applied mathematics together with applied
researchers from medical imaging, radar signal processing and finance. The
authors belong to the latter group. This document was written as a long
introduction to further development of geometric tools in financial
applications such as risk or portfolio analysis. Indeed, risk and portfolio
analysis essentially rely on covariance matrices. Besides that the Gaussian
assumption is known to be inaccurate, covariance matrices are difficult to
estimate from empirical data. To filter noise from the empirical estimate,
Mantegna proposed using hierarchical clustering. In this work, we first show
that this procedure is statistically consistent. Then, we propose to use
clustering with a much broader application than the filtering of empirical
covariance matrices from the estimate correlation coefficients. To be able to
do that, we need to obtain distances between the financial time series that
incorporate all the available information in these cross-dependent random
processes.
"
1603.08114	q-fin	q-fin.CP	"GPU Computing in Bayesian Inference of Realized Stochastic Volatility
  Model"	"  The realized stochastic volatility (RSV) model that utilizes the realized
volatility as additional information has been proposed to infer volatility of
financial time series. We consider the Bayesian inference of the RSV model by
the Hybrid Monte Carlo (HMC) algorithm. The HMC algorithm can be parallelized
and thus performed on the GPU for speedup. The GPU code is developed with CUDA
Fortran. We compare the computational time in performing the HMC algorithm on
GPU (GTX 760) and CPU (Intel i7-4770 3.4GHz) and find that the GPU can be up to
17 times faster than the CPU. We also code the program with OpenACC and find
that appropriate coding can achieve the similar speedup with CUDA Fortran.
"
1603.08142	q-fin	q-fin.EC	"Conjoint axiomatization of the Choquet integral for heterogeneous
  product sets"	"  We propose an axiomatization of the Choquet integral model for the general
case of a heterogeneous product set $X = X_1 \times \ldots \times X_n$. In MCDA
elements of $X$ are interpreted as alternatives, characterized by criteria
taking values from the sets $X_i$. Previous axiomatizations of the Choquet
integral have been given for particular cases $X = Y^n$ and $X = \mathbb{R}^n$.
However, within multicriteria context such identicalness, hence
commensurateness, of criteria cannot be assumed a priori. This constitutes the
major difference of this paper from the earlier axiomatizations. In particular,
the notion of ""comonotonicity"" cannot be used in a heterogeneous structure, as
there does not exist a ""built-in"" order between elements of sets $X_i$ and
$X_j$. However, such an order is implied by the representation model. Our
approach does not assume commensurateness of criteria. We construct the
representation and study its uniqueness properties.
"
1603.08169	q-fin	q-fin.PM	Robust Optimization of Credit Portfolios	"  We introduce a dynamic credit portfolio framework where optimal investment
strategies are robust against misspecifications of the reference credit model.
The risk-averse investor models his fear of credit risk misspecification by
considering a set of plausible alternatives whose expected log likelihood
ratios are penalized. We provide an explicit characterization of the optimal
robust bond investment strategy, in terms of default state dependent value
functions associated with the max-min robust optimization criterion. The value
functions can be obtained as the solutions of a recursive system of HJB
equations. We show that each HJB equation is equivalent to a suitably truncated
equation admitting a unique bounded regular solution. The truncation technique
relies on estimates for the solution of the master HJB equation that we
establish.
"
1603.08216	q-fin	q-fin.CP	A Flexible Galerkin Scheme for Option Pricing in L\'evy Models	"  One popular approach to option pricing in L\'evy models is through solving
the related partial integro differential equation (PIDE). For the numerical
solution of such equations powerful Galerkin methods have been put forward e.g.
by Hilber et al. (2013). As in practice large classes of models are maintained
simultaneously, flexibility in the driving L\'evy model is crucial for the
implementation of these powerful tools. In this article we provide such a
flexible finite element Galerkin method. To this end we exploit the Fourier
representation of the infinitesimal generator, i.e. the related symbol, which
is explicitly available for the most relevant L\'evy models. Empirical studies
for the Merton, NIG and CGMY model confirm the numerical feasibility of the
method.
"
1603.08245	q-fin	q-fin.MF math.PR q-fin.PM	Trading Strategies Generated by Lyapunov Functions	"  Functional portfolio generation, initiated by E.R. Fernholz almost twenty
years ago, is a methodology for constructing trading strategies with controlled
behavior. It is based on very weak and descriptive assumptions on the
covariation structure of the underlying market model, and needs no estimation
of model parameters. In this paper, the corresponding generating functions $G$
are interpreted as Lyapunov functions for the vector process $\mu(\cdot)$ of
market weights; that is, via the property that $G(\mu(\cdot))$ is a
supermartingale under an appropriate change of measure. This point of view
unifies, generalizes, and simplifies several existing results, and allows the
formulation of conditions under which it is possible to outperform the market
portfolio over appropriate time-horizons. From a probabilistic point of view,
the present paper yields results concerning the interplay of stochastic
discount factors and concave transformations of semimartingales on compact
domains.
"
1603.08289	q-fin	q-fin.MF q-fin.PR	"Pricing variance swaps in a hybrid model of stochastic volatility and
  interest rate with regime-switching"	"  In this paper, we consider the problem of pricing discretely-sampled variance
swaps based on a hybrid model of stochastic volatility and stochastic interest
rate with regime-switching. Our modelling framework extends the Heston
stochastic volatility model by including the CIR stochastic interest rate and
model parameters that switch according to a continuous-time observable Markov
chain process. A semi-closed form pricing formula for variance swaps is
derived. The pricing formula is assessed through numerical implementations, and
the impact of including regime-switching on pricing variance swaps is also
discussed.
"
1603.08311	q-fin	q-fin.EC q-fin.GN	Interest Rates and Inflation	"  This article is an extension of the work of one of us (Coopersmith, 2011) in
deriving the relationship between certain interest rates and the inflation rate
of a two component economic system. We use the well-known Fisher relation
between the difference of the nominal interest rate and its inflation adjusted
value to eliminate the inflation rate and obtain a delay differential equation.
We provide computer simulated solutions for this equation over regimes of
interest. This paper could be of interest to three audiences: those in
Economics who are interested in interest and inflation; those in Mathematics
who are interested in examining a detailed analysis of a delay differential
equation, which includes a summary of existing results, simulations, and an
exact solution; and those in Physics who are interested in non-traditional
applications of traditional methods of modeling.
"
1603.08344	q-fin	q-fin.EC q-fin.GN	The unresolved mystery of the great divergence is solved	"  The so-called great divergence in the income per capita is described in the
Unified Growth Theory as the mind-boggling and unresolved mystery about the
growth process. This mystery has now been solved: the great divergence never
happened. It was created by the manipulation of data. Economic growth in
various regions is at different levels of development but it follows similar,
non-divergent trajectories. Unified Growth Theory is shown yet again to be
incorrect and scientifically unacceptable. It promotes incorrect and even
potentially dangerous concepts. The distorted presentation of data supporting
the concept of the great divergence shows that economic growth is now
developing along moderately-increasing trajectories but mathematical analysis
of the same data and even their undistorted presentation shows that these
trajectories are now increasing approximately vertically with time. So, while
the distorted presentation of data used in the Unified Growth Theory suggests
generally sustainable and secure economic growth, the undistorted presentation
of data demonstrates that the growth is unsustainable and insecure. The concept
of takeoffs from stagnation to the sustained-growth regime promoted in the
Unified Growth Theory is also dangerously misleading because it suggests a
sustainable and prosperous future while the mathematical analysis of data shows
that the current economic growth is insecure and unsustainable.
"
1603.08383	q-fin	q-fin.GN physics.soc-ph q-fin.ST	Modelling income, wealth, and expenditure data by use of Econophysics	"  In the present paper, we identify several distributions from Physics and
study their applicability to phenomena such as distribution of income, wealth,
and expenditure. Firstly, we apply logistic distribution to these data and we
find that it fits very well the annual data for the entire income interval
including for upper income segment of population. Secondly, we apply
Fermi-Dirac distribution to these data. We seek to explain possible
correlations and analogies between economic systems and statistical
thermodynamics systems. We try to explain their behavior and properties when we
correlate physical variables with macroeconomic aggregates and indicators. Then
we draw some analogies between parameters of the Fermi-Dirac distribution and
macroeconomic variables. Thirdly, as complex systems are modeled using
polynomial distributions, we apply polynomials to the annual sets of data and
we find that it fits very well also the entire income interval. Fourthly, we
develop a new methodology to approach dynamically the income, wealth, and
expenditure distribution similarly with dynamical complex systems. This
methodology was applied to different time intervals consisting of consecutive
years up to 35 years. Finally, we develop a mathematical model based on a
Hamiltonian that maximizes utility function applied to Ramsey model using
Fermi-Dirac and polynomial utility functions. We find some theoretical
connections with time preference theory. We apply these distributions to a
large pool of data from countries with different levels of development, using
different methods for calculation of income, wealth, and expenditure.
"
1603.08961	q-fin	cs.MA physics.soc-ph q-fin.EC	Betting and Belief: Prediction Markets and Attribution of Climate Change	"  Despite much scientific evidence, a large fraction of the American public
doubts that greenhouse gases are causing global warming. We present a
simulation model as a computational test-bed for climate prediction markets.
Traders adapt their beliefs about future temperatures based on the profits of
other traders in their social network. We simulate two alternative climate
futures, in which global temperatures are primarily driven either by carbon
dioxide or by solar irradiance. These represent, respectively, the scientific
consensus and a hypothesis advanced by prominent skeptics. We conduct
sensitivity analyses to determine how a variety of factors describing both the
market and the physical climate may affect traders' beliefs about the cause of
global climate change. Market participation causes most traders to converge
quickly toward believing the ""true"" climate model, suggesting that a climate
market could be useful for building public consensus.
"
1603.09049	q-fin	q-fin.CP	"Numerical approximation of a cash-constrained firm value with investment
  opportunities"	"  We consider a singular control problem with regime switching that arises in
problems of optimal investment decisions of cash-constrained firms. The value
function is proved to be the unique viscosity solution of the associated
Hamilton-Jacobi-Bellman equation.
  Moreover, we give regularity properties of the value function as well as a
description of the shape of the control regions. Based on these theoretical
results, a numerical deterministic approximation of the related HJB variational
inequality is provided. We finally show that this numerical approximation
converges to the value function. This allows us to describe the investment and
dividend optimal policies.
"
1603.09329	q-fin	math.PR q-fin.MF	"Pricing occupation-time options in a mixed-exponential jump-diffusion
  model"	"  In this short paper, in order to price occupation-time options, such as
(double-barrier) step options and quantile options, we derive various joint
distributions of a mixed-exponential jump-diffusion process and its occupation
times of intervals.
"
1603.09519	q-fin	math.OC q-fin.PM	Deterministic Income with Deterministic and Stochastic Interest Rates	"  We consider an individual or household endowed with an initial capital and an
income, modeled as a deterministic process with a continuous drift rate. At
first, we model the discounting rate as the price of a zero-coupon bond at zero
under the assumption of a short rate evolving as an Ornstein-Uhlenbeck process.
Then, a geometric Brownian motion as the preference function and an
Ornstein-Uhlenbeck process as the short rate are taken into consideration. It
is assumed that the primal interest of the economic agent is to maximise the
cumulated value of (expected) discounted consumption from a given time up to a
finite deterministic time horizon $T\in\R_+$ or, in a stochastic setting,
infinite time horizon. We find an explicit expression for the value function
and for the optimal strategy in the first two cases. In the third case, we have
to apply the viscosity ansatz.
"
1604.00254	q-fin	q-fin.MF q-fin.RM	Systemic Risks in CCP Networks	"  We propose a model for the credit and liquidity risks faced by clearing
members of Central Counterparty Clearing houses (CCPs). This model aims to
capture the features of: gap risk; feedback between clearing member default,
market volatility and margining requirements; the different risks faced by
various types of market participant and the changes in margining requirements a
clearing member faces as the system evolves. By considering the entire network
of CCPs and clearing members, we investigate the distribution of losses to
default fund contributions and contingent liquidity requirements for each
clearing member; further, we identify wrong-way risks between defaults of
clearing members and market turbulence.
"
1604.00283	q-fin	q-fin.GN	"Corruption and Wealth: Unveiling a national prosperity syndrome in
  Europe"	"  Data mining revealed a cluster of economic, psychological, social and
cultural indicators that in combination predicted corruption and wealth of
European nations. This prosperity syndrome of self-reliant citizens, efficient
division of labor, a sophisticated scientific community, and respect for the
law, was clearly distinct from that of poor countries that had a diffuse
relationship between high corruption perception, low GDP/capita, high social
inequality, low scientific development, reliance on family and friends, and
languages with many words for guilt. This suggests that there are many ways for
a nation to be poor, but few ones to become rich, supporting the existence of
synergistic interactions between the components in the prosperity syndrome
favoring economic growth. No single feature was responsible for national
prosperity. Focusing on synergies rather than on single features should improve
our understanding of the transition from poverty and corruption to prosperity
in European nations and elsewhere.
"
1604.00525	q-fin	q-fin.MF math.PR	"On regularity of primal and dual dynamic value functions related to
  investment problem"	"  We study regularity properties of the dynamic value functions of primal and
dual problems of optimal investing for utility functions defined on the whole
real line. Relations between decomposition terms of value processes of primal
and dual problems and between optimal solutions of basic and conditional
utility maximization problems are established. These properties are used to
show that the value function satisfies a corresponding backward stochastic
partial differential equation.
  In the case of complete markets we give conditions on the utility function
when this equation admits a solution.
"
1604.00976	q-fin	physics.soc-ph nlin.AO q-bio.PE q-fin.EC	From Big Data To Important Information	"  Advances in science are being sought in newly available opportunities to
collect massive quantities of data about complex systems. While key advances
are being made in detailed mapping of systems, how to relate this data to
solving many of the challenges facing humanity is unclear. The questions we
often wish to address require identifying the impact of interventions on the
system and that impact is not apparent in the detailed data that is available.
Here we review key concepts and motivate a general framework for building
larger scale views of complex systems and for characterizing the importance of
information in physical, biological and social systems. We provide examples of
its application to evolutionary biology with relevance to ecology,
biodiversity, pandemics, and human lifespan, and in the context of social
systems with relevance to ethnic violence, global food prices, and stock market
panic. Framing scientific inquiry as an effort to determine what is important
and unimportant is a means for advancing our understanding and addressing many
practical concerns, such as economic development or treating disease.
"
1604.01224	q-fin	q-fin.EC	Commodity Dynamics: A Sparse Multi-class Approach	"  The correct understanding of commodity price dynamics can bring relevant
improvements in terms of policy formulation both for developing and developed
countries. Agricultural, metal and energy commodity prices might depend on each
other: although we expect few important effects among the total number of
possible ones, some price effects among different commodities might still be
substantial. Moreover, the increasing integration of the world economy suggests
that these effects should be comparable for different markets. This paper
introduces a sparse estimator of the Multi-class Vector AutoRegressive model to
detect common price effects between a large number of commodities, for
different markets or investment portfolios. In a first application, we consider
agricultural, metal and energy commodities for three different markets. We show
a large prevalence of effects involving metal commodities in the Chinese and
Indian markets, and the existence of asymmetric price effects. In a second
application, we analyze commodity prices for five different investment
portfolios, and highlight the existence of important effects from energy to
agricultural commodities. The relevance of biofuels is hereby confirmed.
Overall, we find stronger similarities in commodity price effects among
portfolios than among markets.
"
1604.01281	q-fin	q-fin.PR math.PR	Option Pricing in the Moderate Deviations Regime	"  We consider call option prices in diffusion models close to expiry, in an
asymptotic regime (""moderately out of the money"") that interpolates between the
well-studied cases of at-the-money options and out-of-the-money fixed-strike
options. First and higher order small-time moderate deviation estimates of call
prices and implied volatility are obtained. The expansions involve only simple
expressions of the model parameters, and we show in detail how to calculate
them for generic local and stochastic volatility models. Some numerical
examples for the Heston model illustrate the accuracy of our results.
"
1604.01322	q-fin	q-fin.GN physics.soc-ph	Controllability Analyses on Firm Networks Based on Comprehensive Data	"  Since governments give stimulus to firms and expect the spillover effect by
fiscal policies, it is important to know the effectiveness that they can
control the economy. To clarify the controllability of the economy, we
investigate a firm production network observed exhaustively in Japan and what
firms should be directly or indirectly controlled by using control theory. By
control theory, we can classify firms into three different types: (a) firms
that should be directly controlled; (b) firms that should be indirectly
controlled; (c) neither of them (ordinary). Since there is a direction
(supplier and client) in the production network, we can consider controls of
two different directions: demand and supply sides. As analyses results, we
obtain the following results: (1) Each industry has diverse share of firms that
should be controlled directly or indirectly. The configurations of the shares
in industries are different between demand- and supply-sides; (2) Advancement
of industries, such like, primary industries or other advanced industries, does
not show apparent difference in controllability; (3) If we clip a network in
descending order of capital size, we do not lose the control effect for both
demand- and supply-sides.
"
1604.01338	q-fin	q-fin.ST	Copula--based Specification of vector MEMs	"  The Multiplicative Error Model (Engle (2002)) for nonnegative valued
processes is specified as the product of a (conditionally autoregressive) scale
factor and an innovation process with nonnegative support. A multivariate
extension allows for the innovations to be contemporaneously correlated. We
overcome the lack of sufficiently flexible probability density functions for
such processes by suggesting a copula function approach to estimate the
parameters of the scale factors and of the correlations of the innovation
processes. We illustrate this vector MEM with an application to the
interactions between realized volatility, volume and the number of trades. We
show that significantly superior realized volatility forecasts are delivered in
the presence of other trading activity indicators and contemporaneous
correlations.
"
1604.01447	q-fin	q-fin.MF	Relativistic Quantum Finance	"  Employing the Klein-Gordon equation, we propose a generalized Black-Scholes
equation. In addition, we found a limit where this generalized equation is
invariant under conformal transformations, in particular invariant under scale
transformations. In this limit, we show that the stock prices distribution is
given by a Cauchy distribution, instead of a normal distribution.
"
1604.01557	q-fin	q-fin.GN physics.soc-ph	"Market Imitation and Win-Stay Lose-Shift strategies emerge as unintended
  patterns in market direction guesses"	"  Decisions taken in our everyday lives are based on a wide variety of
information so it is generally very difficult to assess what are the strategies
that guide us. Stock market therefore provides a rich environment to study how
people take decision since responding to market uncertainty needs a constant
update of these strategies. For this purpose, we run a lab-in-the-field
experiment where volunteers are given a controlled set of financial information
-based on real data from worldwide financial indices- and they are required to
guess whether the market price would go up or down in each situation. From the
data collected we explore basic statistical traits, behavioural biases and
emerging strategies. In particular, we detect unintended patterns of behavior
through consistent actions which can be interpreted as {\it Market Imitation}
and {\it Win-Stay Lose-Shift} emerging strategies, being {\it Market Imitation}
the most dominant one. We also observe that these strategies are affected by
external factors: the expert advice, the lack of information or an information
overload reinforce the use of these intuitive strategies, while the probability
to follow them significantly decreases when subjects spends more time to take a
decision. The cohort analysis shows that women and children are more prone to
use such strategies although their performance is not undermined. Our results
are of interest for better handling clients expectations of trading companies,
avoiding behavioural anomalies in financial analysts decisions and improving
not only the design of markets but also the trading digital interfaces where
information is set down. Strategies and behavioural biases observed can also be
translated into new agent based modelling or stochastic price dynamics to
better understand financial bubbles or the effects of asymmetric risk
perception to price drops.
"
1604.01819	q-fin	q-fin.EC	Aggregating time preferences with decreasing impatience	"  It is well-known that for a group of time-consistent decision makers their
collective time preferences may become time-inconsistent. Jackson and Yariv
(2014) demonstrated that the result of aggregation of exponential discount
functions always exhibits present bias. We show that when preferences satisfy
the axioms of Fishburn and Rubinstein (1982), present bias is equivalent to
decreasing impatience (DI). Applying the notion of comparative DI introduced by
Prelec (2004), we generalize the result of Jackson and Yariv (2014). We prove
that the aggregation of distinct discount functions from comparable DI classes
results in the collective discount function which is strictly more DI than the
least DI of the functions being aggregated. We also prove an analogue of
Weitzman's (1998) result, for hyperbolic rather than exponential discount
functions. We show that if a decision maker is uncertain about her hyperbolic
discount rate, then long-term costs and benefits will be discounted at a rate
which is the probability-weighted harmonic mean of the possible hyperbolic
discount rates.
"
1604.01824	q-fin	q-fin.TR	"The statistical significance of multivariate Hawkes processes fitted to
  limit order book data"	"  Hawkes processes have seen a number of applications in finance, due to their
ability to capture event clustering behaviour typically observed in financial
systems. Given a calibrated Hawkes process, of concern is the statistical fit
to empirical data, particularly for the accurate quantification of self- and
mutual-excitation effects. We investigate the application of a multivariate
Hawkes process with a sum-of-exponentials kernel and piecewise-linear
exogeneity factors, fitted to liquidity demand and replenishment events
extracted from limit order book data. We consider one-, two- and
three-exponential kernels, applying various tests to ascertain goodness-of-fit
and stationarity of residuals, as well as stability of the calibration
procedure. In line with prior research, it is found that performance across all
tests improves as the number of exponentials is increased, with a
sum-of-three-exponentials yielding the best fit to the given set of coupled
point processes.
"
1604.02237	q-fin	q-fin.CP math.PR	Kriging of financial term-structures	"  Due to the lack of reliable market information, building financial
term-structures may be associated with a significant degree of uncertainty. In
this paper, we propose a new term-structure interpolation method that extends
classical spline techniques by additionally allowing for quantification of
uncertainty. The proposed method is based on a generalization of kriging models
with linear equality constraints (market-fit conditions) and shape-preserving
conditions such as monotonicity or positivity (no-arbitrage conditions). We
define the most likely curve and show how to build confidence bands. The
Gaussian process covariance hyper-parameters under the construction constraints
are estimated using cross-validation techniques. Based on observed market
quotes at different dates, we demonstrate the efficiency of the method by
building curves together with confidence intervals for term-structures of OIS
discount rates, of zero-coupon swaps rates and of CDS implied default
probabilities. We also show how to construct interest-rate surfaces or default
probability surfaces by considering time (quotation dates) as an additional
dimension.
"
1604.02269	q-fin	q-fin.MF	On the value of being American	"  The virtue of an American option is that it can be exercised at any time.
This right is particularly valuable when there is model uncertainty. Yet almost
all the extensive literature on American options assumes away model
uncertainty. This paper quantifies the potential value of this flexibility by
identifying the supremum on the price of an American option when no model is
imposed on the data, but rather any model is required to be consistent with a
family of European call prices. The bound is enforced by a hedging strategy
involving these call options which is robust to model error.
"
1604.02274	q-fin	q-fin.MF	More on hedging American options under model uncertainty	"  The purpose of this note is to reconcile two different results concerning the
model-free upper bound on the price of an American option, given a set of
European option prices. Neuberger (2007, `Bounds on the American option') and
Hobson and Neuberger (2016, `On the value of being American') argue that the
cost of the cheapest super-replicating strategy is equal to the highest
model-based price, where we search over all models which price correctly the
given European options. Bayraktar, Huang and Zhou (2015, `On hedging American
options under model uncertainty', SIAM J. Financial Math ematics) argue that
the cost of the cheapest super-replicating strategy can strictly exceed the
highest model-based price. We show that the reason for the difference in
conclusion is that Bayraktar et al do not search over a rich enough class of
models.
"
1604.02759	q-fin	q-fin.TR	Reconstruction of Order Flows using Aggregated Data	"  In this work we investigate tick-by-tick data provided by the TRTH database
for several stocks on three different exchanges (Paris - Euronext, London and
Frankfurt - Deutsche B\""orse) and on a 5-year span. We use a simple algorithm
that helps the synchronization of the trades and quotes data sources, providing
enhancements to the basic procedure that, depending on the time period and the
exchange, are shown to be significant. We show that the analysis of the
performance of this algorithm turns out to be a a forensic tool assessing the
quality of the aggregated database: we are able to track through the data some
significant technical changes that occurred on the studied exchanges. We also
illustrate the fact that the choices made when reconstructing order flows have
consequences on the quantitative models that are calibrated afterwards on such
data. Our study also provides elements on the trade signature, and we are able
to give a more refined look at the standard Lee-Ready procedure, giving new
elements on the way optimal lags should be chosen when using this method. The
findings are in line with both financial reasoning and the analysis of an
illustrative Poisson model of the order flow.
"
1604.03317	q-fin	math.PR q-fin.CP	Pricing American options using martingale bases	"  In this work, we propose an algorithm to price American options by directly
solving the dual minimization problem introduced by Rogers. Our approach relies
on approximating the set of uniformly square integrable martingales by a finite
dimensional Wiener chaos expansion. Then, we use a sample average approximation
technique to efficiently solve the optimization problem. Unlike all the
regression based methods, our method can transparently deal with path dependent
options without extra computations and a parallel implementation writes easily
with very little communication and no centralized work. We test our approach on
several multi--dimensional options with up to 40 assets and show the impressive
scalability of the parallel implementation.
"
1604.03337	q-fin	q-fin.CP q-fin.GN	"The subjective discount factor and the coefficient of relative risk
  aversion under time-additive isoelastic expected utility model"	"  By analysing the restrictions that ensure the existence of capital market
equilibrium, we show that the coefficient of relative risk aversion and the
subjective discount factor cannot be high simultaneously as they are supposed
to be to make the standard asset pricing consistent with financial stylised
facts.
"
1604.03522	q-fin	q-fin.GN	The Topology of African Exports: emerging patterns on spanning trees	"  This paper is a contribution to interweaving two lines of research that have
progressed in separate ways: network analyses of international trade and the
literature on African trade and development. Gathering empirical data on
African countries has important limitations and so does the space occupied by
African countries in the analyses of trade networks. Here, these limitations
are dealt with by the definition of two independent bipartite networks: a
destination share network and\ a\ commodity share network. These networks -
together with their corresponding minimal spanning trees - allow to uncover
some ordering emerging from African exports in the broader context of
international trade. The emerging patterns help to understand important
characteristics of African exports and its binding relations to other economic,
geographic and organizational concerns as the recent literature on African
trade, development and growth has shown.
"
1604.03906	q-fin	math.OC math.PR q-fin.MF	Stochastic Perron for Stochastic Target Problems	"  In this paper, we adapt stochastic Perron's method to analyze a stochastic
target problem with unbounded controls in a jump diffusion set-up. With this
method, we construct a viscosity sub-solution and super-solution to the
associated Hamiltonian-Jacobi-Bellman (HJB) equations. Under comparison
principles, uniqueness of the viscosity solutions holds and the value function
coincides with the unique solution in the parabolic interior. Since classical
control problems can be analyzed under the framework of stochastic target
problems (with unbounded controls), we use our results to generalize the
results in ArXiv:1212.2170 to problems with controlled jumps.
"
1604.04223	q-fin	q-fin.EC	On the survival of poor peasants	"  Previously, in underdeveloped countries, people tried to keep the prices of
food products artificially low, in order to help the poor to buy their food.
But it became soon clear that such system, although helpful for the city poor,
was disastrous for the peasants (who usually are even poorer), so that hunger
increased, instead of decreasing. More recently, thus, higher prices have been
imposed. But a high-price system does not solve the problems. It helps, indeed,
a peasant to buy in the city non-edible products, but not to buy (more
expensive) food products from other peasants. The question is discussed here in
more detail starting from the simplest conceivable case of two peasants
producing each a different food product (bread and cheese, say), then
generalizing to several food items and to any number of peasants producing a
given food item j. Like in every economic system which wants to be sustainable,
or able to reproduce itself in a stationary state at least, prices are
determined by the necessity of exchanging ""means of production"" among
""industries"", except that here industriesare replaced by working peasants and
means of production are replaced by food. It is found that prices must obey
certain inequalities related to the minimal amount of each food item necessary
for survival. Inequalities may be rewritten as equations and, in an important
special case, such equations give rise to a simple version of the matrix
equation used by famous authors to describe the economy.
"
1604.04312	q-fin	q-fin.GN physics.soc-ph	"Convergence of Economic Growth and the Great Recession as Seen From a
  Celestial Observatory"	"  Macroeconomic theories of growth and wealth distribution have an outsized
influence on national and international social and economic policies. Yet, due
to a relative lack of reliable, system wide data, many such theories remain, at
best, unvalidated and, at worst, misleading. In this paper, we introduce a
novel economic observatory and framework enabling high resolution comparisons
and assessments of the distributional impact of economic development through
the remote sensing of planet earth's surface. Striking visual and empirical
validation is observed for a broad, global macroeconomic sigma-convergence in
the period immediately following the end of the Cold War. What is more, we
observe strong empirical evidence that the mechanisms driving sigma-convergence
failed immediately after the financial crisis and the start of the Great
Recession. Nevertheless, analysis of both cross-country and cross-state samples
indicates that, globally, disproportionately high growth levels and excessively
high decay levels have become rarer over time. We also see that urban areas,
especially concentrated within short distances of major capital cities were
more likely than rural or suburban areas to see relatively high growth in the
aftermath of the financial crisis. Observed changes in growth polarity can be
attributed plausibly to post-crisis government intervention and subsidy
policies introduced around the world. Overall, the data and techniques we
present here make economic evidence for the rise of China, the decline of U.S.
manufacturing, the euro crisis, the Arab Spring, and various, recent, Middle
East conflicts visually evident for the first time.
"
1604.05178	q-fin	q-fin.CP cs.CE	"High order finite difference schemes on non-uniform meshes for the
  time-fractional Black-Scholes equation"	"  We construct a three-point compact finite difference scheme on a non-uniform
mesh for the time-fractional Black-Scholes equation. We show that for special
graded meshes used in finance, the Tavella-Randall and the quadratic meshes the
numerical solution has a fourth-order accuracy in space. Numerical experiments
are discussed.
"
1604.05404	q-fin	q-fin.PR	Repo Haircuts and Economic Capital	"  This article develops a haircut model by treating repos as debt investments
and seeks haircuts to control counterparty contingent exposure to asset price
gap risk. It corroborates well with empirically stylized facts, explains
tri-party and bilateral repo haircut differences, recasts haircut increases
during the financial crisis, and sets a limit on access liquidity dealers can
extract while acting as funding intermediaries between money market funds and
hedge funds. Once a haircut is set, repo's residual risk becomes a pricing
challenge, as is neither hedgeable nor diversifiable. We propose a capital
pricing approach of computing repo economic capital and charging the borrower a
cost of capital. Capital charge is shown to be countercyclical and a key
element of repo pricing and used in explaining the repo pricing puzzle and
maturity compression phenomenon.
"
1604.05406	q-fin	q-fin.PR	"Gap Risk KVA and Repo Pricing: An Economic Capital Approach in the
  Black-Scholes-Merton Framework"	"  Although not a formal pricing consideration, gap risk or hedging errors are
the norm of derivatives businesses. Starting with the gap risk during a margin
period of risk of a repurchase agreement (repo), this article extends the
Black-Scholes-Merton option pricing framework by introducing a reserve capital
approach to the hedging error's irreducible variability. An extended partial
differential equation is derived with two new terms for expected gap loss and
economic capital charge, leading to the gap risk economic value adjustment and
capital valuation adjustment (KVA) respectively. Practical repo pricing
formulae is obtained showing that the break-even repo rate decomposes into cost
of fund and economic capital charge in KVA. At zero haircut, a one-year term
repo on main equities could command a capital charge as large as 50 basis
points for a 'BBB' rated borrower.
"
1604.05584	q-fin	q-fin.MF	"Optimal investment and consumption with downside risk constraint in
  jump-diffusion models"	"  This paper extends the results of the article [C. Kl\""{u}ppelberg and S. M.
Pergamenchtchikov. Optimal consumption and investment with bounded downside
risk for power utility functions. In Optimality and Risk: {\it Modern Trends in
Mathematical Finance. The Kabanov Festschrift}, pages 133-169, 2009] to a
jump-diffusion setting. We show that under the assumption that only positive
jumps in the asset prices are allowed, the explicit optimal strategy can be
found in the subset of admissible strategies satisfying the same risk
constraint as in the pure diffusion setting. When negative jumps probably
happen, the regulator should be more conservative. In that case, we suggest to
impose on the investor's portfolio a stricter constraint which depends on the
probability of having negative jumps in the assets during the whole considered
horizon.
"
1604.05598	q-fin	q-fin.ST	"Regime switching vine copula models for global equity and volatility
  indices"	"  For nearly every major stock market there exist equity and implied volatility
indices. These play important roles within finance: be it as a benchmark, a
measure of general uncertainty or a way of investing or hedging. It is well
known in the academic literature, that correlations and higher moments between
different indices tend to vary in time. However, to the best of our knowledge,
no one has yet considered a global setup including both, equity and implied
volatility indices of various continents, and allowing for a changing
dependence structure. We aim to close this gap by applying Markov-switching
$R$-vine models to investigate the existence of different, global dependence
regimes. In particular, we identify times of ""normal"" and ""abnormal"" states
within a data set consisting of North-American, European and Asian indices. Our
results confirm the existence of joint points in time at which global regime
switching takes place.
"
1604.05672	q-fin	q-fin.GN	Risk Aversion and Catastrophic Risks: the Pill Experiment	"  This article focuses on the work of O. Chanel and G. Chichilnisky (2013) on
the flaws of expected utility theory while assessing the value of life.
Expected utility is a fundamental tool in decision theory. However, it does not
fit with the experimental results when it comes to catastrophic outcomes
---see, for example, Chichilnisky (2009) for more details. In the experiments
conducted by Olivier Chanel in 1998 and 2009, several subjects are ask to
imagine they are presented 1 billion identical pills. They are paid \$220,000
to take and swallow one, knowing that one out of 1 billion is deadly. The
objective of this article is to show that risk aversion phenomenon cannot
explain the experimental results found. This is an additional reason why a new
kind of utility function is necessary: the axioms proposed by Graciela
Chichilnisky will be briefly presented, and it will be shown that it better
fits with experiments than any risk aversion utility function.
"
1604.05771	q-fin	q-fin.EC math.AP math.OC	Multidimensional matching	"  We present a general analysis of multidimensional matching problems with
transferable utility, paying particular attention to the case in which the
dimensions of heterogeneity on the two sides of the market are unequal. A
particular emphasis is put on problems where agents on one side of the market
are multidimensional and agents on the other side are uni-dimensional, we
describe a general approach to solve such problems. Lastly, we analyze several
examples, including an hedonic model with differentiated products, a marriage
market model where wives are differentiated in income and fertility, and a
competitive variation of the Rochet-Chon\'e problem. In the latter example, we
show that the bunching phenomena, observed by Rochet and Chon\'e in the
monopoly context, do not occur in the competitive context
"
1604.06284	q-fin	q-fin.EC q-fin.GN	"The Impact of Services on Economic Complexity: Service Sophistication as
  Route for Economic Growth"	"  Economic complexity reflects the amount of knowledge that is embedded in the
productive structure of an economy. By combining tools from network science and
econometrics, a robust and stable relationship between a country's productive
structure and its economic growth has been established. Here we report that not
only goods but also services are important for predicting the rate at which
countries will grow. By adopting a terminology which classifies manufactured
goods and delivered services as products, we investigate the influence of
services on the country's productive structure. In particular, we provide
evidence that complexity indices for services are in general higher than those
for goods, which is reflected in a general tendency to rank countries with
developed service sector higher than countries with economy centred on
manufacturing of goods. By focusing on country dynamics based on experimental
data, we investigate the impact of services on the economic complexity of
countries measured in the product space (consisting of both goods and
services). Importantly, we show that diversification of service exports and its
sophistication can provide an additional route for economic growth in both
developing and developed countries.
"
1604.06629	q-fin	q-fin.RM physics.soc-ph	Entangling credit and funding shocks in interbank markets	"  Credit and liquidity risks represent main channels of financial contagion for
interbank lending markets. On one hand, banks face potential losses whenever
their counterparties are under distress and thus unable to fulfill their
obligations. On the other hand, solvency constraints may force banks to recover
lost fundings by selling their illiquid assets, resulting in effective losses
in the presence of fire sales - that is, when funding shortcomings are
widespread over the market. Because of the complex structure of the network of
interbank exposures, these losses reverberate among banks and eventually get
amplified, with potentially catastrophic consequences for the whole financial
system. Building on Debt Rank [Battiston et al., 2012], in this work we define
a systemic risk metric that estimates the potential amplification of losses in
interbank markets accounting for both credit and liquidity contagion channels:
the Debt-Solvency Rank. We implement this framework on a dataset of 183
European banks that were publicly traded between 2004 and 2013, showing indeed
that liquidity spillovers substantially increase systemic risk, and thus cannot
be neglected in stress-test scenarios. We also provide additional evidence that
the interbank market was extremely fragile up to the 2008 financial crisis,
becoming slightly more robust only afterwards.
"
1604.06892	q-fin	q-fin.PM math.OC	"On the Optimal Dividend Problem for Insurance Risk Models with
  Surplus-Dependent Premiums"	"  This paper concerns an optimal dividend distribution problem for an insurance
company with surplus-dependent premium. In the absence of dividend payments,
such a risk process is a particular case of so-called piecewise deterministic
Markov processes. The control mechanism chooses the size of dividend payments.
The objective consists in maximazing the sum of the expected cumulative
discounted dividend payments received until the time of ruin and a penalty
payment at the time of ruin, which is an increasing function of the size of the
shortfall at ruin. A complete solution is presented to the corresponding
stochastic control problem. We identify the associated Hamilton-Jacobi-Bellman
equation and find necessary and sufficient conditions for optimality of a
single dividend-band strategy, in terms of particular Gerber-Shiu functions. A
number of concrete examples are analyzed.
"
1604.07556	q-fin	q-fin.TR	"Linear models for the impact of order flow on prices II. The Mixture
  Transition Distribution model"	"  Modeling the impact of the order flow on asset prices is of primary
importance to understand the behavior of financial markets. Part I of this
paper reported the remarkable improvements in the description of the price
dynamics which can be obtained when one incorporates the impact of past returns
on the future order flow. However, impact models presented in Part I consider
the order flow as an exogenous process, only characterized by its two-point
correlations. This assumption seriously limits the forecasting ability of the
model. Here we attempt to model directly the stream of discrete events with a
so-called Mixture Transition Distribution (MTD) framework, introduced
originally by Raftery (1985). We distinguish between price-changing and non
price-changing events and combine them with the order sign in order to reduce
the order flow dynamics to the dynamics of a four-state discrete random
variable. The MTD represents a parsimonious approximation of a full high-order
Markov chain. The new approach captures with adequate realism the conditional
correlation functions between signed events for both small and large tick
stocks and signature plots. From a methodological viewpoint, we discuss a novel
and flexible way to calibrate a large class of MTD models with a very large
number of parameters. In spite of this large number of parameters, an
out-of-sample analysis confirms that the model does not overfit the data.
"
1604.07969	q-fin	stat.AP q-fin.ST	"On the Surprising Explanatory Power of Higher Realized Moments in
  Practice"	"  Realized moments of higher order computed from intraday returns are
introduced in recent years. The literature indicates that realized skewness is
an important factor in explaining future asset returns. However, the literature
mainly focuses on the whole market and on the monthly or weekly scale. In this
paper, we conduct an extensive empirical analysis to investigate the
forecasting abilities of realized skewness and realized kurtosis towards
individual stock's future return and variance in the daily scale. It is found
that realized kurtosis possesses significant forecasting power for the stock's
future variance. In the meanwhile, realized skewness is lack of explanatory
power for the future daily return for individual stocks with a short horizon,
in contrast with the existing literature.
"
1604.08037	q-fin	math.PR q-fin.PM q-fin.RM	On Dynamic Deviation Measures and Continuous-Time Portfolio Optimisation	"  In this paper we propose the notion of dynamic deviation measure, as a
dynamic time-consistent extension of the (static) notion of deviation measure.
To achieve time-consistency we require that a dynamic deviation measures
satisfies a generalised conditional variance formula. We show that, under a
domination condition, dynamic deviation measures are characterised as the
solutions to a certain class of backward SDEs. We establish for any dynamic
deviation measure an integral representation, and derive a dual
characterisation result in terms of additively $m$-stable dual sets. Using this
notion of dynamic deviation measure we formulate a dynamic mean-deviation
portfolio optimisation problem in a jump-diffusion setting and identify a
subgame-perfect Nash equilibrium strategy that is linear as function of wealth
by deriving and solving an associated extended HJB equation.
"
1604.08070	q-fin	q-fin.MF	Convex Hedging in Incomplete Markets	"  In incomplete financial markets not every contingent claim can be replicated
by a self-financing strategy. The risk of the resulting shortfall can be
measured by convex risk measures, recently introduced by F\""ollmer, Schied
(2002). The dynamic optimization problem of finding a self-financing strategy
that minimizes the convex risk of the shortfall can be split into a static
optimization problem and a representation problem. It follows that the optimal
strategy consists in superhedging the modified claim $\widetilde{\varphi}H$,
where $H$ is the payoff of the claim and $\widetilde{\varphi}$ is the solution
of the static optimization problem, the optimal randomized test.
  In this paper, we will deduce necessary and sufficient optimality conditions
for the static problem using convex duality methods. The solution of the static
optimization problem turns out to be a randomized test with a typical
$0$-$1$-structure.
"
1604.08224	q-fin	q-fin.MF math.PR	"Utility maximization problem with random endowment and transaction
  costs: when wealth may become negative"	"  In this paper we study the problem of maximizing expected utility from the
terminal wealth with proportional transaction costs and random endowment. In
the context of the existence of consistent price systems, we consider the
duality between the primal utility maximization problem and the dual one, which
is set up on the domain of finitely additive measures. In particular, we prove
duality results for utility functions supporting possibly negative values.
Moreover, we construct the shadow market by the dual optimal process and
consider the utility based pricing for random endowment.
"
1604.08677	q-fin	q-fin.ST	"An Explicit Formula for Likelihood Function for Gaussian Vector
  Autoregressive Moving-Average Model Conditioned on Initial Observables with
  Application to Model Calibration"	"  We derive an explicit formula for likelihood function for Gaussian VARMA
model conditioned on initial observables where the moving-average (MA)
coefficients are scalar. For fixed MA coefficients the likelihood function is
optimized in the autoregressive variables $\Phi$'s by a closed form formula
generalizing regression calculation of the VAR model with the introduction of
an inner product defined by MA coefficients. We show the assumption of scalar
MA coefficients is not restrictive and this formulation of the VARMA model
shares many nice features of VAR and MA model. The gradient and Hessian could
be computed analytically. The likelihood function is preserved under the root
invertion maps of the MA coefficients. We discuss constraints on the gradient
of the likelihood function with moving average unit roots. With the help of FFT
the likelihood function could be computed in $O((kp+1)^2T +ckT\log(T))$ time.
Numerical calibration is required for the scalar MA variables only. The
approach can be generalized to include additional drifts as well as integrated
components. We discuss a relationship with the Borodin-Okounkov formula and the
case of infinite MA components.
"
1604.08735	q-fin	q-fin.PR	Pricing Bermudan options under local L\'evy models with default	"  We consider a defaultable asset whose risk-neutral pricing dynamics are
described by an exponential L\'evy-type martingale. This class of models allows
for a local volatility, local default intensity and a locally dependent L\'evy
measure. We present a pricing method for Bermudan options based on an
analytical approximation of the characteristic function combined with the COS
method. Due to a special form of the obtained characteristic function the price
can be computed using a Fast Fourier Transform-based algorithm resulting in a
fast and accurate calculation. The Greeks can be computed at almost no
additional computational cost. Error bounds for the approximation of the
characteristic function as well as for the total option price are given.
"
1604.08824	q-fin	q-fin.EC q-fin.ST	"A new structural stochastic volatility model of asset pricing and its
  stylized facts"	"  Building on a prominent agent-based model, we present a new structural
stochastic volatility asset pricing model of fundamentalists vs. chartists
where the prices are determined based on excess demand. Specifically, this
allows for modelling stochastic interactions between agents, based on a herding
process corrected by a price misalignment, and incorporating strong noise
components in the agents' demand. The model's parameters are estimated using
the method of simulated moments, where the moments reflect the basic properties
of the daily returns of a stock market index. In addition, for the first time
we apply a (parametric) bootstrap method in a setting where the switching
between strategies is modelled using a discrete choice approach. As we
demonstrate, the resulting dynamics replicate a rich set of the stylized facts
of the daily financial data including: heavy tails, volatility clustering, long
memory in absolute returns, as well as the absence of autocorrelation in raw
returns, volatility-volume correlations, aggregate Gaussianity, concave price
impact and extreme price events.
"
1604.08895	q-fin	q-fin.EC q-fin.GN	The puzzle that just isn't	"  In his stimulating article on the reasons for two puzzling observations about
the behaviour of interest rates, exchange rates and the rate of inflation,
Charles Engel (2016) puts forward an explanation that rests on the concept of a
non-pecuniary liquidity return on assets. Albeit intriguing the analysis
struggles to account for a number of facts which are familiar to participants
of the foreign exchange and bond markets. Reconciling these facts in
conjunction with a careful dissection of the ""puzzle"" to begin with, shows that
the forward premium puzzle just does not exist, at least not in its canonical
form.
"
1605.00173	q-fin	q-fin.PM q-fin.MF q-fin.TR	Robustness of mathematical models and technical analysis strategies	"  The aim of this paper is to compare the performances of the optimal strategy
under parameters mis-specification and of a technical analysis trading
strategy. The setting we consider is that of a stochastic asset price model
where the trend follows an unobservable Ornstein-Uhlenbeck process. For both
strategies, we provide the asymptotic expectation of the logarithmic return as
a function of the model parameters. Finally, numerical examples find that an
investment strategy using the cross moving averages rule is more robust than
the optimal strategy under parameters mis-specification.
"
1605.00230	q-fin	stat.AP q-fin.RM stat.CO	"Density Forecasts and the Leverage Effect: Some Evidence from
  Observation and Parameter-Driven Volatility Models"	"  The leverage effect refers to the well-established relationship between
returns and volatility. When returns fall, volatility increases. We examine the
role of the leverage effect with regards to generating density forecasts of
equity returns using well-known observation and parameter-driven volatility
models. These models differ in their assumptions regarding: The parametric
specification, the evolution of the conditional volatility process and how the
leverage effect is accounted for. The ability of a model to generate accurate
density forecasts when the leverage effect is incorporated or not as well as a
comparison between different model-types is carried out using a large number of
financial time-series. We find that, models with the leverage effect generally
generate more accurate density forecasts compared to their no-leverage
counterparts. Moreover, we also find that our choice with regards to how to
model the leverage effect and the conditional log-volatility process is
important in generating accurate density forecasts
"
1605.00307	q-fin	q-fin.CP q-fin.MF q-fin.PR	"Semi-analytic path integral solution of SABR and Heston equations:
  pricing Vanilla and Asian options"	"  We discuss a semi-analytical method for solving SABR-type equations based on
path integrals. In this approach, one set of variables is integrated
analytically while the second set is integrated numerically via Monte-Carlo.
This method, known in the literature as Conditional Monte-Carlo, leads to
compact expressions functional on three correlated stochastic variables. The
methodology is practical and efficient when solving Vanilla pricing in the
SABR, Heston and Bates models with time depending parameters. Further, it can
also be practically applied to pricing Asian options in the $\beta=0$ SABR
model and to other $\beta=0$ type models.
"
1605.00634	q-fin	q-fin.GN q-fin.TR	Why have asset price properties changed so little in 200 years	"  We first review empirical evidence that asset prices have had episodes of
large fluctuations and been inefficient for at least 200 years. We briefly
review recent theoretical results as well as the neurological basis of trend
following and finally argue that these asset price properties can be attributed
to two fundamental mechanisms that have not changed for many centuries: an
innate preference for trend following and the collective tendency to exploit as
much as possible detectable price arbitrage, which leads to destabilizing
feedback loops.
"
1605.00762	q-fin	q-fin.MF	Revisiting a Theorem of L.A. Shepp on Optimal Stopping	"  Using a bondholder who seeks to determine when to sell his bond as our
motivating example, we revisit one of Larry Shepp's classical theorems on
optimal stopping. We offer a novel proof of Theorem 1 from from \cite{Shepp}.
Our approach is that of guessing the optimal control function and proving its
optimality with martingales. Without martingale theory one could hardly prove
our guess to be correct.
"
1605.01028	q-fin	q-fin.ST q-fin.MF	On Optimal Retirement (How to Retire Early)	"  We pose an optimal control problem arising in a perhaps new model for
retirement investing. Given a control function $f$ and our current net worth as
$X(t)$ for any $t$, we invest an amount $f(X(t))$ in the market. We need a
fortune of $M$ ""superdollars"" to retire and want to retire as early as
possible. We model our change in net worth over each infinitesimal time
interval by the Ito process $dX(t)= (1+f(X(t))dt+ f(X(t))dW(t)$. We show how to
choose the optimal $f=f_0$ and show that the choice of $f_0$ is optimal among
all nonanticipative investment strategies, not just among Markovian ones.
"
1605.01071	q-fin	math.AP q-fin.EC	"Lie symmetries of (1+2) nonautonomous evolution equations in Financial
  Mathematics"	"  We analyse two classes of $(1+2)$ evolution equations which are of special
interest in Financial Mathematics, namely the Two-dimensional Black-Scholes
Equation and the equation for the Two-factor Commodities Problem. Our approach
is that of Lie Symmetry Analysis. We study these equations for the case in
which they are autonomous and for the case in which the parameters of the
equations are unspecified functions of time. For the autonomous Black-Scholes
Equation we find that the symmetry is maximal and so the equation is reducible
to the $(1+2)$ Classical Heat Equation. This is not the case for the
nonautonomous equation for which the number of symmetries is submaximal. In the
case of the two-factor equation the number of symmetries is submaximal in both
autonomous and nonautonomous cases. When the solution symmetries are used to
reduce each equation to a $(1+1)$ equation, the resulting equation is of
maximal symmetry and so equivalent to the $(1+1)$ Classical Heat Equation.
"
1605.01343	q-fin	q-fin.EC cs.CR	Electoral Systems Used around the World	"  We give an overview of the diverse electoral systems used in local, national,
or super-national elections around the world. We discuss existing methods for
selecting single and multiple winners and give real-world examples for some
more elaborate systems. Eventually, we elaborate on some of the better known
strengths and weaknesses of various methods from both the theoretical and
practical points of view.
"
1605.01976	q-fin	q-fin.GN physics.soc-ph	"The Accounting Network: how financial institutions react to systemic
  crisis"	"  The role of Network Theory in the study of the financial crisis has been
widely spotted in the latest years. It has been shown how the network topology
and the dynamics running on top of it can trigger the outbreak of large
systemic crisis. Following this methodological perspective we introduce here
the Accounting Network, i.e. the network we can extract through vector
similarities techniques from companies' financial statements. We build the
Accounting Network on a large database of worldwide banks in the period
2001-2013, covering the onset of the global financial crisis of mid-2007. After
a careful data cleaning, we apply a quality check in the construction of the
network, introducing a parameter (the Quality Ratio) capable of trading off the
size of the sample (coverage) and the representativeness of the financial
statements (accuracy). We compute several basic network statistics and check,
with the Louvain community detection algorithm, for emerging communities of
banks. Remarkably enough sensible regional aggregations show up with the
Japanese and the US clusters dominating the community structure, although the
presence of a geographically mixed community points to a gradual convergence of
banks into similar supranational practices. Finally, a Principal Component
Analysis procedure reveals the main economic components that influence
communities' heterogeneity. Even using the most basic vector similarity
hypotheses on the composition of the financial statements, the signature of the
financial crisis clearly arises across the years around 2008. We finally
discuss how the Accounting Networks can be improved to reflect the best
practices in the financial statement analysis.
"
1605.01998	q-fin	q-fin.CP	Unbiased Monte Carlo Simulation of Diffusion Processes	"  Monte Carlo simulations of diffusion processes often introduce bias in the
final result, due to time discretization. Using an auxiliary Poisson process,
it is possible to run simulations which are unbiased. In this article, we
propose such a Monte Carlo scheme which converges to the exact value. We manage
to keep the simulation variance finite in all cases, so that the strong law of
large numbers guarantees the convergence. Moreover, the simulation noise is a
decreasing function of the Poisson process intensity. Our method handles
multidimensional processes with nonconstant drifts and nonconstant
variance-covariance matrices. It also encompasses stochastic interest rates.
"
1605.02188	q-fin	q-fin.ST	"Forecasting time series with structural breaks with Singular Spectrum
  Analysis, using a general form of recurrent formula"	"  This study extends and evaluates the forecasting performance of the Singular
Spectrum Analysis (SSA) technique using a general non-linear form for the re-
current formula. In this study, we consider 24 series measuring the monthly
seasonally adjusted industrial production of important sectors of the German,
French and UK economies. This is tested by comparing the performance of the new
proposed model with basic SSA and the SSA bootstrap forecasting, especially
when there is evidence of structural breaks in both in-sample and out-of-sample
periods. According to root mean-square error (RMSE), SSA using the general
recursive formula outperforms both the SSA and the bootstrap forecasting at
horizons of up to a year. We found no significant difference in predicting the
direction of change between these methods. Therefore, it is suggested that the
SSA model with the general recurrent formula should be chosen by users in the
case of structural breaks in the series.
"
1605.02283	q-fin	q-fin.ST nlin.AO	Coherence and incoherence collective behavior in financial market	"  Financial markets have been extensively studied as highly complex evolving
systems. In this paper, we quantify financial price fluctuations through a
coupled dynamical system composed of phase oscillators. We find a Financial
Coherence and Incoherence (FCI) coexistence collective behavior emerges as the
system evolves into the stable state, in which the stocks split into two
groups: one is represented by coherent, phase-locked oscillators, the other is
composed of incoherent, drifting oscillators. It is demonstrated that the size
of the coherent stock groups fluctuates during the economic periods according
to real-world financial instabilities or shocks. Further, we introduce the
coherent characteristic matrix to characterize the involvement dynamics of
stocks in the coherent groups. Clustering results on the matrix provides a
novel manifestation of the correlations among stocks in the economic periods.
Our analysis for components of the groups is consistent with the Global
Industry Classification Standard (GICS) classification and can also figure out
features for newly developed industries. These results can provide potentially
implications on characterizing inner dynamical structure of financial markets
and making optimal investment tragedies.
"
1605.02418	q-fin	stat.ME q-fin.ST stat.AP	"Mean-correction and Higher Order Moments for a Stochastic Volatility
  Model with Correlated Errors"	"  In an efficient stock market, the log-returns and their time-dependent
variances are often jointly modelled by stochastic volatility models (SVMs).
Many SVMs assume that errors in log-return and latent volatility process are
uncorrelated, which is unrealistic. It turns out that if a non-zero correlation
is included in the SVM (e.g., Shephard (2005)), then the expected log-return at
time t conditional on the past returns is non-zero, which is not a desirable
feature of an efficient stock market. In this paper, we propose a
mean-correction for such an SVM for discrete-time returns with non-zero
correlation. We also find closed form analytical expressions for higher moments
of log-return and its lead-lag correlations with the volatility process. We
compare the performance of the proposed and classical SVMs on S&P 500 index
returns obtained from NYSE.
"
1605.02472	q-fin	q-fin.MF	Generalized semi-Markovian dividend discount model: risk and return	"  The article presents a general discrete time dividend valuation model when
the dividend growth rate is a general continuous variable. The main assumption
is that the dividend growth rate follows a discrete time semi-Markov chain with
measurable space. The paper furnishes sufficient conditions that assure
finiteness of fundamental prices and risks and new equations that describe the
first and second order price-dividend ratios. Approximation methods to solve
equations are provided and some new results for semi-Markov reward processes
with Borel state space are established. The paper generalizes previous
contributions dealing with pricing firms on the basis of fundamentals.
"
1605.02654	q-fin	q-fin.PM q-fin.MF stat.ML	Stochastic Portfolio Theory: A Machine Learning Perspective	"  In this paper we propose a novel application of Gaussian processes (GPs) to
financial asset allocation. Our approach is deeply rooted in Stochastic
Portfolio Theory (SPT), a stochastic analysis framework introduced by Robert
Fernholz that aims at flexibly analysing the performance of certain investment
strategies in stock markets relative to benchmark indices. In particular, SPT
has exhibited some investment strategies based on company sizes that, under
realistic assumptions, outperform benchmark indices with probability 1 over
certain time horizons. Galvanised by this result, we consider the inverse
problem that consists of learning (from historical data) an optimal investment
strategy based on any given set of trading characteristics, and using a
user-specified optimality criterion that may go beyond outperforming a
benchmark index. Although this inverse problem is of the utmost interest to
investment management practitioners, it can hardly be tackled using the SPT
framework. We show that our machine learning approach learns investment
strategies that considerably outperform existing SPT strategies in the US stock
market.
"
1605.03097	q-fin	math.AP q-fin.MF	"Heat Kernels, Solvable Lie Groups, and the Mean Reverting SABR
  Stochastic Volatility Model"	"  We use commutator techniques and calculations in solvable Lie groups to
investigate certain evolution Partial Differential Equations (PDEs for short)
that arise in the study of stochastic volatility models for pricing contingent
claims on risky assets. In particular, by restricting to domains of bounded
volatility, we establish the existence of the semi-groups generated by the
spatial part of the operators in these models, concentrating on those arising
in the so-called ""SABR stochastic volatility model with mean reversion."" The
main goal of this work is to approximate the solutions of the Cauchy problem
for the SABR PDE with mean reversion, a parabolic problem the generator of
which is denoted by $L$. The fundamental solution for this problem is not known
in closed form. We obtain an approximate solution by performing an expansion in
the so-called volvol or volatility of the volatility, which leads us to study a
degenerate elliptic operator $L_0$, corresponding the the zero-volvol case of
the SABR model with mean reversion, to which the classical results do not
apply. However, using Lie algebra techniques we are able to derive an exact
formula for the solution operator of the PDE $\partial_t u - L_0 u = 0$. We
then compare the semi-group generated by $L$--the existence of which does
follows from standard arguments--to that generated by $L_0$, thus establishing
a perturbation result that is useful for numerical methods for the SABR PDE
with mean reversion. In the process, we are led to study semigroups arising
from both a strongly parabolic and a hyperbolic problem.
"
1605.03551	q-fin	q-fin.GN q-fin.PR	Global Gauge Symmetries, Risk-Free Portfolios, and the Risk-Free Rate	"  We define risk-free portfolios using three gauge invariant differential
operators that require such portfolios to be insensitive to price changes, to
be self-financing, and to produce a zero real return so there are no risk-free
profits. This definition identifies the risk-free rate as the return of an
infinitely diversified portfolio rather than as an arbitrary external
parameter. The risk-free rate measures the rate of global price rescaling,
which is a gauge symmetry of economies. We explore the properties of risk-free
rates, rederive the Black Scholes equation with a new interpretation of the
risk-free rate parameter as a that background gauge field, and discuss gauge
invariant discounting of cash flows.
"
1605.03559	q-fin	q-fin.ST	Survey on log-normally distributed market-technical trend data	"  In this survey, a short introduction in the recent discovery of log-normally
distributed market-technical trend data will be given. The results of the
statistical evaluation of typical market-technical trend variables will be
presented. It will be shown that the log-normal assumption fits better to
empirical trend data than to daily returns of stock prices. This enables to
mathematically evaluate trading systems depending on such variables. In this
manner, a basic approach to an anti cyclic trading system will be given as an
example.
"
1605.03683	q-fin	q-fin.TR	"Optimality of VWAP Execution Strategies under General Shaped Market
  Impact Functions"	"  In this short note, we study an optimization problem of expected
implementation shortfall (IS) cost under general shaped market impact
functions. In particular, we find that an optimal strategy is a VWAP (volume
weighted average price) execution strategy when the market model is a
Black-Scholes type with stochastic clock and market trading volume is large.
"
1605.04219	q-fin	q-fin.GN q-fin.CP	"Empowering cash managers to achieve cost savings by improving predictive
  accuracy"	"  Cash management is concerned with optimizing the short-term funding
requirements of a company. To this end, different optimization strategies have
been proposed to minimize costs using daily cash flow forecasts as the main
input to the models. However, the effect of the accuracy of such forecasts on
cash management policies has not been studied. In this article, using two real
data sets from the textile industry, we show that predictive accuracy is highly
correlated with cost savings when using daily forecasts in cash management
models. A new method is proposed to help cash managers estimate if efforts in
improving predictive accuracy are proportionally rewarded by cost savings. Our
results imply the need for an analysis of potential cost savings derived from
improving predictive accuracy. From that, the search for better forecasting
models is in place to improve cash management.
"
1605.04385	q-fin	q-fin.EC	Knight--Walras Equilibria	"  Knightian uncertainty leads naturally to nonlinear expectations. We introduce
a corresponding equilibrium concept with sublinear prices and establish their
existence. In general, such equilibria lead to Pareto inefficiency and coincide
with Arrow--Debreu equilibria only if the values of net trades are
ambiguity--free in the mean. Without aggregate uncertainty, inefficiencies
arise generically.
  We introduce a constrained efficiency concept, uncertainty--neutral
efficiency and show that Knight--Walras equilibrium allocations are efficient
in this constrained sense. Arrow--Debreu equilibria turn out to be non--robust
with respect to the introduction of Knightian uncertainty.
"
1605.04584	q-fin	q-fin.PR math.OC	"On the Optimal Dividend Problem in the Dual Model with Surplus-Dependent
  Premiums"	"  This paper concerns the dual risk model, dual to the risk model for insurance
applications, where premiums are surplus-dependent. In such a model premiums
are regarded as costs, while claims refer to profits. We calculate the mean of
the cumulative discounted dividends paid until ruin, if the barrier strategy is
applied. We formulate associated Hamilton-Jacobi-Bellman equation and identify
sufficient conditions for a barrier strategy to be optimal. Some numerical
examples are provided when profits have exponential law.
"
1605.04938	q-fin	q-fin.GN q-fin.EC	The topology of card transaction money flows	"  Money flow models are essential tools to understand different economical
phenomena, like saving propensities and wealth distributions. In spite of their
importance, most of them are based on synthetic transaction networks with
simple topologies, e.g. random or scale-free ones, as the characterisation of
real networks is made difficult by the confidentiality and sensitivity of money
transaction data. Here we present an analysis of the topology created by real
credit card transactions from one of the biggest world banks, and show how
different distributions, e.g. number of transactions per card or amount, have
nontrivial characteristics. We further describe a stochastic model to create
transactions data sets, feeding from the obtained distributions, which will
allow researchers to create more realistic money flow models.
"
1605.04940	q-fin	q-fin.RM q-fin.ST	Value-at-Risk: The Effect of Autoregression in a Quantile Process	"  Value-at-Risk (VaR) is an institutional measure of risk favored by financial
regulators. VaR may be interpreted as a quantile of future portfolio values
conditional on the information available, where the most common quantile used
is 95%. Here we demonstrate Conditional Autoregressive Value at Risk, first
introduced by Engle, Manganelli (2001). CAViaR suggests that negative/positive
returns are not i.i.d., and that there is significant autocorrelation. The
model is tested using data from 1986- 1999 and 1999-2009 for GM, IBM, XOM, SPX,
and then validated via the dynamic quantile test. Results suggest that the
tails (upper/lower quantile) of a distribution of returns behave differently
than the core.
"
1605.04941	q-fin	q-fin.PR q-fin.RM	Mortgages and Refinancing	"  In general, homeowners refinance in response to a decrease in interest rates,
as their borrowing costs are lowered. However, it is worth investigating the
effects of refinancing after taking the underlying costs into consideration.
Here we develop a synthetic mortgage calculator that sufficiently accounts for
such costs and the implications on new monthly payments. To confirm the
accuracy of the calculator, we simulate the effects of refinancing over 15 and
30 year periods. We then model the effects of refinancing as risk to the issuer
of the mortgage, as there is negative duration associated with shifts in the
interest rate. Furthermore, we investigate the effects on the swap market as
well as the treasury bond market. We model stochastic interest rates using the
Vasicek model.
"
1605.04945	q-fin	q-fin.ST q-fin.GN	"Extended nonlinear feedback model for describing episodes of high
  inflation"	"  An extension of the nonlinear feedback (NLF) formalism to describe regimes of
hyper- and high-inflation in economy is proposed in the present work. In the
NLF model the consumer price index (CPI) exhibits a finite time singularity of
the type $1/(t_c -t)^{(1- \beta)/\beta}$, with $\beta>0$, predicting a blow up
of the economy at a critical time $t_c$. However, this model fails in
determining $t_c$ in the case of weak hyperinflation regimes like, e.g., that
occurred in Israel. To overcome this trouble, the NLF model is extended by
introducing a parameter $\gamma$, which multiplies all therms with past growth
rate index (GRI). In this novel approach the solution for CPI is also analytic
being proportional to the Gaussian hypergeometric function
$_2F_1(1/\beta,1/\beta,1+1/\beta;z)$, where $z$ is a function of $\beta$,
$\gamma$, and $t_c$. For $z \to 1$ this hypergeometric function diverges
leading to a finite time singularity, from which a value of $t_c$ can be
determined. This singularity is also present in GRI. It is shown that the
interplay between parameters $\beta$ and $\gamma$ may produce phenomena of
multiple equilibria. An analysis of the severe hyperinflation occurred in
Hungary proves that the novel model is robust. When this model is used for
examining data of Israel a reasonable $t_c$ is got. High-inflation regimes in
Mexico and Iceland, which exhibit weaker inflations than that of Israel, are
also successfully described.
"
1605.04948	q-fin	q-fin.TR	Quantum theory of securities price formation in financial markets	"  We develop a theory of securities price formation and dynamics based on
quantum approach and without presuming any similarities with quantum mechanics.
Disorder introduced by trading environment leads to probability distribution of
returns that is not a smooth curve, but a speckle-pattern fluctuating in both
price coordinate and time. This means that any given return can at times
acquire a substantial probability of occurring while remaining low on average
in time. Still, due to local character of order interaction during price
formation the distribution width grows smoothly, has a minimum value at small
time scale and a square root behavior at large time scale. Examples of
calibration to market data, both intraday and daily, are provided.
"
1605.04949	q-fin	q-fin.TR	How brokers can optimally plot against traders	"  Traders buy and sell financial instruments in hopes of making profit, and
brokers are responsible for the transaction. Some brokers, known as
market-makers, take the position opposite to the trader's. If the trader buys,
they sell; if the trader sells, they buy. Said differently, brokers make money
whenever their traders lose money. From this somewhat strange mechanism emerge
various conspiracy theories, notably that brokers manipulate prices in order to
maximize their traders' losses. In this paper, our goal is to perform this evil
task optimally. Assuming total control over the price of an asset (ignoring the
usual aspects of finance such as market conditions, external influence or
stochasticity), we show how in cubic time, given a set of trades specified by a
stop-loss and a take-profit price, a broker can find a maximum loss price
movement. We also study the same problem under a model of probabilistic trades.
We finally look at the online trade setting, where broker and trader exchange
turns, each trying to make a profit. We show that the best option for the
trader is to never trade.
"
1605.04995	q-fin	math.OC math.PR q-fin.MF	Optimality of two-parameter strategies in stochastic control	"  In this note, we study a class of stochastic control problems where the
optimal strategies are described by two parameters. These include a subset of
singular control, impulse control, and two-player stochastic games. The
parameters are first chosen by the two continuous/smooth fit conditions, and
then the optimality of the corresponding strategy is shown by verification
arguments. Under the setting driven by a spectrally one-sided Levy process,
these procedures can be efficiently done thanks to the recent developments of
scale functions. In this note, we illustrate these techniques using several
examples where the optimal strategy as well as the value function can be
concisely expressed via scale functions.
"
1605.05100	q-fin	q-fin.MF	Wrong-Way Risk Models: A Comparison of Analytical Exposures	"  In this paper, we compare static and dynamic (reduced form) approaches for
modeling wrong-way risk in the context of CVA. Although all these approaches
potentially suffer from arbitrage problems, they are popular (respectively) in
industry and academia, mainly due to analytical tractability reasons. We
complete the stochastic intensity models with another dynamic approach,
consisting in the straight modeling of the survival (Az\'ema supermartingale)
process using the $\Phi$-martingale. Just like the other approaches, this
method allows for automatic calibration to a given default probability curve.
We derive analytically the positive exposures $V^+_t$ ""conditional upon
default"" associated to prototypical market price processes of FRA and IRS in
all cases. We further discuss the link between the ""default"" condition and
change-of-measure techniques. The expectation of $V^+_t$ conditional upon
$\tau=t$ is equal to the unconditional expectation of $V^+_t\zeta_t$. The
process $\zeta$ is explicitly derived in the dynamic approaches: it is proven
to be positive and to have unit expectation. Unfortunately however, it fails to
be a martingale, so that Girsanov machinery cannot be used. Nevertheless, the
expectation of $V^+_t\zeta_t$ can be computed explicitly, leading to analytical
expected positive exposure profiles in the considered examples.
"
1605.05545	q-fin	q-fin.EC physics.soc-ph	Elections in Russia, 1991-2008	"  In this paper, I review the main trends in voting in national elections in
Russia since 1991, discuss the evidence of manipulation or falsification by the
authorities, and use statistical techniques to examine the determinants of
voting trends.
"
1605.05631	q-fin	q-fin.EC q-fin.GN	Far from equilibrium: Wealth reallocation in the United States	"  Studies of wealth inequality often assume that an observed wealth
distribution reflects a system in equilibrium. This constraint is rarely tested
empirically. We introduce a simple model that allows equilibrium but does not
assume it. To geometric Brownian motion (GBM) we add reallocation: all
individuals contribute in proportion to their wealth and receive equal shares
of the amount collected. We fit the reallocation rate parameter required for
the model to reproduce observed wealth inequality in the United States from
1917 to 2012. We find that this rate was positive until the 1980s, after which
it became negative and of increasing magnitude. With negative reallocation, the
system cannot equilibrate. Even with the positive reallocation rates observed,
equilibration is too slow to be practically relevant. Therefore, studies which
assume equilibrium must be treated skeptically. By design they are unable to
detect the dramatic conditions found here when data are analysed without this
constraint.
"
1605.05802	q-fin	q-fin.MF math.OC math.PR	Recursive utility maximization under partial information	"  This paper concerns the recursive utility maximization problem under partial
information. We first transform our problem under partial information into the
one under full information. When the generator of the recursive utility is
concave, we adopt the variational formulation of the recursive utility which
leads to a stochastic game problem and a characterization of the saddle point
of the game is obtained. Then, we study the K-ignorance case and explicit
saddle points of several examples are obtained. At last, when the generator of
the recursive utility is smooth, we employ the terminal perturbation method to
characterize the optimal terminal wealth.
"
1605.05814	q-fin	q-fin.CP stat.OT	Some Mathematical Aspects of Price Optimisation	"  Calculation of an optimal tariff is a principal challenge for pricing
actuaries. In this contribution we are concerned with the renewal insurance
business discussing various mathematical aspects of calculation of an optimal
renewal tariff. Our motivation comes from two important actuarial tasks, namely
a) construction of an optimal renewal tariff subject to business and technical
constraints, and b) determination of an optimal allocation of certain premium
loadings. We consider both continuous and discrete optimisation and then
present several algorithmic sub-optimal solutions. Additionally, we explore
some simulation techniques. Several illustrative examples show both the
complexity and the importance of the optimisation approach.
"
1605.06301	q-fin	math.PR q-fin.RM	BSDEs with mean reflection	"  In this paper, we study a new type of BSDE, where the distribution of the
Y-component of the solution is required to satisfy an additional constraint,
written in terms of the expectation of a loss function. This constraint is
imposed at any deterministic time t and is typically weaker than the classical
pointwise one associated to reflected BSDEs. Focusing on solutions (Y, Z, K)
with deterministic K, we obtain the well-posedness of such equation, in the
presence of a natural Skorokhod type condition. Such condition indeed ensures
the minimality of the enhanced solution, under an additional structural
condition on the driver. Our results extend to the more general framework where
the constraint is written in terms of a static risk measure on Y. In
particular, we provide an application to the super hedging of claims under
running risk management constraint.
"
1605.06429	q-fin	q-fin.MF math.OC math.PR	Hedging with Small Uncertainty Aversion	"  We study the pricing and hedging of derivative securities with uncertainty
about the volatility of the underlying asset. Rather than taking all models
from a prespecified class equally seriously, we penalise less plausible ones
based on their ""distance"" to a reference local volatility model. In the limit
for small uncertainty aversion, this leads to explicit formulas for prices and
hedging strategies in terms of the security's cash gamma.
"
1605.06700	q-fin	q-fin.ST q-fin.GN	"The impact of the financial crisis on the long-range memory of European
  corporate bond and stock markets"	"  This paper investigates the presence of long memory in corporate bond and
stock indices of six European Union countries from July 1998 to February 2015.
We compute the Hurst exponent by means of the DFA method and using a sliding
window in order to measure long range dependence. We detect that Hurst
exponents behave differently in the stock and bond markets, being smoother in
the stock indices than in the bond indices. We verify that the level of
informational efficiency is time-varying. Moreover we find an asymmetric impact
of the 2008 financial crisis in the fixed income and the stock markets,
affecting the former but not the latter. Similar results are obtained using the
R/S method.
"
1605.06840	q-fin	q-fin.PM cond-mat.dis-nn math-ph math.MP	"Asymptotic Eigenvalue Distribution of Wishart Matrices whose Components
  are not Independently and Identically Distributed"	"  In the present work, eigenvalue distributions defined by a random rectangular
matrix whose components are neither independently nor identically distributed
are analyzed using replica analysis and belief propagation. In particular, we
consider the case in which the components are independently but not identically
distributed; for example, only the components in each row or in each column may
be {identically distributed}. We also consider the more general case in which
the components are correlated with one another. We use the replica approach
while making only weak assumptions in order to determine the asymptotic
eigenvalue distribution and to derive an algorithm for doing so, based on
belief propagation. One of our findings supports the results obtained from
Feynman diagrams. We present the results of several numerical experiments that
validate our proposed methods.
"
1605.06843	q-fin	q-fin.PM cond-mat.dis-nn math-ph math.MP	"Portfolio Optimization Problem with Non-identical Variances of Asset
  Returns using Statistical Mechanical Informatics"	"  The portfolio optimization problem in which the variances of the return rates
of assets are not identical is analyzed in this paper using the methodology of
statistical mechanical informatics, specifically, replica analysis. We define
two characteristic quantities of an optimal portfolio, namely, minimal
investment risk and concentrated investment level, in order to solve the
portfolio optimization problem and analytically determine their asymptotical
behaviors using replica analysis. Moreover, numerical experiments were
performed, and a comparison between the results of our simulation and those
obtained via replica analysis validated our proposed method.
"
1605.07278	q-fin	q-fin.ST	"Discrete Wavelet Transform-Based Prediction of Stock Index: A Study on
  National Stock Exchange Fifty Index"	"  Financial Times Series such as stock price and exchange rates are, often,
non-linear and non-stationary. Use of decomposition models has been found to
improve the accuracy of predictive models. The paper proposes a hybrid approach
integrating the advantages of both decomposition model (namely, Maximal Overlap
Discrete Wavelet Transform (MODWT)) and machine learning models (ANN and SVR)
to predict the National Stock Exchange Fifty Index. In first phase, the data is
decomposed into a smaller number of subseries using MODWT. In next phase, each
subseries is predicted using machine learning models (i.e., ANN and SVR). The
predicted subseries are aggregated to obtain the final forecasts. In final
stage, the effectiveness of the proposed approach is evaluated using error
measures and statistical test. The proposed methods (MODWT-ANN and MODWT-SVR)
are compared with ANN and SVR models and, it was observed that the return on
investment obtained based on trading rules using predicted values of MODWT-SVR
model was higher than that of Buy-and-hold strategy.
"
1605.07500	q-fin	math.NA math.PR q-fin.CP	Pathwise Iteration for Backward SDEs	"  We introduce a novel numerical approach for a class of stochastic dynamic
programs which arise as discretizations of backward stochastic differential
equations or semi-linear partial differential equations. Solving such dynamic
programs numerically requires the approximation of nested conditional
expectations, i.e., iterated integrals of previous approximations. Our approach
allows us to compute and iteratively improve upper and lower bounds on the true
solution starting from an arbitrary and possibly crude input approximation. We
demonstrate the benefits of our approach in a high dimensional financial
application.
"
1605.07680	q-fin	math.ST math.PR q-fin.MF stat.TH	Generalized Subjective Lexicographic Expected Utility Representation	"  We provide foundations for decisions in face of unlikely events by extending
the standard framework of Savage to include preferences indexed by a family of
events. We derive a subjective lexicographic expected utility representation
which allows for infinitely many lexicographically ordered levels of events and
for event-dependent attitudes toward risk. Our model thus provides foundations
for models in finance that rely on different attitudes toward risk (e.g.
Skiadas [9]) and for off-equilibrium reasonings in infinite dynamic games, thus
extending and generalizing the analysis in Blume, Brandenburger and Dekel [3].
"
1605.07884	q-fin	q-fin.MF math.PR	Risk Arbitrage and Hedging to Acceptability	"  The classical discrete time model of transaction costs relies on the
assumption that the increments of the feasible portfolio process belong to the
solvency set at each step. We extend this setting by assuming that any such
increment belongs to the sum of an element of the solvency set and the family
of acceptable positions, e.g. with respect to a dynamic risk measure.
  We describe the sets of superhedging prices, formulate several no risk
arbitrage conditions and explore connections between them. If the acceptance
sets consist of non-negative random vectors, that is the underlying dynamic
risk measure is the conditional essential infimum, we extend many classical no
arbitrage conditions in markets with transaction costs and provide their
natural geometric interpretation. The mathematical technique relies on results
for unbounded and possibly non-closed random sets in the Euclidean space.
"
1605.07945	q-fin	q-fin.CP	Trading VIX Futures under Mean Reversion with Regime Switching	"  This paper studies the optimal VIX futures trading problems under a
regime-switching model. We consider the VIX as mean reversion dynamics with
dependence on the regime that switches among a finite number of states. For the
trading strategies, we analyze the timings and sequences of the investor's
market participation, which leads to several corresponding coupled system of
variational inequalities. The numerical approach is developed to solve these
optimal double stopping problems by using projected-successive-over-relaxation
(PSOR) method with Crank-Nicolson scheme. We illustrate the optimal boundaries
via numerical examples of two-state Markov chain model. In particular, we
examine the impacts of transaction costs and regime-switching timings on the
VIX futures trading strategies.
"
1605.08025	q-fin	q-fin.EC q-fin.ST	Foreign exchange risk premia: from traditional to state-space analyses	"  This paper examines foreign exchange risk premia from simple univariate
regressions to the state-space method. The adjusted traditional regressions
properly figure out the existence and time-evolving property of the risk
premia. Successively, the state-space estimations overall are quite rationally
competent in examining the essence of time variability of the unobservable risk
premia. To be more precise, the coefficients on the lagged estimated
time-series are significant and the disturbance combined from the observation
and transition equations in the state-space system, rational and premium
errors, respectively, is statistically white noise. Such the two residuals are
discovered to move oppositely with their covariance approaching zero suggested
by the empirics. Besides, foreign exchange risk premia are projected and found
significantly stationary at level and relatively volatile throughout time with
some clustering. This volatility is however not quite dominant in the
deviations of forward prediction errors.
"
1605.08099	q-fin	q-fin.EC math.OC math.PR	Contracting theory with competitive interacting agents	"  In a framework close to the one developed by Holmstr\""om and Milgrom [44], we
study the optimal contracting scheme between a Principal and several Agents.
Each hired Agent is in charge of one project, and can make efforts towards
managing his own project, as well as impact (positively or negatively) the
projects of the other Agents. Considering economic Agents in competition with
relative performance concerns, we derive the optimal contracts in both first
best and moral hazard settings. The enhanced resolution methodology relies
heavily on the connection between Nash equilibria and multidimensional
quadratic BSDEs. The optimal contracts are linear and each agent is paid a
fixed proportion of the terminal value of all the projects of the firm.
Besides, each Agent receives his reservation utility, and those with high
competitive appetence are assigned less volatile projects, and shall even
receive help from the other Agents. From the principal point of view, it is in
the firm interest in our model to strongly diversify the competitive appetence
of the Agents.
"
1605.08908	q-fin	q-fin.PM	"What does past correlation structure tell us about the future? An answer
  from network filtering"	"  We discovered that past changes in the market correlation structure are
significantly related with future changes in the market volatility. By using
correlation-based information filtering networks we device a new tool for
forecasting the market volatility changes. In particular, we introduce a new
measure, the ""correlation structure persistence"", that quantifies the rate of
change of the market dependence structure. This measure shows a deep interplay
with changes in volatility and we demonstrate it can anticipate market risk
variations. Notably, our method overcomes the curse of dimensionality that
limits the applicability of traditional econometric tools to portfolios made of
a large number of assets. We report on forecasting performances and statistical
significance of this tool for two different equity datasets. We also identify
an optimal region of parameters in terms of True Positive and False Positive
trade-off, through a ROC curve analysis. We find that our forecasting method is
robust and it outperforms predictors based on past volatility only. Moreover
the temporal analysis indicates that our method is able to adapt to abrupt
changes in the market, such as financial crises, more rapidly than methods
based on past volatility.
"
1605.09181	q-fin	q-fin.PM cs.CE cs.NA	"The use of the multi-cumulant tensor analysis for the algorithmic
  optimisation of investment portfolios"	"  The cumulant analysis plays an important role in non Gaussian distributed
data analysis. The shares' prices returns are good example of such data. The
purpose of this research is to develop the cumulant based algorithm and use it
to determine eigenvectors that represent investment portfolios with low
variability. Such algorithm is based on the Alternating Least Square method and
involves the simultaneous minimisation 2'nd -- 6'th cumulants of the
multidimensional random variable (percentage shares' returns of many
companies). Then the algorithm was tested during the recent crash on the Warsaw
Stock Exchange. To determine incoming crash and provide enter and exit signal
for the investment strategy the Hurst exponent was calculated using the local
DFA. It was shown that introduced algorithm is on average better that benchmark
and other portfolio determination methods, but only within examination window
determined by low values of the Hurst exponent. Remark that the algorithm of is
based on cumulant tensors up to the 6'th order calculated for a
multidimensional random variable, what is the novel idea. It can be expected
that the algorithm would be useful in the financial data analysis on the world
wide scale as well as in the analysis of other types of non Gaussian
distributed data.
"
1605.09484	q-fin	q-fin.ST stat.AP	"A unified approach to mortality modelling using state-space framework:
  characterisation, identification, estimation and forecasting"	"  This paper explores and develops alternative statistical representations and
estimation approaches for dynamic mortality models. The framework we adopt is
to reinterpret popular mortality models such as the Lee-Carter class of models
in a general state-space modelling methodology, which allows modelling,
estimation and forecasting of mortality under a unified framework. Furthermore,
we propose an alternative class of model identification constraints which is
more suited to statistical inference in filtering and parameter estimation
settings based on maximization of the marginalized likelihood or in Bayesian
inference. We then develop a novel class of Bayesian state-space models which
incorporate apriori beliefs about the mortality model characteristics as well
as for more flexible and appropriate assumptions relating to heteroscedasticity
that present in observed mortality data. We show that multiple period and
cohort effect can be cast under a state-space structure. To study long term
mortality dynamics, we introduce stochastic volatility to the period effect.
The estimation of the resulting stochastic volatility model of mortality is
performed using a recent class of Monte Carlo procedure specifically designed
for state and parameter estimation in Bayesian state-space models, known as the
class of particle Markov chain Monte Carlo methods. We illustrate the framework
we have developed using Danish male mortality data, and show that incorporating
heteroscedasticity and stochastic volatility markedly improves model fit
despite an increase of model complexity. Forecasting properties of the enhanced
models are examined with long term and short term calibration periods on the
reconstruction of life tables.
"
1606.00142	q-fin	stat.ML q-fin.EC stat.CO	"Model selection consistency from the perspective of generalization
  ability and VC theory with an application to Lasso"	"  Model selection is difficult to analyse yet theoretically and empirically
important, especially for high-dimensional data analysis. Recently the least
absolute shrinkage and selection operator (Lasso) has been applied in the
statistical and econometric literature. Consis- tency of Lasso has been
established under various conditions, some of which are difficult to verify in
practice. In this paper, we study model selection from the perspective of
generalization ability, under the framework of structural risk minimization
(SRM) and Vapnik-Chervonenkis (VC) theory. The approach emphasizes the balance
between the in-sample and out-of-sample fit, which can be achieved by using
cross-validation to select a penalty on model complexity. We show that an exact
relationship exists between the generalization ability of a model and model
selection consistency. By implementing SRM and the VC inequality, we show that
Lasso is L2-consistent for model selection under assumptions similar to those
imposed on OLS. Furthermore, we derive a probabilistic bound for the distance
between the penalized extremum estimator and the extremum estimator without
penalty, which is dominated by overfitting. We also propose a new measurement
of overfitting, GR2, based on generalization ability, that converges to zero if
model selection is consistent. Using simulations, we demonstrate that the
proposed CV-Lasso algorithm performs well in terms of model selection and
overfitting control.
"
1606.00631	q-fin	q-fin.MF	"The space of outcomes of semi-static trading strategies need not be
  closed"	"  Semi-static trading strategies make frequent appearances in mathematical
finance, where dynamic trading in a liquid asset is combined with static
buy-and-hold positions in options on that asset. We show that the space of
outcomes of such strategies can have very poor closure properties when all
European options for a fixed date $T$ are available for static trading. This
causes problems for optimal investment, and stands in sharp contrast to the
purely dynamic case classically considered in mathematical finance.
"
1606.01343	q-fin	q-fin.PR q-fin.MF	The Zero-Coupon Rate Model for Derivatives Pricing	"  The aim of this paper is to present a dual-term structure model of interest
rate derivatives in order to solve the two hardest problems in financial
modeling: the exact volatility calibration of the entire swaption matrix, and
the calculation of bucket vegas for structured products. The model takes a
series of long-term zero-coupon rates as basic state variables that are driven
directly by one or more Brownian motion. The model volatility is assigned in a
matrix form with two terms. A complete numerical scheme for implementing the
model has been developed in the paper. At the end, several examples have been
given for the model calibration, the structured products pricing and the
calculation of bucket vegas.
"
1606.02748	q-fin	q-fin.EC	A Contextual Model Of The Secessionist Rebellion in Eastern Ukraine	"  This paper explores the possible contextual factors that drove some
individuals to lead, and others to join the pro-secessionist rebellion in the
2013-2014 conflict in Eastern Ukraine. We expand on the existing rational
choice literature on revolutionary participation and rebellious movements by
building a contextual choice model accounting for both cost-benefit and
behavioral considerations taken by Pro-Russian militants and rebels in the
region of Donbass. Our model generates predictions about the characteristics of
the socio-political-cultural context that are most likely to ignite and sustain
hierarchical rebel movements similar to those in Ukraine.
"
1606.02871	q-fin	q-fin.ST	The study of Thai stock market across the 2008 financial crisis	"  The cohomology theory for financial market can allow us to deform Kolmogorov
space of time series data over time period with the explicit definition of
eight market states in grand unified theory. The anti-de Sitter space induced
from a coupling behavior field among traders in case of a financial market
crash acts like gravitational field in financial market spacetime. Under this
hybrid mathematical superstructure, we redefine a behavior matrix by using
Pauli matrix and modified Wilson loop for time series data. We use it to detect
the 2008 financial market crash by using a degree of cohomology group of sphere
over tensor field in correlation matrix over all possible dominated stocks
underlying Thai SET50 Index Futures. The empirical analysis of financial tensor
network was performed with the help of empirical mode decomposition and
intrinsic time scale decomposition of correlation matrix and the calculation of
closeness centrality of planar graph.
"
1606.03261	q-fin	physics.soc-ph q-fin.GN	Socio-economic inequality: Relationship between Gini and Kolkata indices	"  Socio-economic inequality is characterized from data using various indices.
The Gini ($g$) index, giving the overall inequality is the most common one,
while the recently introduced Kolkata ($k$) index gives a measure of $1-k$
fraction of population who possess top $k$ fraction of wealth in the society.
Here, we show the relationship between the two indices, using both empirical
data and analytical estimates. The significance of their relationship has been
discussed.
"
1606.03388	q-fin	q-fin.MF	Optimal Resource Extraction in Regime Switching L\'evy Markets	"  This paper studies the problem of optimally extracting nonrenewable natural
resource in light of various financial and economic restrictions and
constraints. Taking into account the fact that the market values of the main
natural resources i.e. oil, natural gas, copper,...,etc, fluctuate randomly
following global and seasonal macroeconomic parameters, these values are
modeled using Markov switching L\'evy processes. We formulate this problem as
finite-time horizon combined optimal stopping and optimal control problem. We
prove that the value function is the unique viscosity solution of the
corresponding Hamilton-Jacobi-Bellman equations. Moreover, we prove the
convergence of a finite difference approximation of the value function.
Numerical examples are presented to illustrate these results.
"
1606.03590	q-fin	q-fin.TR	"Market Microstructure During Financial Crisis: Dynamics of Informed and
  Heuristic-Driven Trading"	"  We implement a market microstructure model including informed, uninformed and
heuristic-driven investors, which latter behave in line with loss-aversion and
mental accounting. We show that the probability of informed trading (PIN)
varies significantly during 2008. In contrast, the probability of
heuristic-driven trading (PH) remains constant both before and after the
collapse of Lehman Brothers. Cross-sectional analysis yields that, unlike PIN,
PH is not sensitive to size and volume effects. We show that heuristic-driven
traders are universally present in all market segments and their presence is
constant over time. Furthermore, we find that heuristic-driven investors and
informed traders are disjoint sets.
"
1606.03597	q-fin	q-fin.PR q-fin.ST	"Unravelling the Asymmetric Volatility Puzzle: A Novel Explanation of
  Volatility Through Anchoring"	"  This paper discusses a novel explanation for asymmetric volatility based on
the anchoring behavioral pattern. Anchoring as a heuristic bias causes
investors focusing on recent price changes and price levels, which two lead to
a belief in continuing trend and mean-reversion respectively. The empirical
results support our theoretical explanation through an analysis of large price
fluctuations in the S&P 500 and the resulting effects on implied and realized
volatility. These results indicate that asymmetry (a negative relationship)
between shocks and volatility in the subsequent period indeed exists. Moreover,
contrary to previous research, our empirical tests also suggest that implied
volatility is not simply an upward biased predictor of future deviation
compensating for the variance of the volatility but rather, due to investors
systematic anchoring to losses and gains in their volatility forecasts, it is a
co-integrated yet asymmetric over/under estimated financial instrument. We also
provide results indicating that the medium-term implied volatility (measured by
the VIX Index) is an unbiased though inefficient estimation of realized
volatility, while in contrast, the short-term volatility (measured by the
recently introduced VXST Index representing the 9-day implied volatility) is
also unbiased and yet efficient.
"
1606.03901	q-fin	q-fin.MF	Kolmogorov Space in Time Series Data	"  We provide the proof that the space of time series data is a Kolmogorov space
with $T_{0}$-separation axiom using the loop space of time series data. In our
approach we define a cyclic coordinate of intrinsic time scale of time series
data after empirical mode decomposition. A spinor field of time series data
comes from the rotation of data around price and time axis by defining a new
extradimension to time series data. We show that there exist hidden eight
dimensions in Kolmogorov space for time series data. Our concept is realized as
the algorithm of empirical mode decomposition and intrinsic time scale
decomposition and it is subsequently used for preliminary analysis on the real
time series data.
"
1606.04039	q-fin	q-fin.MF	"The Sound of Silence: equilibrium filtering and optimal censoring in
  financial markets"	"  Following the approach of standard filtering theory, we analyse
investor-valuation of firms, when these are modelled as geometric-Brownian
state processes that are privately and partially observed, at random (Poisson)
times, by agents. Tasked with disclosing forecast values, agents are able
purposefully to withhold their observations; explicit filtering formulas are
derived for downgrading the valuations in the absence of disclosures. The
analysis is conducted for both a solitary firm and m co-dependent firms.
"
1606.04139	q-fin	cs.DL q-fin.GN	"Credit allocation based on journal impact factor and coauthorship
  contribution"	"  Some research institutions demand researchers to distribute the incomes they
earn from publishing papers to their researchers and/or co-authors. In this
study, we deal with the Impact Factor-based ranking journal as a criteria for
the correct distribution of these incomes. We also include the Authorship
Credit factor for distribution of the incomes among authors, using the
geometric progression of Cantor's theory and the Harmonic Credit Index.
Depending on the ranking of the journal, the proposed model develops a proper
publication credit allocation among all authors. Moreover, our tool can be
deployed in the evaluation of an institution for a funding program, as well as
calculating the amounts necessary to incentivize research among personnel.
"
1606.04790	q-fin	q-fin.GN	Local Operators in Kinetic Wealth Distribution	"  The statistical mechanics approach to wealth distribution is based on the
conservative kinetic multi-agent model for money exchange, where the local
interaction rule between the agents is analogous to the elastic particle
scattering process. Here, we discuss the role of a class of conservative local
operators, and we show that, depending on the values of their parameters, they
can be used to generate all the relevant distributions. We also show
numerically that in order to generate the power-law tail an heterogeneous risk
aversion model is required. By changing the parameters of these operators one
can also fine tune the resulting distributions in order to provide support for
the emergence of a more egalitarian wealth distribution.
"
1606.04796	q-fin	q-fin.GN math.PR physics.soc-ph	Kinetic and mean field description of Gibrat's law	"  We introduce and analyze a linear kinetic model that describes the evolution
of the probability density of the number of firms in a society, in which the
microscopic rate of change obeys to the so-called law of proportional effect
proposed by Gibrat. Despite its apparent simplicity, the possible mean field
limits of the kinetic model are varied. In some cases, the asymptotic limit can
be described by a first-order partial differential equation. In other cases,
the mean field equation is a linear diffusion with a non constant diffusion
coefficient that models also the geometric Brownian motion and can be studied
analytically. In this case, it is shown that the large-time behavior of the
solution is represented, for a large class of initial data, by a lognormal
distribution with constant mean value and variance increasing exponentially in
time at a precise rate. The relationship between the kinetic and the diffusion
models allow to introduce an easy-to- implement expression for computing the
Fourier transform of the lognormal distribution.
"
1606.04816	q-fin	q-fin.EC	Note on level r consensus	"  We show that the hierarchy of level $r$ consensus partially collapses. In
particular, any profile $\pi\in \mathcal{P}$ that exhibits consensus of level
$(K-1)!$ around $\succ_0$ in fact exhibits consensus of level $1$ around
$\succ_0$.
"
1606.04872	q-fin	physics.soc-ph cs.CE q-fin.ST	The multiplex dependency structure of financial markets	"  We propose here a multiplex network approach to investigate simultaneously
different types of dependency in complex data sets. In particular, we consider
multiplex networks made of four layers corresponding respectively to linear,
non-linear, tail, and partial correlations among a set of financial time
series. We construct the sparse graph on each layer using a standard network
filtering procedure, and we then analyse the structural properties of the
obtained multiplex networks. The study of the time evolution of the multiplex
constructed from financial data uncovers important changes in intrinsically
multiplex properties of the network, and such changes are associated with
periods of financial stress. We observe that some features are unique to the
multiplex structure and would not be visible otherwise by the separate analysis
of the single-layer networks corresponding to each dependency measure.
"
1606.05164	q-fin	q-fin.RM physics.soc-ph	Network Valuation in Financial Systems	"  We introduce a network valuation model (hereafter NEVA) for the ex-ante
valuation of claims among financial institutions connected in a network of
liabilities. Similar to previous work, the new framework allows to endogenously
determine the recovery rate on all claims upon the default of some
institutions. In addition, it also allows to account for ex-ante uncertainty on
the asset values, in particular the one arising when the valuation is carried
out at some time before the maturity of the claims. The framework encompasses
as special cases both the ex-post approaches of Eisenberg and Noe and its
previous extensions, as well as the ex-ante approaches, in the sense that each
of these models can be recovered exactly for special values of the parameters.
We characterize the existence and uniqueness of the solutions of the valuation
problem under general conditions on how the value of each claim depends on the
equity of the counterparty. Further, we define an algorithm to carry out the
network valuation and we provide sufficient conditions for convergence to the
maximal solution.
"
1606.05488	q-fin	q-fin.MF math.OC math.PR q-fin.PM	"Explicit solutions for continuous time mean-variance portfolio selection
  with nonlinear wealth equations"	"  This paper concerns the continuous time mean-variance portfolio selection
problem with a special nonlinear wealth equation. This nonlinear wealth
equation has a nonsmooth coefficient and the dual method developed in [6] does
not work. We invoke the HJB equation of this problem and give an explicit
viscosity solution of the HJB equation. Furthermore, via this explicit
viscosity solution, we obtain explicitly the efficient portfolio strategy and
efficient frontier for this problem. Finally, we show that our nonlinear wealth
equation can cover three important cases.
"
1606.05877	q-fin	q-fin.MF	A new decomposition of portfolio return	"  For a functionally generated portfolio, there is a natural decomposition of
the relative log-return into the log-change in the generating function and a
drift process. In this note, this decomposition is extended to arbitrary stock
portfolios by an application of Fisk-Stratonovich integration. With the
extended methodology, the generating function is represented by a structural
process, and the drift process is subsumed into a trading process that measures
the profit and loss to the portfolio from trading.
"
1606.06003	q-fin	q-fin.ST q-fin.CP q-fin.MF	Using String Invariants for Prediction Searching for Optimal Parameters	"  We have developed a novel prediction method based on string invariants. The
method does not require learning but a small set of parameters must be set to
achieve optimal performance. We have implemented an evolutionary algorithm for
the parametric optimization. We have tested the performance of the method on
artificial and real world data and compared the performance to statistical
methods and to a number of artificial intelligence methods. We have used data
and the results of a prediction competition as a benchmark. The results show
that the method performs well in single step prediction but the methods
performance for multiple step prediction needs to be improved. The method works
well for a wide range of parameters.
"
1606.06143	q-fin	q-fin.CP cs.CE	"Vibrato and automatic differentiation for high order derivatives and
  sensitivities of financial options"	"  This paper deals with the computation of second or higher order greeks of
financial securities. It combines two methods, Vibrato and automatic
differentiation and compares with other methods. We show that this combined
technique is faster than standard finite difference, more stable than automatic
differentiation of second order derivatives and more general than Malliavin
Calculus. We present a generic framework to compute any greeks and present
several applications on different types of financial contracts: European and
American options, multidimensional Basket Call and stochastic volatility models
such as Heston's model. We give also an algorithm to compute derivatives for
the Longstaff-Schwartz Monte Carlo method for American options. We also extend
automatic differentiation for second order derivatives of options with
non-twice differentiable payoff. 1. Introduction. Due to BASEL III regulations,
banks are requested to evaluate the sensitivities of their portfolios every day
(risk assessment). Some of these portfolios are huge and sensitivities are time
consuming to compute accurately. Faced with the problem of building a software
for this task and distrusting automatic differentiation for non-differentiable
functions, we turned to an idea developed by Mike Giles called Vibrato. Vibrato
at core is a differentiation of a combination of likelihood ratio method and
pathwise evaluation. In Giles [12], [13], it is shown that the computing time,
stability and precision are enhanced compared with numerical differentiation of
the full Monte Carlo path. In many cases, double sensitivities, i.e. second
derivatives with respect to parameters, are needed (e.g. gamma hedging). Finite
difference approximation of sensitivities is a very simple method but its
precision is hard to control because it relies on the appropriate choice of the
increment. Automatic differentiation of computer programs bypass the difficulty
and its computing cost is similar to finite difference, if not cheaper. But in
finance the payoff is never twice differentiable and so generalized derivatives
have to be used requiring approximations of Dirac functions of which the
precision is also doubtful. The purpose of this paper is to investigate the
feasibility of Vibrato for second and higher derivatives. We will first compare
Vibrato applied twice with the analytic differentiation of Vibrato and show
that it is equivalent, as the second is easier we propose the best compromise
for second derivatives: Automatic Differentiation of Vibrato. In [8], Capriotti
has recently investigated the coupling of different mathematical methods --
namely pathwise and likelihood ratio methods -- with an Automatic differ
"
1606.06578	q-fin	q-fin.PM math.OC	"Multi-Period Portfolio Optimization: Translation of Autocorrelation Risk
  to Excess Variance"	"  Growth-optimal portfolios are guaranteed to accumulate higher wealth than any
other investment strategy in the long run. However, they tend to be risky in
the short term. For serially uncorrelated markets, similar portfolios with more
robust guarantees have been recently proposed. This paper extends these robust
portfolios by accommodating non-zero autocorrelations that may reflect
investors' beliefs about market movements. Moreover, we prove that the risk
incurred by such autocorrelations can be absorbed by modifying the covariance
matrix of asset returns.
"
1606.06948	q-fin	q-fin.GN	"A New Currency of the Future: The Novel Commodity Money with Attenuation
  Coefficient Based on the Logistics Cost of Anchor"	"  In this paper, we reveal the attenuation mechanism of anchor of the commodity
money from the perspective of logistics warehousing costs, and propose a novel
Decayed Commodity Money (DCM) for the store of value across time and space.
Considering the logistics cost of commodity warehousing by the third financial
institution such as London Metal Exchange, we can award the difference between
the original and the residual value of the anchor to the financial institution.
This type of currency has the characteristic of self-decaying value over time.
Therefore DCM has the advantages of both the commodity money which has the
function of preserving wealth and credit currency without the logistics cost.
In addition, DCM can also avoid the defects that precious metal money is
hoarded by market and credit currency often leads to excessive liquidity. DCM
is also different from virtual currency, such as bitcoin, which does not have a
corresponding commodity anchor. As a conclusion, DCM can provide a new way of
storing wealth for nations, corporations and individuals effectively.
"
1606.07277	q-fin	cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT q-fin.PM	Validation of the Replica Trick for Simple Models	"  We discuss replica analytic continuation using several simple models in order
to prove mathematically the validity of replica analysis, which is used in a
wide range of fields related to large scale complex systems. While replica
analysis consists of two analytical techniques, the replica trick (or replica
analytic continuation) and the thermodynamical limit (and/or order parameter
expansion), we focus our study on replica analytic continuation, which is the
mathematical basis of the replica trick. We apply replica analysis to solve a
variety of analytical models, and examine the properties of replica analytic
continuation. Based on the positive results for these models we propose that
replica analytic continuation is a robust procedure in replica analysis.
"
1606.07381	q-fin	q-fin.TR q-fin.PR	"Spread, volatility, and volume relationship in financial markets and
  market making profit optimization"	"  We study the relationship between price spread, volatility and trading
volume. We find that spread forms as a result of interplay between order
liquidity and order impact. When trading volume is small adding more liquidity
helps improve price accuracy and reduce spread, but after some point additional
liquidity begins to deteriorate price. The model allows to connect the bid-ask
spread and high-low bars to measurable microstructural parameters and express
their dependence on trading volume, volatility and time horizon. Using the
established relations, we address the operating spread optimization problem to
maximize market-making profit.
"
1606.07831	q-fin	q-fin.CP	"A Neural Network Approach to Efficient Valuation of Large Portfolios of
  Variable Annuities"	"  Managing and hedging the risks associated with Variable Annuity (VA) products
require intraday valuation of key risk metrics for these products. The complex
structure of VA products and computational complexity of their accurate
evaluation have compelled insurance companies to adopt Monte Carlo (MC)
simulations to value their large portfolios of VA products. Because the MC
simulations are computationally demanding, especially for intraday valuations,
insurance companies need more efficient valuation techniques. Recently, a
framework based on traditional spatial interpolation techniques has been
proposed that can significantly decrease the computational complexity of MC
simulation (Gan and Lin, 2015). However, traditional interpolation techniques
require the definition of a distance function that can significantly impact
their accuracy. Moreover, none of the traditional spatial interpolation
techniques provide all of the key properties of accuracy, efficiency, and
granularity (Hejazi et al., 2015). In this paper, we present a neural network
approach for the spatial interpolation framework that affords an efficient way
to find an effective distance function. The proposed approach is accurate,
efficient, and provides an accurate granular view of the input portfolio. Our
numerical experiments illustrate the superiority of the performance of the
proposed neural network approach compared to the traditional spatial
interpolation schemes.
"
1606.08269	q-fin	math.PR q-fin.EC	"An agent behavior based model for diffusion price processes with
  application to phase transition and oscillations"	"  We present an agent behavior based microscopic model for diffusion price
processes. As such we provide a model not only containing a convenient
framework for describing socio-economic behavior, but also a sophisticated link
to price dynamics. We furthermore establish the circumstances under which the
dynamics converge to diffusion processes in the large market limit. To
demonstrate the applicability of a separation of behavior and price process, we
show how herding behavior of market participants can lead to equilibria
transition and oscillations in diffusion price processes.
"
1606.08562	q-fin	cs.SI q-fin.GN	"Complex Systems and a Computational Social Science Perspective on the
  Labor Market"	"  Labor market institutions are central for modern economies, and their polices
can directly affect unemployment rates and economic growth. At the individual
level, unemployment often has a detrimental impact on people's well-being and
health. At the national level, high employment is one of the central goals of
any economic policy, due to its close association with national prosperity. The
main goal of this thesis is to highlight the need for frameworks that take into
account the complex structure of labor market interactions. In particular, we
explore the benefits of leveraging tools from computational social science,
network science, and data-driven theories to measure the flow of opportunities
and information in the context of the labor market. First, we investigate our
key hypothesis, which is that opportunity/information flow through weak ties,
and this is a key determinant of the length of unemployment. We then extend the
idea of opportunity/information flow to clusters of other economic activities,
where we expect the flow within clusters of related activities to be higher
than within isolated activities. This captures the intuition that within
related activities there are more ""capitals"" involved and that such activities
require similar ""capabilities."" Therefore, more extensive clusters of economic
activities should generate greater growth through exploiting the greater flow
of opportunities and information. We quantify the opportunity/information flow
using a complexity measure of two economic activities (i.e. jobs and exports).
"
1606.08984	q-fin	q-fin.EC q-fin.RM	"Optimal Consumption, Investment and Housing with Means-tested Public
  Pension in Retirement"	"  In this paper, we develop an expected utility model for the retirement
behavior in the decumulation phase of Australian retirees with sequential
family status subject to consumption, housing, investment, bequest and
government provided means-tested Age Pension. We account for mortality risk and
risky investment assets, and introduce a health proxy to capture the decreasing
level of consumption for older retirees. Then we find optimal housing at
retirement, and optimal consumption and optimal risky asset allocation
depending on age and wealth. The model is solved numerically as a stochastic
control problem, and is calibrated using the maximum likelihood method on
empirical data of consumption and housing from the Australian Bureau of
Statistics 2009-2010 Survey. The model fits the characteristics of the data
well to explain the behavior of Australian retirees. The key findings are the
following: First, the optimal policy is highly sensitive to means-tested Age
Pension early in retirement but this sensitivity fades with age. Secondly, the
allocation to risky assets shows a complex relationship with the means-tested
Age Pension that disappears once minimum withdrawal rules are enforced. As a
general rule, when wealth decreases the proportion allocated to risky assets
increases, due to the Age Pension working as a buffer against investment
losses. Finally, couples can be more aggressive with risky allocations due to
their longer life expectancy compared with singles.
"
1606.09194	q-fin	q-fin.TR physics.soc-ph	A multilayer approach for price dynamics in financial markets	"  We introduce a new Self-Organized Criticality (SOC) model for simulating
price evolution in an artificial financial market, based on a multilayer
network of traders. The model also implements, in a quite realistic way with
respect to previous studies, the order book dy- namics, by considering two
assets with variable fundamental prices. Fat tails in the probability
distributions of normalized returns are observed, together with other features
of real financial markets.
"
1607.00035	q-fin	q-fin.MF math.PR	"Stock Market Insider Trading in Continuous Time with Imperfect Dynamic
  Information"	"  This paper studies the equilibrium pricing of asset shares in the presence of
dynamic private information. The market consists of a risk-neutral informed
agent who observes the firm value, noise traders, and competitive market makers
who set share prices using the total order flow as a noisy signal of the
insider's information. I provide a characterization of all optimal strategies,
and prove existence of both Markovian and non Markovian equilibria by deriving
closed form solutions for the optimal order process of the informed trader and
the optimal pricing rule of the market maker. The consideration of non
Markovian equilibrium is relevant since the market maker might decide to
re-weight past information after receiving a new signal. Also, I show that a)
there is a unique Markovian equilibrium price process which allows the insider
to trade undetected, and that b) the presence of an insider increases the
market informational efficiency, in particular for times close to dividend
payment.
"
1607.00454	q-fin	q-fin.TR	Limit order trading with a mean reverting reference price	"  Optimal control models for limit order trading often assume that the
underlying asset price is a Brownian motion since they deal with relatively
short time scales. The resulting optimal bid and ask limit order prices tend to
track the underlying price as one might expect. This is indeed the case with
the model of Avellaneda and Stoikov (2008), which has been studied extensively.
We consider here this model under the condition when the underlying price is
mean reverting. Our main result is that when time is far from the terminal, the
optimal price for bid and ask limit orders is constant, which means that it
does not track the underlying price. Numerical simulations confirm this
behavior. When the underlying price is mean reverting, then for times
sufficiently far from terminal, it is more advantageous to focus on the mean
price and ignore fluctuations around it. Mean reversion suggests that limit
orders will be executed with some regularity, and this is why they are optimal.
We also explore intermediate time regimes where limit order prices are
influenced by the inventory of outstanding orders. The duration of this
intermediate regime depends on the liquidity of the market as measured by
specific parameters in the model.
"
1607.00638	q-fin	q-fin.MF math.PR	Time-Inconsistent Stochastic Linear-quadratic Differential Game	"  We consider a general time-inconsistent stochastic linear-quadratic
differential game. The time-inconsistency arises from the presence of quadratic
terms of the expected state as well as state-dependent term in the objective
functionals. We define an equilibrium strategy, which is different from the
classical one, and derived a sufficient conditions for equilibrium strategies
via a system of forward-backward stochastic differential equations. When the
state is one-dimensional and the coefficients are all deterministic, we find an
explicit equilibrium strategy. The uniqueness of such equilibrium strategy is
also given.
"
1607.00721	q-fin	q-fin.MF math.OC	Recursive utility optimization with concave coefficients	"  This paper concerns the recursive utility maximization problem. We assume
that the coefficients of the wealth equation and the recursive utility are
concave. Then some interesting and important cases with nonlinear and nonsmooth
coefficients satisfy our assumption. After given an equivalent backward
formulation of our problem, we employ the Fenchel-Legendre transform and derive
the corresponding variational formulation. By the convex duality method, the
primal ""sup-inf"" problem is translated to a dual minimization problem and the
saddle point of our problem is derived. Finally, we obtain the optimal terminal
wealth. To illustrate our results, three cases for investors with ambiguity
aversion are explicitly worked out under some special assumptions.
"
1607.00756	q-fin	q-fin.RM	"Comments on the BCBS proposal for a New Standardized Approach for
  Operational Risk"	"  On March 4th 2016 the Basel Committee on Banking Supervision published a
consultative document where a new methodology, called the Standardized
Measurement Approach (SMA), is introduced for computing Operational Risk
regulatory capital for banks. In this note, the behavior of the SMA is studied
under a variety of hypothetical and realistic conditions, showing that the
simplicity of the new approach is very costly on other aspects: we find that
the SMA does not respond appropriately to changes in the risk profile of a
bank, nor is it capable of differentiating among the range of possible risk
profiles across banks; that SMA capital results generally appear to be more
variable across banks than the previous AMA option of fitting the loss data;
that the SMA can result in banks over- or under-insuring against operational
risks relative to previous AMA standards. Finally, we argue that the SMA is not
only retrograde in terms of its capability to measure risk, but perhaps more
importantly, it fails to create any link between management actions and capital
requirement.
"
1607.00830	q-fin	q-fin.MF	"A probability-free and continuous-time explanation of the equity premium
  and CAPM"	"  This paper gives yet another definition of game-theoretic probability in the
context of continuous-time idealized financial markets. Without making any
probabilistic assumptions (but assuming positive and continuous price paths),
we obtain a simple expression for the equity premium and derive a version of
the capital asset pricing model.
"
1607.01207	q-fin	q-fin.MF q-fin.PR	"Natural gas-fired power plants valuation and optimisation under Levy
  copulas and regime-switching"	"  In this work we analyse a stochastic control problem for the valuation of a
natural gas power station while taking into account operating characteristics.
Both electricity and gas spot price processes exhibit mean-reverting spikes and
Markov regime-switches. The Levy regime-switching model incorporates the
effects of demand-supply fluctuations in energy markets and abrupt economic
disruptions or business cycles. We make use of skewed Levy copulas to model the
dependence risk of electricity and gas jumps.
  The corresponding HJB equation is the non-linear PIDE which is solved by an
explicit finite difference method. The numerical approach gives us both the
value of the plant and its optimal operating strategy depending on the gas and
electricity prices, current temperature of the boiler and time. The surfaces of
control strategies and contract values are obtained by implementing the
numerical method for a particular example.
"
1607.01248	q-fin	q-fin.GN	Evolutionary Model of Stock Markets	"  The paper presents an evolutionary economic model for the price evolution of
stocks. Treating a stock market as a self-organized system governed by a fast
purchase process and slow variations of demand and supply the model suggests
that the short term price distribution has the form a logistic (Laplace)
distribution. The long term return can be described by Laplace-Gaussian mixture
distributions. The long term mean price evolution is governed by a Walrus
equation, which can be transformed into a replicator equation. This allows
quantifying the evolutionary price competition between stocks. The theory
suggests that stock prices scaled by the price over all stocks can be used to
investigate long-term trends in a Fisher-Pry plot. The price competition that
follows from the model is illustrated by examining the empirical long-term
price trends of two stocks.
"
1607.01519	q-fin	q-fin.PR math.PR	Granger Independent Martingale Processes	"  We introduce a new class of processes for the evaluation of multivariate
equity derivatives. The proposed setting is well suited for the application of
the standard copula function theory to processes, rather than variables, and
easily enables to enforce the martingale pricing requirement. The martingale
condition is imposed in a general multidimensional Markov setting to which we
only add the restriction of no-Granger-causality of the increments
(Granger-independent increments). We call this class of processes GIMP (Granger
Independent Martingale Processes). The approach can also be extended to the
application of time change, under which the martingale restriction continues to
hold. Moreover, we show that the class of GIMP processes is closed under time
changing: if a Granger independent process is used as a multivariate stochastic
clock for the change of time of a GIMP process, the new process is also GIMP.
"
1607.01902	q-fin	math.OC math.PR q-fin.RM	"On optimal joint reflective and refractive dividend strategies in
  spectrally positive L\'evy models"	"  The expected present value of dividends is one of the classical stability
criteria in actuarial risk theory. In this context, numerous papers considered
threshold (refractive) and barrier (reflective) dividend strategies. These were
shown to be optimal in a number of different contexts for bounded and unbounded
payout rates, respectively. In this paper, motivated by the behaviour of some
dividend paying stock exchange companies, we determine the optimal dividend
strategy when both continuous (refractive) and lump sum (reflective) dividends
can be paid at any time, and if they are subject to different transaction
rates. We consider the general family of spectrally positive L\'evy processes.
Using scale functions, we obtain explicit formulas for the expected present
value of dividends until ruin, with a penalty at ruin. We develop a
verification lemma, and show that a two-layer (a,b) strategy is optimal. Such a
strategy pays continuous dividends when the surplus exceeds level a>0, and all
of the excess over b>a as lump sum dividend payments. Results are illustrated.
"
1607.01999	q-fin	q-fin.EC	"Inferring the contiguity matrix for spatial autoregressive analysis with
  applications to house price prediction"	"  Inference methods in traditional statistics, machine learning and data mining
assume that data is generated from an independent and identically distributed
(iid) process. Spatial data exhibits behavior for which the iid assumption must
be relaxed. For example, the standard approach in spatial regression is to
assume the existence of a contiguity matrix which captures the spatial
autoregressive properties of the data. However all spatial methods, till now,
have assumed that the contiguity matrix is given apriori or can be estimated by
using a spatial similarity function. In this paper we propose a convex
optimization formulation to solve the spatial autoregressive regression (SAR)
model in which both the contiguity matrix and the non-spatial regression
parameters are unknown and inferred from the data. We solve the problem using
the alternating direction method of multipliers (ADMM) which provides a
solution which is both robust and efficient. While our approach is general we
use data from housing markets of Boston and Sydney to both guide the analysis
and validate our results. A novel side effect of our approach is the automatic
discovery of spatial clusters which translate to submarkets in the housing data
sets.
"
1607.02093	q-fin	q-fin.ST cs.CE	"Artificial Neural Network and Time Series Modeling Based Approach to
  Forecasting the Exchange Rate in a Multivariate Framework"	"  Any discussion on exchange rate movements and forecasting should include
explanatory variables from both the current account and the capital account of
the balance of payments. In this paper, we include such factors to forecast the
value of the Indian rupee vis a vis the US Dollar. Further, factors reflecting
political instability and lack of mechanism for enforcement of contracts that
can affect both direct foreign investment and also portfolio investment, have
been incorporated. The explanatory variables chosen are the 3 month Rupee
Dollar futures exchange rate (FX4), NIFTY returns (NIFTYR), Dow Jones
Industrial Average returns (DJIAR), Hang Seng returns (HSR), DAX returns (DR),
crude oil price (COP), CBOE VIX (CV) and India VIX (IV). To forecast the
exchange rate, we have used two different classes of frameworks namely,
Artificial Neural Network (ANN) based models and Time Series Econometric
models. Multilayer Feed Forward Neural Network (MLFFNN) and Nonlinear
Autoregressive models with Exogenous Input (NARX) Neural Network are the
approaches that we have used as ANN models. Generalized Autoregressive
Conditional Heteroskedastic (GARCH) and Exponential Generalized Autoregressive
Conditional Heteroskedastic (EGARCH) techniques are the ones that we have used
as Time Series Econometric methods. Within our framework, our results indicate
that, although the two different approaches are quite efficient in forecasting
the exchange rate, MLFNN and NARX are the most efficient.
"
1607.02319	q-fin	q-fin.RM	"Should the advanced measurement approach be replaced with the
  standardized measurement approach for operational risk?"	"  Recently, Basel Committee for Banking Supervision proposed to replace all
approaches, including Advanced Measurement Approach (AMA), for operational risk
capital with a simple formula referred to as the Standardised Measurement
Approach (SMA). This paper discusses and studies the weaknesses and pitfalls of
SMA such as instability, risk insensitivity, super-additivity and the implicit
relationship between SMA capital model and systemic risk in the banking sector.
We also discuss the issues with closely related operational risk
Capital-at-Risk (OpCar) Basel Committee proposed model which is the precursor
to the SMA. In conclusion, we advocate to maintain the AMA internal model
framework and suggest as an alternative a number of standardization
recommendations that could be considered to unify internal modelling of
operational risk. The findings and views presented in this paper have been
discussed with and supported by many OpRisk practitioners and academics in
Australia, Europe, UK and USA, and recently at OpRisk Europe 2016 conference in
London.
"
1607.02349	q-fin	q-fin.GN	"Toward an integrated workforce planning framework using structured
  equations"	"  Strategic Workforce Planning is a company process providing best in class,
economically sound, workforce management policies and goals. Despite the
abundance of literature on the subject, this is a notorious challenge in terms
of implementation. Reasons span from the youth of the field itself to broader
data integration concerns that arise from gathering information from financial,
human resource and business excellence systems. This paper aims at setting the
first stones to a simple yet robust quantitative framework for Strategic
Workforce Planning exercises. First a method based on structured equations is
detailed. It is then used to answer two main workforce related questions: how
to optimally hire to keep labor costs flat? How to build an experience
constrained workforce at a minimal cost?
"
1607.02378	q-fin	q-fin.EC	Matrix-vector representation of various solution concepts	"  A unified matrix-vector representation is developed of such solution concepts
as the core, the uncovered, the uncaptured, the minimal weakly stable, the
minimal undominated, the minimal dominant and the untrapped sets. We also
propose several new versions of solution sets.
"
1607.02410	q-fin	q-fin.GN	Tail protection for long investors: Trend convexity at work	"  The performance of trend following strategies can be ascribed to the
difference between long-term and short-term realized variance. We revisit this
general result and show that it holds for various definitions of trend
strategies. This explains the positive convexity of the aggregate performance
of Commodity Trading Advisors (CTAs) which -- when adequately measured -- turns
out to be much stronger than anticipated. We also highlight interesting
connections with so-called Risk Parity portfolios. Finally, we propose a new
portfolio of strangle options that provides a pure exposure to the long-term
variance of the underlying, offering yet another viewpoint on the link between
trend and volatility.
"
1607.02419	q-fin	q-fin.EC cs.AI	"Divisive-agglomerative algorithm and complexity of automatic
  classification problems"	"  An algorithm of solution of the Automatic Classification (AC for brevity)
problem is set forth in the paper. In the AC problem, it is required to find
one or several artitions, starting with the given pattern matrix or
dissimilarity, similarity matrix.
"
1607.02421	q-fin	q-fin.EC	"Alternative versions of the global competitive industrial performance
  ranking constructed by methods from social choice theory"	"  The Competitive Industrial Performance index (developed by experts of the
UNIDO) is designed as a measure of national competitiveness. Index is an
aggregate of eight observable variables, representing different dimensions of
competitive industrial performance.
"
1607.02422	q-fin	q-fin.EC q-fin.GN	Rating models: emerging market distinctions	"  The Basel II Accords have sparked increased interest in the development of
approaches based on internal ratings systems and have initiated the elaboration
of models for remote ratings forecasts based on external ones as part of Risk
Management and Early Warning Systems. This article evaluates the peculiarities
of current ratings systems and addresses specific issues of development of
econometrical rating models for emerging market companies.
"
1607.02423	q-fin	q-fin.EC	Fair division with divisible and indivisible items	"  In the work the fair division problem for two participants in presence of
both divisible and indivisible items is considered. The set of all divisions is
formally described; it is demonstrated that fair (in terms of Brams and Taylor)
divisions, unlikely the case where all the items are divisible, not always
exist. The necessary and sufficient conditions of existence of proportional and
equitable division were found.
"
1607.03161	q-fin	cs.GT physics.soc-ph q-fin.EC	A mathematical model for a gaming community	"  We consider a large community of individuals who mix strongly and meet in
pairs to bet on a coin toss. We investigate the asset distribution of the
players involved in this zero-sum repeated game. Our main result is that the
asset distribution converges to the exponential distribution, irrespective of
the size of the bet, as long as players can never go bankrupt. Analytical
results suggests that the exponential distribution is a stable fixed point for
this zero-sum repreated game. This is confirmed in numerical experiments.
"
1607.03430	q-fin	q-fin.RM	Dual representations for systemic risk measures	"  The financial crisis showed the importance of measuring, allocating and
regulating systemic risk. Recently, the systemic risk measures that can be
decomposed into an aggregation function and a scalar measure of risk, received
a lot of attention. In this framework, capital allocations are added after
aggregation and can represent bailout costs. More recently, a framework has
been introduced, where institutions are supplied with capital allocations
before aggregation. This yields an interpretation that is particularly useful
for regulatory purposes. In each framework, the set of all feasible capital
allocations leads to a multivariate risk measure. In this paper, we present
dual representations for scalar systemic risk measures as well as for the
corresponding multivariate risk measures concerning capital allocations. Our
results cover both frameworks: aggregating after allocating and allocating
after aggregation. Economic interpretations of the obtained results are
provided. It turns out that the representations in both frameworks are closely
related.
"
1607.04047	q-fin	q-fin.MF	"A Principal-Agent Model of Trading Under Market Impact -Crossing
  networks interacting with dealer markets-"	"  We use a principal-agent model to analyze the structure of a book-driven
dealer market when the dealer faces competition from a crossing network or dark
pool. The agents are privately informed about their types (e.g. their
portfolios), which is something that the dealer must take into account when
engaging his counterparties. Instead of trading with the dealer, the agents may
chose to trade in a crossing network. We show that the presence of such a
network results in more types being serviced by the dealer and that, under
certain conditions and due to reduced adverse selection effects, the book's
spread shrinks. We allow for the pricing on the dealer market to determine the
structure of the crossing network and show that the same conditions that lead
to a reduction of the spread imply the existence of an equilibrium
book/crossing network pair.
"
1607.04100	q-fin	q-fin.RM	Insurance valuation: a computable multi-period cost-of-capital approach	"  We present an approach to market-consistent multi-period valuation of
insurance liability cash flows based on a two-stage valuation procedure. First,
a portfolio of traded financial instrument aimed at replicating the liability
cash flow is fixed. Then the residual cash flow is managed by repeated
one-period replication using only cash funds. The latter part takes capital
requirements and costs into account, as well as limited liability and risk
averseness of capital providers. The cost-of-capital margin is the value of the
residual cash flow. We set up a general framework for the cost-of-capital
margin and relate it to dynamic risk measurement. Moreover, we present explicit
formulas and properties of the cost-of-capital margin under further assumptions
on the model for the liability cash flow and on the conditional risk measures
and utility functions. Finally, we highlight computational aspects of the
cost-of-capital margin, and related quantities, in terms of an example from
life insurance.
"
1607.04136	q-fin	q-fin.GN	"Secular bipolar growth rate of the real US GDP per capita: implications
  for understanding past and future economic growth"	"  We present a quantitative characterisation of the fluctuations of the
annualized growth rate of the real US GDP per capita growth at many scales,
using a wavelet transform analysis of two data sets, quarterly data from 1947
to 2015 and annual data from 1800 to 2010. Our main finding is that the
distribution of GDP growth rates can be well approximated by a bimodal function
associated to a series of switches between regimes of strong growth rate
$\rho_\text{high}$ and regimes of low growth rate $\rho_\text{low}$. The
succession of such two regimes compounds to produce a remarkably stable long
term average real annualized growth rate of 1.6\% from 1800 to 2010 and
$\approx 2.0\%$ since 1950, which is the result of a subtle compensation
between the high and low growth regimes that alternate continuously. Thus, the
overall growth dynamics of the US economy is punctuated, with phases of strong
growth that are intrinsically unsustainable, followed by corrections or
consolidation until the next boom starts. We interpret these findings within
the theory of ""social bubbles"" and argue as a consequence that estimations of
the cost of the 2008 crisis may be misleading. We also interpret the absence of
strong recovery since 2008 as a protracted low growth regime $\rho_\text{low}$
associated with the exceptional nature of the preceding large growth regime.
"
1607.04484	q-fin	q-fin.EC	The Oxford Olympics Study 2016: Cost and Cost Overrun at the Games	"  Given that Olympic Games held over the past decade each have cost USD 8.9
billion on average, the size and financial risks of the Games warrant study.
The objectives of the Oxford Olympics study are to (1) establish the actual
outturn costs of previous Olympic Games in a manner where cost can consistently
be compared across Games; (2) establish cost overruns for previous Games, i.e.,
the degree to which final outturn costs reflect projected budgets at the bid
stage, again in a way that allows comparison across Games; (3) test whether the
Olympic Games Knowledge Management Program has reduced cost risk for the Games,
and, finally, (4) benchmark cost and cost overrun for the Rio 2016 Olympics
against previous Games. The main contribution of the Oxford study is to
establish a phenomenology of cost and cost overrun at the Olympics, which
allows consistent and systematic comparison across Games. This has not been
done before. The study concludes that for a city and nation to decide to stage
the Olympic Games is to decide to take on one of the most costly and
financially most risky type of megaproject that exists, something that many
cities and nations have learned to their peril.
"
1607.04737	q-fin	q-fin.RM	"A form of multivariate Pareto distribution with applications to
  financial risk measurement"	"  A new multivariate distribution possessing arbitrarily parametrized and
positively dependent univariate Pareto margins is introduced. Unlike the
probability law of Asimit et al. (2010) [Asimit, V., Furman, E. and Vernic, R.
(2010) On a multivariate Pareto distribution. Insurance: Mathematics and
Economics 46(2), 308-316], the structure in this paper is absolutely continuous
with respect to the corresponding Lebesgue measure. The distribution is of
importance to actuaries through its connections to the popular frailty models,
as well as because of the capacity to describe dependent heavy-tailed risks.
The genesis of the new distribution is linked to a number of existing
probability models, and useful characteristic results are proved. Expressions
for, e.g., the decumulative distribution and probability density functions,
(joint) moments and regressions are developed. The distributions of minima and
maxima, as well as, some weighted risk measures are employed to exemplify
possible applications of the distribution in insurance.
"
1607.04739	q-fin	q-fin.RM	Multiple risk factor dependence structures: Distributional properties	"  We introduce a class of dependence structures, that we call the Multiple Risk
Factor (MRF) dependence structures. On the one hand, the new constructions
extend the popular CreditRisk+ approach, and as such they formally describe
default risk portfolios exposed to an arbitrary number of fatal risk factors
with conditionally exponential and dependent hitting (or occurrence) times. On
the other hand, the MRF structures can be seen as an encompassing family of
multivariate probability distributions with univariate margins distributed
Pareto of the 2nd kind, and in this role they can be used to model insurance
risk portfolios of dependent and heavy tailed risk components.
"
1607.04968	q-fin	q-fin.MF	"Numerical and analytical methods for bond pricing in short rate
  convergence models of interest rates"	"  In this survey paper we discuss recent advances on short interest rate models
which can be formulated in terms of a stochastic differential equation for the
instantaneous interest rate (also called short rate) or a system of such
equations in case the short rate is assumed to depend also on other stochastic
factors. Our focus is on convergence models, which explain the evolution of
interest rate in connection with the adoption of Euro currency. Here, the
domestic short rate depends on a stochastic European short rate. In short rate
models, the bond prices, which determine the term structure of interest rate,
are obtained as solutions to partial differential equations. Analytical
solutions are available only in special cases; therefore we consider the
question of obtaining their approximations. We use both analytical and
numerical methods to get an approximate solution to the partial differential
equation for bond prices.
"
1607.05514	q-fin	q-fin.GN	"Sectoral co-movements in the Indian stock market: A mesoscopic network
  analysis"	"  In this article we review several techniques to extract information from
stock market data. We discuss recurrence analysis of time series, decomposition
of aggregate correlation matrices to study co-movements in financial data,
stock level partial correlations with market indices, multidimensional scaling
and minimum spanning tree. We apply these techniques to daily return time
series from the Indian stock market. The analysis allows us to construct
networks based on correlation matrices of individual stocks in one hand and on
the other, we discuss dynamics of market indices. Thus both micro level and
macro level dynamics can be analyzed using such tools. We use the
multi-dimensional scaling methods to visualize the sectoral structure of the
stock market, and analyze the comovements among the sectoral stocks. Finally,
we construct a mesoscopic network based on sectoral indices. Minimum spanning
tree technique is seen to be extremely useful in order to separate
technologically related sectors and the mapping corresponds to actual
production relationship to a reasonable extent.
"
1607.05660	q-fin	q-fin.ST	"A Comparison of Nineteen Various Electricity Consumption Forecasting
  Approaches and Practicing to Five Different Households in Turkey"	"  The accuracy of the household electricity consumption forecast is vital in
taking better cost effective and energy efficient decisions. In order to design
accurate, proper and efficient forecasting model, characteristics of the series
have to been analyzed. The source of time series data comes from Online
Enerjisa System, the system of electrical energy provider in capital of Turkey,
which consumers can reach their latest two year period electricity
consumptions; in our study the period was May 2014 to May 2016. Various
techniques had been applied in order to analyze the data; classical
decomposition models; standard typed and also with the centering moving average
method, regression equations, exponential smoothing models and ARIMA models. In
our study, nine teen different approaches; all of these have at least
diversified aspects of methodology, had been compared and the best model for
forecasting were decided by considering the smallest values of MAPE, MAD and
MSD. As a first step we took the time period May 2014 to May 2016 and found
predicted value for June 2016 with the best forecasting model. After finding
the best forecasting model and fitted value for June 2016, than validating
process had been taken place; we made comparisons to see how well the real
value of June 2016 and forecasted value for that specific period matched.
Afterwards we made electrical consumption forecast for the following 3 months;
June-September 2016 for each of five households individually.
"
1607.06163	q-fin	math.ST q-fin.EC stat.ME stat.TH	Indirect Inference With(Out) Constraints	"  The traditional implementation of Indirect Inference (I-I) is to perform
inference on structural parameters $\theta$ by matching observed and simulated
auxiliary statistics. These auxiliary statistics are consistent estimators of
instrumental parameters whose value depends on the value of structural
parameters through a binding function. Since instrumental parameters
encapsulate the statistical information used for inference about the structural
parameters, it sounds paradoxical to constrain these parameters, that is, to
restrain the information used for inference. However, there are situations
where the definition of instrumental parameters $\beta$ naturally comes with a
set of $q$ restrictions. Such situations include: settings where the auxiliary
parameters must be estimated subject to $q$ possibly binding strict inequality
constraints $g(\cdot) > 0$; cases where the auxiliary model is obtained by
imposing $q$ equality constraints $g(\theta) = 0$ on the structural model to
define tractable auxiliary parameter estimates of $\beta$ that are seen as an
approximation of the true $\theta$, since the simplifying constraints are
misspecified; examples where the auxiliary parameters are defined by $q$
estimating equations that overidentify them. We demonstrate that the optimal
solution in these settings is to disregard the constrained auxiliary
statistics, and perform I-I without these constraints using appropriately
modified unconstrained versions of the auxiliary statistics. In each of the
above examples, we outline how such unconstrained auxiliary statistics can be
constructed and demonstrate that this I-I approach without constraints can be
reinterpreted as a standard implementation of I-I through a properly modified
binding function.
"
1607.06373	q-fin	q-fin.MF	Systemic Risk and Stochastic Games with Delay	"  We propose a model of inter-bank lending and borrowing which takes into
account clearing debt obligations. The evolution of log-monetary reserves of
$N$ banks is described by coupled diffusions driven by controls with delay in
their drifts. Banks are minimizing their finite-horizon objective functions
which take into account a quadratic cost for lending or borrowing and a linear
incentive to borrow if the reserve is low or lend if the reserve is high
relative to the average capitalization of the system. As such, our problem is
an $N$-player linear-quadratic stochastic differential game with delay. An
open-loop Nash equilibrium is obtained using a system of fully coupled forward
and advanced backward stochastic differential equations. We then describe how
the delay affects liquidity and systemic risk characterized by a large number
of defaults. We also derive a close-loop Nash equilibrium using an HJB
approach.
"
1607.07099	q-fin	math.OC q-fin.CP q-fin.MF q-fin.RM	Inverse Optimization of Convex Risk Functions	"  The theory of convex risk functions has now been well established as the
basis for identifying the families of risk functions that should be used in
risk averse optimization problems. Despite its theoretical appeal, the
implementation of a convex risk function remains difficult, as there is little
guidance regarding how a convex risk function should be chosen so that it also
well represents one's own risk preferences. In this paper, we address this
issue through the lens of inverse optimization. Specifically, given solution
data from some (forward) risk-averse optimization problems we develop an
inverse optimization framework that generates a risk function that renders the
solutions optimal for the forward problems. The framework incorporates the
well-known properties of convex risk functions, namely, monotonicity,
convexity, translation invariance, and law invariance, as the general
information about candidate risk functions, and also the feedbacks from
individuals, which include an initial estimate of the risk function and
pairwise comparisons among random losses, as the more specific information. Our
framework is particularly novel in that unlike classical inverse optimization,
no parametric assumption is made about the risk function, i.e. it is
non-parametric. We show how the resulting inverse optimization problems can be
reformulated as convex programs and are polynomially solvable if the
corresponding forward problems are polynomially solvable. We illustrate the
imputed risk functions in a portfolio selection problem and demonstrate their
practical value using real-life data.
"
1607.07108	q-fin	q-fin.PR math.PR	Model-Independent Price Bounds for Catastrophic Mortality Bonds	"  In this paper, we are concerned with the valuation of Catastrophic Mortality
Bonds and, in particular, we examine the case of the Swiss Re Mortality Bond
2003 as a primary example of this class of assets. This bond was the first
Catastrophic Mortality Bond to be launched in the market and encapsulates the
behaviour of a well-defined mortality index to generate payoffs for
bondholders. Pricing this type of bonds is a challenging task and no closed
form solution exists in the literature. In our approach, we adapt the payoff of
such a bond in terms of the payoff of an Asian put option and present a new
approach to derive model-independent bounds exploiting comonotonic theory as
illustrated in \cite{prime1} for the pricing of Asian options. We carry out
Monte Carlo simulations to estimate the bond price and illustrate the strength
of the bounds.
"
1607.07510	q-fin	q-fin.GN	The Rank Effect for Commodities	"  We uncover a large and significant low-minus-high rank effect for commodities
across two centuries. There is nothing anomalous about this anomaly, nor is it
clear how it can be arbitraged away. Using nonparametric econometric methods,
we demonstrate that such a rank effect is a necessary consequence of a
stationary relative asset price distribution. We confirm this prediction using
daily commodity futures prices and show that a portfolio consisting of
lower-ranked, lower-priced commodities yields 23% higher annual returns than a
portfolio consisting of higher-ranked, higher-priced commodities. These excess
returns have a Sharpe ratio nearly twice as high as the U.S. stock market yet
are uncorrelated with market risk. In contrast to the extensive literature on
asset pricing factors and anomalies, our results are structural and rely on
minimal and realistic assumptions for the long-run behavior of relative asset
prices.
"
1607.07582	q-fin	q-fin.MF q-fin.GN	"Modelling the impact of financialization on agricultural commodity
  markets"	"  We propose a stylized model of production and exchange in which long-term
investors set their production decision over a horizon {\tau} , the ""time to
produce"", and are liquidity constrained, while financial investors trade over a
much shorter horizon {\delta} (<< {\tau} ) and are therefore more duly informed
on the exogenous shocks affecting the production output. The equilibrium
solution proves that: (i) long-term producers modify their production decisions
to anticipate the impact of short-term investors allocations on prices; (ii)
short-term investments return a positive expected profit commensurate to the
informational advantage. While the presence of financial investors improves the
efficiency of risk allocation in the short-term and reduces price volatility,
the model shows that the aggregate effect of commodity market financialization
results in rising the volatility of both farms' default risk and production
output.
"
1607.07706	q-fin	q-fin.GN cs.SI	Online shopping key features analysis in Mures county	"  The aim of this paper is to get an overview of the online buyer profile, and
also some key aspects in the way the online shopping is conducted. In this
project we conducted a quantitative research, consisting of a questionnaire
based survey. For data processing and interpretation we used SPSS statistical
software and Excel. For data analysis, we used the descriptive statistics
indicators, and a series of bi-varied analysis for testing some statistical
assumptions. Viewed at first with skepticism by the Internet users in Romania,
because of the many news about how dangerous the credit card payments are, the
online stores have gained much ground and trust in the recent years. Since the
study was conducted mainly in the online environment, we can not talk about the
representativeness of the sample, only about a trend observed in the studied
population. The study helps us understand the population reactions and
attitudes regarding the online shopping. The study revealed some important
issues regarding the online shopping in Mures county, issues that are described
in detail in the content of this paper.
"
1607.08214	q-fin	q-fin.GN q-fin.ST	Asymmetric volatility connectedness on forex markets	"  We show how bad and good volatility propagate through forex markets, i.e., we
provide evidence for asymmetric volatility connectedness on forex markets.
Using high-frequency, intra-day data of the most actively traded currencies
over 2007 - 2015 we document the dominating asymmetries in spillovers that are
due to bad rather than good volatility. We also show that negative spillovers
are chiefly tied to the dragging sovereign debt crisis in Europe while positive
spillovers are correlated with the subprime crisis, different monetary policies
among key world central banks, and developments on commodities markets. It
seems that a combination of monetary and real-economy events is behind the net
positive asymmetries in volatility spillovers, while fiscal factors are linked
with net negative spillovers.
"
1608.00213	q-fin	q-fin.EC	"Self-organization in a distributed coordination game through heuristic
  rules"	"  In this paper we consider a distributed coordination game played by a large
number of agents with finite information sets, which characterizes emergence of
a single dominant attribute out of a large number of competitors. Formally, $N$
agents play a coordination game repeatedly which has exactly $N$ Nash
equilibria and all of the equilibria are equally preferred by the agents. The
problem is to select one equilibrium out of $N$ possible equilibria in the
least number of attempts. We propose a number of heuristic rules based on
reinforcement learning to solve the coordination problem. We see that the
agents self-organize into clusters with varying intensities depending on the
heuristic rule applied although all clusters but one are transitory in most
cases. Finally, we characterize a trade-off in terms of the time requirement to
achieve a degree of stability in strategies and the efficiency of such a
solution.
"
1608.00230	q-fin	q-fin.PR math.PR	"Application of Malliavin calculus to exact and approximate option
  pricing under stochastic volatility"	"  The article is devoted to models of financial markets with stochastic
volatility, which is defined by a functional of Ornstein-Uhlenbeck process or
Cox-Ingersoll-Ross process. We study the question of exact price of European
option. The form of the density function of the random variable, which
expresses the average of the volatility over time to maturity is established
using Malliavin calculus.The result allows calculate the price of the option
with respect to minimum martingale measure when the Wiener process driving the
evolution of asset price and the Wiener process, which defines volatility, are
uncorrelated.
"
1608.00280	q-fin	q-fin.PR q-fin.MF	Pricing Weakly Model Dependent Barrier Products	"  We discuss the pricing methodology for Bonus Certificates and Barrier
Reverse-Convertible Structured Products. Pricing for a European barrier
condition is straightforward for products of both types and depends on an
efficient interpolation of observed market option pricing. Pricing products We
discuss the pricing methodology for Bonus Certificates and Barrier
Reverse-Convertible Structured Products. Pricing for a European barrier
condition is straightforward for products of both types and depends on an
efficient interpolation of observed market option pricing. Pricing products
with an American barrier condition requires stochastic modelling. We show that
for typical market parameters, this stochastic pricing problem can be
systematically reduced to evaluating only one fairly simple stochastic
parameter being the asymmetry of hitting the barrier. Eventually, pricing Bonus
Certificates and Barrier Reverse Convertibles with an American barrier
condition, shows to be dependent on stochastic modelling only within a range of
$\pm\frac{2}{3}$ of accuracy - e.g. within this accuracy limitation we can
price these products without stochastic modelling. We show that the remaining
price component is weakly dependent on the stochastic models. Combining these
together, we prove to have established an almost model independent pricing
procedure for Bonus Certificates and Barrier Reverse-Convertible Structured
Products with American barrier conditions.
"
1608.00756	q-fin	q-fin.TR q-fin.ST	"A continuous and efficient fundamental price on the discrete order book
  grid"	"  This paper develops a model of liquidity provision in financial markets by
adapting the Madhavan, Richardson, and Roomans (1997) price formation model to
realistic order books with quote discretization and liquidity rebates. We
postulate that liquidity providers observe a fundamental price which is
continuous, efficient, and can assume values outside the interval spanned by
the best quotes. We confirm the predictions of our price formation model with
extensive empirical tests on large high-frequency datasets of 100 liquid Nasdaq
stocks. Finally we use the model to propose an estimator of the fundamental
price based on the rebate adjusted volume imbalance at the best quotes and we
empirically show that it outperforms other simpler estimators.
"
1608.00814	q-fin	math.PR math.AP q-fin.MF	SPDE limit of the global fluctuations in rank-based models	"  We consider systems of diffusion processes (""particles"") interacting through
their ranks (also referred to as ""rank-based models"" in the mathematical
finance literature). We show that, as the number of particles becomes large,
the process of fluctuations of the empirical cumulative distribution functions
converges to the solution of a linear parabolic SPDE with additive noise. The
coefficients in the limiting SPDE are determined by the hydrodynamic limit of
the particle system which, in turn, can be described by the porous medium PDE.
The result opens the door to a thorough investigation of large equity markets
and investment therein. In the course of the proof we also derive quantitative
propagation of chaos estimates for the particle system.
"
1608.00878	q-fin	q-fin.GN cs.CY q-fin.EC	On the Use of Computer Programs as Money	"  Money is a technology for promoting economic prosperity. Over history money
has become increasingly abstract, it used to be hardware, gold coins and the
like, now it is mostly software, data structures located in banks. Here I
propose the logical conclusion of the abstraction of money: to use as money the
most general form of information - computer programs. The key advantage that
using programs for money (program-money) adds to the technology of money is
agency. Program-money is active and thereby can fully participate in economics
as economic agents. I describe the three basic technologies required to
implement program-money: computational languages/logics to unambiguously
describe the actions and interactions of program-money; computational
cryptography to ensure that only the correct actions and interactions are
performed; and a distributed computational environment in which the money can
execute. I demonstrate that most of the technology for program-money has
already been developed. The adoption of program-money transfers responsibility
from human economic agents to money itself and has great potential economic
advantages over the current passive form of money. For example in
microeconomics, adding agency to money will simplify the exchange of ownership,
ensure money is only used legally, automate the negotiation and forming of
contracts, etc. Similar advantages occur in macroeconomics, where for example
the control of the money supply could be transferred from central banks to
money. It is also possible to envisage money that is not owned by any external
human agent or corporation. One motivation for this is to force economic
systems to behave more rationally and/or more like a specific economic theory,
thereby increasing the success of economic forecasting.
"
1608.01103	q-fin	q-fin.ST physics.data-an	"Fluctuation of USA Gold Price - Revisited with Chaos-based Complex
  Network Method"	"  We give emphasis on the use of chaos-based rigorous nonlinear technique
called Visibility Graph Analysis, to study one economic time series - gold
price of USA. This method can offer reliable results with fiinite data. This
paper reports the result of such an analysis on the times series depicting the
fluctuation of gold price of USA for the span of 25 years(1990 - 2013). This
analysis reveals that a quantitative parameter from the theory can explain
satisfactorily the real life nature of fluctuation of gold price of USA and
hence building a strong database in terms of a quantitative parameter which can
eventually be used for forecasting purpose.
"
1608.01133	q-fin	math.PR math.ST q-fin.MF q-fin.RM stat.TH	The boundary non-Crossing probabilities for Slepian process	"  In this contribution we derive an explicit formula for the boundary
non-crossing probabilities for Slepian processes associated with the piecewise
linear boundary function. This formula is used to develop an approximation
formula to the boundary non-crossing probabilities for general continuous
boundaries. The formulas we developed are easy to implement in calculation the
boundary non-crossing probabilities.
"
1608.01351	q-fin	q-fin.EC	"Multidimensional Polarization Index and its Application to an Analysis
  of the Russian State Duma"	"  The multidimensional extension of the Aleskerov-Golubenko polarization index
is developed. Several versions of the polarization index are proposed based on
different distance functions. Basic properties of the index are examined.
"
1608.01415	q-fin	q-fin.MF	"Shadow prices, fractional Brownian motion, and portfolio optimisation
  under transaction costs"	"  We continue the analysis of our previous paper (Czichowsky/Schachermayer/Yang
2014) pertaining to the existence of a shadow price process for portfolio
optimisation under proportional transaction costs. There, we established a
positive answer for a continuous price process $S=(S_t)_{0\leq t\leq T}$
satisfying the condition $(NUPBR)$ of ""no unbounded profit with bounded risk"".
This condition requires that $S$ is a semimartingale and therefore is too
restrictive for applications to models driven by fractional Brownian motion. In
the present paper, we derive the same conclusion under the weaker condition
$(TWC)$ of ""two way crossing"", which does not require $S$ to be a
semimartingale. Using a recent result of R.~Peyre, this allows us to show the
existence of a shadow price for exponential fractional Brownian motion and
$all$ utility functions defined on the positive half-line having reasonable
asymptotic elasticity. Prime examples of such utilities are logarithmic or
power utility.
"
1608.02068	q-fin	q-fin.RM q-fin.MF	Arbitrage and utility maximization in market models with an insider	"  We study arbitrage opportunities, market viability and utility maximization
in market models with an insider. Assuming that an economic agent possesses
from the beginning an additional information in the form of a random variable
G, which only becomes known to the ordinary agents at date T, we give criteria
for the No Unbounded Profits with Bounded Risk property to hold, characterize
optimal arbitrage strategies, and prove duality results for the utility
maximization problem faced by the insider. Examples of markets satisfying NUPBR
yet admitting arbitrage opportunities are provided for both atomic and
continuous random variables G.
"
1608.02365	q-fin	q-fin.MF q-fin.RM	"Allocation of risk capital in a cost cooperative game induced by a
  modified Expected Shortfall"	"  The standard theory of coherent risk measures fails to consider individual
institutions as part of a system which might itself experience instability and
spread new sources of risk to the market participants. In compliance with an
approach adopted by Shapley and Shubik (1969), this paper proposes a
cooperative market game where agents and institutions play the same role can be
developed. We take into account a multiple institutions framework where some of
them jointly experience distress events in order to evaluate their individual
and collective impact on the remaining institutions in the market. To carry out
this analysis, we define a new risk measure (SCoES), generalising the Expected
Shortfall of Acerbi (2002) and we characterise the riskiness profile as the
outcome of a cost cooperative game played by institutions in distress (a
similar approach was adopted by Denault 2001). Each institution's marginal
contribution to the spread of riskiness towards the safe institutions in then
evaluated by calculating suitable solution concepts of the game such as the
Banzhaf--Coleman and the Shapley--Shubik values.
"
1608.02428	q-fin	q-fin.EC	"The Opium for the Poor Is Opium. Medicare Providers in States with Low
  Income Prescribe High Levels of Opiates"	"  The majority of Medicare opioid prescriptions originate with family practice
and internal medicine providers.
  I show that the average number of Medicare opium prescriptions by these
providers vary strongly by state and that 54% of the variance is accounted for
by the state median household income. I also show that there is a very similar
relationship in opioid claims per capita and per Medicare recipient.
  In all cases Alabama is the state with the most claims and Hawaii is the
state with the least claims.
"
1608.02446	q-fin	q-fin.MF	Who would invest only in the risk-free asset?	"  Within the setup of continuous-time semimartingale financial markets, we show
that a multiprior Gilboa-Schmeidler minimax expected utility maximizer forms a
portfolio consisting only of the riskless asset if and only if among the
investor's priors there exists a probability measure under which all admissible
wealth processes are supermartingales. Furthermore, we show that under a
certain attainability condition (which is always valid in finite or complete
markets) this is also equivalent to the existence of an equivalent (local)
martingale measure among the investor's priors. As an example, we generalize a
no betting result due to Dow and Werlang.
"
1608.02690	q-fin	q-fin.PR math.PR q-fin.RM	Arbitrage-Free XVA	"  We develop a framework for computing the total valuation adjustment (XVA) of
a European claim accounting for funding costs, counterparty credit risk, and
collateralization. Based on no-arbitrage arguments, we derive backward
stochastic differential equations (BSDEs) associated with the replicating
portfolios of long and short positions in the claim. This leads to the
definition of buyer's and seller's XVA, which in turn identify a no-arbitrage
interval. In the case that borrowing and lending rates coincide, we provide a
fully explicit expression for the unique XVA, expressed as a percentage of the
price of the traded claim, and for the corresponding replication strategies. In
the general case of asymmetric funding, repo and collateral rates, we study the
semilinear partial differential equations (PDE) characterizing buyer's and
seller's XVA and show the existence of a unique classical solution to it. To
illustrate our results, we conduct a numerical study demonstrating how funding
costs, repo rates, and counterparty risk contribute to determine the total
valuation adjustment.
"
1608.02706	q-fin	q-fin.MF math.PR	"Another example of duality between game-theoretic and measure-theoretic
  probability"	"  This paper makes a small step towards a non-stochastic version of
superhedging duality relations in the case of one traded security with a
continuous price path. Namely, we prove the coincidence of game-theoretic and
measure-theoretic expectation for lower semicontinuous positive functionals. We
consider a new broad definition of game-theoretic probability, leaving the
older narrower definitions for future work.
"
1608.03237	q-fin	q-fin.RM math.PR	Managing counterparty credit risk via BSDEs	"  We discuss a general dynamic replication approach to counterparty credit risk
modeling. This leads to a fundamental jump-process backward stochastic
differential equation (BSDE) for the credit risk adjusted portfolio value. We
then reduce the fundamental BSDE to a continuous BSDE. Depending on the close
out value convention, the reduced fundamental BSDE's solution can be
represented explicitly or through an accurate approximate expression.
Furthermore, we discuss practical aspects of the approach, important for the
its industry applications: (i) efficient numerical methodology for solving a
BSDE driven by a moderate number of Brownian motions, and (ii) factor reduction
methodology that allows one to approximately replace a portfolio driven by a
large number of risk factors with a portfolio driven by a moderate number of
risk factors.
"
1608.03352	q-fin	stat.CO q-fin.CP q-fin.PR	Some Contributions to Sequential Monte Carlo Methods for Option Pricing	"  Pricing options is an important problem in financial engineering. In many
scenarios of practical interest, financial option prices associated to an
underlying asset reduces to computing an expectation w.r.t.~a diffusion
process. In general, these expectations cannot be calculated analytically, and
one way to approximate these quantities is via the Monte Carlo method; Monte
Carlo methods have been used to price options since at least the 1970's. It has
been seen in Del Moral, P. \& Shevchenko, P.V. (2014) `Valuation of barrier
options using Sequential Monte Carlo' and Jasra, A. \& Del Moral, P. (2011)
`Sequential Monte Carlo for option pricing' that Sequential Monte Carlo (SMC)
methods are a natural tool to apply in this context and can vastly improve over
standard Monte Carlo. In this article, in a similar spirit to Del Moral, P. \&
Shevchenko, P.V. (2014) `Valuation of barrier options using sequential Monte
Carlo' and Jasra, A. \& Del Moral, P. (2011) `Sequential Monte Carlo for option
pricing' we show that one can achieve significant gains by using SMC methods by
constructing a sequence of artificial target densities over time. In
particular, we approximate the optimal importance sampling distribution in the
SMC algorithm by using a sequence of weighting functions. This is demonstrated
on two examples, barrier options and target accrual redemption notes (TARN's).
We also provide a proof of unbiasedness of our SMC estimate.
"
1608.03428	q-fin	q-fin.MF math.PR	"A Gaussian Markov alternative to fractional Brownian motion for pricing
  financial derivatives"	"  Replacing Black-Scholes' driving process, Brownian motion, with fractional
Brownian motion allows for incorporation of a past dependency of stock prices
but faces a few major downfalls, including the occurrence of arbitrage when
implemented in the financial market. We present the development, testing, and
implementation of a simplified alternative to using fractional Brownian motion
for pricing derivatives. By relaxing the assumption of past independence of
Brownian motion but retaining the Markovian property, we are developing a
competing model that retains the mathematical simplicity of the standard
Black-Scholes model but also has the improved accuracy of allowing for past
dependence. This is achieved by replacing Black-Scholes' underlying process,
Brownian motion, with a particular Gaussian Markov process, proposed by
Vladimir Dobri\'{c} and Francisco Ojeda.
"
1608.03636	q-fin	q-fin.ST q-fin.CP	"A General Framework for Pairs Trading with a Control-Theoretic Point of
  View"	"  Pairs trading is a market-neutral strategy that exploits historical
correlation between stocks to achieve statistical arbitrage. Existing
pairs-trading algorithms in the literature require rather restrictive
assumptions on the underlying stochastic stock-price processes and the
so-called spread function. In contrast to existing literature, we consider an
algorithm for pairs trading which requires less restrictive assumptions than
heretofore considered. Since our point of view is control-theoretic in nature,
the analysis and results are straightforward to follow by a non-expert in
finance. To this end, we describe a general pairs-trading algorithm which
allows the user to define a rather arbitrary spread function which is used in a
feedback context to modify the investment levels dynamically over time. When
this function, in combination with the price process, satisfies a certain
mean-reversion condition, we deem the stocks to be a tradeable pair. For such a
case, we prove that our control-inspired trading algorithm results in positive
expected growth in account value. Finally, we describe tests of our algorithm
on historical trading data by fitting stock price pairs to a popular spread
function used in literature. Simulation results from these tests demonstrate
robust growth while avoiding huge drawdowns.
"
1608.03985	q-fin	q-fin.GN q-fin.TR	Property bubble in Hong Kong: A predicted decade-long slump (2016-2025)	"  Between 2003 and 2015 the prices of apartments in Hong Kong (adjusted for
inflation) increased by a factor of 3.8. This is much higher than in the United
States prior to the so-called subprime crisis of 2007. The analysis of this
speculative episode confirms the mechanism and regularities already highlighted
by the present authors in similar episodes in other countries. Based on these
regularities, it is possible to predict the price trajectory over the time
interval 2016-2025. It suggests that, unless appropriate relief is provided by
the mainland, Hong Kong will experience a decade-long slump. Possible
implications for its relations with Beijing are discussed at the end of the
paper.
"
1608.04506	q-fin	q-fin.ST physics.soc-ph	Time-scale effects on the gain-loss asymmetry in stock indices	"  The gain-loss asymmetry, observed in the inverse statistics of stock indices
is present for logarithmic return levels that are over $2\%$, and it is the
result of the non-Pearson type auto-correlations in the index. These
non-Pearson type correlations can be viewed also as functionally dependent
daily volatilities, extending for a finite time interval. A generalized
time-window shuffling method is used to show the existence of such
auto-correlations. Their characteristic time-scale proves to be smaller (less
than $25$ trading days) than what was previously believed. It is also found
that this characteristic time-scale has decreased with the appearance of
program trading in the stock market transactions. Connections with the leverage
effect are also established.
"
1608.04522	q-fin	q-fin.PM cond-mat.dis-nn math.OC	"Maximizing and Minimizing Investment Concentration with Constraints of
  Budget and Investment Risk"	"  In this paper, as a first step in examining the properties of a feasible
portfolio subset that is characterized by budget and risk constraints, we
assess the maximum and minimum of the investment concentration using replica
analysis. To do this, we apply an analytical approach of statistical mechanics.
We note that the optimization problem considered in this paper is the dual
problem of the portfolio optimization problem discussed in the literature, and
we verify that these optimal solutions are also dual. We also present numerical
experiments, in which we use the method of steepest descent that is based on
Lagrange's method of undetermined multipliers, and we compare the numerical
results to those obtained by replica analysis in order to assess the
effectiveness of our proposed approach.
"
1608.04537	q-fin	math.PR q-fin.MF	"Timing in the Presence of Directional Predictability: Optimal Stopping
  of Skew Brownian Motion"	"  We investigate a class of optimal stopping problems arising in, for example,
studies considering the timing of an irreversible investment when the
underlying follows a skew Brownian motion. Our results indicate that the local
directional predictability modeled by the presence of a skew point for the
underlying has a nontrivial and somewhat surprising impact on the timing
incentives of the decision maker. We prove that waiting is always optimal at
the skew point for a large class of exercise payoffs. An interesting
consequence of this finding, which is in sharp contrast with studies relying on
ordinary Brownian motion, is that the exercise region for the problem can
become unconnected even when the payoff is linear. We also establish that
higher skewness increases the incentives to wait and postpones the optimal
timing of an investment opportunity. Our general results are explicitly
illustrated for a piecewise linear payoff.
"
1608.04556	q-fin	math.OC q-fin.GN stat.AP	"Rank-optimal weighting or ""How to be best in the OECD Better Life
  Index?"""	"  We present a method of rank-optimal weighting which can be used to explore
the best possible position of a subject in a ranking based on a composite
indicator by means of a mathematical optimization problem. As an example, we
explore the dataset of the OECD Better Life Index and compute for each country
a weight vector which brings it as far up in the ranking as possible with the
greatest advance of the immediate rivals. The method is able to answer the
question ""What is the best possible rank a country can achieve with a given set
of weighted indicators?"" Typically, weights in composite indicators are
justified normatively and not empirically. Our approach helps to give bounds on
what is achievable by such normative judgments from a purely output-oriented
and strongly competitive perspective. The method can serve as a basis for exact
bounds in sensitivity analysis focused on ranking positions.
  In the OECD Better Life Index data we find that 19 out the 36 countries in
the OECD Better Life Index 2014 can be brought to the top of the ranking by
specific weights. We give a table of weights for each country which brings it
to its highest possible position. Many countries achieve their best rank by
focusing on their strong dimensions and setting the weights of many others to
zero. Although setting dimensions to zero is possible in the OECD's online
tool, this contradicts the idea of better life being multidimensional in
essence. We discuss modifications of the optimization problem which could take
this into account, e.g. by allowing only a minimal weight of one.
  Methods to find rank-optimal weights can be useful for various
multidimensional datasets like the ones used to rank universities or employers.
"
1608.04621	q-fin	q-fin.RM math.PR	Optimal importance sampling for L\'evy Processes	"  We develop generic and efficient importance sampling estimators for Monte
Carlo evaluation of prices of single- and multi-asset European and
path-dependent options in asset price models driven by L\'evy processes,
extending earlier works which focused on the Black-Scholes and continuous
stochastic volatility models. Using recent results from the theory of large
deviations on the path space for processes with independent increments, we
compute an explicit asymptotic approximation for the variance of the pay-off
under an Esscher-style change of measure. Minimizing this asymptotic variance
using convex duality, we then obtain an easy to compite asymptotically
efficient importance sampling estimator of the option price. Numerical tests
for European baskets and for Asian options in the variance gamma model show
consistent variance reduction with a very small computational overhead.
"
1608.05024	q-fin	q-fin.PM q-fin.RM	"Risk reduction and Diversification within Markowitz's Mean-Variance
  Model: Theoretical Revisit"	"  The conventional wisdom of mean-variance (MV) portfolio theory asserts that
the nature of the relationship between risk and diversification is a decreasing
asymptotic function, with the asymptote approximating the level of portfolio
systematic risk or undiversifiable risk. This literature assumes that investors
hold an equally-weighted or a MV portfolio and quantify portfolio
diversification using portfolio size. However, the equally-weighted portfolio
and portfolio size are MV optimal if and only if asset returns distribution is
exchangeable or investors have no useful information about asset expected
return and risk. Moreover, the whole of literature, absolutely all of it,
focuses only on risky assets, ignoring the role of the risk free asset in the
efficient diversification. Therefore, it becomes interesting and important to
answer this question: how valid is this conventional wisdom when investors have
full information about asset expected return and risk and asset returns
distribution is not exchangeable in both the case where the risk free rate is
available or not? Unfortunately, this question have never been addressed in the
current literature. This paper fills the gap.
"
1608.05038	q-fin	q-fin.EC physics.soc-ph	Electoral Stability and Rigidity	"  Some argue that political stability is best served through a two-party
system. This study refutes this. The author mathematically defines the
stability and rigidity of electoral systems comprised of any quantity of
electors and parties. In fact, stability is a function of the quantity of
electors - i.e., the number of occupied seats at the table. As the number of
electors increases, the properties of an electorate are increasingly well
resolved, and well described by those of an electorate that is least excessive
-- that is to say an electorate that is closest to equilibrium. Further,
electoral rigidity is a function of the quantity of parties and their
probabilities of representation. An absolutely rigid system admits no
fluctuations -- whatever happens to one elector will happen to all electors. As
the quantity of parties increases so does the number of party lines, and with
it the quantity of alternatives with which to respond to an external stimulus.
Rigidity is significant in a social system that places high value on party
loyalty. In conclusion, (i) electoral stability is best served by increasing
the quantity of electors; (ii) electoral rigidity is best served by decreasing
the quantity of parties, and by increasing the representation of some parties
at the expense of others; and (iii) the less stable a branch of government, the
more concern is placed on those who would hold those offices for the people.
"
1608.05060	q-fin	q-fin.TR	"General Semi-Markov Model for Limit Order Books: Theory, Implementation
  and Numerics"	"  The paper considers a general semi-Markov model for Limit Order Books with
two states, which incorporates price changes that are not fixed to one tick.
Furthermore, we introduce an even more general case of the semi-Markov model
for LimitOrder Books that incorporates an arbitrary number of states for the
price changes. For both cases the justifications, diffusion limits,
implementations and numerical results are presented for different Limit Order
Book data: Apple, Amazon, Google, Microsoft, Intel on 2012/06/21 and Cisco,
Facebook, Intel, Liberty Global, Liberty Interactive, Microsoft, Vodafone from
2014/11/03 to 2014/11/07.
"
1608.05145	q-fin	q-fin.CP q-fin.MF q-fin.PR	Filling the gaps smoothly	"  The calibration of a local volatility models to a given set of option prices
is a classical problem of mathematical finance. It was considered in multiple
papers where various solutions were proposed. In this paper an extension of the
approach proposed in LiptonSepp2011 is developed by i) replacing a piecewise
constant local variance construction with a piecewise linear one, and ii)
allowing non-zero interest rates and dividend yields. Our approach remains
analytically tractable; it combines the Laplace transform in time with an
analytical solution of the resulting spatial equations in terms of Kummer's
degenerate hypergeometric functions.
"
1608.05378	q-fin	q-fin.PR	A Semi-Analytic Approach To Valuing Auto-Callable Accrual Notes	"  We develop a semi-analytic approach to the valuation of auto-callable
structures with accrual features subject to barrier conditions. Our approach is
based on recent studies of multi-assed binaries, present in the literature. We
extend these studies to the case of time-dependent parameters. We compare
numerically the semi-analytic approach and the day to day Monte Carlo approach
and conclude that the semi-analytic approach is more advantageous for high
precision valuation.
"
1608.05585	q-fin	q-fin.MF	Consistency of option prices under bid-ask spreads	"  Given a finite set of European call option prices on a single underlying, we
want to know when there is a market model which is consistent with these
prices. In contrast to previous studies, we allow models where the underlying
trades at a bid-ask spread. The main question then is how large (in terms of a
deterministic bound) this spread must be to explain the given prices. We fully
solve this problem in the case of a single maturity, and give several partial
results for multiple maturities. For the latter, our main mathematical tool is
a recent generalization of Strassen's theorem [S. Gerhold, I.C. G\""ul\""um,
arXiv:1512.06640], which characterizes the existence of martingales in balls
w.r.t. the infinity Wasserstein distance.
"
1608.05814	q-fin	q-fin.MF	"Stochastic Evolution Equations in Banach Spaces and Applications to
  Heath-Jarrow-Morton-Musiela Equation"	"  In this paper we study the stochastic evolution equation (1.1) in
martingale-type 2 Banach spaces (with the linear part of the drift being only a
generator of a C0-semigroup). We prove the existence and the uniqueness of
solutions to this equation. We apply the abstract results to the
Heath-Jarrow-Morton-Musiela (HJMM) equation (6.3). In particular, we prove the
existence and the uniqueness of solutions to the latter equation in the
weighted Lebesgue and Sobolev spaces respectively. We also find a sufficient
condition for the existence and the uniqueness of an invariant measure for the
Markov semigroup associated to equation (6.3) in the weighted Lebesgue spaces.
"
1608.05851	q-fin	q-fin.GN physics.soc-ph	"The Growth of Oligarchy in a Yard-Sale Model of Asset Exchange: A
  Logistic Equation for Wealth Condensation"	"  The addition of wealth-attained advantage (WAA) to the Yard-Sale Model (YSM)
of asset exchange has been demonstrated to induce wealth condensation. In a
model of WAA for which the bias is a continuous function of the wealth
difference of the transacting agents, the condensation was shown to arise from
a second-order phase transition to a coexistence regime. In this paper, we
present the first analytic time-dependent results for this model, by showing
that the condensed wealth obeys a logistic equation in time.
"
1608.06045	q-fin	q-fin.MF	Optimal Switching under Ambiguity and Its Applications in Finance	"  In this paper, we study optimal switching problems under ambiguity. To
characterize the optimal switching under ambiguity in the finite horizon, we
use multidimensional reflected backward stochastic differential equations
(multidimensional RBSDEs) and show that a value function of the optimal
switching under ambiguity coincides with a solutions to multidimensional RBSDEs
with allowing negative switching costs. Furthermore, we naturally extend the
finite horizon problem to the infinite horizon problem. In some applications,
we show that ambiguity affects an optimal switching strategy with the different
way to a usual switching problem without ambiguity.
"
1608.06121	q-fin	q-fin.PM math.PR q-fin.MF	Volatility and Arbitrage	"  The capitalization-weighted total relative variation $\sum_{i=1}^d
\int_0^\cdot \mu_i (t) \mathrm{d} \langle \log \mu_i \rangle (t)$ in an equity
market consisting of a fixed number $d$ of assets with capitalization weights
$\mu_i (\cdot)$ is an observable and nondecreasing function of time. If this
observable of the market is not just nondecreasing, but actually grows at a
rate which is bounded away from zero, then strong arbitrage can be constructed
relative to the market over sufficiently long time horizons. It has been an
open issue for more than ten years, whether such strong outperformance of the
market is possible also over arbitrary time horizons under the stated
condition. We show that this is not possible in general, thus settling this
long-open question. We also show that, under appropriate additional conditions,
outperformance over any time horizon indeed becomes possible, and exhibit
investment strategies that effect it.
"
1608.06376	q-fin	q-fin.MF math.PR	L\'evy-Vasicek Models and the Long-Bond Return Process	"  The classical derivation of the well-known Vasicek model for interest rates
is reformulated in terms of the associated pricing kernel. An advantage of the
pricing kernel method is that it allows one to generalize the construction to
the L\'evy-Vasicek case, avoiding issues of market incompleteness. In the
L\'evy-Vasicek model the short rate is taken in the real-world measure to be a
mean-reverting process with a general one-dimensional L\'evy driver admitting
exponential moments. Expressions are obtained for the L\'evy-Vasicek bond
prices and interest rates, along with a formula for the return on a unit
investment in the long bond, defined by $L_t = \lim_{T \rightarrow \infty}
P_{tT} / P_{0T}$, where $P_{tT}$ is the price at time $t$ of a $T$-maturity
discount bond. We show that the pricing kernel of a L\'evy-Vasicek model is
uniformly integrable if and only if the long rate of interest is strictly
positive.
"
1608.06416	q-fin	q-fin.CP q-fin.RM stat.AP	"RELARM: A rating model based on relative PCA attributes and k-means
  clustering"	"  Following widely used in visual recognition concept of relative attributes,
the article establishes definition of the relative PCA attributes for a class
of objects defined by vectors of their parameters. A new rating model (RELARM)
is built using relative PCA attribute ranking functions for rating object
description and k-means clustering algorithm. Rating assignment of each rating
object to a rating category is derived as a result of cluster centers
projection on the specially selected rating vector. Empirical study has shown a
high level of approximation to the existing S & P, Moody's and Fitch ratings.
"
1608.06959	q-fin	math.OC q-fin.EC	"Strategic Growth with Recursive Preferences: Decreasing Marginal
  Impatience"	"  We study the interaction between strategy, heterogeneity and growth in a
two-agent model of capital accumulation. Preferences are represented by
recursive utility functions with decreasing marginal impatience. The stationary
equilibria of this dynamic game are analyzed under two alternative information
structures: one in which agents precommit to future actions, and another one
where agents use Markovian strategies. In both cases, we develop sufficient
conditions to prove the existence of equilibria and characterize their
stability properties. The precommitment case is characterized by monotone
convergence, but Markovian equilibria may exhibit nonmonotonic paths, even in
the long-run.
"
1608.07193	q-fin	q-fin.ST stat.AP	"Quantile Dependence between Stock Markets and its Application in
  Volatility Forecasting"	"  This paper examines quantile dependence between international stock markets
and evaluates its use for improving volatility forecasting. First, we analyze
quantile dependence and directional predictability between the US stock market
and stock markets in the UK, Germany, France and Japan. We use the
cross-quantilogram, which is a correlation statistic of quantile hit processes.
The detailed dependence between stock markets depends on specific quantile
ranges and this dependence is generally asymmetric; the negative spillover
effect is stronger than the positive spillover effect and there exists strong
directional predictability from the US market to the UK, Germany, France and
Japan markets. Second, we consider a simple quantile-augmented volatility model
that accommodates the quantile dependence and directional predictability
between the US market and these other markets. The quantile-augmented
volatility model provides superior in-sample and out-of-sample volatility
forecasts.
"
1608.07694	q-fin	q-fin.ST	"Foreign Exchange Market Performance: Evidence from Bivariate Time Series
  Approach"	"  There are many studies dealing with the analysis of similarity among
currencies in foreign exchange market by using network analysis approach. In
those studies, each currency is represented by a univariate time series of
exchange rate return. This is the standard practice to analyze the underlying
information in the foreign exchange market. In this paper, Escoufier's RV
coefficient is applied to measure the similarity among currencies where each of
them is represented by bivariate time series. Based on that coefficient, we
analyze the topological structure of the currencies. An example of FOREX
analysis will be presented and discussed to illustrate the advantages of RV
coefficient.
"
1608.07831	q-fin	q-fin.RM	Rethinking Financial Contagion	"  How, and to what extent, does an interconnected financial system endogenously
amplify external shocks? This paper attempts to reconcile some apparently
different views emerged after the 2008 crisis regarding the nature and the
relevance of contagion in financial networks. We develop a common framework
encompassing several network contagion models and show that, regardless of the
shock distribution and the network topology, precise ordering relationships on
the level of aggregate systemic losses hold among models. We argue that the
extent of contagion crucially depends on the amount of information that each
model assumes to be available to market players. Under no uncertainty about the
network structure and values of external assets, the well-known Eisenberg and
Noe (2001) model applies, which delivers the lowest level of contagion. This is
due to a property of loss conservation: aggregate losses after contagion are
equal to the losses incurred by those institutions initially hit by a shock.
This property implies that many contagion analyses rule out by construction any
loss amplification, treating de facto an interconnected system as a single
aggregate entity, where losses are simply mutualised. Under higher levels of
uncertainty, as captured for instance by the DebtRank model, losses become
non-conservative and get compounded through the network. This has important
policy implications: by reducing the levels of uncertainty in times of distress
(e.g. by obtaining specific data on the network) policymakers would be able to
move towards more conservative scenarios. Empirically, we compare the magnitude
of contagion across models on a sample of the largest European banks during the
years 2006-2016. In particular, we analyse contagion effects as a function of
the size of the shock and the type of external assets shocked.
"
1608.07901	q-fin	physics.soc-ph cs.SI q-fin.GN	Networks: An Economic Perspective	"  We discuss social network analysis from the perspective of economics. We
organize the presentaion around the theme of externalities: the effects that
one's behavior has on others' well-being. Externalities underlie the
interdependencies that make networks interesting. We discuss network formation,
as well as interactions between peoples' behaviors within a given network, and
the implications in a variety of settings. Finally, we highlight some empirical
challenges inherent in the statistical analysis of network-based data.
"
1608.08210	q-fin	q-fin.GN	"What is the Contribution of Intra-household Inequality to Overall Income
  Inequality? Evidence from Global Data, 1973-2013"	"  Intra-household inequality continues to remain a neglected corner despite
renewed focus on income and wealth inequality. Using the LIS micro data, we
present evidence that this neglect is equivalent to ignoring up to a third of
total inequality. For a wide range of countries and over four decades, we show
that at least 30 per cent of total inequality is attributable to inequality
within the household. Using a simple normative measure of inequality, we
comment on the welfare implications of these trends.
"
1608.08268	q-fin	q-fin.PM	On the Market-Neutrality of Optimal Pairs-Trading Strategies	"  We consider the problem of optimal investment in a market with two
cointegrated stocks and an agent with CRRA utility. We extend the findings of
Liu and Timmermann [The Review of Financial Studies, 26(4):1048-1086, 2013] by
paying special attention to when/if the associated stochastic control problem
is well-posed and providing a verification result. Our new findings lead to a
sharp well-posedness condition which is, surprisingly, also the necessary and
sufficient condition for the optimal investment to be market-neutral (i.e.
having offsetting long/short positions in the stocks). Hence, we provide a
theoretical justification for market-neutral pairs-trading which, despite
having a strong practical relevance, has been lacking a theoretical ground.
"
1608.08283	q-fin	q-fin.RM	Risk measures and Margining control	"  This document constitutes the final report of the contractual activity
between Directa SIM and Dipartimento di Automatica e Informatica, Politecnico
di Torino, on the research topic titled ""quantificazione del rischio di un
portafoglio di strumenti finanziari per trading online su device fissi e
mobili.""
"
1609.00232	q-fin	math.NA q-fin.CP	"An adjoint method for the exact calibration of Stochastic Local
  Volatility models"	"  This paper deals with the exact calibration of semidiscretized stochastic
local volatility (SLV) models to their underlying semidiscretized local
volatility (LV) models. Under an SLV model, it is common to approximate the
fair value of European-style options by semidiscretizing the backward
Kolmogorov equation using finite differences. In the present paper we introduce
an adjoint semidiscretization of the corresponding forward Kolmogorov equation.
This adjoint semidiscretization is used to obtain an expression for the
leverage function in the pertinent SLV model such that the approximated fair
values defined by the LV and SLV models are identical for non-path-dependent
European-style options. In order to employ this expression, a large non-linear
system of ODEs needs to be solved. The actual numerical calibration is
performed by combining ADI time stepping with an inner iteration to handle the
non-linearity. Ample numerical experiments are presented that illustrate the
effectiveness of the calibration procedure.
"
1609.00415	q-fin	q-fin.GN q-fin.EC	"Does Infrastructure Investment Lead to Economic Growth or Economic
  Fragility? Evidence from China"	"  The prevalent view in the economics literature is that a high level of
infrastructure investment is a precursor to economic growth. China is
especially held up as a model to emulate. Based on the largest dataset of its
kind, this paper punctures the twin myths that, first, infrastructure creates
economic value, and, second, China has a distinct advantage in its delivery.
Far from being an engine of economic growth, the typical infrastructure
investment fails to deliver a positive risk adjusted return. Moreover, China's
track record in delivering infrastructure is no better than that of rich
democracies. Where investments are debt-financed, overinvesting in unproductive
projects results in the buildup of debt, monetary expansion, instability in
financial markets, and economic fragility, exactly as we see in China today. We
conclude that poorly managed infrastructure investments are a main explanation
of surfacing economic and financial problems in China. We predict that, unless
China shifts to a lower level of higher-quality infrastructure investments, the
country is headed for an infrastructure-led national financial and economic
crisis, which is likely also to be a crisis for the international economy.
China's infrastructure investment model is not one to follow for other
countries but one to avoid.
"
1609.00554	q-fin	q-fin.RM	"On Jensen's inequality for generalized Choquet integral with an
  application to risk aversion"	"  In the paper we give necessary and sufficient conditions for the Jensen
inequality to hold for the generalized Choquet integral with respect to a pair
of capacities. Next, we apply obtained result to the theory of risk aversion by
providing the assumptions on utility function and capacities under which an
agent is risk averse. Moreover, we show that the Arrow-Pratt theorem can be
generalized to cover the case, where the expectation is replaced by the
generalized Choquet integral.
"
1609.00702	q-fin	q-fin.MF math.NA	"Numerical solution of a semilinear parabolic degenerate
  Hamilton-Jacobi-Bellman equation with singularity"	"  We consider a semilinear parabolic degenerated Hamilton-Jacobi-Bellman (HJB)
equation with singularity which is related to a stochastic control problem with
fuel constraint. The fuel constraint translates into a singular initial
condition for the HJB equation. We first propose a transformation based on a
change of variables that gives rise to an equivalent HJB equation with
nonsingular initial condition but irregular coefficients. We then construct
explicit and implicit numerical schemes for solving the transformed HJB
equation and prove their convergences by establishing an extension to the
result of Barles and Souganidis (1991).
"
1609.00819	q-fin	q-fin.PR q-fin.CP q-fin.MF q-fin.RM	Option-Based Pricing of Wrong Way Risk for CVA	"  The two main issues for managing wrong way risk (WWR) for the credit
valuation adjustment (CVA, i.e. WW-CVA) are calibration and hedging. Hence we
start from a novel model-free worst-case approach based on static hedging of
counterparty exposure with liquid options. We say ""start from"" because we
demonstrate that a naive worst-case approach contains hidden unrealistic
assumptions on the variance of the hazard rate (i.e. that it is infinite). We
correct this by making it an explicit (finite) parameter and present an
efficient method for solving the parametrized model optimizing the hedges. We
also prove that WW-CVA is theoretically, but not practically, unbounded. The
option-based hedges serve to significantly reduce (typically halve) practical
WW-CVA. Thus we propose a realistic and practical option-based worst case CVA.
"
1609.00869	q-fin	q-fin.RM q-fin.PM q-fin.TR	"Determining Optimal Stop-Loss Thresholds via Bayesian Analysis of
  Drawdown Distributions"	"  Stop-loss rules are often studied in the financial literature, but the
stop-loss levels are seldom constructed systematically. In many papers, and
indeed in practice as well, the level of the stops is too often set
arbitrarily. Guided by the overarching goal in finance to maximize expected
returns given available information, we propose a natural method by which to
systematically select the stop-loss threshold by analyzing the distribution of
maximum drawdowns. We present results for an hourly trading strategy with two
variations on the construction.
"
1609.00926	q-fin	q-fin.ST math.ST stat.TH	Multivariate Mixed Tempered Stable Distribution	"  The multivariate version of the Mixed Tempered Stable is proposed. It is a
generalization of the Normal Variance Mean Mixtures. Characteristics of this
new distribution and its capacity in fitting tails and capturing dependence
structure between components are investigated. We discuss a random number
generating procedure and introduce an estimation methodology based on the
minimization of a distance between empirical and theoretical characteristic
functions. Asymptotic tail behavior of the univariate Mixed Tempered Stable is
exploited in the estimation procedure in order to obtain a better model
fitting. Advantages of the multivariate Mixed Tempered Stable distribution are
discussed and illustrated via simulation study.
"
1609.01900	q-fin	q-fin.GN	The loss of interest for the euro in Romania	"  We generalize a money demand micro-founded model to explain Romanians' recent
loss of interest for the euro. We show that the reason behind this loss of
interest is a severe decline in the relative degree of the euro liquidity
against that of the Romanian leu.
"
1609.02108	q-fin	q-fin.MF q-fin.CP	The characteristic function of rough Heston models	"  It has been recently shown that rough volatility models, where the volatility
is driven by a fractional Brownian motion with small Hurst parameter, provide
very relevant dynamics in order to reproduce the behavior of both historical
and implied volatilities. However, due to the non-Markovian nature of the
fractional Brownian motion, they raise new issues when it comes to derivatives
pricing. Using an original link between nearly unstable Hawkes processes and
fractional volatility models, we compute the characteristic function of the
log-price in rough Heston models. In the classical Heston model, the
characteristic function is expressed in terms of the solution of a Riccati
equation. Here we show that rough Heston models exhibit quite a similar
structure, the Riccati equation being replaced by a fractional Riccati
equation.
"
1609.02334	q-fin	q-fin.EC q-fin.GN	The interaction between trade and FDI: the CEE countries experience	"  Inside the EU, the commercial integration of the CEE countries has gained
remarkable momentum before the crisis appearance, but it has slightly slowed
down afterwards. Consequently, the interest in identifying the factors
supporting the commercial integration process is high. Recent findings in the
new trade theory suggest that FDI influence the trade intensity but the studies
approaching this relationship for the CEE countries present mixed evidence, and
investigate the commercial integration of CEE countries with the old EU
members. Against this background, the purpose of this paper is to assess the
CEE countries' intra-integration, focusing on the Czech Republic, Hungary,
Poland and the Slovak Republic. For each country we employ a panel
gravitational model for the bilateral trade and FDI, considering its
interactions with the other three countries in the sample on the one hand, and
with the three EU main commercial partners on the other hand. We investigate
different facets of the trade -- FDI nexus, resorting to a fixed effects model,
a random effects model, as well as to an instrumental variable estimator, over
the period 2000-2013. Our results suggest that outward FDI sustains the CEE
countries' commercial integration, while inward FDI has no significant effect.
In all the cases a complementarity effect between trade and FDI is documented,
which is stronger for the CEE countries' historical trade partners.
Consequently, these findings show that CEE countries' policymakers are
interested in encouraging the outward FDI toward their neighbour countries in
order to increase the commercial integration.
"
1609.02354	q-fin	stat.CO q-fin.ST stat.AP	Generalized Autoregressive Score Models in R: The GAS Package	"  This paper presents the R package GAS for the analysis of time series under
the Generalized Autoregressive Score (GAS) framework of Creal et al. (2013) and
Harvey (2013). The distinctive feature of the GAS approach is the use of the
score function as the driver of time-variation in the parameters of nonlinear
models. The GAS package provides functions to simulate univariate and
multivariate GAS processes, estimate the GAS parameters and to make time series
forecasts. We illustrate the use of the GAS package with a detailed case study
on estimating the time-varying conditional densities of a set of financial
assets.
"
1609.02774	q-fin	q-fin.RM	Value at risk and the diversification dogma	"  The so-called risk diversification principle is analyzed, showing that its
convenience depends on individual characteristics of the risks involved and the
dependence relationship among them.
  -----
  Se analiza el principio de diversificaci\'on de riesgos y se demuestra que no
siempre resulta mejor que no diversificar, pues esto depende de
caracter\'isticas individuales de los riesgos involucrados, as\'i como de la
relaci\'on de dependencia entre los mismos.
"
1609.03223	q-fin	q-fin.EC physics.soc-ph	The Solution to Science's Replication Crisis	"  The solution to science's replication crisis is a new ecosystem in which
scientists sell what they learn from their research. In each pairwise
transaction, the information seller makes (loses) money if he turns out to be
correct (incorrect). Responsibility for the determination of correctness is
delegated, with appropriate incentives, to the information purchaser. Each
transaction is brokered by a central exchange, which holds money from the
anonymous information buyer and anonymous information seller in escrow, and
which enforces a set of incentives facilitating the transfer of useful, bluntly
honest information from the seller to the buyer. This new ecosystem, capitalist
science, directly addresses socialist science's replication crisis by
explicitly rewarding accuracy and penalizing inaccuracy.
"
1609.03344	q-fin	stat.ML cs.LG math.ST q-fin.EC stat.CO stat.TH	"Finite-sample and asymptotic analysis of generalization ability with an
  application to penalized regression"	"  In this paper, we study the performance of extremum estimators from the
perspective of generalization ability (GA): the ability of a model to predict
outcomes in new samples from the same population. By adapting the classical
concentration inequalities, we derive upper bounds on the empirical
out-of-sample prediction errors as a function of the in-sample errors,
in-sample data size, heaviness in the tails of the error distribution, and
model complexity. We show that the error bounds may be used for tuning key
estimation hyper-parameters, such as the number of folds $K$ in
cross-validation. We also show how $K$ affects the bias-variance trade-off for
cross-validation. We demonstrate that the $\mathcal{L}_2$-norm difference
between penalized and the corresponding un-penalized regression estimates is
directly explained by the GA of the estimates and the GA of empirical moment
conditions. Lastly, we prove that all penalized regression estimates are
$L_2$-consistent for both the $n \geqslant p$ and the $n < p$ cases.
Simulations are used to demonstrate key results.
  Keywords: generalization ability, upper bound of generalization error,
penalized regression, cross-validation, bias-variance trade-off,
$\mathcal{L}_2$ difference between penalized and unpenalized regression, lasso,
high-dimensional data.
"
1609.03471	q-fin	q-fin.EC q-fin.TR	"The Informational Content of the Limit Order Book: An Empirical Study of
  Prediction Markets"	"  In this paper I empirically investigate prediction markets for binary
options. Advocates of prediction markets have suggested that asset prices are
consistent estimators of the ""true"" probability of a state of the world being
realized. I test whether the market reaches a ""consensus."" I find little
evidence for convergence in beliefs. I then determine whether an econometrician
using data beyond execution prices can leverage this data to estimate the
consensus belief. I use an incomplete specification of equilibrium outcomes to
derive bounds on beliefs from order submission decisions. Interval estimates of
mean beliefs cannot exclude aggregate beliefs equal to 0.5.
"
1609.03996	q-fin	cs.MA q-fin.EC	SEAL's operating manual: a Spatially-bounded Economic Agent-based Lab	"  This text reports in detail how SEAL, a modeling framework for the economy
based on individual agents and firms, works. Thus, it aims to be an usage
manual for those wishing to use SEAL or SEAL's results. As a reference work,
theoretical and research studies are only cited. SEAL is thought as a Lab that
enables the simulation of the economy with spatially bounded
microeconomic-based computational agents. Part of the novelty of SEAL comes
from the possibility of simulating the economy in space and the instantiation
of different public offices, i.e. government institutions, with embedded
markets and actual data. SEAL is designed for Public Policy analysis,
specifically those related to Public Finance, Taxes and Real Estate.
"
1609.04065	q-fin	q-fin.RM math.OC q-fin.CP q-fin.MF q-fin.PM	"Closed-form solutions for worst-case law invariant risk measures with
  application to robust portfolio optimization"	"  Worst-case risk measures refer to the calculation of the largest value for
risk measures when only partial information of the underlying distribution is
available. For the popular risk measures such as Value-at-Risk (VaR) and
Conditional Value-at-Risk (CVaR), it is now known that their worst-case
counterparts can be evaluated in closed form when only the first two moments
are known for the underlying distribution. These results are remarkable since
they not only simplify the use of worst-case risk measures but also provide
great insight into the connection between the worst-case risk measures and
existing risk measures. We show in this paper that somewhat surprisingly
similar closed-form solutions also exist for the general class of law invariant
coherent risk measures, which consists of spectral risk measures as special
cases that are arguably the most important extensions of CVaR. We shed light on
the one-to-one correspondence between a worst-case law invariant risk measure
and a worst-case CVaR (and a worst-case VaR), which enables one to carry over
the development of worst-case VaR in the context of portfolio optimization to
the worst-case law invariant risk measures immediately.
"
1609.04199	q-fin	q-fin.ST	Entropy and efficiency of the ETF market	"  We investigate the relative information efficiency of financial markets by
measuring the entropy of the time series of high frequency data. Our tool to
measure efficiency is the Shannon entropy, applied to 2-symbol and 3-symbol
discretisations of the data. Analysing 1-minute and 5-minute price time series
of 55 Exchange Traded Funds traded at the New York Stock Exchange, we develop a
methodology to isolate true inefficiencies from other sources of regularities,
such as the intraday pattern, the volatility clustering and the microstructure
effects. The first two are modelled as multiplicative factors, while the
microstructure is modelled as an ARMA noise process. Following an analytical
and empirical combined approach, we find a strong relationship between low
entropy and high relative tick size and that volatility is responsible for the
largest amount of regularity, averaging 62% of the total regularity against 18%
of the intraday pattern regularity and 20% of the microstructure.
"
1609.04529	q-fin	math.PR q-fin.RM	The joint distributions of running maximum of a Slepian processes	"  Consider the Slepian process $S$ defined by $ S(t)=B(t+1)-B(t),t\in [0,1]$
with $B(t),t\in \R$ a standard Brownian motion.In this contribution we analyze
the joint distribution between the maximum $m_{s}=\max_{0\leq u\leq s}S(u)$
certain and the maximum $M_t=\max_{0\leq u\leq t}S(u)$ for $0< s < t$ fixed.
Explicit integral expression are obtained for the distribution function of the
partial maximum $m_{s}$ and the joint distribution function between $m_{s}$ and
$M_t$. We also use our results to determine the moments of $m_{s}$.
"
1609.04620	q-fin	q-fin.TR	Price impact without order book: A study of the OTC credit index market	"  We present a study of price impact in the over-the-counter credit index
market, where no limit order book is used. Contracts are traded via dealers,
that compete for the orders of clients. Despite this distinct microstructure,
we successfully apply the propagator technique to estimate the price impact of
individual transactions. Because orders are typically split less than in
multilateral markets, impact is observed to be mainly permanent, in line with
theoretical expectations. A simple method is presented to correct for errors in
our classification of trades between buying and selling. We find a very
significant, temporary increase in order flow correlations during late 2015 and
early 2016, which we attribute to increased order splitting or herding among
investors. We also find indications that orders advertised to less dealers may
have lower price impact. Quantitative results are compatible with earlier
findings in other more classical markets, further supporting the argument that
price impact is a universal phenomenon, to a large degree independent of market
microstructure.
"
1609.04629	q-fin	q-fin.GN cs.SI nlin.AO	Institutionalization in Efficient Markets: The Case of Price Bubbles	"  We seek to deepen understanding of the micro-foundations of
institutionalization while contributing to a sociological theory of markets by
investigating the puzzle of price bubbles in financial markets. We find that
such markets, despite textbook conditions of high efficiency -- perfect
information, atomistic agents, no uncertainty -- quickly develop patterns
consistent with institutionalization processes.
"
1609.04907	q-fin	q-fin.MF	"Asset Pricing in a Semi-Markov Modulated Market with Time-dependent
  Volatility"	"  This project attempts to address the problem of asset pricing in a financial
market, where the interest rates and volatilities exhibit regime switching.
This is an extension of the Black-Scholes model. Studies of Markov-modulated
regime switching models have been well-documented. This project extends that
notion to a class of semi-Markov processes known as age-dependent processes. We
also allow for time-dependence in volatility within regimes. We show that the
problem of option pricing in such a market is equivalent to solving a certain
integral equation.
"
1609.04956	q-fin	q-fin.EC cond-mat.stat-mech physics.soc-ph	"Export dynamics as an optimal growth problem in the network of global
  economy"	"  We analyze export data aggregated at world global level of 219 classes of
products over a period of 39 years. Our main goal is to set up a dynamical
model to identify and quantify plausible mechanisms by which the evolutions of
the various exports affect each other. This is pursued through a stochastic
differential description, partly inspired by approaches used in population
dynamics or directed polymers in random media. We outline a complex network of
transfer rates which describes how resources are shifted between different
product classes, and determines how casual favorable conditions for one export
can spread to the other ones. A calibration procedure allows to fit four free
model-parameters such that the dynamical evolution becomes consistent with the
average growth, the fluctuations, and the ranking of the export values observed
in real data. Growth crucially depends on the balance between maintaining and
shifting resources to different exports, like in an explore-exploit problem.
Remarkably, the calibrated parameters warrant a close-to-maximum growth rate
under the transient conditions realized in the period covered by data, implying
an optimal self organization of the global export. According to the model,
major structural changes in the global economy take tens of years.
"
1609.05055	q-fin	q-fin.GN	A Simple Model of Credit Expansion	"  The proposed model is aimed to reveal important patterns in the behavior of a
simplified financial system. The patterns could be detected as regular cycles
consisting of debt bubbles and crises. Financial cycles have a well defined
structure and form periodic sequences along the axis of credit expansion while
retaining stochastic nature in terms of time.
"
1609.05056	q-fin	q-fin.GN	Copula-Based Univariate Time Series Structural Shift Identification Test	"  An approach is proposed to determine structural shift in time-series assuming
non-linear dependence of lagged values of dependent variable. Copulas are used
to model non-linear dependence of time series components.
"
1609.05177	q-fin	q-fin.TR q-fin.MF q-fin.ST	The microstructural foundations of leverage effect and rough volatility	"  We show that typical behaviors of market participants at the high frequency
scale generate leverage effect and rough volatility. To do so, we build a
simple microscopic model for the price of an asset based on Hawkes processes.
We encode in this model some of the main features of market microstructure in
the context of high frequency trading: high degree of endogeneity of market,
no-arbitrage property, buying/selling asymmetry and presence of metaorders. We
prove that when the first three of these stylized facts are considered within
the framework of our microscopic model, it behaves in the long run as a Heston
stochastic volatility model, where leverage effect is generated. Adding the
last property enables us to obtain a rough Heston model in the limit,
exhibiting both leverage effect and rough volatility. Hence we show that at
least part of the foundations of leverage effect and rough volatility can be
found in the microstructure of the asset.
"
1609.05200	q-fin	q-fin.EC	Chinese Medical Device Market and The Investment Vector	"  China has attracted increasing amounts of foreign investment since it opened
its doors to the world and whilst many analysts have focused on foreign
investment in popular areas, little has been written about medical device
investment. The purpose of this article is to analyze the status of the Chinese
medical device market from the perspective of the healthcare industry and its
important market drivers; the study reveals that the medical device market has
significant growth potential. This article aims to identify and assess the
profitable sectors of medical device technologies as a guide for international
companies and investors.
"
1609.05394	q-fin	cs.LG q-fin.ST	"Predicting Future Shanghai Stock Market Price using ANN in the Period
  21-Sep-2016 to 11-Oct-2016"	"  Predicting the prices of stocks at any stock market remains a quest for many
investors and researchers. Those who trade at the stock market tend to use
technical, fundamental or time series analysis in their predictions. These
methods usually guide on trends and not the exact likely prices. It is for this
reason that Artificial Intelligence systems, such as Artificial Neural Network,
that is feedforward multi-layer perceptron with error backpropagation, can be
used for such predictions. A difficulty in neural network application is the
determination of suitable network parameters. A previous research by the author
already determined the network parameters as 5:21:21:1 with 80% training data
or 4-year of training data as a good enough model for stock prediction. This
model has been put to the test in predicting selected Shanghai Stock Exchange
stocks in the future period of 21-Sep-2016 to 11-Oct-2016, about one week after
the publication of these predictions. The research aims at confirming that
simple neural network systems can be quite powerful in typical stock market
predictions.
"
1609.05475	q-fin	q-fin.PM cond-mat.dis-nn math.OC stat.AP	Replica Analysis for the Duality of the Portfolio Optimization Problem	"  In the present paper, the primal-dual problem consisting of the investment
risk minimization problem and the expected return maximization problem in the
mean-variance model is discussed using replica analysis. As a natural extension
of the investment risk minimization problem under only a budget constraint that
we analyzed in a previous study, we herein consider a primal-dual problem in
which the investment risk minimization problem with budget and expected return
constraints is regarded as the primal problem, and the expected return
maximization problem with budget and investment risk constraints is regarded as
the dual problem. With respect to these optimal problems, we analyze a quenched
disordered system involving both of these optimization problems using the
approach developed in statistical mechanical informatics, and confirm that both
optimal portfolios can possess the primal-dual structure. Finally, the results
of numerical simulations are shown to validate the effectiveness of the
proposed method.
"
1609.05523	q-fin	q-fin.PR q-fin.TR	"Static vs adapted optimal execution strategies in two benchmark trading
  models"	"  We consider the optimal solutions to the trade execution problem in the two
different classes of i) fully adapted or adaptive and ii) deterministic or
static strategies, comparing them. We do this in two different benchmark
models. The first model is a discrete time framework with an information flow
process, dealing with both permanent and temporary impact, minimizing the
expected cost of the trade. The second model is a continuous time framework
where the objective function is the sum of the expected cost and a value at
risk (or expected shortfall) type risk criterion. Optimal adapted solutions are
known in both frameworks from the original works of Bertsimas and Lo (1998) and
Gatheral and Schied (2011). In this paper we derive the optimal static
strategies for both benchmark models and we study quantitatively the
improvement in optimality when moving from static strategies to fully adapted
ones. We conclude that, in the benchmark models we study, the difference is not
relevant, except for extreme unrealistic cases for the model or impact
parameters. This indirectly confirms that in the similar framework of Almgren
and Chriss (2000) one is fine deriving a static optimal solution, as done by
those authors, as opposed to a fully adapted one, since the static solution
happens to be tractable and known in closed form.
"
1609.05939	q-fin	q-fin.RM	Crises and Physical Phases of a Bipartite Market Model	"  We analyze the linear response of a market network to shocks based on the
bipartite market model we introduced in an earlier paper, which we claimed to
be able to identify the time-line of the 2009-2011 Eurozone crisis correctly.
We show that this model has three distinct phases that can broadly be
categorized as ""stable"" and ""unstable"". Based on the interpretation of our
behavioral parameters, the stable phase describes periods where investors and
traders have confidence in the market (e.g. predict that the market rebounds
from a loss). We show that the unstable phase happens when there is a lack of
confidence and seems to describe ""boom-bust"" periods in which changes in prices
are exponential. We analytically derive these phases and where the phase
transition happens using a mean field approximation of the model. We show that
the condition for stability is $\alpha \beta <1$ with $\alpha$ being the
inverse of the ""price elasticity"" and $\beta$ the ""income elasticity of
demand"", which measures how rash the investors make decisions. We also show
that in the mean-field limit this model reduces to the Langevin model by
Bouchaud et al. for price returns.
"
1609.07472	q-fin	q-fin.CP cs.LG q-fin.PR	Gated Neural Networks for Option Pricing: Rationality by Design	"  We propose a neural network approach to price EU call options that
significantly outperforms some existing pricing models and comes with
guarantees that its predictions are economically reasonable. To achieve this,
we introduce a class of gated neural networks that automatically learn to
divide-and-conquer the problem space for robust and accurate pricing. We then
derive instantiations of these networks that are 'rational by design' in terms
of naturally encoding a valid call option surface that enforces no arbitrage
principles. This integration of human insight within data-driven learning
provides significantly better generalisation in pricing performance due to the
encoded inductive bias in the learning, guarantees sanity in the model's
predictions, and provides econometrically useful byproduct such as risk neutral
density.
"
1609.07558	q-fin	q-fin.PR math.PR q-fin.CP	Discrete Sums of Geometric Brownian Motions, Annuities and Asian Options	"  The discrete sum of geometric Brownian motions plays an important role in
modeling stochastic annuities in insurance. It also plays a pivotal role in the
pricing of Asian options in mathematical finance. In this paper, we study the
probability distributions of the infinite sum of geometric Brownian motions,
the sum of geometric Brownian motions with geometric stopping time, and the
finite sum of the geometric Brownian motions. These results are extended to the
discrete sum of the exponential L\'evy process. We derive tail asymptotics and
compute numerically the asymptotic distribution function. We compare the
results against the known results for the continuous time integral of the
geometric Brownian motion up to an exponentially distributed time. The results
are illustrated with numerical examples for life annuities with discrete
payments, and Asian options.
"
1609.07559	q-fin	q-fin.PR	Short Maturity Asian Options in Local Volatility Models	"  We present a rigorous study of the short maturity asymptotics for Asian
options with continuous-time averaging, under the assumption that the
underlying asset follows a local volatility model. The asymptotics for
out-of-the-money, in-the-money, and at-the-money cases are derived, considering
both fixed strike and floating strike Asian options. The asymptotics for the
out-of-the-money case involves a non-trivial variational problem which is
solved completely. We present an analytical approximation for Asian options
prices, and demonstrate good numerical agreement of the asymptotic results with
the results of Monte Carlo simulations and benchmark test cases in the
Black-Scholes model for option parameters relevant in practical applications.
"
1609.07897	q-fin	q-fin.RM	Risk-Consistent Conditional Systemic Risk Measures	"  We axiomatically introduce risk-consistent conditional systemic risk measures
defined on multidimensional risks. This class consists of those conditional
systemic risk measures which can be decomposed into a state-wise conditional
aggregation and a univariate conditional risk measure. Our studies extend known
results for unconditional risk measures on finite state spaces. We argue in
favor of a conditional framework on general probability spaces for assessing
systemic risk. Mathematically, the problem reduces to selecting a realization
of a random field with suitable properties. Moreover, our approach covers many
prominent examples of systemic risk measures from the literature and used in
practice.
"
1609.07903	q-fin	q-fin.MF	Strongly Consistent Multivariate Conditional Risk Measures	"  We consider families of strongly consistent multivariate conditional risk
measures. We show that under strong consistency these families admit a
decomposition into a conditional aggregation function and a univariate
conditional risk measure as introduced Hoffmann et al. (2016). Further, in
analogy to the univariate case in F\""ollmer (2014), we prove that under
law-invariance strong consistency implies that multivariate conditional risk
measures are necessarily multivariate conditional certainty equivalents.
"
1609.08520	q-fin	q-fin.GN	Clustering Approaches for Financial Data Analysis: a Survey	"  Nowadays, financial data analysis is becoming increasingly important in the
business market. As companies collect more and more data from daily operations,
they expect to extract useful knowledge from existing collected data to help
make reasonable decisions for new customer requests, e.g. user credit category,
confidence of expected return, etc. Banking and financial institutes have
applied different data mining techniques to enhance their business performance.
Among these techniques, clustering has been considered as a significant method
to capture the natural structure of data. However, there are not many studies
on clustering approaches for financial data analysis. In this paper, we
evaluate different clustering algorithms for analysing different financial
datasets varied from time series to transactions. We also discuss the
advantages and disadvantages of each method to enhance the understanding of
inner structure of financial datasets as well as the capability of each
clustering method in this context.
"
1609.08978	q-fin	math.PR physics.soc-ph q-fin.GN	A stylized model for wealth distribution	"  The recent book by T. Piketty (Capital in the Twenty-First Century) promoted
the important issue of wealth inequality. In the last twenty years, physicists
and mathematicians developed models to derive the wealth distribution using
discrete and continuous stochastic processes (random exchange models) as well
as related Boltzmann-type kinetic equations. In this literature, the usual
concept of equilibrium in Economics is either replaced or completed by
statistical equilibrium.
  In order to illustrate this activity with a concrete example, we present a
stylised random exchange model for the distribution of wealth. We first discuss
a fully discrete version (a Markov chain with finite state space). We then
study its discrete-time continuous-state-space version and we prove the
existence of the equilibrium distribution. Finally, we discuss the connection
of these models with Boltzmann-like kinetic equations for the marginal
distribution of wealth. This paper shows in practice how it is possible to
start from a finitary description and connect it to continuous models following
Boltzmann's original research program.
"
1609.09571	q-fin	cs.CY q-fin.GN	"The Role of Rating and Loan Characteristics in Online Microfunding
  Behaviors"	"  We propose an in-depth study of lending behaviors in Kiva using a mix of
quantitative and large-scale data mining techniques. Kiva is a non-profit
organization that offers an online platform to connect lenders with borrowers.
Their site, kiva.org, allows citizens to microlend small amounts of money to
entrepreneurs (borrowers) from different countries. The borrowers are always
affiliated with a Field Partner (FP) which can be a microfinance institution
(MFI) or other type of local organization that has partnered with Kiva. Field
partners give loans to selected businesses based on their local knowledge
regarding the country, the business sector including agriculture, health or
manufacture among others, and the borrower.Our objective is to understand the
relationship between lending activity and various features offered by the
online platform. Specifically, we focus on two research questions: (i) the role
that MFI ratings play in driving lending activity and (ii) the role that
various loan features have in the lending behavior. The first question analyzes
whether there exists a relationship between the MFI ratings - that lenders can
explore online - and their lending volumes. The second research question
attempts to understand if certain loan features - available online at Kiva -
such as the type of small business, the gender of the borrower, or the loan's
country information might affect the way lenders lend.
"
1609.09601	q-fin	q-fin.CP q-fin.GN	Biased Roulette Wheel: A Quantitative Trading Strategy Approach	"  The purpose of this research paper it is to present a new approach in the
framework of a biased roulette wheel. It is used the approach of a quantitative
trading strategy, commonly used in quantitative finance, in order to assess the
profitability of the strategy in the short term. The tools of backtesting and
walk-forward optimization were used to achieve such task. The data has been
generated from a real European roulette wheel from an on-line casino based in
Riga, Latvia. It has been recorded 10,980 spins and sent to the computer
through a voice-to-text software for further numerical analysis in R. It has
been observed that the probabilities of occurrence of the numbers at the
roulette wheel follows an Ornstein-Uhlenbeck process. Moreover, it is shown
that a flat betting system against Kelly Criterion was more profitable in the
short term.
"
1610.00256	q-fin	q-fin.PR q-fin.CP q-fin.PM q-fin.RM	XVA at the Exercise Boundary	"  XVA is a material component of a trade valuation and hence it must impact the
decision to exercise options within a given netting set. This is true for both
unsecured trades and secured / cleared trades where KVA and MVA play a material
role even if CVA and FVA do not. However, this effect has frequently been
ignored in XVA models and indeed in exercise decisions made by option owners.
This paper describes how XVA impacts the exercise decision and how this can be
readily evaluated using regression techniques (Longstaff and Schwartz 2001).
The paper then assesses the materiality of the impact of XVA at the exercise
boundary on swaption examples.
"
1610.00259	q-fin	q-fin.ST	"Hysteresis and Duration Dependence of Financial Crises in the US:
  Evidence from 1871-2016"	"  This study analyses the duration dependence of events that trigger volatility
persistence in stock markets. Such events, in our context, are monthly spells
of contiguous price decline or negative returns for the S&P500 stock market
index over the last 145 years. Factors known to affect the duration of these
spells are the magnitude or intensity of the price decline, long-term interest
rates and economic recessions, among others. The result of interest is the
conditional probability of ending a spell of consecutive months over which
stock market returns remain negative. In this study, we rely on continuous time
survival models in order to investigate this question. Several specifications
were attempted, some of which under the proportional hazards assumption and
others under the accelerated failure time assumption. The best fit of the
various models endeavored was obtained for the log-normal distribution. This
distribution yields a non-monotonic hazard function that increases up to a
maximum and then decreases. The peak is achieved 2-3 months after the spells
onset with a hazard of around 0.9 or higher; this hazard then decays
asymptotically to zero. Spells duration increase during recessions, when
interest rate rises and when price declines are more intense. The main
conclusion is that short spells of negative returns appear to be mainly
frictional while long spells become structural and trigger hysteresis effects
after an initial period of adjustment. Although in line with our expectations,
these results may be of some importance for policy-makers.
"
1610.00312	q-fin	q-fin.MF	"Volatility Inference and Return Dependencies in Stochastic Volatility
  Models"	"  Stochastic volatility models describe stock returns $r_t$ as driven by an
unobserved process capturing the random dynamics of volatility $v_t$. The
present paper quantifies how much information about volatility $v_t$ and future
stock returns can be inferred from past returns in stochastic volatility models
in terms of Shannon's mutual information.
"
1610.00395	q-fin	q-fin.MF q-fin.PM	Optimal Portfolios of Illiquid Assets	"  This paper investigates the investment behaviour of a large unregulated
financial institution (FI) with CARA risk preferences. It shows how the FI
optimizes its trading to account for market illiquidity using an extension of
the Almgren-Chriss market impact model of multiple risky assets. This expected
utility optimization problem over the set of adapted strategies turns out to
have the same solutions as a mean-variance optimization over deterministic
trading strategies. That means the optimal adapted trading strategy is both
deterministic and time-consistent. It is also found to have an explicit closed
form that clearly displays interesting properties. For example, the classic
constant Merton portfolio strategy, a particular solution of the frictionless
limit of the problem, behaves like an attractor in the space of more general
solutions. The main effect of temporary market impact is to slow down the speed
of convergence to this constant Merton portfolio. The effect of permanent
market impact is to incentivize the FI to buy additional risky assets near the
end of the period. This property, that we name the Ponzi property, is related
to the creation and bursting of bubbles in the market. The proposed model can
be used as a stylized dynamic model of a typical FI in the study of the asset
fire sale channel relevant to understanding systemic risk and financial
stability.
"
1610.00577	q-fin	q-fin.PR math.PR	"Exponential functionals of Levy processes and variable annuity
  guaranteed benefits"	"  Exponential functionals of Brownian motion have been extensively studied in
financial and insurance mathematics due to their broad applications, for
example, in the pricing of Asian options. The Black-Scholes model is appealing
because of mathematical tractability, yet empirical evidence shows that
geometric Brownian motion does not adequately capture features of market equity
returns. One popular alternative for modeling equity returns consists in
replacing the geometric Brownian motion by an exponential of a Levy process. In
this paper we use this latter model to study variable annuity guaranteed
benefits and to compute explicitly the distribution of certain exponential
functionals.
"
1610.00937	q-fin	q-fin.PM	Sharpe portfolio using a cross-efficiency evaluation	"  The Sharpe ratio is a way to compare the excess returns (over the risk free
asset) of portfolios for each unit of volatility that is generated by a
portfolio. In this paper we introduce a robust Sharpe ratio portfolio under the
assumption that the risk free asset is unknown. We propose a robust portfolio
that maximizes the Sharpe ratio when the risk free asset is unknown, but is
within a given interval. To compute the best Sharpe ratio portfolio all the
Sharpe ratios for any risk free asset are considered and compared by using the
so-called cross-efficiency evaluation. An explicit expression of the
Cross-Eficiency Sharpe ratio portfolio is presented when short selling is
allowed.
"
1610.00955	q-fin	q-fin.GN	Inventory growth cycles with debt-financed investment	"  We propose a continuous-time stock-flow consistent model for inventory
dynamics in an economy with firms, banks, and households. On the supply side,
firms decide on production based on adaptive expectations for sales demand and
a desired level of inventories. On the demand side, investment is determined as
a function of utilization and profitability and can be financed by debt,
whereas consumption is independently determined as a function of income and
wealth. Prices adjust sluggishly to both changes in labour costs and inventory.
Disequilibrium between expected sales and demand is absorbed by unplanned
changes in inventory. This results in a five-dimensional dynamical system for
wage share, employment rate, private debt ratio, expected sales, and capacity
utilization. We analyze two limiting cases: the long-run dynamics provides a
version of the Keen model with effective demand and varying inventories,
whereas the short-run dynamics gives rise to behaviour that we interpret as
Kitchin cycles.
"
1610.01149	q-fin	q-fin.ST q-fin.TR	Taylor's Law of temporal fluctuation scaling in stock illiquidity	"  Taylor's law of temporal fluctuation scaling, variance $\sim$ $a($mean$)^b$,
is ubiquitous in natural and social sciences. We report for the first time
convincing evidence of a solid temporal fluctuation scaling law in stock
illiquidity by investigating the mean-variance relationship of the
high-frequency illiquidity of almost all stocks traded on the Shanghai Stock
Exchange (SHSE) and the Shenzhen Stock Exchange (SZSE) during the period from
1999 to 2011. Taylor's law holds for A-share markets (SZSE Main Board, SZSE
Small & Mediate Enterprise Board, SZSE Second Board, and SHSE Main Board) and
B-share markets (SZSE B-share and SHSE B-share). We find that the scaling
exponent $b$ is greater than 2 for the A-share markets and less than 2 for the
B-share markets. We further unveil that Taylor's law holds for stocks in 17
industry categories, in 28 industrial sectors and in 31 provinces and
direct-controlled municipalities with the majority of scaling exponents
$b\in(2,3)$. We also investigate the $\Delta{t}$-min illiquidity and find that
the scaling exponent $b(\Delta{t})$ increases logarithmically for small
$\Delta{t}$ values and decreases fast to a stable level.
"
1610.01227	q-fin	q-fin.MF math.OC math.PR	A Duality Result for Robust Optimization with Expectation Constraints	"  This paper demonstrates a practical method for computing the solution of an
expectation-constrained robust maximization problem with immediate applications
to model-free no-arbitrage bounds and super-replication values for many
financial derivatives. While the previous literature has connected
super-replication values to a convex minimization problem whose objective
function is related to a sequence of iterated concave envelopes, we show how
this whole process can be encoded in a single convex minimization problem. The
natural finite-dimensional approximation of this minimization problem results
in an easily-implementable sparse linear program. We highlight this technique
by obtaining no-arbitrage bounds on the prices of forward-starting options,
continuously-monitored variance swaps, and discretely-monitored gamma swaps,
each subject to observed bid-ask spreads of finitely-many vanilla options.
"
1610.01270	q-fin	q-fin.GN physics.soc-ph	Information inefficiency in a random linear economy model	"  We study the effects of introducing information inefficiency in a model for a
random linear economy with a representative consumer. This is done by
considering statistical, instead of classical, economic general equilibria.
Employing two different approaches we show that inefficiency increases the
consumption set of a consumer but decreases her expected utility. In this
scenario economic activity grows while welfare shrinks, that is the opposite of
the behavior obtained by considering a rational consumer.
"
1610.01338	q-fin	q-fin.PR q-fin.GN	"The Cross-section of Expected Returns on Penny Stocks: Are Low-hanging
  Fruits Not-so Sweet?"	"  In this paper, we study the determinants of expected returns on the listed
penny stocks from two perspectives. Traditionally financial economics
literature has been devoted to study the macro and micro determinants of
expected returns on stocks (Subrahmanyam, 2010). Very few research has been
carried out on penny stocks (Liu, Rhee, & Zhang, 2011; Nofsinger & Verma,
2014). Our study is an effort to contribute more empirical evidence on penny
stocks in the emerging market context. We see the return dynamics of penny
stocks from corporate governance perspective. Issues such as shareholding
patters are considered to be of much significance when it comes to understand
the price movements. Using cross-sectional data on 167 penny stocks listed in
the National Stock Exchange of India, we show that (i) Returns of portfolio of
lower market-cap penny stocks are significantly different(higher) than that of
higher market-cap penny stocks. (ii)Returns of portfolio lower P/E stocks are
significantly different (higher) than that of higher P/E stocks. Similarly,
returns of portfolio of lower P/B stocks are significantly different (higher)
than that of higher P/B stocks, and returns of portfolio of lower priced penny
stocks are significantly different(higher) than that of higher priced penny
stocks. (iii) Trading volume differences due to alphabetism are insignificant.
(iv)Differences in returns of portfolios based on beta and shareholding
patterns are insignificant.
"
1610.01645	q-fin	q-fin.GN	"Administration Costs in the Management of Research Funds; A Case Study
  of a Public Fund for the Promotion of Industrial Innovation"	"  Research funding agencies routinely use a proportion of their total revenues
to support internal administration and marketing costs. The ratio of
administration to total costs, referred to as the administration ratio, is
highly variable and within any single fund depends on many factors including
the number and average size of projects and the overall efficiency of the
funding agency. In this study, the standard agency activities have been
identified and used to develop a model of administration costs against expected
outcomes. In particular, the model has been designed to estimate the optimum
portfolio success rate and administration ratio as a function of a range of key
input variables including the project size, the complexity of proposal
evaluation and project management, the risk tolerance of the sponsor and the
targeted research domain.
"
1610.01937	q-fin	q-fin.TR math.PR q-fin.MF q-fin.PM	"Trading against disorderly liquidation of a large position under
  asymmetric information and market impact"	"  We consider trading against a hedge fund or large trader that must liquidate
a large position in a risky asset if the market price of the asset crosses a
certain threshold. Liquidation occurs in a disorderly manner and negatively
impacts the market price of the asset. We consider the perspective of small
investors whose trades do not induce market impact and who possess different
levels of information about the liquidation trigger mechanism and the market
impact. We classify these market participants into three types: fully informed,
partially informed and uninformed investors. We consider the portfolio
optimization problems and compare the optimal trading and wealth processes for
the three classes of investors theoretically and by numerical illustrations.
"
1610.01946	q-fin	q-fin.CP	Efficient Valuation of SCR via a Neural Network Approach	"  As part of the new regulatory framework of Solvency II, introduced by the
European Union, insurance companies are required to monitor their solvency by
computing a key risk metric called the Solvency Capital Requirement (SCR). The
official description of the SCR is not rigorous and has lead researchers to
develop their own mathematical frameworks for calculation of the SCR. These
frameworks are complex and are difficult to implement. Recently, Bauer et al.
suggested a nested Monte Carlo (MC) simulation framework to calculate the SCR.
But the proposed MC framework is computationally expensive even for a simple
insurance product. In this paper, we propose incorporating a neural network
approach into the nested simulation framework to significantly reduce the
computational complexity in the calculation. We study the performance of our
neural network approach in estimating the SCR for a large portfolio of an
important class of insurance products called Variable Annuities (VAs). Our
experiments show that the proposed neural network approach is both efficient
and accurate.
"
1610.02126	q-fin	q-fin.RM	"Multiple risk factor dependence structures: Copulas and related
  properties"	"  Copulas have become an important tool in the modern best practice Enterprise
Risk Management, often supplanting other approaches to modelling stochastic
dependence. However, choosing the `right' copula is not an easy task, and the
temptation to prefer a tractable rather than a meaningful candidate from the
encompassing copulas toolbox is strong. The ubiquitous applications of the
Gaussian copula is just one illuminating example.
  Speaking generally, a `good' copula should conform to the problem at hand,
allow for asymmetry in the domain of definition and exhibit some extent of tail
dependence. In this paper we introduce and study a new class of Multiple Risk
Factor (MRF) copula functions, which we show are exactly such. Namely, the MRF
copulas (1) arise from a number of meaningful default risk specification with
stochastic default barriers, (2) are in general non-exchangeable and (3)
possess a variety of tail dependences. That being said, the MRF copulas turn
out to be surprisingly tractable analytically.
"
1610.02863	q-fin	q-fin.ST math.ST stat.TH	"Feasible Invertibility Conditions for Maximum Likelihood Estimation for
  Observation-Driven Models"	"  Invertibility conditions for observation-driven time series models often fail
to be guaranteed in empirical applications. As a result, the asymptotic theory
of maximum likelihood and quasi-maximum likelihood estimators may be
compromised. We derive considerably weaker conditions that can be used in
practice to ensure the consistency of the maximum likelihood estimator for a
wide class of observation-driven time series models. Our consistency results
hold for both correctly specified and misspecified models. The practical
relevance of the theory is highlighted in a set of empirical examples. We
further obtain an asymptotic test and confidence bounds for the unfeasible ""
true "" invertibility region of the parameter space.
"
1610.03958	q-fin	q-fin.PM math.OC	"Optimal Consumption and Investment with Fixed and Proportional
  Transaction Costs"	"  The classical optimal investment and consumption problem with infinite
horizon is studied in the presence of transaction costs. Both proportional and
fixed costs as well as general utility functions are considered. Weak dynamic
programming is proved in the general setting and a comparison result for
possibly discontinuous viscosity solutions of the dynamic programming equation
is provided. Detailed numerical experiments illustrate several properties of
the optimal investment strategies.
"
1610.04051	q-fin	q-fin.MF	Time value of extra information against its timely value	"  We introduce an interactive market setup with sequential auctions where
agents receive variegated signals with a known deadline. The effects of
differential information and mutual learning on the allocation of overall
profit \& loss (P\&L) and the pace of price discovery are analysed. We
characterise the signal-based expected P\&L of agents based on explicit
formulae for the directional quality of the trading signal, and study the
optimal trading pattern using dynamic programming and provided that there is a
common anticipation by agents of gains from trade. We find evidence in favour
of exploiting new information whenever it arrives, and market efficiency. Brief
extensions of the problem to risk-adjusted gains as well as risk-averse agents
are provided. We then introduce the `information-adjusted risk premium' and
recover the signal-based equilibrium price as the weighted average of the
signal-based individual prices with respect to the risk-aversion levels.
"
1610.04334	q-fin	q-fin.ST	Time-Varying Comovement of Foreign Exchange Markets	"  A time-varying cointegration model for foreign exchange rates is presented.
Unlike previous studies, we allow the loading matrix in the vector error
correction (VEC) model to be varying over time. Because the loading matrix in
the VEC model is associated with the speed at which deviations from the
long-run relationship disappear, we propose a new degree of market comovement\
based on the time-varying loading matrix to measure the strength or robustness
of the long-run relationship over time. Since exchange rates are determined by
macrovariables, cointegration among exchange rates implies those macroeconomic
variables share common stochastic trends. Therefore, the proposed degree
measures the degree of market comovement. Our main finding is that the market
comovement has become stronger over the past quarter century, but the rate at
which market comovement strengthens is decreasing with two major turning
points: one in 1995 and the other one in 2008.
"
1610.04458	q-fin	q-fin.TR	Optimal trading policies for wind energy producer	"  We study the optimal trading policies for a wind energy producer who aims to
sell the future production in the open forward, spot, intraday and adjustment
markets, and who has access to imperfect dynamically updated forecasts of the
future production. We construct a stochastic model for the forecast evolution
and determine the optimal trading policies which are updated dynamically as new
forecast information becomes available. Our results allow to quantify the
expected future gain of the wind producer and to determine the economic value
of the forecasts.
"
1610.04760	q-fin	q-fin.ST	Uncertainty Estimates in the Heston Model via Fisher Information	"  We address the information content of European option prices about volatility
in terms of the Fisher information matrix. We assume that observed option
prices are centred on the theoretical price provided by Heston's model
disturbed by additive Gaussian noise. We fit the likelihood function on the
components of the VIX, i.e., near- and next-term put and call options on the
S&P 500 with more than 23 days and less than 37 days to expiration and
non-vanishing bid, and compute their Fisher information matrices from the
Greeks in the Heston model. We find that option prices allow reliable estimates
of volatility with negligible uncertainty as long as volatility is large
enough. Interestingly, if volatility drops below a critical value, inferences
from option prices become impossible because Vega, the derivative of a European
option w.r.t. volatility, nearly vanishes.
"
1610.05171	q-fin	q-fin.EC	Urban-rural gap and poverty traps in China: A prefecture level analysis	"  Urban-rural gap and regional inequality are long standing problems in China
and result in considerable number of studies. This paper examines the dynamic
behaviors of incomes for both urban and rural areas with a prefectural data
set. The analysis is conducted by using a distribution dynamics approach, which
have advantages in examination on persistence, polarization and convergence
clubs. The results show that persistence and immobility are the dominant
characteristics in the income distribution dynamics. The prefectural urban and
rural areas converge into their own steady states differentiated in income
levels. This pattern of urban-rural gap also exists in three regional groups,
namely the eastern, central and western regions. Examination on the dynamics of
the poorest areas shows that geographical poverty traps exist in both urban and
rural prefectural areas. Our results indicate that more policy interventions
are required to narrow down the urban-rural gap and to eliminate the poverty
traps in China.
"
1610.05448	q-fin	stat.ML math.ST q-fin.EC stat.TH	"Generalization error minimization: a new approach to model evaluation
  and selection with an application to penalized regression"	"  We study model evaluation and model selection from the perspective of
generalization ability (GA): the ability of a model to predict outcomes in new
samples from the same population. We believe that GA is one way formally to
address concerns about the external validity of a model. The GA of a model
estimated on a sample can be measured by its empirical out-of-sample errors,
called the generalization errors (GE). We derive upper bounds for the GE, which
depend on sample sizes, model complexity and the distribution of the loss
function. The upper bounds can be used to evaluate the GA of a model, ex ante.
We propose using generalization error minimization (GEM) as a framework for
model selection. Using GEM, we are able to unify a big class of penalized
regression estimators, including lasso, ridge and bridge, under the same set of
assumptions. We establish finite-sample and asymptotic properties (including
$\mathcal{L}_2$-consistency) of the GEM estimator for both the $n \geqslant p$
and the $n < p$ cases. We also derive the $\mathcal{L}_2$-distance between the
penalized and corresponding unpenalized regression estimates. In practice, GEM
can be implemented by validation or cross-validation. We show that the GE
bounds can be used for selecting the optimal number of folds in $K$-fold
cross-validation. We propose a variant of $R^2$, the $GR^2$, as a measure of
GA, which considers both both in-sample and out-of-sample goodness of fit.
Simulations are used to demonstrate our key results.
"
1610.05697	q-fin	q-fin.ST	"""Butterfly Effect"" vs Chaos in Energy Futures Markets"	"  In this paper we test for the sensitive dependence on initial conditions (the
so called ""butterfly effect"") of energy futures time series (heating oil,
natural gas), and thus the determinism of those series. This paper is
distinguished from previous studies in the following points: first, we reread
existent works in the literature on energy markets, enlightening the role of
\emph{butterfly effect} in chaos definition (introduced by Devaney), using this
definition to prevent us from misleading results about ostensible chaoticity of
the price series. Second, we test for the time series for sensitive dependence
on initial conditions, introducing a coefficient that describes the determinism
rate of the series and that represents its reliability level (in percentage).
The introduction of this reliability level is motivated by the fact that time
series generated from stochastic systems also might show sensitive dependence
on initial conditions. According to this perspective, the maximum reliability
level obtained here is too low to be able to ensure that there is strong
evidence of sensitive The maximum reliability level obtained here was been
$\simeq 56\% $, too low to ensure strong evidence of sensitive dependence on
initial conditions.
"
1610.05703	q-fin	q-fin.EC	"Two approaches to modeling the interaction of small and medium
  price-taking traders with a stock exchange by mathematical programming
  techniques"	"  The paper presents two new approaches to modeling the interaction of small
and medium pricetaking traders with a stock exchange. In the framework of these
approaches, the traders can form and manage their portfolios of financial
instruments traded on a stock exchange with the use of linear, integer, and
mixed programming techniques. Unlike previous authors publications on the
subject, besides standard securities, the present publication considers
derivative financial instruments such as futures and options contracts.
"
1610.05892	q-fin	cs.SI physics.soc-ph q-fin.EC	"Centrality measures in networks based on nodes attributes, long-range
  interactions and group influence"	"  We propose a new method for assessing agents influence in network structures,
which takes into consideration nodes attributes, individual and group
influences of nodes, and the intensity of interactions. This approach helps us
to identify both explicit and hidden central elements which cannot be detected
by classical centrality measures or other indices.
"
1610.07028	q-fin	q-fin.ST	Techniques for multifractal spectrum estimation in financial time series	"  Multifractal analysis is one of the important approaches that enables us to
measure the complexity of various data via the scaling properties. We compare
the most common techniques used for multifractal exponents estimation from both
theoretical and practical point of view. Particularly, we discuss the methods
based on estimation of R\'enyi entropy, which provide a powerful tool
especially in presence of heavy-tailed data. To put some flesh on bare bones,
all methods are compared on various real financial datasets, including daily
and high-frequency data.
"
1610.07131	q-fin	math.PR q-fin.RM	Asymptotic of Non-Crossings probability of Additive Wiener Fields	"  Let $W_i=\{W_i(t_i), t_i\in \R_+\}, i=1,2,\ldots,d$ are independent Wiener
processes. $W=\{W(\mathbf{t}),t\in \R_+^d\}$ be the additive Wiener field
define as the sum of $W_i$. For any trend $f$ in $\kHC$ (the reproducing kernel
Hilbert Space of $W$), we derive upper and lower bounds for the boundary
non-crossing probability $$P_f=P\{\sum_{i=1}^{d}W_i(t_i) +f(\mathbf{t})\leq
u(\mathbf{t}), \mathbf{t}\in\R_+^d\},$$ where $u: \R_+^d\rightarrow \R_+$ is a
measurable function. Furthermore, for large trend functions $\gamma f>0$, we
show that the asymptotically relation $\ln P_{\gamma f}\sim \ln P_{\gamma
\underline{f}}$ as $\gamma \to \IF$, where $\underline{f}$ is the projection of
$f$ on some closed convex subset of $\kHC$.
"
1610.07287	q-fin	q-fin.ST	"The asset price bubbles in emerging financial markets: a new statistical
  approach"	"  The bubble is a controversial and important issue. Many methods which based
on the rational expectation have been proposed to detect the bubble. However,
for some developing countries, epically China, the asset markets are so young
that for many companies, there are no dividends and fundamental value, making
it difficult (if not impossible) to measure the bubbles by existing methods.
Therefore, we proposed a simple but effective statistical method and three
statistics (that is, C, U, V) to capture and quantify asset price bubbles,
especially in immature emerging markets. To present a clear example of the
application of this method to real world problems, we also applied our method
to re-examine empirically the asset price bubble in some stock markets. Our
main contributions to current literature are as follows: firstly, this method
does not rely on fundamental value, the discount rates and dividends, therefore
is applicable to the immature markets without the sufficient data of such
kinds, secondly, this new method allows us to examine different influences
(herding behavior, abnormal fluctuation and composite influence) of bubble. Our
new statistical approach is, to the best of our knowledge, the only robust way
in existing literature to to quantify the asset price bubble especially in
emerging markets.
"
1610.08143	q-fin	q-fin.MF q-fin.RM q-fin.TR	"Optimal Risk-Averse Timing of an Asset Sale: Trending vs Mean-Reverting
  Price Dynamics"	"  This paper studies the optimal risk-averse timing to sell a risky asset. The
investor's risk preference is described by the exponential, power, or log
utility. Two stochastic models are considered for the asset price -- the
geometric Brownian motion and exponential Ornstein-Uhlenbeck models -- to
account for, respectively, the trending and mean-reverting price dynamics. In
all cases, we derive the optimal thresholds and certainty equivalents to sell
the asset, and compare them across models and utilities, with emphasis on their
dependence on asset price, risk aversion, and quantity. We find that the timing
option may render the investor's value function and certainty equivalent
non-concave in price. Numerical results are provided to illustrate the
investor's strategies and the premium associated with optimally timing to sell.
"
1610.08414	q-fin	q-fin.ST	"The Fellowship of LIBOR: A Study of Spurious Interbank Correlations by
  the Method of Wigner-Ville Function"	"  The manipulation of LIBOR by a group of banks became one of the major blows
to the remaining confidence in financial industry. Yet, despite an enormous
amount of popular literature on the subject, rigorous time-series studies are
few. In my paper, I discuss the following hypothesis. Namely, if we should
assume for a statistical null, the quotes, which were submitted by the member
banks were true, the deviations from the LIBOR should have been entirely random
because they were determined by idiosyncratic conditions by the member banks.
This hypothesis can be statistically verified. Serial correlations of the
rates, which cannot be explained by the differences in credit qualities of the
member banks or the domicile Governments, were subjected to correlation tests.
A new econometric method--the analysis of the Wigner-Ville function borrowed
from quantum mechanics and signal processing--is used and explained for the
statistical interpretation of regression residuals.
"
1610.08415	q-fin	q-fin.ST	"A Comparison of Various Electricity Tariff Price Forecasting Techniques
  in Turkey and Identifying the Impact of Time Series Periods"	"  It is very vital for suppliers and distributors to predict the deregulated
electricity prices for creating their bidding strategies in the competitive
market area. Pre requirement of succeeding in this field, accurate and suitable
electricity tariff price forecasting tools are needed. In the presence of
effective forecasting tools, taking the decisions of production, merchandising,
maintenance and investment with the aim of maximizing the profits and benefits
can be successively and effectively done. According to the electricity demand,
there are four various electricity tariffs pricing in Turkey; monochromic, day,
peak and night. The objective is find the best suitable tool for predicting the
four pricing periods of electricity and produce short term forecasts (one year
ahead-monthly). Our approach based on finding the best model, which ensures the
smallest forecasting error measurements of: MAPE, MAD and MSD. We conduct a
comparison of various forecasting approaches in total accounts for nine teen,
at least all of those have different aspects of methodology. Our beginning step
was doing forecasts for the year 2015. We validated and analyzed the
performance of our best model and made comparisons to see how well the
historical values of 2015 and forecasted data for that specific period matched.
Results show that given the time-series data, the recommended models provided
good forecasts. Second part of practice, we also include the year 2015, and
compute all the models with the time series of January 2011 to December 2015.
Again by choosing the best appropriate forecasting model, we conducted the
forecast process and also analyze the impact of enhancing of time series
periods (January 2007 to December 2015) to model that we used for forecasting
process.
"
1610.08558	q-fin	q-fin.PM	"Portfolio Benchmarking under Drawdown Constraint and Stochastic Sharpe
  Ratio"	"  We consider an investor who seeks to maximize her expected utility derived
from her terminal wealth relative to the maximum performance achieved over a
fixed time horizon, and under a portfolio drawdown constraint, in a market with
local stochastic volatility (LSV). In the absence of closed-form formulas for
the value function and optimal portfolio strategy, we obtain approximations for
these quantities through the use of a coefficient expansion technique and
nonlinear transformations. We utilize regularity properties of the risk
tolerance function to numerically compute the estimates for our approximations.
In order to achieve similar value functions, we illustrate that, compared to a
constant volatility model, the investor must deploy a quite different portfolio
strategy which depends on the current level of volatility in the stochastic
volatility model.
"
1610.08644	q-fin	q-fin.MF	"Utility Maximization and Indifference Value under Risk and Information
  Constraints for a Market with a Change Point"	"  In this article we consider an optimization problem of expected utility
maximization of continuous-time trading in a financial market. This trading is
constrained by a benchmark for a utility-based shortfall risk measure. The
market consists of one asset whose price process is modeled by a Geometric
Brownian motion where the market parameters change at a random time. The
information flow is modeled by initially and progressively enlarged filtrations
which represent the knowledge about the price process, the Brownian motion and
the random time. We solve the maximization problem and give the optimal
terminal wealth depending on these different filtrations for general utility
functions by using martingale representation results for the corresponding
filtration. Moreover, for a special utility function and risk measure we
calculate the utility indifference value which measures the gain of further
information for the investor.
"
1610.08676	q-fin	q-fin.GN physics.soc-ph	$\kappa$-generalized models of income and wealth distributions: A survey	"  The paper provides a survey of results related to the ""$\kappa$-generalized
distribution"", a statistical model for the size distribution of income and
wealth. Topics include, among others, discussion of basic analytical
properties, interrelations with other statistical distributions as well as
aspects that are of special interest in the income distribution field, such as
the Gini index and the Lorenz curve. An extension of the basic model that is
most able to accommodate the special features of wealth data is also reviewed.
The survey of empirical applications given in this paper shows the
$\kappa$-generalized models of income and wealth to be in excellent agreement
with the observed data in many cases.
"
1610.08767	q-fin	q-fin.TR	Equity Market Impact Modeling: an Empirical Analysis for Chinese Market	"  Market impact has become a subject of increasing concern among academics and
industry experts. We put forward a price impact model which considers the
heteroscedasticity of price in the time dimension and dependency between
permanent impact and temporary impact. We discuss and derive the extremum of
the expectation of permanent impact and realized impact by constructing several
special trading trajectories. Given our use of a large trade and quote tick
records of 17,213,238,343 compiled from the Chinese stock market, the model
assessment ultimately suggest that our model is better than Almgren's model.
Interestingly, the result of random effect analysis indicates the parameter
$\alpha$, which is the exponent of the impact function, is a constant with a
value of around 0.7 across all stocks. Our model and empirical result would
give academia some insight of mechanism of Chinese market, and can be applied
to algorithm trading.
"
1610.08782	q-fin	q-fin.RM q-fin.MF	Intrinsic risk measures	"  Monetary risk measures are usually interpreted as the smallest amount of
external capital that must be added to a financial position to make it
acceptable. We propose a new concept: intrinsic risk measures and argue that
this approach provides a direct path from unacceptable positions towards the
acceptance set. Intrinsic risk measures use only internal resources and return
the smallest percentage of the currently held financial position which has to
be sold and reinvested into an eligible asset such that the resulting position
becomes acceptable. While avoiding the problem of infinite values, intrinsic
risk measures allow a free choice of the eligible asset and they preserve
desired properties such as monotonicity and quasi-convexity. A dual
representation on convex acceptance sets is derived and the link of intrinsic
risk measures to their monetary counterparts on cones is detailed.
"
1610.08818	q-fin	q-fin.PM	Agnostic Risk Parity: Taming Known and Unknown-Unknowns	"  Markowitz' celebrated optimal portfolio theory generally fails to deliver
out-of-sample diversification. In this note, we propose a new portfolio
construction strategy based on symmetry arguments only, leading to ""Eigenrisk
Parity"" portfolios that achieve equal realized risk on all the principal
components of the covariance matrix. This holds true for any other definition
of uncorrelated factors. We then specialize our general formula to the most
agnostic case where the indicators of future returns are assumed to be
uncorrelated and of equal variance. This ""Agnostic Risk Parity"" (AGP) portfolio
minimizes unknown-unknown risks generated by over-optimistic hedging of the
different bets. AGP is shown to fare quite well when applied to standard
technical strategies such as trend following.
"
1610.09085	q-fin	q-fin.CP	"On the difference between locally risk-minimizing and delta hedging
  strategies for exponential L\'evy models"	"  We discuss the difference between locally risk-minimizing and delta hedging
strategies for exponential L\'evy models, where delta hedging strategies in
this paper are defined under the minimal martingale measure. We give firstly
model-independent upper estimations for the difference. In addition we show
numerical examples for two typical exponential L\'evy models: Merton models and
variance gamma models.
"
1610.09124	q-fin	q-fin.MF math.PR q-fin.PR	"Model-independent pricing with insider information: a Skorokhod
  embedding approach"	"  In this paper, we consider the pricing and hedging of a financial derivative
for an insider trader, in a model-independent setting. In particular, we
suppose that the insider wants to act in a way which is independent of any
modelling assumptions, but that she observes market information in the form of
the prices of vanilla call options on the asset. We also assume that both the
insider's information, which takes the form of a set of impossible paths, and
the payoff of the derivative are time-invariant. This setup allows us to adapt
recent work of Beiglboeck, Cox and Huesmann (2016) to prove duality results and
a monotonicity principle, which enables us to determine geometric properties of
the optimal models. Moreover, we show that this setup is powerful, in that we
are able to find analytic and numerical solutions to certain pricing and
hedging problems.
"
1610.09306	q-fin	q-fin.MF	Calls, zonoids, peacocks and log-concavity	"  The main results are two characterisations of log-concave densities in terms
of the collection of lift zonoids corresponding to a peacock. These notions are
recalled and connected to arbitrage-free asset pricing in financial
mathematics.
"
1610.09384	q-fin	q-fin.MF q-fin.GN	"Equitable retirement income tontines: Mixing cohorts without
  discriminating"	"  There is growing interest in the design of pension annuities that insure
against idiosyncratic longevity risk while pooling and sharing systematic risk.
This is partially motivated by the desire to reduce capital and reserve
requirements while retaining the value of mortality credits; see for example
Piggott, Valdez and Detzel (2005) or Donnelly, Guillen and Nielsen (2014). In
this paper we generalize the natural retirement income tontine introduced by
Milevsky and Salisbury (2015) by combining heterogeneous cohorts into one pool.
We engineer this scheme by allocating tontine shares at either a premium or a
discount to par based on both the age of the investor and the amount they
invest. For example, a 55 year-old allocating $\$10,000$ to the tontine might
be told to pay $\$$200 per share and receive 50 shares, while a 75 year-old
allocating $\$8,000$ might pay $\$$40 per share and receive 200 shares. They
would all be mixed together into the same tontine pool and each tontine share
would have equal income rights. The current paper addresses existence and
uniqueness issues and discusses the conditions under which this scheme can be
constructed equitably -- which is distinct from fairly -- even though it isn't
optimal for any cohort. As such, this also gives us the opportunity to compare
and contrast various pooling schemes that have been proposed in the literature
and to differentiate between arrangements that are socially equitable, vs.
actuarially fair vs. economically optimal.
"
1610.09404	q-fin	q-fin.GN	Understanding the Tracking Errors of Commodity Leveraged ETFs	"  Commodity exchange-traded funds (ETFs) are a significant part of the rapidly
growing ETF market. They have become popular in recent years as they provide
investors access to a great variety of commodities, ranging from precious
metals to building materials, and from oil and gas to agricultural products. In
this article, we analyze the tracking performance of commodity leveraged ETFs
and discuss the associated trading strategies. It is known that leveraged ETF
returns typically deviate from their tracking target over longer holding
horizons due to the so-called volatility decay. This motivates us to construct
a benchmark process that accounts for the volatility decay, and use it to
examine the tracking performance of commodity leveraged ETFs. From empirical
data, we find that many commodity leveraged ETFs underperform significantly
against the benchmark, and we quantify such a discrepancy via the novel idea of
\emph{realized effective fee}. Finally, we consider a number of trading
strategies and examine their performance by backtesting with historical price
data.
"
1610.09622	q-fin	q-fin.CP	Numerical study of splitting methods for American option valuation	"  This paper deals with the numerical approximation of American-style option
values governed by partial differential complementarity problems. For a variety
of one- and two-asset American options we investigate by ample numerical
experiments the temporal convergence behaviour of three modern splitting
methods: the explicit payoff approach, the Ikonen-Toivanen approach and the
Peaceman-Rachford method. In addition, the temporal accuracy of these splitting
methods is compared to that of the penalty approach.
"
1610.09714	q-fin	q-fin.PR	"Pricing variance swaps with stochastic volatility and stochastic
  interest rate under full correlation structure"	"  This paper considers the pricing of discretely-sampled variance swaps under
the class of equity-interest rate hybridization. Our modeling framework
consists of the equity which follows the dynamics of the Heston stochastic
volatility model and the stochastic interest rate driven by the
Cox-Ingersoll-Ross (CIR) process with full correlation structure among the
state variables. Since one limitation of hybrid models is the unavailability of
analytical pricing formula of variance swaps due to the non-affinity property,
we obtain an efficient semi-closed form pricing formula of variance swaps for
an approximation of the hybrid model via the derivation of characteristic
functions. We implement numerical experiments to evaluate the accuracy of our
formula and confirm that the impact of the correlation between the underlying
and interest rate is significant.
"
1610.09875	q-fin	q-fin.MF q-fin.PR	"Loading Pricing of Catastrophe Bonds and Other Long-Dated,
  Insurance-Type Contracts"	"  Catastrophe risk is a major threat faced by individuals, companies, and
entire economies. Catastrophe (CAT) bonds have emerged as a method to offset
this risk and a corresponding literature has developed that attempts to provide
a market-consistent pricing methodology for these and other long-dated,
insurance-type contracts. This paper aims to unify and generalize several of
the widely-used pricing approaches for long-dated contracts with a focus on
stylized CAT bonds and market-consistent valuation. It proposes a loading
pricing concept that combines the theoretically possible minimal price of a
contract with its formally obtained risk neutral price, without creating
economically meaningful arbitrage. A loading degree controls how much influence
the formally obtained risk neutral price has on the market price. A key finding
is that this loading degree has to be constant for a minimally fluctuating
contract, and is an important, measurable characteristic for prices of
long-dated contracts. Loading pricing allows long-dated, insurance-type
contracts to be priced less expensively and with higher return on investment
than under classical pricing approaches. Loading pricing enables insurance
companies to accumulate systematically reserves needed to manage its risk of
ruin in a market consistent manner.
"
1610.10029	q-fin	q-fin.PM	Meta-CTA Trading Strategies based on the Kelly Criterion	"  The influence of Commodity Trading Advisors (CTA) on the price process is
explored with the help of a simple model. CTA managers are taken to be Kelly
optimisers, which invest a fixed proportion of their assets in the risky asset
and the remainder in a riskless asset. This requires regular adjustment of the
portfolio weights as prices evolve. The CTA trading activity impacts the price
change in the form of a power law. These two rules governing investment ratios
and price impact are combined and lead through updating at fixed time intervals
to a deterministic price dynamic. For different choices of the model parameters
one gets qualitatively different dynamics. The result can be expressed as a
phase diagram. Meta-CTA strategies can be devised to exploit the predictability
inherent in the model dynamics by avoiding critical areas of the phase diagram
or by taking a contrarian position at an opportune time.
"
1610.10078	q-fin	q-fin.MF q-fin.GN	Optimal retirement income tontines	"  Tontines were once a popular type of mortality-linked investment pool. They
promised enormous rewards to the last survivors at the expense of those died
early. And, while this design appealed to the gambling instinc}, it is a
suboptimal way to generate retirement income. Indeed, actuarially-fair life
annuities making constant payments -- where the insurance company is exposed to
longevity risk -- induce greater lifetime utility. However, tontines do not
have to be structured the historical way, i.e. with a constant cash flow shared
amongst a shrinking group of survivors. Moreover, insurance companies do not
sell actuarially-fair life annuities, in part due to aggregate longevity risk.
  We derive the tontine structure that maximizes lifetime utility. Technically
speaking we solve the Euler-Lagrange equation and examine its sensitivity to
(i.) the size of the tontine pool $n$, and (ii.) individual longevity risk
aversion $\gamma$. We examine how the optimal tontine varies with $\gamma$ and
$n$, and prove some qualitative theorems about the optimal payout.
Interestingly, Lorenzo de Tonti's original structure is optimal in the limit as
longevity risk aversion $\gamma \to \infty$. We define the natural tontine as
the function for which the payout declines in exact proportion to the survival
probabilities, which we show is near-optimal for all $\gamma$ and $n$. We
conclude by comparing the utility of optimal tontines to the utility of loaded
life annuities under reasonable demographic and economic conditions and find
that the life annuity's advantage over the optimal tontine is minimal.
  In sum, this paper's contribution is to (i.) rekindle a discussion about a
retirement income product that has been long neglected, and (ii.) leverage
economic theory as well as tools from mathematical finance to design the next
generation of tontine annuities.
"
1611.00156	q-fin	q-fin.GN q-fin.EC	"Globalization Process in Emerging Capital Markets -- Lessons and
  Implications to China"	"  Since 2002 when China first introduced QFII (Qualified Foreign Institutional
Investors) system, QFII has been developing in China for 14 years, during when
RQFII, Shanghai-Hongkong Stock Connect Program, Shanghai-London Stock Connect
Program furthur broadened the avenue for foreign capital to invest in Chinese
Security Market. As FTA (Free Trade Area) Financial Reform Program emerged, RMB
(CNY) Capital Project is likely to make the currency exchangeable. With the
success in QFII, RQFII and Shanghai-Hongkong Stock Connect Program, China's
long term advantage in interest rate, and the relatively low stock index value
after the recent stock market crashes in mid 2015 and early 2016, foreign
capitals' demand for Chinese market to loosen its restrictions continually
increases. This article picks the three most representative emerging capital
markets in the world, namely Taiwan, Korea and India, by comparing and
analyzing their paths of globalization, attempts to shed light on China's next
steps regarding globalization.
"
1611.00316	q-fin	q-fin.CP math.NA	"Essentially high-order compact schemes with application to stochastic
  volatility models on non-uniform grids"	"  We present high-order compact schemes for a linear second-order parabolic
partial differential equation (PDE) with mixed second-order derivative terms in
two spatial dimensions. The schemes are applied to option pricing PDE for a
family of stochastic volatility models. We use a non-uniform grid with more
grid-points around the strike price. The schemes are fourth-order accurate in
space and second-order accurate in time for vanishing correlation. In our
numerical convergence study we achieve fourth-order accuracy also for non-zero
correlation. A combination of Crank-Nicolson and BDF-4 discretisation is
applied in time. Numerical examples confirm that a standard, second-order
finite difference scheme is significantly outperformed.
"
1611.00464	q-fin	q-fin.CP q-fin.MF	Pricing Bounds for VIX Derivatives via Least Squares Monte Carlo	"  Derivatives on the Chicago Board Options Exchange volatility index (VIX) have
gained significant popularity over the last decade. The pricing of VIX
derivatives involves evaluating the square root of the expected realised
variance which cannot be computed by direct Monte Carlo methods. Least squares
Monte Carlo methods can be used but the sign of the error is difficult to
determine. In this paper, we propose new model independent upper and lower
pricing bounds for VIX derivatives. In particular, we first present a general
stochastic duality result on payoffs involving concave functions. This is then
applied to VIX derivatives along with minor adjustments to handle issues caused
by the square root function. The upper bound involves the evaluation of a
variance swap, while the lower bound involves estimating a martingale increment
corresponding to its hedging portfolio. Both can be achieved simultaneously
using a single linear least square regression. Numerical results show that the
method works very well for VIX futures, calls and puts under a wide range of
parameter choices.
"
1611.00723	q-fin	q-fin.GN physics.soc-ph	Socio-economic inequality and prospects of institutional Econophysics	"  Socio-economic inequality is measured using various indices. The Gini ($g$)
index, giving the overall inequality is the most commonly used, while the
recently introduced Kolkata ($k$) index gives a measure of $1-k$ fraction of
population who possess top $k$ fraction of wealth in the society. This article
reviews the character of such inequalities, as seen from a variety of data
sources, the apparent relationship between the two indices, and what toy models
tell us. These socio-economic inequalities are also investigated in the context
of man-made social conflicts or wars, as well as in natural disasters. Finally,
we forward a proposal for an international institution with sufficient fund for
visitors, where natural and social scientists from various institutions of the
world can come to discuss, debate and formulate further developments.
"
1611.00970	q-fin	q-fin.GN	"Working Paper on Organizational Dynamics within Corporate Venture
  Capital Firms"	"  Corporate venture capital is in the midst of a renaissance. The end of 2015
marked all-time highs both in the number of corporate firms participating in VC
deals and in the amount of capital being deployed by corporate VCs. This paper
explores, rather than defines, how these firms find success in the wake of this
sudden influx of corporate investors. A series of interviews was conducted in
order to capture the direct and indirect objectives, philosophies, and modes of
operation within some of these corporate VC organizations. During the course of
this exploration, numerous operational coherency issues were discovered. Many
firms were implicitly incentivizing conflicting and inconsistent behavior among
their investment team. Perhaps most surprising, the worst offenders were the
more mature corporate VCs who have been in the game for some time. As will be
discussed, fundamental evidence suggests that this misalignment is due to lack
of attention and commitment at the executive level as corporate strategy
evolves.
"
1611.00997	q-fin	q-fin.PM	LQG for portfolio optimization	"  We introduce a generic solver for dynamic portfolio allocation problems when
the market exhibits return predictability, price impact and partial
observability. We assume that the price modeling can be encoded into a linear
state-space and we demonstrate how the problem then falls into the LQG
framework. We derive the optimal control policy and introduce analytical tools
that preserve the intelligibility of the solution. Furthermore, we link the
existence and uniqueness of the optimal controller to a dynamical non-arbitrage
criterion. Finally, we illustrate our method using a synthetic portfolio
allocation problem.
"
1611.01285	q-fin	q-fin.EC q-fin.MF q-fin.PM	Naive Diversification Preferences and their Representation	"  A widely applied diversification paradigm is the naive diversification choice
heuristic. It stipulates that an economic agent allocates equal decision
weights to given choice alternatives independent of their individual
characteristics. This article provides mathematically and economically sound
choice theoretic foundations for the naive approach to diversification. We
axiomatize naive diversification by defining it as a preference for equality
over inequality and derive its relationship to the classical diversification
paradigm. In particular, we show that (i) the notion of permutation invariance
lies at the core of naive diversification and that an economic agent is a naive
diversifier if and only if his preferences are convex and permutation
invariant; (ii) Schur-concave utility functions capture the idea of being
inequality averse on top of being risk averse; and (iii) the transformations,
which rebalance unequal decision weights to equality, are characterized in
terms of their implied turnover.
"
1611.01379	q-fin	q-fin.CP math.NA	"Sparse grid high-order ADI scheme for option pricing in stochastic
  volatility models"	"  We present a sparse grid high-order alternating direction implicit (ADI)
scheme for option pricing in stochastic volatility models. The scheme is
second-order in time and fourth-order in space. Numerical experiments confirm
the computational efficiency gains achieved by the sparse grid combination
technique.
"
1611.01381	q-fin	physics.soc-ph cs.SI q-fin.EC	Revealing the Anatomy of Vote Trading	"  Cooperation in the form of vote trading, also known as logrolling, is central
for law-making processes, shaping the development of democratic societies.
Empirical evidence of logrolling is scarce and limited to highly specific
situations because existing methods are not easily applicable to broader
contexts. We have developed a general and scalable methodology for revealing a
network of vote traders, allowing us to measure logrolling on a large scale.
Analysis on more than 9 million votes spanning 40 years in the U.S. Congress
reveals a higher logrolling prevalence in the Senate and an overall decreasing
trend over recent congresses, coincidental with high levels of political
polarization. Our method is applicable in multiple contexts, shedding light on
many aspects of logrolling and opening new doors in the study of hidden
cooperation.
"
1611.01440	q-fin	q-fin.MF	Liquidity induced asset bubbles via flows of ELMMs	"  We consider a constructive model for asset price bubbles, where the market
price $W$ is endogenously determined by the trading activity on the market and
the fundamental price $W^F$ is exogenously given, as in the work of Jarrow,
Protter and Roch (2012). To justify $W^F$ from a fundamental point of view, we
embed this constructive approach in the martingale theory of bubbles, see
Jarrow, Protter and Shimbo (2010) and Biagini, F\""ollmer and Nedelcu (2014), by
showing the existence of a flow of equivalent martingale measures for $W$,
under which $W^F$ equals the expectation of the discounted future cash flow. As
an application, we study bubble formation and evolution in a financial network.
"
1611.01471	q-fin	q-fin.GN q-fin.EC	"A fair monetization model to reconcile authors and consumers of
  intellectual property"	"  In this small article one compromise monetization strategy is proposed, which
hopefully may lead to a more satisfactory coexistence of IP manufacturers and
consumers. The motto is ""fair exchange"": you use our IP-product, we use your
product (in form of money); when you do not need our product any more, we
change back.
"
1611.01524	q-fin	q-fin.PM q-fin.MF	"`To Have What They are Having': Portfolio Choice for Mimicking
  Mean-Variance Savers"	"  We consider a group of mean-variance investors with mimicking desire such
that each investor is willing to penalize deviations of his portfolio
composition from compositions of other group members. Penalizing norm
constraints are already applied for statistical improvement of Markowitz
portfolio procedure in order to cope with estimation risk. We relate these
penalties to individuals' wish of social learning and introduce a mutual fund
(investment club) aggregating group member preferences unknown for individual
savers. We derive the explicit analytical solution for the fund's optimal
portfolio weights and show advantages to invest in such a fund for individuals
willing to mimic.
"
1611.01767	q-fin	q-fin.EC math.OC stat.ML	EM Algorithm and Stochastic Control in Economics	"  Generalising the idea of the classical EM algorithm that is widely used for
computing maximum likelihood estimates, we propose an EM-Control (EM-C)
algorithm for solving multi-period finite time horizon stochastic control
problems. The new algorithm sequentially updates the control policies in each
time period using Monte Carlo simulation in a forward-backward manner; in other
words, the algorithm goes forward in simulation and backward in optimization in
each iteration. Similar to the EM algorithm, the EM-C algorithm has the
monotonicity of performance improvement in each iteration, leading to good
convergence properties. We demonstrate the effectiveness of the algorithm by
solving stochastic control problems in the monopoly pricing of perishable
assets and in the study of real business cycle.
"
1611.01771	q-fin	q-fin.EC q-fin.GN	An Equilibrium Model with Computationally Constrained Agents	"  We study a large economy in which firms cannot compute exact solutions to the
non-linear equations that characterize the equilibrium price at which they can
sell future output. Instead, firms use polynomial expansions to approximate
prices. The precision with which they can compute prices is endogenous and
depends on the overall level of supply. At the same time, firms' individual
supplies, and thus aggregate supply, depend on the precision with which they
approximate prices. This interrelation between supply and price forecast
induces multiple equilibria, with inefficiently low output, in economies that
otherwise have a unique, efficient equilibrium. Moreover, exogenous parameter
changes, which would increase output were there no computational frictions, can
diminish agents' ability to approximate future prices, and reduce output. Our
model therefore accommodates the intuition that interventions, such as
unprecedented quantitative easing, can put agents into ""uncharted territory"".
"
1611.02026	q-fin	q-fin.PR math.PR q-fin.MF	"Pricing Derivatives in a Regime Switching Market with Time Inhomogeneous
  Volatility"	"  This paper studies pricing derivatives in an age-dependent semi-Markov
modulated market. We consider a financial market where the asset price dynamics
follow a regime switching geometric Brownian motion model in which the
coefficients depend on finitely many age-dependent semi-Markov processes. We
further allow the volatility coefficient to depend on time explicitly. Under
these market assumptions, we study locally risk minimizing pricing of a class
of European options. It is shown that the price function can be obtained by
solving a non-local B-S-M type PDE. We establish existence and uniqueness of a
classical solution of the Cauchy problem. We also find another characterization
of price function via a system of Volterra integral equation of second kind.
This alternative representation leads to computationally efficient methods for
finding price and hedging. Finally, we analyze the PDE to establish continuous
dependence of the solution on the instantaneous transition rates of semi-Markov
processes. An explicit expression of quadratic residual risk is also obtained.
"
1611.02556	q-fin	q-fin.ST	Application of the Generalized Linear Models in Actuarial Framework	"  This paper aims to review the methodology behind the generalized linear
models which are used in analyzing the actuarial situations instead of the
ordinary multiple linear regression. We introduce how to assess the adequacy of
the model which includes comparing nested models using the deviance and the
scaled deviance. The Akiake information criterion is proposed as a
comprehensive tool for selecting the adequate model. We model a simple
automobile portfolio using the generalized linear models, and use the best
chosen model to predict the number of claims made by the policyholders in the
portfolio.
"
1611.02760	q-fin	q-fin.EC	The missing assets and the size of Shadow Banking: an update	"  In a recent paper, using data from Forbes Global 2000, we have observed that
the upper tail of the firm size distribution (by assets) falls off much faster
than a Pareto distribution. The missing mass was suggested as an indicator of
the size of the Shadow Banking (SB) sector. This short note provides the latest
figures of the missing assets for 2013, 2014 and 2015. In 2013 and 2014 the
dynamics of the missing assets continued being strongly correlated with
estimates of the size of the SB sector of the Financial Stability Board. In
2015 we find a sharp decrease in the size of missing assets, suggesting that
the SB sector is deflating.
"
1611.02877	q-fin	q-fin.MF	"Disentangling wrong-way risk: pricing CVA via change of measures and
  drift adjustment"	"  A key driver of Credit Value Adjustment (CVA) is the possible dependency
between exposure and counterparty credit risk, known as Wrong-Way Risk (WWR).
At this time, addressing WWR in a both sound and tractable way remains
challenging: arbitrage-free setups have been proposed by academic research
through dynamic models but are computationally intensive and hard to use in
practice. Tractable alternatives based on resampling techniques have been
proposed by the industry, but they lack mathematical foundations. This probably
explains why WWR is not explicitly handled in the Basel III regulatory
framework in spite of its acknowledged importance. The purpose of this paper is
to propose a new method consisting of an appealing compromise: we start from a
stochastic intensity approach and end up with a pricing problem where WWR does
not enter the picture explicitly. This result is achieved thanks to a set of
changes of measure: the WWR effect is now embedded in the drift of the
exposure, and this adjustment can be approximated by a deterministic function
without affecting the level of accuracy typically required for CVA figures. The
performances of our approach are illustrated through an extensive comparison of
Expected Positive Exposure (EPE) profiles and CVA figures produced either by
(i) the standard method relying on a full bivariate Monte Carlo framework and
(ii) our drift-adjustment approximation. Given the uncertainty inherent to CVA,
the proposed method is believed to provide a promising way to handle WWR in a
sound and tractable way.
"
1611.02952	q-fin	math.PR q-fin.MF	Unexpected Default in an Information Based Model	"  This paper provides sufficient conditions for the time of bankruptcy (of a
company or a state) for being a totally inaccessible stopping time and provides
the explicit computation of its compensator in a framework where the flow of
market information on the default is modelled explicitly with a Brownian bridge
between 0 and 0 on a random time interval.
"
1611.02961	q-fin	math.NA q-fin.CP	"A Finite Volume - Alternating Direction Implicit Approach for the
  Calibration of Stochastic Local Volatility Models"	"  Calibration of stochastic local volatility (SLV) models to their underlying
local volatility model is often performed by numerically solving a
two-dimensional non-linear forward Kolmogorov equation. We propose a novel
finite volume (FV) discretization in the numerical solution of general 1D and
2D forward Kolmogorov equations. The FV method does not require a
transformation of the PDE. This constitutes a main advantage in the calibration
of SLV models as the pertinent PDE coefficients are often nonsmooth. Moreover,
the FV discretization has the crucial property that the total numerical mass is
conserved. Applying the FV discretization in the calibration of SLV models
yields a non-linear system of ODEs. Numerical time stepping is performed by the
Hundsdorfer-Verwer ADI scheme to increase the computational efficiency. The
non-linearity in the system of ODEs is handled by introducing an inner
iteration. Ample numerical experiments are presented that illustrate the
effectiveness of the calibration procedure.
"
1611.03110	q-fin	q-fin.ST	Asynchronous ADRs: Overnight vs Intraday Returns and Trading Strategies	"  American Depositary Receipts (ADRs) are exchange-traded certificates that
rep- resent shares of non-U.S. company securities. They are major financial
instruments for investing in foreign companies. Focusing on Asian ADRs in the
context of asyn- chronous markets, we present methodologies and results of
empirical analysis of their returns. In particular, we dissect their returns
into intraday and overnight com- ponents with respect to the U.S. market hours.
The return difference between the S&P500 index, traded through the SPDR S&P500
ETF (SPY), and each ADR is found to be a mean-reverting time series, and is
fitted to an Ornstein-Uhlenbeck process via maximum-likelihood estimation
(MLE). Our empirical observations also lead us to develop and backtest pairs
trading strategies to exploit the mean-reverting ADR-SPY spreads. We find
consistent positive payoffs when long position in ADR and short position in SPY
are simultaneously executed at selected entry and exit levels.
"
1611.03239	q-fin	q-fin.PR	"Distributional Mellin calculus in $\mathbb{C}^n$, with applications to
  option pricing"	"  We discuss several aspects of Mellin transform, including distributional
Mellin transform and inversion of multiple Mellin-Barnes integrals in
$\mathbb{C}^n$ and its connection to residue expansion or evaluation of Laplace
integrals. These mathematical concepts are demonstrated on several
option-pricing models. This includes European option models such as
Black-Scholes or fractional-diffusion models, as well as evaluation of
quantities related to the optimal exercise price of American options.
"
1611.03740	q-fin	q-fin.GN	"Properties of the financial break-even point in a simple investment
  project as a function of the discount rate"	"  We consider a simple investment project with the following parameters: I>0:
Initial investment which is amortizable in n years; n: Number of years the
investment allows production with constant output per year; A>0: Annual
amortization (A=I/n); Q>0: Quantity of products sold per year; Cv>0: Variable
cost per unit; p>0: Price of the product with p>Cv; Cf>0: Annual fixed costs;
te: Tax of earnings; r: Annual discount rate. We also assume inflation is
negligible. We derive a closed expression of the financial break-even point Qf
(i.e. the value of Q for which the net present value (NPV) is zero) as a
function of the parameters I, n, Cv, Cf, te, r, p. We study the behavior of Qf
as a function of the discount rate r and we prove that: (i) For r negligible Qf
equals the accounting break-even point Qc (i.e. the earnings before taxes (EBT)
is null) ; (ii) When r is large the graph of the function Qf=Qf(r) has an
asymptotic straight line with positive slope. Moreover, Qf(r) is an strictly
increasing and convex function of the variable r; (iii) From a sensitivity
analysis we conclude that, while the influence of p and Cv on Qf is strong, the
influence of Cf on Qf is weak.
"
1611.03782	q-fin	q-fin.RM physics.soc-ph	"What do central counterparties default funds really cover? A
  network-based stress test answer"	"  In the last years, increasing efforts have been put into the development of
effective stress tests to quantify the resilience of financial institutions.
Here we propose a stress test methodology for central counterparties based on a
network characterization of clearing members, whose links correspond to direct
credits and debits. This network constitutes the ground for the propagation of
financial distress: equity losses caused by an initial shock with both
exogenous and endogenous components reverberate within the network and are
amplified through credit and liquidity contagion channels. At the end of the
dynamics, we determine the vulnerability of each clearing member, which
represents its potential equity loss. We apply the proposed framework to the
Fixed Income asset class of CC&G, the central counterparty operating in Italy
whose main cleared securities are Italian Government Bonds. We consider two
different scenarios: a distributed, plausible initial shock, as well as a shock
corresponding to the cover 2 regulatory requirement (the simultaneous default
of the two most exposed clearing members). Although the two situations lead to
similar results after an unlimited reverberation of shocks on the network, the
distress propagation is much more hasty in the latter case, with a large number
of additional defaults triggered at early stages of the dynamics. Our results
thus show that setting a default fund to cover insolvencies only on a cover 2
basis may not be adequate for taming systemic events, and only very
conservative default funds, such as CC&G's one, can face total losses due to
the shock propagation. Overall, our network-based stress test represents a
refined tool for calibrating default fund amounts.
"
1611.04320	q-fin	q-fin.PR	"Regularization and analytic option pricing under $\alpha$-stable
  distribution of arbitrary asymmetry"	"  We consider a non-Gaussian option pricing model, into which the underlying
log-price is assumed to be driven by an $\alpha$-stable distribution. We remove
the a priori divergence of the model by introducing a Mellin regularization for
the L\'evy propagator. Using distributional and $\mathbb{C}^n$ tools, we derive
an analytic closed formula for the option price, valid for any stability
$\alpha\in]1,2]$ and any asymmetry. This formula is very efficient and recovers
previous cases (Black-Scholes, Carr-Wu); we calibrate the formula on market
datas, make numerical tests, and discuss its many interesting properties.
"
1611.04851	q-fin	q-fin.RM q-fin.ST	"Multinomial VaR Backtests: A simple implicit approach to backtesting
  expected shortfall"	"  Under the Fundamental Review of the Trading Book (FRTB) capital charges for
the trading book are based on the coherent expected shortfall (ES) risk
measure, which show greater sensitivity to tail risk. In this paper it is
argued that backtesting of expected shortfall - or the trading book model from
which it is calculated - can be based on a simultaneous multinomial test of
value-at-risk (VaR) exceptions at different levels, an idea supported by an
approximation of ES in terms of multiple quantiles of a distribution proposed
in Emmer et al. (2015). By comparing Pearson, Nass and likelihood-ratio tests
(LRTs) for different numbers of VaR levels $N$ it is shown in a series of
simulation experiments that multinomial tests with $N\geq 4$ are much more
powerful at detecting misspecifications of trading book loss models than
standard binomial exception tests corresponding to the case $N=1$. Each test
has its merits: Pearson offers simplicity; Nass is robust in its size
properties to the choice of $N$; the LRT is very powerful though slightly
over-sized in small samples and more computationally burdensome. A
traffic-light system for trading book models based on the multinomial test is
proposed and the recommended procedure is applied to a real-data example
spanning the 2008 financial crisis.
"
1611.04877	q-fin	q-fin.PM	"The Asset Liability Management problem of a nuclear operator : a
  numerical stochastic optimization approach"	"  We numerically study an Asset Liability Management problem linked to the
decommissioning of French nuclear power plants. We link the risk aversion of
practitioners to an optimization problem. Using different price models we show
that the optimal solution is linked to a de-risking management strategy similar
to a concave strategy and we propose an effective heuristic to simulate the
underlying optimal strategy. Besides we show that the strategy is stable with
respect to the main parameters involved in the liability problem.
"
1611.05194	q-fin	q-fin.MF	"Computation of first-order Greeks for barrier options using chain rules
  for Wiener path integrals"	"  This paper presents a new methodology to compute first-order Greeks for
barrier options under the framework of path-dependent payoff functions with
European, Lookback, or Asian type and with time-dependent trigger levels. In
particular, we develop chain rules for Wiener path integrals between two curves
that arise in the computation of first-order Greeks for barrier options. We
also illustrate the effectiveness of our method through numerical examples.
"
1611.05518	q-fin	q-fin.PR q-fin.MF	Robust Trading of Implied Skew	"  In this paper, we present a method for constructing a (static) portfolio of
co-maturing European options whose price sign is determined by the skewness
level of the associated implied volatility. This property holds regardless of
the validity of a specific model - i.e. the method is robust. The strategy is
given explicitly and depends only on beliefs about the future values of implied
skewness, which is an observable market indicator. As such, our method allows
to use the existing statistical tools to formulate the beliefs, providing a
practical interpretation of the more abstract mathematical setting, in which
the belies are understood as a family of probability measures. One of the
applications of our results is a method for trading views on the future changes
in implied skew, largely independently of other market factors. Another
application provides a concrete improvement of the existing model-independent
super- and sub- replication strategies for barrier options, which exploits a
given set of beliefs on the implied skew. Our theoretical results are tested
empirically, using the historical prices of SP500 options.
"
1611.05688	q-fin	q-fin.GN	"The Tragedy of Your Upstairs Neighbors: Is the Airbnb Negative
  Externality Internalized?"	"  A commonly expressed concern about the rise of the peer-to-peer rental market
Airbnb is that hosts---those renting out their properties---impose costs on
their unwitting neighbors. I consider the question of whether apartment
building owners will, in a competitive rental market, set a building-specific
Airbnb hosting policy that is socially efficient. I find that if tenants can
sort across apartments based on the owners policy then the equilibrium fraction
of buildings allowing Airbnb listing would be socially efficient.
"
1611.06010	q-fin	q-fin.RM q-fin.ST stat.AP	Value-at-Risk Prediction in R with the GAS Package	"  GAS models have been recently proposed in time-series econometrics as
valuable tools for signal extraction and prediction. This paper details how
financial risk managers can use GAS models for Value-at-Risk (VaR) prediction
using the novel GAS package for R. Details and code snippets for prediction,
comparison and backtesting with GAS models are presented. An empirical
application considering Dow Jones Index constituents investigates the VaR
forecasting performance of GAS models.
"
1611.06098	q-fin	math.NA q-fin.MF	"On the wavelets-based SWIFT method for backward stochastic differential
  equations"	"  We propose a numerical algorithm for backward stochastic differential
equations based on time discretization and trigonometric wavelets. This method
combines the effectiveness of Fourier-based methods and the simplicity of a
wavelet-based formula, resulting in an algorithm that is both accurate and easy
to implement. Furthermore, we mitigate the problem of errors near the
computation boundaries by means of an antireflective boundary technique, giving
an improved approximation. We test our algorithm with different numerical
experiments.
"
1611.06181	q-fin	q-fin.CP	"Calibration to American Options: Numerical Investigation of the
  de-Americanization"	"  American options are the reference instruments for the model calibration of a
large and important class of single stocks. For this task, a fast and accurate
pricing algorithm is indispensable. The literature mainly discusses pricing
methods for American options that are based on Monte Carlo, tree and partial
differential equation methods. We present an alternative approach that has
become popular under the name de-Americanization in the financial industry. The
method is easy to implement and enjoys fast run-times. Since it is based on ad
hoc simplifications, however, theoretical results guaranteeing reliability are
not available. To quantify the resulting methodological risk, we empirically
test the performance of the de-Americanization method for calibration. We
classify the scenarios in which de-Americanization performs very well. However,
we also identify the cases where de-Americanization oversimplifies and can
result in large errors.
"
1611.06407	q-fin	q-fin.ST q-fin.CP	"Interplay between endogenous and exogenous fluctuations in financial
  markets"	"  We address microscopic, agent based, and macroscopic, stochastic, modeling of
the financial markets combining it with the exogenous noise. The interplay
between the endogenous dynamics of agents and the exogenous noise is the
primary mechanism responsible for the observed long-range dependence and
statistical properties of high volatility return intervals. By exogenous noise
we mean information flow or/and order flow fluctuations. Numerical results
based on the proposed model reveal that the exogenous fluctuations have to be
considered as indispensable part of comprehensive modeling of the financial
markets.
"
1611.06452	q-fin	math.NA q-fin.CP	Model reduction for calibration of American options	"  American put options are among the most frequently traded single stock
options, and their calibration is computationally challenging since no
closed-form expression is available. Due to the higher flexibility in
comparison to European options, the mathematical model involves additional
constraints, and a variational inequality is obtained. We use the Heston
stochastic volatility model to describe the price of a single stock option. In
order to speed up the calibration process, we apply two model reduction
strategies. Firstly, a reduced basis method (RBM) is used to define a suitable
low-dimensional basis for the numerical approximation of the
parameter-dependent partial differential equation ($\mu$PDE) model. By doing so
the computational complexity for solving the $\mu$PDE is drastically reduced,
and applications of standard minimization algorithms for the calibration are
significantly faster than working with a high-dimensional finite element basis.
Secondly, so-called de-Americanization strategies are applied. Here, the main
idea is to reformulate the calibration problem for American options as a
problem for European options and to exploit closed-form solutions. Both
reduction techniques are systematically compared and tested for both synthetic
and market data sets.
"
1611.06666	q-fin	q-fin.TR q-fin.ST	"Quantifying immediate price impact of trades based on the $k$-shell
  decomposition of stock trading networks"	"  Traders in a stock market exchange stock shares and form a stock trading
network. Trades at different positions of the stock trading network may contain
different information. We construct stock trading networks based on the limit
order book data and classify traders into $k$ classes using the $k$-shell
decomposition method. We investigate the influences of trading behaviors on the
price impact by comparing a closed national market (A-shares) with an
international market (B-shares), individuals and institutions, partially filled
and filled trades, buyer-initiated and seller-initiated trades, and trades at
different positions of a trading network. Institutional traders professionally
use some trading strategies to reduce the price impact and individuals at the
same positions in the trading network have a higher price impact than
institutions. We also find that trades in the core have higher price impacts
than those in the peripheral shell.
"
1611.08330	q-fin	q-fin.GN q-fin.EC	"The 2015-2017 policy changes to the means-tests of Australian Age
  Pension: implication to decisions in retirement"	"  The Australian Government uses the means-test as a way of managing the
pension budget. Changes in Age Pension policy impose difficulties in retirement
modelling due to policy risk, but any major changes tend to be `grandfathered'
meaning that current retirees are exempt from the new changes. In 2015, two
important changes were made in regards to allocated pension accounts -- the
income means-test is now based on deemed income rather than account
withdrawals, and the income-test deduction no longer applies. We examine the
implications of the new changes in regards to optimal decisions for
consumption, investment, and housing. We account for regulatory minimum
withdrawal rules that are imposed by regulations on allocated pension accounts,
as well as the 2017 asset-test rebalancing. The new policy changes are modelled
in a utility maximizing lifecycle model and solved as an optimal stochastic
control problem. We find that the new rules decrease the benefits from planning
the consumption in relation to the means-test, while the housing allocation
increases slightly in order to receive additional Age Pension. The difference
in optimal drawdown between the old and new policy are only noticeable early in
retirement until regulatory minimum withdrawal rates are enforced. However, the
amount of extra Age Pension received for many households is now significantly
different due to the new deeming income rules, which benefit slightly wealthier
households who previously would receive no Age Pension due to the income-test
and minimum withdrawals.
"
1611.08393	q-fin	q-fin.PM q-fin.CP	Mean-Reverting Portfolio Design via Majorization-Minimization Method	"  This paper considers the mean-reverting portfolio design problem arising from
statistical arbitrage in the financial markets. The problem is formulated by
optimizing a criterion characterizing the mean-reversion strength of the
portfolio and taking into consideration the variance of the portfolio and an
investment budget constraint at the same time. An efficient algorithm based on
the majorization-minimization (MM) method is proposed to solve the problem.
Numerical results show that our proposed mean-reverting portfolio design method
can significantly outperform every underlying single spread and the benchmark
method in the literature.
"
1611.09062	q-fin	q-fin.MF math.PR q-fin.PR q-fin.RM	"Generalization of Doob Decomposition Theorem and Risk Assessment in
  Incomplete Markets"	"  In the paper, we introduce the notion of a local regular supermartingale
relative to a convex set of equivalent measures and prove for it the necessary
and sufficient conditions of optional Doob decomposition in the discrete case.
This Theorem is a generalization of the famous Doob decomposition onto the case
of supermartingales relative to a convex set of equivalent measures. The
description of all local regular supermartingales relative to a convex set of
equivalent measures is presented. A notion of complete set of equivalent
measures is introduced. We prove that every non negative bounded
supermartingale relative to a complete set of equivalent measures is local
regular. A new definition of fair price of contingent claim in incomplete
market is given and a formula for fair price of Standard option of European
type is found.
"
1611.09631	q-fin	q-fin.MF math.PR	"Cover's universal portfolio, stochastic portfolio theory and the
  numeraire portfolio"	"  Cover's celebrated theorem states that the long run yield of a properly
chosen ""universal"" portfolio is as good as the long run yield of the best
retrospectively chosen constant rebalanced portfolio. The ""universality""
pertains to the fact that this result is model-free, i.e., not dependent on an
underlying stochastic process. We extend Cover's theorem to the setting of
stochastic portfolio theory as initiated by R. Fernholz: the rebalancing rule
need not to be constant anymore but may depend on the present state of the
stock market. This model-free result is complemented by a comparison with the
log-optimal numeraire portfolio when fixing a stochastic model of the stock
market. Roughly speaking, under appropriate assumptions, the optimal long run
yield coincides for the three approaches mentioned in the title of this paper.
We present our results in discrete and continuous time.
"
1611.09893	q-fin	q-fin.GN cs.SI physics.soc-ph	"Exploring the Uncharted Export: an Analysis of Tourism-Related Foreign
  Expenditure with International Spend Data"	"  Tourism is one of the most important economic activities in the world: for
many countries it represents the single largest product in their export basket.
However, it is a product difficult to chart: ""exporters"" of tourism do not ship
it abroad, but they welcome importers inside the country. Current research uses
social accounting matrices and general equilibrium models, but the standard
industry classifications they use make it hard to identify which domestic
industries cater to foreign visitors. In this paper, we make use of open source
data and of anonymized and aggregated transaction data giving us insights about
the spend behavior of foreigners inside two countries, Colombia and the
Netherlands, to inform our research. With this data, we are able to describe
what constitutes the tourism sector, and to map the most attractive
destinations for visitors. In particular, we find that countries might observe
different geographical tourists' patterns -- concentration versus
decentralization --; we show the importance of distance, a country's reported
wealth and cultural affinity in informing tourism; and we show the potential of
combining open source data and anonymized and aggregated transaction data on
foreign spend patterns in gaining insight as to the evolution of tourism from
one year to another.
"
1611.09926	q-fin	q-fin.EC cs.AI	Choquet integral in decision analysis - lessons from the axiomatization	"  The Choquet integral is a powerful aggregation operator which lists many
well-known models as its special cases. We look at these special cases and
provide their axiomatic analysis. In cases where an axiomatization has been
previously given in the literature, we connect the existing results with the
framework that we have developed. Next we turn to the question of learning,
which is especially important for the practical applications of the model. So
far, learning of the Choquet integral has been mostly confined to the learning
of the capacity. Such an approach requires making a powerful assumption that
all dimensions (e.g. criteria) are evaluated on the same scale, which is rarely
justified in practice. Too often categorical data is given arbitrary numerical
labels (e.g. AHP), and numerical data is considered cardinally and ordinally
commensurate, sometimes after a simple normalization. Such approaches clearly
lack scientific rigour, and yet they are commonly seen in all kinds of
applications. We discuss the pros and cons of making such an assumption and
look at the consequences which axiomatization uniqueness results have for the
learning problems. Finally, we review some of the applications of the Choquet
integral in decision analysis. Apart from MCDA, which is the main area of
interest for our results, we also discuss how the model can be interpreted in
the social choice context. We look in detail at the state-dependent utility,
and show how comonotonicity, central to the previous axiomatizations, actually
implies state-independency in the Choquet integral model. We also discuss the
conditions required to have a meaningful state-dependent utility representation
and show the novelty of our results compared to the previous methods of
building state-dependent models.
"
1612.00221	q-fin	q-fin.EC cs.LG nlin.AO	The Coconut Model with Heterogeneous Strategies and Learning	"  In this paper, we develop an agent-based version of the Diamond search
equilibrium model - also called Coconut Model. In this model, agents are faced
with production decisions that have to be evaluated based on their expectations
about the future utility of the produced entity which in turn depends on the
global production level via a trading mechanism. While the original dynamical
systems formulation assumes an infinite number of homogeneously adapting agents
obeying strong rationality conditions, the agent-based setting allows to
discuss the effects of heterogeneous and adaptive expectations and enables the
analysis of non-equilibrium trajectories. Starting from a baseline
implementation that matches the asymptotic behavior of the original model, we
show how agent heterogeneity can be accounted for in the aggregate dynamical
equations. We then show that when agents adapt their strategies by a simple
temporal difference learning scheme, the system converges to one of the fixed
points of the original system. Systematic simulations reveal that this is the
only stable equilibrium solution.
"
1612.00270	q-fin	physics.soc-ph q-fin.GN	"Predicting the rise of right-wing populism in response to unbalanced
  immigration"	"  Among the central tenets of globalization is free migration of labor.
Although much has been written about its benefits, little is known about the
limitations of globalization, including how immigration affects the
anti-globalist sentiment. Analyzing polls data, we find that over the last
three years in a group of EU countries affected by the recent migrant crisis,
the percentage of right-wing (RW) populist voters in a given country depends on
the prevalence of immigrants in this country's population and the total
immigration inflow into the entire EU. The latter is likely due to the EU
resembling a supranational state, where the lack of inner borders causes that
""somebody else's problem"" easily turns into ""my problem"". We further find that
the increase in the percentage of RW voters substantially surpasses the
immigration inflow, implying that if this process continues, RW populism may
democratically prevail and eventually lead to a demise of globalization. We
present evidence for tipping points in relation to the rise of RW populism.
Finally, we model these empirical findings using a complex network framework
wherein the success of globalization largely rests on the balance between
immigration and immigrant integration.
"
1612.00402	q-fin	cs.CE q-fin.CP	"Reduced Order Models for Pricing European and American Options under
  Stochastic Volatility and Jump-Diffusion Models"	"  European options can be priced by solving parabolic partial(-integro)
differential equations under stochastic volatility and jump-diffusion models
like Heston, Merton, and Bates models. American option prices can be obtained
by solving linear complementary problems (LCPs) with the same operators. A
finite difference discretization leads to a so-called full order model (FOM).
Reduced order models (ROMs) are derived employing proper orthogonal
decomposition (POD). The early exercise constraint of American options is
enforced by a penalty on subset of grid points. The presented numerical
experiments demonstrate that pricing with ROMs can be orders of magnitude
faster within a given model parameter variation range.
"
1612.00720	q-fin	q-fin.MF	Optimal consumption and investment under transaction costs	"  In this article we consider the Merton problem in a market with a single
risky asset and transaction costs. We give a complete solution of the problem
up to the solution of a free-boundary problem for a first-order differential
equation, and find that the form of the solution (whether the problem is
well-posed, whether the problem is well-posed only for large transaction costs,
whether the no-transaction wedge lies in the first, second or fourth quadrants)
depends only on a quadratic whose co-efficients are functions of the parameters
of the problem, and then only through the value and slope of this quadratic at
zero, one and the turning point.
  We find that for some parameter values and for large transaction costs the
location of the boundary at which sales of the risky asset occur is independent
of the transaction cost on purchases. We give both a mathematical and financial
reason for this phenomena.
"
1612.00780	q-fin	q-fin.PR	A Market Driver Volatility Model via Policy Improvement Algorithm	"  In the over-the-counter market in derivatives, we sometimes see large numbers
of traders taking the same position and risk. When there is this kind of
concentration in the market, the position impacts the pricings of all other
derivatives and changes the behaviour of the underlying volatility in a
nonlinear way. We model this effect using Heston's stochastic volatility model
modified to take into account the impact. The impact can be incorporated into
the model using a special product called a market driver, potentially with a
large face value, affecting the underlying volatility itself. We derive a
revised version of Heston's partial differential equation which is to be
satisfied by arbitrary derivatives products in the market. This enables us to
obtain valuations that reflect the actual market and helps traders identify the
risks and hold appropriate assets to correctly hedge against the impact of the
market driver.
"
1612.00828	q-fin	q-fin.PR q-fin.GN	A New Set of Financial Instruments	"  We develop a new method for hedging derivatives based on the premise that a
hedger should not always rely on a universal set of trading instruments that
are used to form a linear portfolio of the stock, riskless bond and standard
derivatives, but rather should design a set of specific, most suited financial
instruments for the hedging problem. We introduce a sequence of new financial
instruments best suited for hedging in jump-diffusion and stochastic volatility
market models and those with long-range dependence. Our methods lead to a new
set of partial and partial and partial-integro differential equations for
pricing derivatives.
"
1612.00833	q-fin	q-fin.GN q-fin.EC	"Measuring and Analyzing the Shares of Economic Growth Sources in the
  Mining Sector of Iran: A Neoclassical Growth Accounting Approach"	"  The purpose of this study is to measure the Total Factor Productivity (TFP)
growth and determine the share of each of the economic growth sources in the
mining sector of Iran. The time period of this study is 1355-1385 of the Solar
Hijri calendar (roughly overlaying with the time period of 1976-2006 of the
Gregorian calendar). In this paper, the shares of total factor productivity
growth (TFPG) and factors' accumulations in the economic growth of the mining
sector are estimated using a neoclassical growth accounting approach. Based on
the estimated restricted Cobb-Douglas production function and the results
obtained from the Solow residual equation, the annual growth rates of TFP were
measured for each year. According to the findings, the average annual growth
rate of TFP has been 2.94% during the time period of the present study. The
other findings of this study indicate that the average contributions of TFPG,
labor accumulation and capital accumulation in the economic growth of the
mining sector have been 56%, 23%, and 21%, respectively, during the time period
of the study. As such, it can be concluded that the policy of benefiting from
available factors in the mining sector together with the policy of accumulating
factors have simultaneously caused the value-added growth of this sector.
Therefore, considering the desired performance of the mining sector in terms of
its sizable productivity growth, it can be argued that the mining sector can
aid Iran's economic development plans to achieve their assigned economic
objectives, one of which is to increase the share of total factor productivity
growth in economic growth.
"
1612.01013	q-fin	q-fin.MF	"Long-Term Growth Rate of Expected Utility for Leveraged ETFs: Martingale
  Extraction Approach"	"  This paper studies the long-term growth rate of expected utility from holding
a leveraged exchanged-traded fund (LETF), which is a constant proportion
portfolio of the reference asset. Working with the power utility function, we
develop an analytical approach that employs martingale extraction and involves
finding the eigenpair associated with the infinitesimal generator of a
Markovian time-homogeneous diffusion. We derive explicitly the long-term growth
rates under a number of models for the reference asset, including the geometric
Brownian motion model, GARCH model, inverse GARCH model, extended CIR model,
3/2 model, quadratic model, as well as the Heston and 3/2 stochastic volatility
models. We also investigate the impact of stochastic interest rate such as the
Vasicek model and the inverse GARCH short rate model. We determine the optimal
leverage ratio for the long-term investor and examine the effects of model
parameters.
"
1612.01132	q-fin	q-fin.GN q-fin.RM	A Model of Synchronization for Self-Organized Crowding Behavior	"  This paper proposes a general model for synchronized crowding behavior. An
order parameter is introduced to quantify the level of synchronization which is
shown a function of percentage of agents in reactive state. Further,
synchronization is shown to be driven by the most active agents with the
highest volatility. A tipping point is identified when crowd becomes
self-amplifying and unstable. By applying this model, financial bubbles, market
momentum and volatility patterns are simulated.
"
1612.01155	q-fin	q-fin.GN	A Multifaceted Panel Data Gravity Model Analysis of Peru's Foreign Trade	"  Peru's abundant natural resources and friendly trade policies has made the
country a major economic player in both South America and the global community.
Consequently, exports are playing an increasingly important role in Peru's
national economy. Indeed, growing from 13.1% as of 1994, exports now contribute
approximately 21% of the GDP of Peru as of 2015. Given Peru's growing global
influence, the time is ripe for a thorough analysis of the most important
factors governing its export performance. Thus, within the framework of the
augmented gravity model of trade, this paper examines Peru's export performance
and attempts to identify the dominant economic factors that should be further
developed to increase the value of exports. The analysis was conducted from
three different aspects: (1) general economic parameters' effect on Peru's
export value, (2) more specific analysis into a major specific trade good,
copper, and (3) the impact that regional trade agreements have had on Peru's
export performance. Our panel data analysis results for each dataset revealed
interesting economic trends and were consistent with the theoretical
expectations of the gravity model: namely positive coefficients for economic
size and negative coefficients for distance. This report's results can be a
reference for the proper direction of Peruvian economic policy so as to enhance
economic growth in a sustainable direction.
"
1612.01327	q-fin	q-fin.MF	A multi-asset investment and consumption problem with transaction costs	"  In this article we study a multi-asset version of the Merton investment and
consumption problem with proportional transaction costs. In general it is
difficult to make analytical progress towards a solution in such problems, but
we specialise to a case where transaction costs are zero except for sales and
purchases of a single asset which we call the illiquid asset.
  Assuming agents have CRRA utilities and asset prices follow exponential
Brownian motions we show that the underlying HJB equation can be transformed
into a boundary value problem for a first order differential equation. The
optimal strategy is to trade the illiquid asset only when the fraction of the
total portfolio value invested in this asset falls outside a fixed interval.
Important properties of the multi-asset problem (including when the problem is
well-posed, ill-posed, or well-posed only for large transaction costs) can be
inferred from the behaviours of a quadratic function of a single variable and
another algebraic function.
"
1612.01951	q-fin	q-fin.MF	Stability of calibration procedures: fractals in the Black-Scholes model	"  Usually, in the Black-Scholes pricing theory the volatility is a positive
real parameter. Here we explore what happens if it is allowed to be a complex
number. The function for pricing a European option with a complex volatility
has essential singularities at zero and infinity. The singularity at zero
reflects the put-call parity. Solving for the implied volatility that
reproduces a given market price yields not only a real root, but also
infinitely many complex roots in a neighbourhood of the origin. The
Newton-Raphson calculation of the complex implied volatility has a chaotic
nature described by fractals.
"
1612.01979	q-fin	q-fin.PR	"Multi-Purpose Binomial Model: Fitting all Moments to the Underlying
  Geometric Brownian Motion"	"  We construct a binomial tree model fitting all moments to the approximated
geometric Brownian motion. Our construction generalizes the classical
Cox-Ross-Rubinstein, the Jarrow-Rudd, and the Tian binomial tree models. The
new binomial model is used to resolve a discontinuity problem in option
pricing.
"
1612.02112	q-fin	q-fin.MF	Financial market with no riskless (safe) asset	"  We study markets with no riskless (safe) asset. We derive the corresponding
Black-Scholes-Merton option pricing equations for markets where there are only
risky assets which have the following price dynamics: (i) continuous
diffusions; (ii) jump-diffusions; (iii) diffusions with stochastic
volatilities, and; (iv) geometric fractional Brownian and Rosenblatt motions.
No arbitrage and market completeness conditions are derived in all four cases.
"
1612.02312	q-fin	q-fin.PR math.PR	"Game options with gradual exercise and cancellation under proportional
  transaction costs"	"  Game (Israeli) options in a multi-asset market model with proportional
transaction costs are studied in the case when the buyer is allowed to exercise
the option and the seller has the right to cancel the option gradually at a
mixed (or randomised) stopping time, rather than instantly at an ordinary
stopping time. Allowing gradual exercise and cancellation leads to increased
flexibility in hedging, and hence tighter bounds on the option price as
compared to the case of instantaneous exercise and cancellation. Algorithmic
constructions for the bid and ask prices, and the associated superhedging
strategies and optimal mixed stopping times for both exercise and cancellation
are developed and illustrated. Probabilistic dual representations for bid and
ask prices are also established.
"
1612.02567	q-fin	q-fin.ST	Order statistics of horse racing and the randomly broken stick	"  We find a remarkable agreement between the statistics of a randomly divided
interval and the observed statistical patterns and distributions found in horse
racing betting markets. We compare the distribution of implied winning odds,
the average true winning probabilities, the implied odds conditional on a win,
and the average implied odds of the winning horse with the corresponding
quantities from the ""randomly broken stick problem"". We observe that the market
is at least to some degree informationally efficient. From the mapping between
exponential random variables and the statistics of the random division we
conclude that horses' true winning abilities are exponentially distributed.
"
1612.02653	q-fin	q-fin.EC	"Are Chinese transport policies effective? A new perspective from direct
  pollution rebound effect, and empirical evidence from road transport sector"	"  The air pollution has become a serious challenge in China. Emissions from
motor vehicles have been found as one main source of air pollution. Although
the Chinese government has taken numerous policies to mitigate the harmful
emissions from road transport sector, it is still uncertain for both policy
makers and researchers to know to what extent the policies are effective in the
short and long terms. Inspired by the concept and empirical results from
current literature on energy rebound effect (ERE), we first propose a new
concept of pollution rebound effect (PRE). Then, we estimate direct air PRE as
a measure for the effectiveness of the policies of reducing air pollution from
transport sector based on time-series data from the period 1986-2014. We find
that the short-term direct air PRE is -1.4105, and the corresponding long-run
PRE is -1.246. The negative results indicate that the direct air PRE does not
exist in road passenger transport sector in China, either in the short term or
in the long term during the period 1986-2014. This implies that the Chinese
transport policies are effective in terms of harmful emissions reduction in the
transport sector. This research, to the best of our knowledge, is the first
attempt to quantify the effectiveness of the transport policies in the
transitional China.
"
1612.02654	q-fin	q-fin.EC	"China building energy consumption: definitions and measures from an
  operational perspective"	"  There is an increasing awareness of the significance of Chinese building
energy consumption(BEC). However, something worth discussing is that estimate
the building energy consumption adopting the definition of life cycle or
operation. In the existing studies with various evaluation methods, the issue
about the amount of energy consumed by China buildings has not been understood.
In order to settle the disputes over the calculation of BEC, this paper
establish an appropriate accounting method of building energy to present BEC
situation in China and lay the foundation for building energy efficiency.
Adopting the conception of building operational energy consumption, we find
that the energy consumption of buildings just accounts for 15% - 16% of the
final total energy consumption in China; by contrast, the previous calculations
usually have double accounting through top-down approach if central heat-supply
of buildings was given into additional consideration.
"
1612.02656	q-fin	q-fin.EC	"The demand for road transport in China: imposing theoretical regularity
  and flexible functional forms selection"	"  Road transport sector is found to be one of the major emitters, and
responsible for serious air pollution and huge pubic health losses. One
important parameter for determining the consequences of transport demand shocks
for the macroeconomy, air pollution and public health is the elasticity of the
demand for transport. Most published studies that use flexible functional forms
have ignored the theoretical regularity conditions implied by microeconomic
theories. Moreover, even a few studies have checked and/or imposed regularity
conditions, most of them equate curvature alone with regularity, thus ignoring
or minimizing the importance of other regularities. And then, the results
appear biased and may in fact be biased. Therefore, we select three of the most
widely used flexible functional forms, the Rotterdam model, the Almost Ideal
Demand System (AIDS), and the quadratic AIDS (QUAIDS) to investigate the demand
for road transport in China using recent annual expenditure data, over a 13
year period from 2002 to 2014, on three expenditure categories in the
transportation sector: private transportation, local transportation and
intercity transportation. Estimation shows that the AIDS model is the only
model that is able to provide theoretically consistent estimates of the
residents demand for road transport in China. Our estimates show that the
private transportation is a luxury among the transportation goods, and is
elastic in price changes relatively. The empirical results imply that the
private and the local transportation, the local and intercity transportation
are gross complements. And, the private transportation is a substitute for the
inter-city transportation, while the intercity transportation is a complement
of the private transportation.
"
1612.02658	q-fin	q-fin.EC	"The distribution dynamics of Carbon Dioxide Emission intensity across
  Chinese provinces: A weighted Approach"	"  This paper examines the distribution dynamics of carbon dioxide (CO2)
emission intensity across 30 Chinese provinces using a weighted distribution
dynamics approach. The results show that CO2 emission intensity tends to
diverge during the sample period of 1995-2014. However, convergence clubs are
found in the ergodic distributions of the full sample and two sub-sample
periods. Divergence, polarization and stratification are the dominant
characteristics in the distribution dynamics. Weightings with economic and
population sizes have important impacts on current distributions and hence long
run steady distributions. Neglecting economic size may under-estimate the
deterioration in the long run steady state. The result also shows that
conditioning on space and income cannot eliminate the multimodality in the long
run distribution. However, capital intensity has important impact on the
formation of convergence clubs. Our findings have contributions in the
understanding of the spatial dynamic behaviours of CO2 emissions across Chinese
provinces, and have important policy implications for CO2 emissions reduction
in China.
"
1612.02666	q-fin	q-fin.ST cs.LG stat.ML	"Evaluating the Performance of ANN Prediction System at Shanghai Stock
  Market in the Period 21-Sep-2016 to 11-Oct-2016"	"  This research evaluates the performance of an Artificial Neural Network based
prediction system that was employed on the Shanghai Stock Exchange for the
period 21-Sep-2016 to 11-Oct-2016. It is a follow-up to a previous paper in
which the prices were predicted and published before September 21. Stock market
price prediction remains an important quest for investors and researchers. This
research used an Artificial Intelligence system, being an Artificial Neural
Network that is feedforward multi-layer perceptron with error backpropagation
for prediction, unlike other methods such as technical, fundamental or time
series analysis. While these alternative methods tend to guide on trends and
not the exact likely prices, neural networks on the other hand have the ability
to predict the real value prices, as was done on this research. Nonetheless,
determination of suitable network parameters remains a challenge in neural
network design, with this research settling on a configuration of 5:21:21:1
with 80% training data or 4-year of training data as a good enough model for
stock prediction, as already determined in a previous research by the author.
The comparative results indicate that neural network can predict typical stock
market prices with mean absolute percentage errors that are as low as 1.95%
over the ten prediction instances that was studied in this research.
"
1612.02985	q-fin	q-fin.RM	Risk averse fractional trading using the current drawdown	"  In this paper the fractional trading ansatz of money management is
reconsidered with special attention to chance and risk parts in the goal
function of the related optimization problem. By changing the goal function
with due regards to other risk measures like current drawdowns, the optimal
fraction solutions reflect the needs of risk averse investors better than the
original optimal f solution of Ralph Vince.
  Keywords: fractional trading, optimal f, current drawdown, terminal wealth
relative, risk aversion
"
1612.03031	q-fin	q-fin.PR q-fin.CP	"Early exercise decision in American options with dividends, stochastic
  volatility and jumps"	"  Using a fast numerical technique, we investigate a large database of investor
suboptimal non-exercise of short maturity American call options on
dividend-paying stocks listed on the Dow Jones. The correct modelling of the
discrete dividend is essential for a correct calculation of the early exercise
boundary as confirmed by theoretical insights. Pricing with stochastic
volatility and jumps instead of the Black-Scholes-Merton benchmark cuts by a
quarter the amount lost by investors through suboptimal exercise. The remaining
three quarters are largely unexplained by transaction fees and may be
interpreted as an opportunity cost for the investors to monitor optimal
exercise.
"
1612.03698	q-fin	q-fin.PM nlin.CD	Fractal Optimization of Market Neutral Portfolio	"  A fractal approach to the long-short portfolio optimization is proposed. The
algorithmic system based on the composition of market-neutral spreads into a
single entity was considered. The core of the optimization scheme is a fractal
walk model of returns, optimizing a risk aversion according to the investment
horizon. The covariance matrix of spread returns has been used for the
optimization and modified according to the Hurst stability analysis.
Out-of-sample performance data has been represented for the space of exchange
traded funds in five period time period of observation. The considered
portfolio system has turned out to be statistically more stable than a passive
investment into benchmark with higher risk adjusted cumulative return over the
observed period.
"
1612.04126	q-fin	q-fin.RM	"The hierarchical generalized linear model and the bootstrap estimator of
  the error of prediction of loss reserves in a non-life insurance company"	"  This paper presents the hierarchical generalized linear model (HGLM) for loss
reserving in a non-life insurance company. Because in this case the error of
prediction is expressed by a complex analytical formula, the error bootstrap
estimator is proposed instead. Moreover, the bootstrap procedure is used to
obtain full information about the error by applying quantiles of the absolute
prediction error. The full R code is available on the Github
https://github.com/woali/BootErrorLossReserveHGLM.
"
1612.04370	q-fin	q-fin.ST q-fin.PM	"S&P500 Forecasting and Trading using Convolution Analysis of Major Asset
  Classes"	"  By monitoring the time evolution of the most liquid Futures contracts traded
globally as acquired using the Bloomberg API from 03 January 2000 until 15
December 2014 we were able to forecast the S&P 500 index beating the Buy and
Hold trading strategy. Our approach is based on convolution computations of 42
of the most liquid Futures contracts of four basic financial asset classes,
namely, equities, bonds, commodities and foreign exchange. These key assets
were selected on the basis of the global GDP ranking across countries worldwide
according to the lists published by the International Monetary Fund (IMF,
Report for Selected Country Groups and Subjects, 2015). The main hypothesis is
that the shifts between the asset classes are smooth and are shaped by slow
dynamics as trading decisions are shaped by several constraints associated with
the portfolios allocation, as well as rules restrictions imposed by state
financial authorities. This hypothesis is grounded on recent research based on
the added value generated by diversification targets of market participants
specialized on active asset management, who try to efficiently and smoothly
navigate the market's volatility.
"
1612.04407	q-fin	q-fin.MF	Dynamic Convex Duality in Constrained Utility Maximization	"  In this paper, we study a constrained utility maximization problem following
the convex duality approach. After formulating the primal and dual problems, we
construct the necessary and sufficient conditions for both the primal and dual
problems in terms of FBSDEs plus additional conditions. Such formulation then
allows us to explicitly characterize the primal optimal control as a function
of the adjoint process coming from the dual FBSDEs in a dynamic fashion and
vice versa. Moreover, we also find that the optimal primal wealth process
coincides with the adjoint process of the dual problem and vice versa. Finally
we solve three constrained utility maximization problems, which contrasts the
simplicity of the duality approach we propose and the technical complexity of
solving the primal problems directly.
"
1612.04507	q-fin	math.ST q-fin.ST stat.TH	"Optimal Kernel Estimation of Spot Volatility of Stochastic Differential
  Equations"	"  Kernel Estimation is one of the most widely used estimation methods in
non-parametric Statistics, having a wide-range of applications, including spot
volatility estimation of stochastic processes. The selection of bandwidth and
kernel function is of great importance, especially for the finite sample
settings commonly encountered in econometric applications. In the context of
spot volatility estimation, most of the proposed selection methods are either
largely heuristic or just formally stated without any feasible implementation.
In this work, an objective method of bandwidth and kernel selection is
proposed, under some mild conditions on the volatility, which not only cover
classical Brownian motion driven dynamics but also some processes driven by
long-memory fractional Brownian motions or other Gaussian processes. We
characterize the leading order terms of the Mean Squared Error, which are also
ratified by central limit theorems for the estimation error. As a byproduct, an
approximated optimal bandwidth is then obtained in closed form. This result
allows us to develop a feasible plug-in type bandwidth selection procedure, for
which, as a sub-problem, we propose a new estimator of the volatility of
volatility. The optimal selection of kernel function is also discussed. For
Brownian Motion type volatilities, the optimal kernel function is proved to be
the exponential kernel. For fractional Brownian motion type volatilities,
numerical results to compute the optimal kernel are devised and, for the
deterministic volatility case, explicit optimal kernel functions of different
orders are derived. Simulation studies further confirm the good performance of
the proposed methods.
"
1612.04512	q-fin	cs.MA q-fin.GN	Agent-based Model for Spot and Balancing Electricity Markets	"  We present a simple, yet realistic, agent-based model of an electricity
market. The proposed model combines the spot and balancing markets with a
resolution of one minute, which enables a more accurate depiction of the
physical properties of the power grid. As a test, we compare the results
obtained from our simulation to data from Nord Pool.
"
1612.05021	q-fin	stat.AP q-fin.GN	"Dynamic Modeling of Price Responsive Demand in Real-time Electricity
  Market: Empirical Analysis"	"  In this paper, we study the price responsiveness of electricity consumption
from empirical commercial and industrial load data obtained from Texas.
Employing a dynamical system perspective, we show that price responsive demand
can be modeled as a hybrid of a Hammerstein model with delay following a price
surge, and a linear ARX model under moderate price changes. It is observed that
electricity consumption therefore has unique characteristics including (1)
qualitatively distinct response between moderate and extremely high prices; and
(2) a time delay associated with the response to high prices. It is shown that
these observed features may render traditional approaches to demand response
and retail pricing based on classical economic theories ineffective. In
particular, ultimate real-time retail pricing may be limitedly beneficial than
as considered in classical economic theories.
"
1612.05072	q-fin	q-fin.ST math.ST stat.TH	Predictability Hidden by Anomalous Observations	"  Testing procedures for predictive regressions with lagged autoregressive
variables imply a suboptimal inference in presence of small violations of ideal
assumptions. We propose a novel testing framework resistant to such violations,
which is consistent with nearly integrated regressors and applicable to
multi-predictor settings, when the data may only approximately follow a
predictive regression model. The Monte Carlo evidence demonstrates large
improvements of our approach, while the empirical analysis produces a strong
robust evidence of market return predictability hidden by anomalous
observations, both in- and out-of-sample, using predictive variables such as
the dividend yield or the volatility risk premium.
"
1612.05227	q-fin	q-fin.RM	"European banking supervision, the role of stress test. Some brief
  considerations"	"  A quick review of European financial stability institutions and the role of
stress tests in the current juridical system.
"
1612.05229	q-fin	q-fin.ST stat.AP	Stylized Facts and Simulating Long Range Financial Data	"  We propose a new method (implemented in an R-program) to simulate long-range
daily stock-price data. The program reproduces various stylized facts much
better than various parametric models from the extended GARCH-family. In
particular, the empirically observed changes in unconditional variance are
truthfully mirrored in the simulated data.
"
1612.05855	q-fin	stat.AP q-fin.TR	"Should we opt for the Black Friday discounted price or wait until the
  Boxing Day?"	"  We derive an optimal strategy for minimizing the expected loss in the
two-period economy when a pivotal decision needs to be made during the first
time period and cannot be subsequently reversed. Our interest in the problem
has been motivated by the classical shopper's dilemma during the Black Friday
promotion period, and our solution crucially relies on the pioneering work of
McDonnell and Abbott on the two-envelope paradox.
"
1612.06133	q-fin	q-fin.PM q-fin.RM	Optimal Investment under Information Driven Contagious Distress	"  We introduce a dynamic optimization framework to analyze optimal portfolio
allocations within an information driven contagious distress model. The
investor allocates his wealth across several stocks whose growth rates and
distress intensities are driven by a hidden Markov chain, and also influenced
by the distress state of the economy. We show that the optimal investment
strategies depend on the gradient of value functions, recursively linked to
each other via the distress states. We establish uniform bounds for the
solutions to a sequence of approximation problems, show their convergence to
the unique Sobolev solution of the recursive system of Hamilton-Jacobi-Bellman
partial differential equations (HJB PDEs), and prove a verification theorem. We
provide a numerical study to illustrate the sensitivity of the strategies to
contagious distress, stock volatilities and risk aversion.
"
1612.06244	q-fin	q-fin.GN cs.CR	The Blockchain: A Gentle Four Page Introduction	"  Blockchain is a distributed database that keeps a chronologically-growing
list (chain) of records (blocks) secure from tampering and revision. While
computerisation has changed the nature of a ledger from clay tables in the old
days to digital records in modern days, blockchain technology is the first true
innovation in record keeping that could potentially revolutionise the basic
principles of information keeping. In this note, we provide a brief
self-contained introduction to how the blockchain works.
"
1612.06451	q-fin	cs.NI cs.CY q-fin.EC stat.AP	"Panel dataset description for econometric analysis of the ISP-OTT
  relationship in the years 2008-2013"	"  The latest technological advancements in the telecommunications domain (e.g.,
widespread adoption of mobile devices, introduction of 5G wireless
communications, etc.) have brought new stakeholders into the spotlight. More
specifically, Over-the-Top (OTT) providers have recently appeared, offering
their services over the existing deployed telecommunication networks. The entry
of the new players has changed the dynamics in the domain, as it creates
conflicting situations with the Internet Service Providers (ISPs), who
traditionally dominate the area, motivating the necessity for novel analytical
studies for this relationship. However, despite the importance of accessing
real observational data, there is no database with the aggregate information
that can serve as a solid base for this research. To that end, this document
provides a detailed summary report for financial and statistic data for the
period 2008-2013 that can be exploited for realistic econometric models that
will provide useful insights on this topic. The document summarizes data from
various sources with regard to the ISP revenues and Capital Expenditures
(CAPEX), the OTT revenues, the Internet penetration and the Gross Domestic
Product (GDP), taking into account three big OTT providers (i.e., Facebook,
Skype, WhatsApp) and ten major ISPs that operate in seven different countries.
"
1612.06654	q-fin	q-fin.MF math.OC	The Impact of Negative Interest Rates on Optimal Capital Injections	"  In the present paper, we investigate the optimal capital injection behaviour
of an insurance company if the interest rate is allowed to become negative. The
surplus process of the considered insurance entity is assumed to follow a
Brownian motion with drift. The changes in the interest rate are described via
a Markov-switching process. It turns out that in times with a positive rate, it
is optimal to inject capital only if the company becomes insolvent. However, if
the rate is negative it might be optimal to hold a strictly positive reserve.
We establish an algorithm for finding the value function and the optimal
strategy, which is proved to be of barrier type. Using the iteration argument,
we show that the value function solves the Hamilton--Jacobi--Bellman equation,
corresponding to the problem.
"
1612.07016	q-fin	q-fin.MF	Pricing Derivatives in Hermite Markets	"  We introduce Hermite fractional financial markets, where market uncertainties
are described by multidimensional Hermite motions. Hermite markets include as
particular cases financial markets driven by multivariate fractional Brownian
motion and multivariate Rosenblatt motion. Conditions for no-arbitrage and
market completeness for Hermite markets are derived. Perpetual derivatives,
bonds forwards, and futures are priced. The corresponding partial and
partial-differential equations are derived.
"
1612.07132	q-fin	q-fin.RM math.PR	"Conditional loss probabilities for systems of economic agents sharing
  light-tailed claims with analysis of portfolio diversification benefits"	"  We analyze systems of agents sharing light-tailed risky claims issued by
different financial objects. Assuming exponentially distributed claims, we
obtain that both agents' and system's losses follow generalized exponential
mixture distributions. We show that this leads to qualitatively different
results on individual and system risks compared to heavy-tailed claims
previously studied in the literature. By deducing conditional loss
distributions we investigate the impact of stress situations on agents' and
system's losses. Moreover, we present a criterion for agents to decide whether
holding few objects or portfolio diversification minimizes their risks in
system crisis situations.
"
1612.07194	q-fin	q-fin.RM q-fin.PM	Leverage and Uncertainty	"  Risk and uncertainty will always be a matter of experience, luck, skills, and
modelling. Leverage is another concept, which is critical for the investor
decisions and results. Adaptive skills and quantitative probabilistic methods
need to be used in successful management of risk, uncertainty and leverage. The
author explores how uncertainty beyond risk determines consistent leverage in a
simple model of the world with fat tails due to significant, not fully
quantifiable and not too rare events. Among particular technical results, for
the single asset fractional Kelly criterion is derived in the presence of the
fat tails associated with subjective uncertainty. For the multi-asset
portfolio, Kelly criterion provides an insightful perspective on Risk Parity
strategies, which can be extended for the assets with fat tails.
"
1612.07543	q-fin	q-fin.EC	"Rating evaluation of sports development efficiency using statistical
  analysis: evidence from Russian football"	"  Increasing investments into various dimensions of sports draw a significant
amount of attention to the way these resources are being managed and which
organizations achieve development goals with higher efficiency. This paper
reviews the methodology of designing an efficiency rating model for assessing
sports entities, focusing on the experience of Russian football. The Russian
Regional Efficiency of Football Development model aims to evaluate the regional
federations of the Football Union of Russian via 5 dimensions. The scoring
method of the model is based on the three-sigma rule of distribution. Support
factors in the form of population density and climate were also included, since
Russian regions significantly differentiate in these aspects. The findings of
this paper showcased that not a single region was able to achieve a maximum 5-
star rating, while regions set to host the 2018 FIFA World Cup did not score
better compared to others. In conclusion the authors provide various
suggestions on further developing and implementing rating models within global
sports organizations.
"
1612.08338	q-fin	physics.soc-ph q-bio.PE q-fin.GN	"A Generalized Population Dynamics Model of a City and an Algorithm for
  Engineering Regime Shifts"	"  Measures of wealth and production have been found to scale superlinearly with
the population of a city. Therefore, it makes economic sense for humans to
congregate together in dense settlements. A recent model of population dynamics
showed that population growth can become superexponential due to the
superlinear scaling of production with population in a city. Here, we
generalize this population dynamics model and demonstrate the existence of
multiple stable equilibrium points, showing how population growth can be
stymied by a poor economic environment. This occurs when the goods and services
produced by the city become less profitable due to a lack of diversification in
the city's economy. Then, relying on critical slowing down signals related to
the stability of an equilibrium point, we present an algorithm for engineering
regime shifts such that a city at a stable equilibrium point may continue to
grow again. The generality of the model and the algorithm used here implies
that the model and algorithm need not be restricted to urban systems; they are
easily applicable to other types of systems where the assumptions used are
valid.
"
1612.08486	q-fin	q-fin.GN q-fin.TR	Understanding the Impacts of Dark Pools on Price Discovery	"  This paper investigates the impact of dark pools on price discovery (the
efficiency of prices on stock exchanges to aggregate information). Assets are
traded in either an exchange or a dark pool, with the dark pool offering better
prices but lower execution rates. Informed traders receive noisy and
heterogeneous signals about an asset's fundamental. We find that informed
traders use dark pools to mitigate their information risk and there is a
sorting effect: in equilibrium, traders with strong signals trade in exchanges,
traders with moderate signals trade in dark pools, and traders with weak
signals do not trade. As a result, dark pools have an amplification effect on
price discovery. That is, when information precision is high (information risk
is low), the majority of informed traders trade in the exchange hence adding a
dark pool enhances price discovery, whereas when information precision is low
(information risk is high), the majority of the informed traders trade in the
dark pool hence adding a dark pool impairs price discovery. The paper
reconciles the conflicting empirical evidence and produces novel empirical
predictions. The paper also provides regulatory suggestions with dark pools on
current equity markets and in emerging markets.
"
1612.08488	q-fin	q-fin.RM stat.ME	"Bayesian Semi-parametric Realized-CARE Models for Tail Risk Forecasting
  Incorporating Realized Measures"	"  A new model framework called Realized Conditional Autoregressive Expectile
(Realized-CARE) is proposed, through incorporating a measurement equation into
the conventional CARE model, in a manner analogous to the Realized-GARCH model.
Competing realized measures (e.g. Realized Variance and Realized Range) are
employed as the dependent variable in the measurement equation and to drive
expectile dynamics. The measurement equation here models the contemporaneous
dependence between the realized measure and the latent conditional expectile.
We also propose employing the quantile loss function as the target criterion,
instead of the conventional violation rate, during the expectile level grid
search. For the proposed model, the usual search procedure and asymmetric least
squares (ALS) optimization to estimate the expectile level and CARE parameters
proves challenging and often fails to convergence. We incorporate a fast random
walk Metropolis stochastic search method, combined with a more targeted grid
search procedure, to allow reasonably fast and improved accuracy in estimation
of this level and the associated model parameters. Given the convergence issue,
Bayesian adaptive Markov Chain Monte Carlo methods are proposed for estimation,
whilst their properties are assessed and compared with ALS via a simulation
study. In a real forecasting study applied to 7 market indices and 2 individual
asset returns, compared to the original CARE, the parametric GARCH and
Realized-GARCH models, one-day-ahead Value-at-Risk and Expected Shortfall
forecasting results favor the proposed Realized-CARE model, especially when
incorporating the Realized Range and the sub-sampled Realized Range as the
realized measure in the model.
"
1612.08583	q-fin	q-fin.EC	"A Proposal to Extend Expected Utility in a Quantum Probabilistic
  Framework"	"  Expected utility theory (EUT) is widely used in economic theory. However, its
subjective probability formulation, first elaborated by Savage, is linked to
Ellsberg-like paradoxes and ambiguity aversion. This has led various scholars
to work out non-Bayesian extensions of EUT which cope with its paradoxes and
incorporate attitudes toward ambiguity. A variant of the Ellsberg paradox,
recently proposed by Mark Machina and confirmed experimentally, challenges
existing non-Bayesian models of decision-making under uncertainty. Relying on a
decade of research which has successfully applied the formalism of quantum
theory to model cognitive entities and fallacies of human reasoning, we put
forward a non-Bayesian extension of EUT in which subjective probabilities are
represented by quantum probabilities, while the preference relation between
acts depends on the state of the situation that is the object of the decision.
We show that the benefits of using the quantum theoretical framework enables
the modeling of the Ellsberg and Machina paradoxes, as the representation of
ambiguity and behavioral attitudes toward it. The theoretical framework
presented here is a first step toward the development of a `state-dependent
non-Bayesian extension of EUT' and it has potential applications in economic
modeling.
"
1612.08689	q-fin	q-fin.GN	"Crisis' Heritage Management - New Business Opportunities Out of the
  Financial Collapse"	"  This paper intends to present the opportunities emerging for the national
economy, out of the financial crisis. In particular the management of those,
which arise from the commercial real estate owned property sector, defined by
the author as crisis heritage management. On one hand, as real estate property
prices are subject of wide fluctuations, the longer possession of such assets
can seriously impact the financial condition of the already shattered financial
institutions, but on the on other - with the help of professional and proactive
management, and the right kind of attitude by all the stakeholders, the
heritage left out of the financial collapse, can not only help stabilize the
system - bringing liquidity into it, but can also support its healthy corporate
governance in the long-term. The properties themselves (business buildings,
warehouses, retail-and-office spaces), being an object of optimization of
maintenance costs, re-engineering, intensive marketing, as a result of the
crisis, can serve as a solid base for number of new and profitable business and
investment opportunities, described in the article, as a proof of the healing
effect of the financial crisis and the second chance it gives.
"
1612.08705	q-fin	q-fin.ST	Speculation and Power Law	"  It is now well established empirically that financial price changes are
distributed according to a power law, with cubic exponent. This is a
fascinating regularity, as it holds for various classes of securities, on
various markets, and on various time scales. The universality of this law
suggests that there must be some basic, general and stable mechanism behind it.
The standard (neoclassical) paradigm implies no such mechanism. Agent-based
models of financial markets, on the other hand, exhibit realistic price
changes, but they involve relatively complicated, and often mathematically
intractable, mechanisms. This paper identifies a simple principle behind the
power law: the feedback intrinsic to the very idea of speculation, namely
buying when one expects a price rise (and selling when one expects a price
fall). By this feedback, price changes follow a random coefficient
autoregressive process, and therefore they have a power law by Kesten theorem.
"
1612.08767	q-fin	q-fin.MF	Pricing of Asian-type and Basket Options via Upper and Lower Bounds	"  This paper sets out to provide a general framework for the pricing of
average-type options via lower and upper bounds. This class of options includes
Asian, basket and options on the volume-weighted average price. We demonstrate
that in cases under discussion lower bounds allow for the dimensionality of the
problem to be reduced and that these methods provide reasonable approximations
to the price of the option.
  Keywords: Asian options, Basket options, Lower and Upper bounds,
Volume-weighted average prices (VWAP), Levy processes.
"
1612.09189	q-fin	q-fin.ST	Global economic dynamics of the forthcoming years. A forecast	"  The paper analyzes the current state of the world economy and offers a
short-term forecast of its development. Our analysis of log-periodic
oscillations in the DJIA dynamics suggests that in the second half of 2017 the
United States and other more developed countries could experience a new
recession, due to the third phase of the global financial crisis. The economies
of developing countries will continue their slowdown due to lower prices of raw
commodities and the increased pressure of dollar debt load. The bottom of the
slowdown in global economic growth is likely to be achieved in 2017-2018. Then
we expect the start of a new acceleration of global economic growth at the
upswing phase of the 6th Kondratieff cycle (2018-2050). A speedy and steady
withdrawal from the third phase of the global financial crisis requires
cooperative action between developed and developing countries within G20 to
stimulate global demand, world trade and a fair solution of the debt problem of
developing countries.
"
cond-mat/0004179	q-fin	cond-mat.stat-mech q-fin.ST	A Stochastic Cascade Model for FX Dynamics	"  A time series model for the FX dynamics is presented which takes into account
structural peculiarities of the market, namely its heterogeneity and an
information flow from long to short time horizons. The model emerges from an
analogy between FX dynamics and hydrodynamic turbulence. The heterogeneity of
the market is modeled in form of a multiplicative cascade of time scales
ranging from several minutes to a few months, analogous to the Kolmogorov
cascade in turbulence.
  The model reproduces well the important empirical characteristics of FX rates
for major currencies, as the heavy-tailed distribution of returns, their change
in shape with increasing time interval, and the persistence of volatility.
"
cond-mat/0005319	q-fin	cond-mat.stat-mech physics.comp-ph q-fin.PR	"Path Dependent Option Pricing: the path integral partial averaging
  method"	"  In this paper I develop a new computational method for pricing path dependent
options. Using the path integral representation of the option price, I show
that in general it is possible to perform analytically a partial averaging over
the underlying risk-neutral diffusion process. This result greatly eases the
computational burden placed on the subsequent numerical evaluation. For
short-medium term options it leads to a general approximation formula that only
requires the evaluation of a one dimensional integral. I illustrate the
application of the method to Asian options and occupation time derivatives.
"
cond-mat/0104260	q-fin	cond-mat.stat-mech q-fin.ST	"Correlations Between Reconstructed EUR Exchange Rates vs. CHF, DKK, GBP,
  JPY and USD"	"  On Jan. 1, 1999 the European Union introduced a common currency Euro ($EUR$),
to become the legal currency in all eleven countries which form the $EUR$. In
order to test the $EUR$ behavior and understand various features, the $EUR$
exchange rate is artificially extrapolated back to 1993 by a linear
superposition of the exchange rates of the 11 currencies composing $EUR$ with
respect to several currencies not belonging to the $EUR$, i.e. Swiss Franc
($CHF$), Danish Kroner ($DKK$), British Pound ($GBP$), Japanese Yen ($JPY$) and
U.S. Dollar ($USD$) of interest for reasons given in the text. The distribution
of fluctuations of the exchange rates is shown to be Gaussian for the central
part of the distribution, and having fat tails for the large size fluctuations.
Within the {\it Detrended Fluctuation Analysis} ($DFA$) statistical method we
have obtained the power law behavior describing the root-mean-square deviation
of the exchange rate fluctuations as a function of time. For the period between
Jan. 1995 and Jan. 1999 we have compared the time-dependent exponent of these
exchange rate fluctuations for $EUR$ and that of the 11 currencies which form
the $EUR$. The German Mark ($DEM$) and the French Franc ($FRF$) have been the
currencies primarily leading the fluctuations of the exchange rates, while
Italian Lira ($ITL$) and ($PTE$) Portuguese Escudo are the less relevant
currencies from this point of view. Technical considerations for the $EUR$
implementation are given as conclusions. The cases of exchange rates with $DKK$
appear quite different from the other four major currencies.
"
cond-mat/0110354	q-fin	cond-mat.stat-mech q-fin.TR	Microscopic Models of Financial Markets	"  Submitted to F. Schweitzer (ed.), Microscopic Models for Economic Dynamics,
  Lecture notes in physics, Springer, Berlin-Heidelberg 2002.kiel.tex
"
cond-mat/0206446	q-fin	cond-mat.stat-mech q-fin.TR	"Exact Hurst exponent and crossover behavior in a limit order market
  model"	"  An exclusion particle model is considered as a highly simplified model of a
limit order market. Its price behavior reproduces the well known crossover from
over-diffusion (Hurst exponent H>1/2) to diffusion (H=1/2) when the time
horizon is increased, provided that orders are allowed to be canceled. For
early times a mapping to the totally asymmetric exclusion process yields the
exact result H=2/3 which is in good agreement with empirical data. The
underlying universality class of the exclusion process suggests some robustness
of the exponent with respect to changes in the trading rules. In the crossover
regime the Hurst plot has a scaling property where the bulk
deposition/cancellation rate is the critical parameter. Analytical results are
fully supported by numerical simulations.
"
cond-mat/0211108	q-fin	cond-mat.stat-mech q-fin.ST	Reconstructing an economic space from a market metric	"  Using a metric related to the returns correlation, a method is proposed to
reconstruct an economic space from the market data. A reduced subspace,
associated to the systematic structure of the market, is identified and its
dimension related to the number of terms in factor models. Example were worked
out involving sets of companies from the DJIA and S&P500 indexes. Having a
metric defined in the space of companies, network topology coefficients may be
used to extract further information from the data. A notion of ""continuous
clustering"" is defined and empirically related to the occurrence of market
shocks.
"
cond-mat/0211162	q-fin	cond-mat.stat-mech q-fin.ST	"Analysis of high-resolution foreign exchange data of USD-JPY for 13
  years"	"  We analyze high-resolution foreign exchange data consisting of 20 million
data points of USD-JPY for 13 years to report firm statistical laws in
distributions and correlations of exchange rate fluctuations. A conditional
probability density analysis clearly shows the existence of trend-following
movements at time scale of 8-ticks, about 1 minute.
"
cond-mat/0302342	q-fin	cond-mat.stat-mech q-fin.ST	"Long-range correlations and nonstationarity in the Brazilian stock
  market"	"  We report an empirical study of the Ibovespa index of the Sao Paulo Stock
Exchange in which we detect the existence of long-range correlations. To
analyze our data we introduce a rescaled variant of the usual Detrended
Fluctuation Analysis that allows us to obtain the Hurst exponent through a
one-parameter fitting. We also compute a time-dependent Hurst exponent H(t)
using three-year moving time windows. In particular, we find that before the
launch of the Collor Plan in 1990 the curve H(t) remains, in general, well
above 1/2, while afterwards it stays close to 1/2. We thus argue that the
structural reforms set off by the Collor Plan has lead to a more efficient
stock market in Brazil. We also suggest that the time dependence of the
Ibovespa Hurst exponent could be described in terms of a multifractional
Brownian motion.
"
cond-mat/0304469	q-fin	cond-mat.dis-nn q-fin.ST	Using Recurrent Neural Networks To Forecasting of Forex	"  This paper reports empirical evidence that a neural networks model is
applicable to the statistically reliable prediction of foreign exchange rates.
Time series data and technical indicators such as moving average, are fed to
neural nets to capture the underlying ""rules"" of the movement in currency
exchange rates. The trained recurrent neural networks forecast the exchange
rates between American Dollar and four other major currencies, Japanese Yen,
Swiss Frank, British Pound and EURO. Various statistical estimates of forecast
quality have been carried out. Obtained results show, that neural networks are
able to give forecast with coefficient of multiple determination not worse then
0.65. Linear and nonlinear statistical data preprocessing, such as
Kolmogorov-Smirnov test and Hurst exponents for each currency were calculated
and analyzed.
"
cond-mat/0304685	q-fin	cond-mat.stat-mech q-fin.TR	Analytic treatment of a trading market model	"  We mathematically analyze a simple market model where trading at each point
in time involves only two agents with the sum of their money being conserved
and with neither parties resulting with negative money after the interaction
process. The exchange involves random re-distribution among the two players of
a fixed fraction of their total money. We obtain a simple integral nonlinear
equation for the money distribution. We find that the zero savings and finite
savings cases belong to different universality classes. While the zero savings
case can be solved analytically, the finite savings solution is obtained by
numerically solving the integral equation. We find remarkable agreement with
results obtained by other researchers using sophisticated numerical techniques.
"
cond-mat/0401378	q-fin	cond-mat.other cond-mat.stat-mech q-fin.RM	"Long range Ising model for credit risk modeling in homogeneous
  portfolios"	"  Within the framework of maximum entropy principle we show that the
finite-size long-range Ising model is the adequate model for the description of
homogeneous credit portfolios and the computation of credit risk when default
correlations between the borrowers are included. The exact analysis of the
model suggest that when the correlation increases a first-order-like transition
may occur inducing a sudden risk increase. Such a feature is not reproduced by
the standard models used in credit risk modeling.
"
cond-mat/0401422	q-fin	cond-mat.other q-fin.TR	"The Opinion Game: Stock price evolution from microscopic market
  modelling"	"  We propose a class of Markovian agent based models for the time evolution of
a share price in an interactive market. The models rely on a microscopic
description of a market of buyers and sellers who change their opinion about
the stock value in a stochastic way. The actual price is determined in
realistic way by matching (clearing) offers until no further transactions can
be performed. Some analytic results for a non-interacting model are presented.
We also propose basic interaction mechanisms and show in simulations that these
already reproduce certain particular features of prices in real stock markets.
"
cond-mat/0403333	q-fin	cond-mat.stat-mech q-fin.ST	"Complex Behavior of Stock Markets: Processes of Synchronization and
  Desynchronization during Crises"	"  This paper investigates the dynamics of in the S&P500 index from daily
returns for the last 30 years. Using a stochastic geometry technique, each
S&P500 yearly batch of data is embedded in a subspace that can be accurately
described by a reduced number of dimensions. Such feature is understood as
empirical evidence for the presence of a certain amount of structure in the
market. As part of the inquiry into the structure of the market we investigate
changes in its volume and shape, and we define new measures for that purpose.
Having these measures defined in the space of stocks we analyze the effects of
some extreme phenomena on the geometry of the market. We discuss the hypothesis
that collective behavior in period of crises reinforces the structure of
correlations between stocks, but that it also may have an opposite effect on
clustering by similar economic sectors. Comparing the crises of 1987 and 2001,
we discuss why the expansion of the ellipsoid describing the geometry of the
distances in the market, which occurs in the latter period, is not homogeneous
through sectors. The conclusions from this research identify some of the
changes in the structure of the market over the last 30 years.
"
cond-mat/0404416	q-fin	cond-mat.stat-mech physics.soc-ph q-fin.ST	"Serial Correlation, Periodicity and Scaling of Eigenmodes in an Emerging
  Market"	"  We investigate serial correlation, periodic, aperiodic and scaling behaviour
of eigenmodes, i.e. daily price fluctuation time-series derived from
eigenvectors, of correlation matrices of shares listed on the Johannesburg
Stock Exchange (JSE) from January 1993 to December 2002. Periodic, or calendar,
components are detected by spectral analysis. We find that calendar effects are
limited to eigenmodes which correspond to eigenvalues outside the Wishart
range. Using a variance ratio test, we uncover serial correlation in the first
eigenmodes and find slight negative serial correlation for eigenmodes within
the Wishart range. Our spectral analysis and variance ratio investigations
suggest that interpolating missing data or illiquid trading days with
zero-order hold introduces high frequency noise and spurious serial
correlation.
  Aperiodic and scaling behaviour of the eigenmodes are investigated by using
rescaled-range (R/S) methods and detrended fluctuation analysis (DFA). We find
that DFA and classic and modified R/S exponents suggest the presence of
long-term memory effects in the first five eigenmodes.
"
cond-mat/0405257	q-fin	cond-mat.other q-fin.ST	Self-Organized Criticality and Stock Market Dynamics: an Empirical Study	"  The Stock Market is a complex self-interacting system, characterized by an
intermittent behaviour. Periods of high activity alternate with periods of
relative calm. In the present work we investigate empirically about the
possibility that the market is in a self-organized critical state (SOC). A
wavelet transform method is used in order to separate high activity periods,
related to the avalanches of sandpile models, from quiescent.
  A statistical analysis of the filtered data show a power law behaviour in the
avalanche size, duration and laminar times. The memory process, implied by the
power law distribution, of the laminar times is not consistent with classical
conservative models for self-organized criticality. We argue that a
``near-SOC'' state or a time dependence in the driver, which may be chaotic,
can explain this behaviour.
"
cond-mat/0406365	q-fin	cond-mat.stat-mech cond-mat.other q-fin.TR	Mathew Effect in Artificial Stock Market	"  In this article, we established a stock market model based on agents'
investing mentality. The agents decide whether to purchase the shares at the
probability, according to their anticipation of the market's behaviors. The
expectation of the amount of shares they want to buy is directly proportional
to the value of asset they hold. The agents sell their shares because of the
gaining-profit psychology, stopping-loss psychology, or dissatisfaction with
the long-time congealing of the assets. We studied how the distribution of
agent's assets varies along with systemic evolution. The experiments show us
obvious Mathew effect on asset distribution in the artificial stock market, and
we have found that the Mathew effect on asset distribution was more and more
salient along with the increasing of system running time, stock market size and
agents' activity extent.
"
cond-mat/0409329	q-fin	cond-mat.stat-mech cond-mat.other q-fin.GN	"An analytic treatment of the Gibbs-Pareto behavior in wealth
  distribution"	"  We develop a general framework, based on Boltzmann transport theory, to
analyze the distribution of wealth in societies. Within this framework we
derive the distribution function of wealth by using a two-party trading model
for the poor people while for the rich people a new model is proposed where
interaction with wealthy entities (huge reservoir) is relevant. At equilibrium,
the interaction with wealthy entities gives a power-law (Pareto-like) behavior
in the wealth distribution while the two-party interaction gives a
Boltzmann-Gibbs distribution.
"
cond-mat/0702607	q-fin	cond-mat.stat-mech q-fin.ST	Geometrical Brownian Motion Driven by Color Noise	"  The evolution of prices on ideal market is given by geometrical Brownian
motion, where Gaussian white noise describes fluctuations. We study the effect
of correlations introduced by a color noise.
"
cond-mat/9702082	q-fin	cond-mat.stat-mech q-fin.GN	Scaling behavior in economics: I. Empirical results for company growth	"  We address the question of the growth of firm size. To this end, we analyze
the Compustat data base comprising all publicly-traded United States
manufacturing firms within the years 1974-1993. We find that the distribution
of firm sizes remains stable for the 20 years we study, i.e., the mean value
and standard deviation remain approximately constant. We study the distribution
of sizes of the ``new'' companies in each year and find it to be well
approximated by a log-normal. We find (i) the distribution of the logarithm of
the growth rates, for a fixed growth period of one year, and for companies with
approximately the same size $S$ displays an exponential form, and (ii) the
fluctuations in the growth rates -- measured by the width of this distribution
$\sigma_1$ -- scale as a power law with $S$, $\sigma_1\sim S^{-\beta}$. We find
that the exponent $\beta$ takes the same value, within the error bars, for
several measures of the size of a company. In particular, we obtain:
$\beta=0.20\pm0.03$ for sales, $\beta=0.18\pm0.03$ for number of employees,
$\beta=0.18\pm0.03$ for assets, $\beta=0.18\pm0.03$ for cost of goods sold, and
$\beta=0.20\pm0.03$ for property, plant, & equipment.
"
cond-mat/9710336	q-fin	cond-mat.stat-mech q-fin.ST	Renormalization Group Analysis of October Market Crashes	"  The self-similar analysis of time series, suggested earlier by the authors,
is applied to the description of market crises. The main attention is payed to
the October 1929, 1987 and 1997 stock market crises, which can be successfully
treated by the suggested approach. The analogy between market crashes and
critical phenomena is emphasized.
"
cond-mat/9712164	q-fin	cond-mat.stat-mech q-fin.ST	Phenomenology of the Interest Rate Curve	"  This paper contains a phenomenological description of the whole U.S. forward
rate curve (FRC), based on an data in the period 1990-1996. We find that the
average FRC (measured from the spot rate) grows as the square-root of the
maturity, with a prefactor which is comparable to the spot rate volatility.
This suggests that forward rate market prices include a risk premium,
comparable to the probable changes of the spot rate between now and maturity,
which can be understood as a `Value-at-Risk' type of pricing. The instantaneous
FRC however departs form a simple square-root law. The distortion is maximum
around one year, and reflects the market anticipation of a local trend on the
spot rate. This anticipated trend is shown to be calibrated on the past
behaviour of the spot itself. We show that this is consistent with the
volatility `hump' around one year found by several authors (and which we
confirm). Finally, the number of independent components needed to interpret
most of the FRC fluctuations is found to be small. We rationalize this by
showing that the dynamical evolution of the FRC contains a stabilizing second
derivative (line tension) term, which tends to suppress short scale distortions
of the FRC. This shape dependent term could lead, in principle, to arbitrage.
However, this arbitrage cannot be implemented in practice because of
transaction costs. We suggest that the presence of transaction costs (or other
market `imperfections') is crucial for model building, for a much wider class
of models becomes eligible to represent reality.
"
cond-mat/9802136	q-fin	cond-mat.stat-mech q-fin.CP	"``String'' formulation of the Dynamics of the Forward Interest Rate
  Curve"	"  We propose a formulation of the term structure of interest rates in which the
forward curve is seen as the deformation of a string. We derive the general
condition that the partial differential equations governing the motion of such
string must obey in order to account for the condition of absence of arbitrage
opportunities. This condition takes a form similar to a fluctuation-dissipation
theorem, albeit on the same quantity (the forward rate), linking the bias to
the covariance of variation fluctuations. We provide the general structure of
the models that obey this constraint in the framework of stochastic partial
(possibly non-linear) differential equations. We derive the general solution
for the pricing and hedging of interest rate derivatives within this framework,
albeit for the linear case (we also provide in the appendix a simple and
intuitive derivation of the standard European option problem). We also show how
the ``string'' formulation simplifies into a standard N-factor model under a
Galerkin approximation.
"
cond-mat/9806138	q-fin	cond-mat.stat-mech adap-org hep-lat hep-th nlin.AO physics.soc-ph q-fin.TR quant-ph	Electrodynamical model of quasi-efficient financial market	"  The modelling of financial markets presents a problem which is both
theoretically challenging and practically important. The theoretical aspects
concern the issue of market efficiency which may even have political
implications \cite{Cuthbertson}, whilst the practical side of the problem has
clear relevance to portfolio management \cite{Elton} and derivative pricing
\cite{Hull}. Up till now all market models contain ""smart money"" traders and
""noise"" traders whose joint activity constitutes the market \cite{DeLong,Bak}.
On a short time scale this traditional separation does not seem to be
realistic, and is hardly acceptable since all high-frequency market
participants are professional traders and cannot be separated into ""smart"" and
""noisy"". In this paper we present a ""microscopic"" model with homogenuous
quasi-rational behaviour of traders, aiming to describe short time market
behaviour. To construct the model we use an analogy between ""screening"" in
quantum electrodynamics and an equilibration process in a market with temporal
mispricing \cite{Ilinski,Dunbar}. As a result, we obtain the time-dependent
distribution function of the returns which is in quantitative agreement with
real market data and obeys the anomalous scaling relations recently reported
for both high-frequency exchange rates \cite{Breymann}, S&P500 \cite{Stanley}
and other stock market indices \cite{Bouchaud,Australia}.
"
cond-mat/9807397	q-fin	cond-mat.stat-mech q-fin.PR	Option Pricing Model for Incomplete Market	"  The problem of determining the European-style option price in the incomplete
market has been examined within the framework of stochastic optimization. An
analytic method based on the discrete dynamic programming equation (Bellman
equation) has been developed that gives the general formalism for determining
the option price and the optimal trading strategy (optimal control policy) that
reduces total risk inherent in writing the option.
  The basic purpose of paper is to present an effective algorithm that can be
used in practice.
  Keywords: option pricing, incomplete market, transaction costs, stochastic
optimization, Bellman equation.
"
math/0004016	q-fin	math.CA math.PR q-fin.CP	On the valuation of Paris options: foundational results	"  This paper adresses the valuation of the Paris barrier options proposed by
Yor, Jeanblanc-Picque, and Chesnay (Advances in Applied Probability, 29(1997),
165-184) using the Laplace transform approach. Based on suggestions by Pliska
the notion of Paris options is extended such that their valuation is possible
at any point during their lifespan. The Laplace transforms derived by Yor et
al. are modified when necessary, and their basic analytic properties are
discussed.
"
math/0012072	q-fin	math.CA math.PR q-fin.PR	"On the valuation of arithmetic-average Asian options: Laguerre series
  and Theta integrals"	"  In a recent significant advance, using Laguerre series, the valuation of
Asian options has been reduced by Dufresne to computing the negative moments of
Yor's accumulation processes. For these he has given functional recursion rules
whose probabilistic structure has been the object of intensive recent studies
of Yor and co-workers. Stressing the role of Theta functions, this paper now
solves these recursion rules and expresses these negative moments as linear
combinations of certain Theta integrals. Using the Jacobi transformation
formula, very rapidly and very stably convergent series for them are derived.
In this way computable series for Black--Scholes price of the Asian option
result which are numerically illustrated. Moreover, the Laguerre series
approach of Dufresne is made rigorous, and extensions and modifications are
discussed. The key for this is the analysis of the integrability and growth
properties of Yor's 1992 Asia density, basic problems which seem to be
addressed here for the first time.
"
math/0102080	q-fin	math.CA math.PR q-fin.PR	"On the valuation of arithmetic-average Asian options: the Geman-Yor
  Laplace transform revisited"	"  The 1993 Laplace transform approach of Geman and Yor is a celebrated advance
in valuing Asian options. Its insights are fundamental from both a mathematical
and a financial perspective. In this paper, we discuss two observations
regarding the financial relevance of its results. First, we show that the Geman
and Yor Laplace transform is not that of an Asian option price, as reported in
Geman and Yor and other papers. We nonetheless show how the Geman and Yor
Laplace transform can be used to obtain the price of an Asian option. Second,
we find that following Geman and Yor these Laplace transfoms are available only
if the risk-neutral drift is not less than half the squared volatility. Using
complex analytic techniques, we lift this restriction, thus extending the
financial applicability of the Laplace transform approach.
"
math/0202298	q-fin	math.CA math.PR q-fin.PR	"Analytical ramifications of derivatives valuation: Asian options and
  special functions"	"  Averaging problems are ubiquitous in Finance with the valuation of the
so-called Asian options on arithmetic averages as their most conspicuous form.
There is an abundance of numerical work on them, and their stochastic structure
has been extensively studied by Yor and his school. However, the analytical
structure of these problems is largely unstudied. Our philosophy now is that
such valuation problems should be considered as an extension of the theory of
special functions: they lead to new problems about new classes of special
functions which should be studied in terms of and using of the methods of
special functions and their theory. This is exemplified by deriving integral
representations for the Black-Scholes prices based on Yor's Laplace transform
ansatz to their valuation. They are obtained by analytic Laplace inversion
using complex analytic methods. The analysis ultimately rests on the gamma
function which in this sense is found to be at the base of Asian options. The
results improve on those of Yor and have served us a as starting point for
deriving first time benchmark prices for these options.
"
math/0202299	q-fin	math.PR math.CA q-fin.PR	Brownian excursions an Parisian barrier options: a note	"  This note re-addresses the Paris barrier options proposed by Yor and
collaborators and their valuation using the Laplace transform approach. The
notion of Paris barrier options, based on excursion theory and using the
Brownian meander, is extended such that their valuation is now possible at any
point during their lifespan. The pertinent Laplace transforms are modified when
necessary.
"
math/0609212	q-fin	math.PR math.AP q-fin.PR	"The Exact Value for European Options on a Stock Paying a Discrete
  Dividend"	"  In the context of a Black-Scholes economy and with a no-arbitrage argument,
we derive arbitrarily accurate lower and upper bounds for the value of European
options on a stock paying a discrete dividend. Setting the option price error
below the smallest monetary unity, both bounds coincide, and we obtain the
exact value of the option.
"
math/0610219	q-fin	math.PR q-fin.ST	"The minimal entropy martingale measure for general
  Barndorff-Nielsen/Shephard models"	"  We determine the minimal entropy martingale measure for a general class of
stochastic volatility models where both price process and volatility process
contain jump terms which are correlated. This generalizes previous studies
which have treated either the geometric L\'{e}vy case or continuous price
processes with an orthogonal volatility process. We proceed by linking the
entropy measure to a certain semi-linear integro-PDE for which we prove the
existence of a classical solution.
"
math/0610324	q-fin	math.PR q-fin.CP	On the value of optimal stopping games	"  We show, under weaker assumptions than in the previous literature, that a
perpetual optimal stopping game always has a value. We also show that there
exists an optimal stopping time for the seller, but not necessarily for the
buyer. Moreover, conditions are provided under which the existence of an
optimal stopping time for the buyer is guaranteed. The results are illustrated
explicitly in two examples.
"
math/0612212	q-fin	math.PR q-fin.ST	"A filtering approach to tracking volatility from prices observed at
  random times"	"  This paper is concerned with nonlinear filtering of the coefficients in asset
price models with stochastic volatility. More specifically, we assume that the
asset price process $S=(S_{t})_{t\geq0}$ is given by \[
dS_{t}=m(\theta_{t})S_{t} dt+v(\theta_{t})S_{t} dB_{t}, \] where
$B=(B_{t})_{t\geq0}$ is a Brownian motion, $v$ is a positive function and
$\theta=(\theta_{t})_{t\geq0}$ is a c\'{a}dl\'{a}g strong Markov process. The
random process $\theta$ is unobservable. We assume also that the asset price
$S_{t}$ is observed only at random times $0<\tau_{1}<\tau_{2}<....$ This is an
appropriate assumption when modeling high frequency financial data (e.g.,
tick-by-tick stock prices).
  In the above setting the problem of estimation of $\theta$ can be approached
as a special nonlinear filtering problem with measurements generated by a
multivariate point process $(\tau_{k},\log S_{\tau_{k}})$. While quite natural,
this problem does not fit into the ``standard'' diffusion or simple point
process filtering frameworks and requires more technical tools. We derive a
closed form optimal recursive Bayesian filter for $\theta_{t}$, based on the
observations of $(\tau_{k},\log S_{\tau_{k}})_{k\geq1}$. It turns out that the
filter is given by a recursive system that involves only deterministic
Kolmogorov-type equations, which should make the numerical implementation
relatively easy.
"
math/0612648	q-fin	math.PR q-fin.PR	A Call-Put Duality for Perpetual American Options	"  It is well known that in models with time-homogeneous local volatility
functions and constant interest and dividend rates, the European Put prices are
transformed into European Call prices by the simultaneous exchanges of the
interest and dividend rates and of the strike and spot price of the underlying.
This paper investigates such a Call Put duality for perpetual American options.
It turns out that the perpetual American Put price is equal to the perpetual
American Call price in a model where, in addition to the previous exchanges
between the spot price and the strike and between the interest and dividend
rates, the local volatility function is modified. We prove that equality of the
dual volatility functions only holds in the standard Black-Scholes model with
constant volatility. Thanks to these duality results, we design a theoretical
calibration procedure of the local volatility function from the perpetual Call
and Put prices for a fixed spot price $x_0$. The knowledge of the Put (resp.
Call) prices for all strikes enables to recover the local volatility function
on the interval $(0,x_0)$ (resp. $(x_0,+\infty)$).
"
math/0612649	q-fin	math.PR q-fin.PR	General Duality for Perpetual American Options	"  In this paper, we investigate the generalization of the Call-Put duality
equality obtained in [1] for perpetual American options when the Call-Put
payoff $(y-x)^+$ is replaced by $\phi(x,y)$. It turns out that the duality
still holds under monotonicity and concavity assumptions on $\phi$. The
specific analytical form of the Call-Put payoff only makes calculations easier
but is not crucial unlike in the derivation of the Call-Put duality equality
for European options. Last, we give some examples for which the optimal
strategy is known explicitly.
"
math/9801057	q-fin	math.NA q-fin.CP	"Valuation of path-dependent American options using a Monte Carlo
  approach"	"  It is shown how to obtain accurate values for American options using Monte
Carlo simulation. The main feature of the novel algorithm consists of tracking
the boundary between exercise and hold regions via optimization of a certain
payoff function. We compare estimates from simulation for some types of claims
with results from binomial tree calculations and find very good agreement. The
novel method allows to calculate so far untractable path-dependent option
values.
"
physics/0506137	q-fin	physics.soc-ph q-fin.ST	"The Geometry of Crashes - A Measure of the Dynamics of Stock Market
  Crises"	"  This paper investigates the dynamics of stocks in the S&P500 index for the
last 30 years. Using a stochastic geometry technique, we investigate the
evolution of the market space and define a new measure for that purpose, which
is a robust index of the dynamics of the market structure and provides
information on the intensity and the sectoral impact of the crises. With this
measure, we analyze the effects of some extreme phenomena on the geometry of
the market. Nine crashes between 1987 and 2001 are compared by looking at the
way they modify the shape of the manifold that describes the S&P500 market
space. These crises are identified as (a) structural, (b) general and (c)
local.
"
physics/0509240	q-fin	physics.soc-ph physics.comp-ph q-fin.GN	Condensation in an Economic Model with Brand Competition	"  We present a linear agent based model on brand competition. Each agent
belongs to one of the two brands and interacts with its nearest neighbors. In
the process the agent can decide to change to the other brand if the move is
beneficial. The numerical simulations show that the systems always condenses
into a state when all agents belong to a single brand. We study the
condensation times for different parameters of the model and the influence of
different mechanisms to avoid condensation, like anti monopoly rules and brand
fidelity.
"
physics/0509250	q-fin	physics.soc-ph q-fin.ST	"An econophysics approach to analyse uncertainty in financial markets: an
  application to the Portuguese stock market"	"  In recent years there has been a closer interrelationship between several
scientific areas trying to obtain a more realistic and rich explanation of the
natural and social phenomena. Among these it should be emphasized the
increasing interrelationship between physics and financial theory. In this
field the analysis of uncertainty, which is crucial in financial analysis, can
be made using measures of physics statistics and information theory, namely the
Shannon entropy. One advantage of this approach is that the entropy is a more
general measure than the variance, since it accounts for higher order moments
of a probability distribution function. An empirical application was made using
data collected from the Portuguese Stock Market.
"
physics/0510047	q-fin	physics.data-an physics.soc-ph q-fin.ST	"Time series of stock price and of two fractal overlap: Anticipating
  market crashes?"	"  We find prominent similarities in the features of the time series for the
overlap of two Cantor sets when one set moves with uniform relative velocity
over the other and time series of stock prices. An anticipation method for some
of the crashes have been proposed here, based on these observations.
"
physics/0601205	q-fin	physics.data-an q-fin.ST	Level Crossing Analysis of the Stock Markets	"  We investigate the average frequency of positive slope $\nu_{\alpha}^{+}$,
crossing for the returns of market prices.
  The method is based on stochastic processes which no scaling feature is
explicitly required. Using this method we define new quantity to quantify stage
of development and activity of stocks exchange. We compare the Tehran and
western stock markets and show that some stocks such as Tehran (TEPIX) and New
Zealand (NZX) stocks exchange are emerge, and also TEPIX is a non-active market
and financially motivated to absorb capital.
"
physics/0607240	q-fin	physics.data-an physics.soc-ph q-fin.PR	Non-Parametric Extraction of Implied Asset Price Distributions	"  Extracting the risk neutral density (RND) function from option prices is well
defined in principle, but is very sensitive to errors in practice. For risk
management, knowledge of the entire RND provides more information for
Value-at-Risk (VaR) calculations than implied volatility alone [1]. Typically,
RNDs are deduced from option prices by making a distributional assumption, or
relying on implied volatility [2]. We present a fully non-parametric method for
extracting RNDs from observed option prices. The aim is to obtain a continuous,
smooth, monotonic, and convex pricing function that is twice differentiable.
Thus, irregularities such as negative probabilities that afflict many existing
RND estimation techniques are reduced. Our method employs neural networks to
obtain a smoothed pricing function, and a central finite difference
approximation to the second derivative to extract the required gradients.
  This novel technique was successfully applied to a large set of FTSE 100
daily European exercise (ESX) put options data and as an Ansatz to the
corresponding set of American exercise (SEI) put options. The results of paired
t-tests showed significant differences between RNDs extracted from ESX and SEI
option data, reflecting the distorting impact of early exercise possibility for
the latter. In particular, the results for skewness and kurtosis suggested
different shapes for the RNDs implied by the two types of put options. However,
both ESX and SEI data gave an unbiased estimate of the realised FTSE 100
closing prices on the options' expiration date. We confirmed that estimates of
volatility from the RNDs of both types of option were biased estimates of the
realised volatility at expiration, but less so than the LIFFE tabulated
at-the-money implied volatility.
"
physics/0609088	q-fin	physics.soc-ph q-fin.ST	The Why of the Applicability of Statistical Physics to Economics	"  We analyze the relationships between game theory and quantum mechanics and
the extensions to statistical physics and information theory. We use certain
quantization relationships to assign quantum states to the strategies of a
player. These quantum states are contained in a density operator which
describes the new quantum system. The system is also described through an
entropy over its states, its evolution equation which is the quantum replicator
dynamics and a criterion of equilibrium based on the Collective Welfare
Principle. We show how the density operator and entropy are the bonds between
game theories, quantum information theory and statistical physics. We propose
the results of the study of these relationships like a reason of the
applicability of physics in economics and the born of econophysics.
"
physics/0609245	q-fin	physics.soc-ph q-fin.GN	Quantum Econophysics	"  The relationships between game theory and quantum mechanics let us propose
certain quantization relationships through which we could describe and
understand not only quantum but also classical, evolutionary and the biological
systems that were described before through the replicator dynamics. Quantum
mechanics could be used to explain more correctly biological and economical
processes and even it could encloses theories like games and evolutionary
dynamics. This could make quantum mechanics a more general theory that we had
thought. Although both systems analyzed are described through two apparently
different theories (quantum mechanics and game theory) it is shown that both
systems are analogous and thus exactly equivalents. So, we can take some
concepts and definitions from quantum mechanics and physics for the best
understanding of the behavior of economics and biology. Also, we could maybe
understand nature like a game in where its players compete for a common welfare
and the equilibrium of the system that they are members.
"
